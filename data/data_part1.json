[
    {
        "key": "HTTPCLIENT-1177",
        "summary": "HttpClient treats URI fragments in redirect URIs incosistently",
        "description": "HttpClient treats URI fragments in redirect URIs incosistently. It strips fragments from relative URIs but leaves absolute ones unchanges.  ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-271",
        "summary": "PostMethod#setParameter",
        "description": "[HttpClient2.0-rc1]\n\n-------- code fragment 1 -------------------------\nPostMethod method = new PostMethod(uriString);\nmethod.addParameter(\"tel\", \"1111-1111\");\nmethod.addParameter(\"tel\", \"2222-2222\");\nmethod.setParameter(\"tel\", \"3333-3333\");\n\n(post data sent)\ntel=1111-1111&tel=2222-2222&tel=3333-3333\n\n(post data i hope)\ntel=3333-3333\n-------------------------------------------------\n\n---------------- code fragment 2 -----------------\nPostMethod method = new PostMethod(uriString);\nmethod.addParameter(\"tel\", \"1111-1111\");\nmethod.addParameter(\"tel\", \"2222-2222\");\nmethod.addParameter(\"tel\", \"3333-3333\");\n\n(post data sent)\ntel=1111-1111&tel=2222-2222&tel=3333-3333\n--------------------------------------------------\n\nwhat difference between code 1 and code2 ?\n\nsorry for my poor english.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-511",
        "summary": "Preemptive Authorization parameter initialization incorrect, causes preemptive auth not to work",
        "description": "Preemptive authorization is defeated by an incorrect initialization. Patch \nfollows:\n--- DefaultHttpParamsFactory.java       2005-10-10 19:09:10.000000000 -0700\n+++ DefaultHttpParamsFactory.java.fixed 2005-10-17 17:00:10.259174920 -0700\n@@ -118,9 +118,9 @@\n         if (preemptiveDefault != null) {\n             preemptiveDefault = preemptiveDefault.trim().toLowerCase();\n             if (preemptiveDefault.equals(\"true\")) {\n-                params.setParameter\n(HttpClientParams.PREEMPTIVE_AUTHENTICATION, \"on\");\n+                params.setParameter\n(HttpClientParams.PREEMPTIVE_AUTHENTICATION, Boolean.TRUE);\n             } else if (preemptiveDefault.equals(\"false\")) {\n-                params.setParameter\n(HttpClientParams.PREEMPTIVE_AUTHENTICATION, \"off\");\n+                params.setParameter\n(HttpClientParams.PREEMPTIVE_AUTHENTICATION, Boolean.FALSE);\n             }\n         }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-312",
        "summary": "Update license terms",
        "description": "Copyright 1999-2003 The Apache Software Foundation.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-668",
        "summary": "make sure no static loggers are used",
        "description": "Review all loggers used in the component, make sure they are stored in non-static attributes only.\nhttp://wiki.apache.org/jakarta-commons/Logging/StaticLog\n",
        "label": "NUG",
        "classified": "TASK",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-404",
        "summary": "SO_TIMEOUT parameter on the method level has no effect",
        "description": "This bug has been reported on the HttpClient user list by Ilya Kharmatsky <ilyak\n-at- mainsoft.com>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1072",
        "summary": "Inline nested jars in OSGi bundles",
        "description": "Eclipse doesn't support bundles with nested jars (https://bugs.eclipse.org/bugs/show_bug.cgi?id=111238). The workaround is to inline the contents of the nested jars. This is a simple fix that shouldn't impact non-Eclipse users:\n\npom.xml\n===================================================================\n- <Embed-Dependency>*;scope=compile|runtime;inline=false</Embed-Dependency>\n+ <Embed-Dependency>*;scope=compile|runtime;inline=true</Embed-Dependency>\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-62",
        "summary": "Developer documentation",
        "description": "Provide more example code in CVS and give a clear link on the website.  A\nwalkthrough of the API.  Documenntation suitable for new users.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-126",
        "summary": "Default charset",
        "description": "As defined in RFC2616 the default character set is ISO-8859-1 an not US-ASCII \nas defined in HttpMethodBase. See \"3.7.1 Canonicalization and Text Defaults\" at\nRFC 2616",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-742",
        "summary": "common interface for HttpRoute and RouteTracker",
        "description": "Classes HttpRoute and RouteTracker have many identical getters. There should be a common interface, for example RouteInfo, to define these getters and a toRoute() method that returns an unmodifiable representation. Some portions of the API may then accept the interface instead of the specific class HttpRoute.\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-652",
        "summary": "Add optional state attribute to managed client connections",
        "description": "Provide an optional state attribute to managed client connections. The connection state can represent a user identify in case of connection based authentication schemes such as NTLM or SSL, thus allowing for connection re-use on a per user identity basis.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-675",
        "summary": "thread starving in MultiThreadedHttpConnectionManager",
        "description": "Hi folks,\n\nI might have found a bug in MTHCM. It has to do with removing HostConnectionPool instances that have no more connections in them. That was a fix for a memory leak we previously had. There are two cases where the pools get deleted. One is in handleLostConnection: (excerpt)\n  ...\n  if (hostPool.numConnections == 0) mapHosts.remove(config);\n  notifyWaitingThread(config);\n  ...\n\nCould this delete a pool in which there is still a thread waiting to get a connection? If so, the thread would remain in the global pool. But even if it is interrupted there, it would still use the old HostConnectionPool in which no connection will ever become available again.\n\nI suggest to change the removal check in both cases to:\n  if ((hostPool.numConnections < 1) && hostPool.waitingThreads.isEmpty)\n\nWhat do you think?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-67",
        "summary": "Build environment configuration: Mavenize the build process",
        "description": "- ease of building. HttpClient should be buildable without the user needing to\ngo away and download extra jars. Maven does a good job of this.\n- automated site and build on a nightly basis to pick up changes\n- move to j2sdk1.4",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-791",
        "summary": "Default retry count three even if documentation says it's five",
        "description": "The exception handling documentation (http://hc.apache.org/httpclient-3.x/exception-handling.html) says \"HttpClient will automatically retry up to 5 times those methods...\", but in DefaultHttpMethodRetryHandler  e.g. in trunk (http://svn.apache.org/viewvc/httpcomponents/oac.hc3x/trunk/src/java/org/apache/commons/httpclient/DefaultHttpMethodRetryHandler.java?revision=608014&view=markup) you can see that the retry count is three:\n\n    public DefaultHttpMethodRetryHandler(int retryCount, boolean requestSentRetryEnabled) {\n        super();\n        this.retryCount = retryCount;\n        this.requestSentRetryEnabled = requestSentRetryEnabled;\n    }\n    \n    /**\n     * Creates a new DefaultHttpMethodRetryHandler that retries up to 3 times\n     * but does not retry methods that have successfully sent their requests.\n     */\n    public DefaultHttpMethodRetryHandler() {\n        this(3, false);\n    }",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-204",
        "summary": "StackOverflowError in HttpConnection",
        "description": "When the HttpConnection#WrappedOutputStream.flush () encounters IOException \ndruign write, it is calling HttpConnection.close which calls \nHttpConnection.closeSocketAndStreams and which eventually calls \nHttpConnection#WrappedOutputStream.flush again.  The circular calls will cause \nStackOverflowError.\n\nI run into this accidentally when I was trying to extend HttpConnection.  But \nlooking through the code, I believe any IOException may cause the same \nproblem.  The circular calls should be either removed or controlled.  Below is \npart of teh stack trace\n\njava.lang.StackOverflowError\n        at java.lang.Exception.<init>(Unknown Source)\n        at java.io.IOException.<init>(Unknown Source)\n        at java.net.SocketException.<init>(Unknown Source)\n        at java.net.SocketOutputStream.socketWrite(Native Method)\n        at java.net.SocketOutputStream.write(Unknown Source)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ\ne(HttpConnection.java:1273)\n        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)\n        at java.io.BufferedOutputStream.flush(Unknown Source)\n        at java.io.FilterOutputStream.close(Unknown Source)\n        at org.apache.commons.httpclient.HttpConnection.closeSocketAndStreams(Ht\ntpConnection.java:1083)\n        at org.apache.commons.httpclient.HttpConnection.close(HttpConnection.jav\na:1024)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.hand\nleException(HttpConnection.java:1235)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ\ne(HttpConnection.java:1275)\n        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)\n        at java.io.BufferedOutputStream.flush(Unknown Source)\n        at java.io.FilterOutputStream.close(Unknown Source)\n        at org.apache.commons.httpclient.HttpConnection.closeSocketAndStreams(Ht\ntpConnection.java:1083)\n        at org.apache.commons.httpclient.HttpConnection.close(HttpConnection.jav\na:1024)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.hand\nleException(HttpConnection.java:1235)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ\ne(HttpConnection.java:1275)\n        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)\n        at java.io.BufferedOutputStream.flush(Unknown Source)\n        at java.io.FilterOutputStream.close(Unknown Source)\n        at org.apache.commons.httpclient.HttpConnection.closeSocketAndStreams(Ht\ntpConnection.java:1083)\n        at org.apache.commons.httpclient.HttpConnection.close(HttpConnection.jav\na:1024)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.hand\nleException(HttpConnection.java:1235)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ\ne(HttpConnection.java:1275)\n        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)\n        at java.io.BufferedOutputStream.flush(Unknown Source)\n        at java.io.FilterOutputStream.close(Unknown Source)\n        at org.apache.commons.httpclient.HttpConnection.closeSocketAndStreams(Ht\ntpConnection.java:1083)\n        at org.apache.commons.httpclient.HttpConnection.close(HttpConnection.jav\na:1024)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.hand\nleException(HttpConnection.java:1235)\n        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ\ne(HttpConnection.java:1275)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-187",
        "summary": "Provide general HTTP date parsing",
        "description": "Add generally accessible support for parsing HTTP dates as used in headers/cookies.\n\nInitially submitted to HttpClient dev by Chris Brown.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-695",
        "summary": "broken link to the release notes",
        "description": "On http://jakarta.apache.org/httpcomponents/httpclient-3.x/downloads.html\nthe link to the release notes is broken",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-490",
        "summary": "Can not set the \"Proxy-connection\" header",
        "description": "When using a proxy the HttpClient refuses to set the \"Proxy-connection\" header\nto the value \"close\". The value will be converted to \"keep-alive\" when the final\nrequest is sent to network.\n\nThe following code snippet can be used to replicate the defect. Method is GET:\n...\nmethod.removeRequestHeader(\"Proxy-Connection\");\nlogger.debug(\"Proxy-Connection header removed.\");\nmethod.addRequestHeader(\"Proxy-Connection\", \"close\");\nlogger.debug(\"Proxy-Connection header set to: \" +\nmethod.getRequestHeader(\"Proxy-Connection\") );\ntry {\n  \tint statusCode = httpclient.executeMethod( method );\n...\n\nNow if you look at the wire log, you will notice that the actual value will be\n\"keep-alive\".",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-714",
        "summary": "move route computation from client to director",
        "description": "The computation of routes should be done in the ClientRequestDirector, not in the Client.\nThe director needs to compute routes for redirects, so it should compute all routes.\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-677",
        "summary": "Connection pool uses Thread.interrupt()",
        "description": "The connection pool for TSCCM uses Thread.interrupt() to wake up waiting threads.\nThis interferes with application interrupts.\n\n- expose InterruptedException in interface\n- change pool implementation to use wait/notify\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-994",
        "summary": "cache does not allow client to override origin-specified freshness using max-stale",
        "description": "According to the RFC, the default freshness lifetime is supposed to be the LEAST restrictive of that specified by the origin, the client, and the cache. Right now, a client can't use 'max-stale' to relax the freshness constraints to get a cache hit without validation occuring first.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-206",
        "summary": "URI class constructors need revision, optimization",
        "description": "1. Currently there's not way to pass an escaped string as a parameter to URI\nclass. As a result the url parameter in HttpMethodBase#HttpMethodBase(String)\nconstructor gets converted into an array of char just to be converted back to\nstring in URI contructor called in that method. \n\n2. The overall design of URI class contructors does not appear very coherent (at\nleast to me)",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-779",
        "summary": "toplevel exception cleanup",
        "description": "HttpClient.execute should throw only one exception, for easier general use.\nHttpMethod constructors (HttpGet, HttpPut, etc..) should throw IllegalArgumentException in the string constructor (imply the string is pre-checked).  People wanting to see a URIException can use 'new HttpGet(new URI(uri))' and trigger the exception from the explicit URI creation.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-243",
        "summary": "Transfer-Encoding: identity not supported + possible patch",
        "description": "In HttpMethodBase.readResponseBody only chunked transfer encoding is \nsupported.  Some proxy servers like Privoxy, etc send a Transfer-Encoding: \nidentity header and HttpClient fails quietly and returns a null result input \nstream.  At line 2037 in HttpMethodBase.java revision 1.160 I inserted the \nfollowing two lines and it appeared to work fine:\n\n} else if (\"identity\".equalsIgnoreCase(transferEncodingHeader.getValue())) {\n   result = is;\n\nI think it should at least throw an exception or do something when it \nencounters an unsupported Transfer-Encoding instead of returning a null input \nstream.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-74",
        "summary": "J2EE FORM authentication (also affects pluggable authentication)",
        "description": "Add support for J2EE style FORM authentication type. \n\nUnlike the BASIC and DIGEST types this is not handled by HTTP headers so needs\nan adjustment to the way in which the authentication is sent. As far as i can\ntell from my testing with one or two J2EE servers the way to successfully login\nrequires request of a protected page which will respond with the login FORM and\nthen the submission of that form. The two requests must be associated with one\nanother using the jsessionid cookie.\n\nIt seems to me that this 'bug' must be solved in cooperation with the recent\ndiscussions of pluggable authentication module. i suggestion the following\nsignature: \n\nPluggableAuthenticator.authenticate(HttpMethod method, HttpState state). \n\nThis mirrors the existing Authenticator method but also requires change to the\nstate object to allow access to the connection properties (i dont know how this\naffects MultiClient). Alternately we could go for: \n\nPluggableAuthenticator.authenticate(HttpMethod method, HttpClient client).\n\nIn either case Authenticator needs a way to know which plugin to call. I suggest\nmodification of HttpMethodBase to detect the 'j_security_check' form action in\nthe response and automatically submit credentials if they are provided using the\nnew class \n\nJ2EEFormAuthenticator implements PluggableAuthenticator.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-747",
        "summary": "No entry created for this pool.",
        "description": "Followup to https://issues.apache.org/jira/browse/HTTPCLIENT-741, as reported by Sam Berlin:\n\njava.lang.IllegalStateException: No entry created for this pool. HttpRoute[{}->http://74.160.66.42:14561]\n    at org.apache.http.impl.conn.tsccm.RouteSpecificPool.freeEntry(RouteSpecificPool.java:137)\n    at org.apache.http.impl.conn.tsccm.ConnPoolByRoute.freeEntry(ConnPoolByRoute.java:337)\n    at org.apache.http.impl.conn.tsccm.ThreadSafeClientConnManager.releaseConnection(ThreadSafeClientConnManager.java:230)\n    at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:427)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:500)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:455)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:421)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor.performRequest(DefaultHttpExecutor.java:97)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor.access$000(DefaultHttpExecutor.java:26)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor$MultiRequestor.run(DefaultHttpExecutor.java:139)\n    at org.limewire.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1006)\n    at org.limewire.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:549)\n    at java.lang.Thread.run(Thread.java:613)\n---\n\nDefaultHttpExecutor$MultiRequestor basically is just a Runnable / Cancellable [exposes a cancel() method] that can be cancelled from any thread. cancel just calls abort() on the current AbortableHttpRequest, but is called on a thread other than the one that's doing the client.execute(request).\n\nThe last one is the most common exception, and seems to happen with some regularity. The other two we've only seen once, so may just be a memory quirk (we've seen some crazy bugs, including recursive NPEs while constructing an NPE.)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-872",
        "summary": "Add preemptive authentication",
        "description": "Wishlist request for preemptive authentication to be included in the API, like HttpClient 3.x had.  There is an example ClientPreemptiveBasicAuthentication.java that uses HttpRequestInterceptor which I had adapted to my application and it works fine.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-244",
        "summary": "URI uses  sun.security.action.GetPropertyAction",
        "description": "URI uses a sun.* class but should not.  Use of this class should be removed.\n\nReported my Mark Wilcox",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-657",
        "summary": "TestBasicCookieAttribHandlers fails on non-english Locale systems",
        "description": "The Test checks for written dates in the format for cookies which unfortunately includes a two character abbreviation of the day. This differs by locale, so the dateformat has to be constructed with Locale.US (as in DateUtils)",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-569",
        "summary": "HttpState.clearCookies() should be synchronized",
        "description": "The HttpState class has a clearCookies method that is not synchronized but\nshould be considering it modifies an ArrayList (which is unsynchronized). All\nother methods which modify or read from the ArrayList are synchronized except\nthe clearCookies method. \n\nI stumbled upon this fact because a webapp I am working on that uses HttpClient\nthrew an IllegalArgumentException indicating that one of the cookies in the\narray returned from HttpState.getCookies() was null, which shouldn't be\npossible.  Upon further inspection and testing, the only possible option is that\nthe threadsafety hole left by the unsynchronized clearCookies method caused the\nissue.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-716",
        "summary": "application-defined routes",
        "description": "Allow applications to specifiy a route as request parameter (or in the context).\nThis functionality is a replacement for RoutedRequest, which is removed by HTTPCLIENT-715.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-650",
        "summary": "Wire log is incomplete if HttpParser detects an error",
        "description": "If HttpParser detects an error in any of the headers, it throws a ProtocolException\n\nAlthough the failing header is included in the Exception detail, the headers leading up to the failure are not logged, which makes it hard to debug (and is quite confusing, as the PE does not appear to be related to the data that has been received).\n\nThis is because the wire-logging is done in the caller (HttpMethodDirector) which only logs the header if the parse succeeds.\n\nPerhaps the Wire logging should be done at the point where the HttpParser reads the line.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-444",
        "summary": "Preemptive authentication causes NTLM auth scheme to fail",
        "description": "The NTLM authentication scheme does not work when the preemptive authentication\nis enabled.\n\nReported by Dave Seidel <dave at mindreef.com>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-366",
        "summary": "PostMethod Java doc refers to wrong section of RFC1945",
        "description": "\"The HTTP POST method is defined in section 9.5 of RFC1945\" should read \"The\nHTTP POST method is defined in section 8.3 of RFC1945\"\n\nChange 9.5 to 8.3.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-266",
        "summary": "[patch] Support for digest auth MD5-sess",
        "description": "I was attempting to access a device that requires Digest authentication using\nMD5-sess, which does not seem to be supported.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-777",
        "summary": "SingleClientConnectionManager Needs to Recreate UniquePoolEntry",
        "description": "Due to the change yesterday of adding some state into DefaultClientConnection (remembering when shutdown was called & aborting the next opening), SingeClientConnectionManager now breaks when subsequent requests are performed if the first one encountered an exception or was aborted.  \n\nAttaching a patch with the fix + a testcase (that previously failed).",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-701",
        "summary": "Cookie guide lists RFC 2965 as unsupported",
        "description": "HttpClient 3.1 added support for RFC 2965 (port-sensitive cookies), but the Cookie guide on the 3.x website still lists that as unsupported.\nhttp://jakarta.apache.org/httpcomponents/httpclient-3.x/cookies.html\n\ncheers,\n  Roland\n ",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-456",
        "summary": "HttpClient should always override the host of HostConfiguration if an absolute request URI is given",
        "description": "This bug most likely occurs on all patforms and OS's, but I have only tested it\non WinXP.\n\nThe HttpClient.executeMethod(HostConfiguration,HttpMethod,HttpState) will\nreceive and throw an IllegalArgumentException stating that \"host parameter is\nnull\" when a  HostConfiguration object is passed in that ONLY has a proxy set\n(via HostConfiguration.setProxy(String, int)). Details to reproduce follow--the\nbug can be easily reproduced by using the Apache Axis 1.2 CommonsHTTPSender\nclass (with JVM system props http.proxyHost, http.proxyPort set):\n\nThere is a bug in the Apache Commons HTTP Client 3.0rc2 that does not set the\nhostname property\nin the <code>HostConfiguration</code> object if the following two steps\nare performed:<br>\n1. You call\n<code>HttpClient.executeMethod(HostConfiguration,HttpMethod,HttpState)</code>\nwith a <code>HostConfiguration</code> object and an <code>HttpMethod</code> object\n(created using the HttpMethod(String uri) constructor).This method \nis called in this exact way in the Apache Axis 1.2 client\n(CommonsHTTPSender.java lines 132 and 186).<br>\n2. That <code>HostConfiguration</code> object only has a proxy set (using\nsetProxy(String, int)). This method \nis called in this exact way in the Apache Axis 1.2 client\n(CommonsHTTPSender.java line 389).<br>\n\nApache Axis 1.2rc3 CommonsHTTPSender.java did not expose this bug in Commons\nHTTP Client 3.0rc2 because\nit set the <code>HostConfiguration</code> in a different manner, as follows:<br>\n1. Call <code>HttpClient.setHostConfiguration(HostConfiguration)</code> first.\nAgain,\nThe <code>HostConfiguration</code> object must only have a proxy set and no host\nname.<br>\n2. Then call <code>HttpClient.executeMethod(HttpMethod)</code>.<br>\n\nUsing the above steps (as in Axis 1.2rc3 CommonsHTTPSender.java, invoke()\nmethod), line 379 in HttpClient.java evaluates to true\nbecause the argument <code>hostConfiguration</code> is null (see line 324 in\nHttpClient.java) and the local \nvariable <code>defaultHostConfiguration</code> ==\n<code>HttpClient.setHostConfiguration(HostConfiguration)</code>\nwhich was set in item #1 above. The hostname then gets set in the\n<code>HostConfiguration</code>\nobject in line 384 of HttpClient.java.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-784",
        "summary": "Multipart post is broken",
        "description": "I tried to do HttpPost request with MultipartEntity, this request was encoded to wire with 3 line separators after header and not processed correctly by http server.\nMultipartEntry add 1 extra line separator before write itself to wire. I'm not sure about standards, but it is at least not \"browser compatible\".\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-97",
        "summary": "Error reading data",
        "description": "Hi,\n\nI have some problems with HttpClient HEAD. It works fine with a build of \n20020720 of HttpClient though.\n\nIt seems HttpClient is not reading correctly the returned HTTP response.\n\nI'm attaching the logs.\n\nHere is the output from Cactus build:\n\n\n\n     [java]     [junit] Testcase: testLongProcess took 3.645 sec\n     [java]     [junit]         Caused an ERROR\n     [java]     [junit] Failed to get the test results. This is probably due \nto an error that happen\ned on the server side when trying to execute the tests. Here is what was \nreturned by the server : [<\nhtml><head><Long Process></head><body>Some data</body></html>\n     [java]     [junit] ]\n     [java]     [junit] org.apache.cactus.util.ChainedRuntimeException: Failed \nto get the test resul\nts. This is probably due to an error that happened on the server side when \ntrying to execute the tes\nts. Here is what was returned by the server : [<html><head><Long \nProcess></head><body>Some data</bod\ny></html>\n     [java]     [junit] ]\n     [java]     [junit]         at \norg.apache.cactus.client.AbstractHttpClient.doTest(Unknown Source\n)\n     [java]     [junit]         at \norg.apache.cactus.AbstractWebTestCase.runWebTest(Unknown Source)\n     [java]     [junit]         at \norg.apache.cactus.AbstractWebTestCase.runGenericTest(Unknown Sour\nce)\n     [java]     [junit]         at org.apache.cactus.ServletTestCase.runTest\n(Unknown Source)\n     [java]     [junit]         at org.apache.cactus.AbstractTestCase.runBare\n(Unknown Source)\n     [java]     [junit] org.apache.cactus.client.ParsingException: Not a valid \nresponse. First 100 c\nharacters of the reponse: [</webresult>HTTP/1.1 200 OK\n     [java]     [junit] Server: Resin/2.1.2\n     [java]     [junit] Content-Length: 23\n     [java]     [junit] Date: Tue, 13 Aug 2002 08:45:2]\n     [java]     [junit]         at \norg.apache.cactus.client.WebTestResultParser.readExceptionClassna\nme(Unknown Source)\n     [java]     [junit]         at \norg.apache.cactus.client.WebTestResultParser.parse(Unknown Source\n\nThanks\n-Vincent",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-606",
        "summary": "HttpMethodDirector fails when redirecting to a encoded URL location",
        "description": "When HttpMethodDirector handles the case of redirecting the incoming connection to the location specified in the header of the http caller method, if this location has any \"special\" charset encoding (extended charsets like ISO 8859-1,etc.) the redirection fails this way:\n\ndd-MMM-YYYY hh:mm:ss org.apache.commons.httpclient.HttpMethodDirector processRedirectResponse\nWARNING: Redirected location 'http://www.anyCharsetEncodedUrl.ko' is malformed\n\n\nYou can test it using this class:\n\n\npublic class SimpleHttpTestNotWorking {\n\n\tpublic static int urlStatus(String pUrl) throws org.apache.commons.httpclient.HttpException,java.io.IOException{\n\t\torg.apache.commons.httpclient.HttpClient client = new org.apache.commons.httpclient.HttpClient();\n\t\torg.apache.commons.httpclient.HttpMethod method = new org.apache.commons.httpclient.methods.GetMethod(pUrl);\n\t\treturn client.executeMethod(method);\n\t}\n\t\t\n\tpublic static void main(String[] args) {\n\t\ttry{\n\t\t\tString url = \"http://www.dipualba.es/municipios/F%E9rez\"; //known problematic URL\n\t\t\tSystem.out.println(\"Return code for [\"+url+\"]: \"+SimpleHttpTestWorking.urlStatus(url));\n\t\t}catch(Exception e){\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n\n\nWhat I've done to solve it for my particular case has been:\n\n\n1) In the requester side, I've modified the calling:\n\n\npublic class SimpleHttpTestWorking {\n\n\tpublic static int urlStatus(String pUrl) throws org.apache.commons.httpclient.HttpException,java.io.IOException{\n\t\torg.apache.commons.httpclient.HttpClient client = new org.apache.commons.httpclient.HttpClient();\n\t\torg.apache.commons.httpclient.HttpMethod method;\n\t    String encoding = (String)client.getParams().getParameter(\"http.protocol.content-charset\");\n\t    client.getParams().setParameter(\"http.protocol.element-charset\", encoding);\n\t    try{\n\t    \tmethod = new org.apache.commons.httpclient.methods.GetMethod(pUrl);\n\t    }catch(IllegalArgumentException iae){\n\t\t    try{\n\t\t    \torg.apache.commons.httpclient.URI uri = new org.apache.commons.httpclient.URI(pUrl,true);\n\t\t    \tmethod = new org.apache.commons.httpclient.methods.GetMethod(uri.getURI());\n\t\t    }catch(org.apache.commons.httpclient.URIException ue){\n\t\t    \torg.apache.commons.httpclient.URI uri = new org.apache.commons.httpclient.URI(pUrl,false,encoding);\n\t\t\t    method = new org.apache.commons.httpclient.methods.GetMethod(uri.getEscapedURI());\n\t\t    }\t\t    \t\n\t    }\t\t\n\t\treturn client.executeMethod(method);\n\t}\n\t\t\t\n\tpublic static void main(String[] args) {\n\t\ttry{\n\t\t\tString url = \"http://www.dipualba.es/municipios/F\u00e9rez\"; //the same problematic URL\n\t\t\tSystem.out.println(\"Return code for [\"+url+\"]: \"+SimpleHttpTestWorking.urlStatus(url));\n\t\t}catch(Exception e){\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n\n\n2) In org.apache.commons.httpclient.HttpMethodDirector.processRedirectResponse(HttpMethod method) , I've replaced\n\n\n...\nredirectUri = new URI(location, true);\n...\n\n\nfor the following code:\n\n\n...\n/*\n * [2006-11-14] \n * Handles redirections to encoded URI locations \n * (only if URI and Connection encoding charset has been properly setted)\n * */ \ntry{\n\tredirectUri = new URI(location, true);\n}catch(URIException ue){\n\tObject encoding = this.conn.getParams().getParameter(\"http.protocol.element-charset\");\n\tif(encoding != null){\n\t\tredirectUri = new URI(location, false, (String)encoding);\n\t}else{\n\t\tthrow ue;\n\t}\n}\n...\n\n\n\nHope it helps!",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-672",
        "summary": "re-sync client with changes in core alpha6 snapshot",
        "description": "There have been API changes in core since it's alpha5 release.\nClient needs to be adapted so it's alpha2 (snapshot) builds and runs against the current core API.\n",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "HTTPCLIENT-841",
        "summary": "potential memory leak when using ThreadSafeClientConnManager",
        "description": "When using ThreadSafeClientConnManager and developing with Jetty using auto-redeploy feature eventually I run into a PermGen out of memory exception.  I investigated with YourKit 8.0.6 and found a class loader circular reference in RefQueueWorker.  Not really sure what I was doing I made the refQueueHandler non-final and nulled it in the shutdown method of RedQueueWorker.  I don't seem to have the problem any longer with circular class loader references.\n\nHere is a diff from 4.0-beta2\n\n\n--- httpclient/src/main/java/org/apache/http/impl/conn/tsccm/RefQueueWorker.jav(revision 763223)\n+++ httpclient/src/main/java/org/apache/http/impl/conn/tsccm/RefQueueWorker.jav(working copy)\n@@ -50,7 +50,7 @@\n     protected final ReferenceQueue<?> refQueue;\n \n     /** The handler for the references found. */\n-    protected final RefQueueHandler refHandler;\n+    protected RefQueueHandler refHandler;\n \n \n     /**\n@@ -112,6 +112,8 @@\n             this.workerThread = null; // indicate shutdown\n             wt.interrupt();\n         }\n+\n+        refHandler = null;\n     }\n \n \n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-673",
        "summary": "revise max-per-host configuration",
        "description": "Max-per-host settings for ThreadSafeClientConnManagers are currently stored in HttpParams, where the parameter value is a map from HttpRoute (formerly HostConfiguration) to Integer. This has several drawbacks:\n\n1) maintaining a map as a value in HttpParams doesn't match my understanding of how params should be used\n2) the maximums based on HttpRoute are really specific to the TSCCM implementation and not a generic parameterization\n\nsome of the options are:\n\na) revise to define a more generic parameterization approach\nb) revise into an implementation specific parameterization approach\nc) define an implementation (TSCCM) specific configuration interface and a default implementation keeping the map as run-time data\n\ncheers,\n  Roland\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-136",
        "summary": "Inadequate HTTP proxy server support in HttpClient.",
        "description": "1. The HttpClient class does not save the StatusLine from the hidden\nConnectMethod object used to connect via an HTTP proxy server, thus any proxy\nfailures are only picked up as 'anonymous exceptions', this is useless for\ngracefull recovery and rapid debugging.\n\n2. The current class structure is too fragile to neatly support HTTP Proxy (and\nauthenication) chains so it would be a good idea to look at this at the same\ntime, preferable with support for a Proxy chain redirect when an non/dead HTTP\nProxy server is found.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-445",
        "summary": "304 response status handling",
        "description": "I have an IBM WebSphere server that returns 304 responses with a Content-\nLength header set to something other than 0 and the server is not closing the \nconnection.  According to the HTTP RFC \n(http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.5):\n\n\"The 304 response MUST NOT contain a message-body, and thus is always \nterminated by the first empty line after the header fields.\"\n\nObviously, the web server is returning a bad response but the HTTPClient \nblocks waiting on data in the response even though there shouldn't be any.  \nOther HTTP clients (browsers) do not have this issue and seem to ignore the \nfact that the server set an invalid Content-Length in the response.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1076",
        "summary": "[GSoC 2011] Fluent API to HttpClient",
        "description": "Develop fluent API / facade to HttpClient based on code currently maintained by Apache Stanbol and Apache Sling projects. \n\nFor details see \n\nhttp://markmail.org/message/mmyljtgjp3za6kyz\n\nor contact Apache HttpComponents committers at dev@hc.apache.org",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-194",
        "summary": "httpClient does not support installation of different SSLSocketFactory",
        "description": "Description:\n\nThe SSLProtocolSocketFactory class had hard-\ncoded \"javax.net.ssl.SSLSocketFactory\" as the socket factory.  It does not \nsupport installation of other socket factory.\n\nProposed Fix:\n\nWe added a setDefaultSSLSocketFactory method to the SSLProtocolSocketFactory \nand modified the code to use the factory it it is set.  The code falls back on \nusing \"javax.net.ssl.SSLSocketFactory\" if a default is not set.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-261",
        "summary": "infinite loop on 302 redirect with different host in Location: header",
        "description": "Using the CVS version - 2.1 rc I think.\n\nTrying to get the url contents for a url with followRedirects specified and \nStrictMode off and I get a 302 redirect to a different url with a different \nhost in the Location header causes it to go into an infinite loop (mercifully \naborting at 100 redirects).  An example offending url: \n\nhttp://www.snowcrest.net/mice/mice.htm\n\nThe problem lies in HttpMethodBase.java version 1.177 at line 1225.  It does \nthe following:\n\n        if (getRequestHeader(\"host\") != null) {\n            LOG.debug(\n                \"Request to add Host header ignored: header already added\");\n            return;\n        }\n\nand there is already the Host header from the previous url request so it \nendlessly loops until it aborts at the max redirects (default is 100 I guess).  \nI commented this out and it worked fine.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-289",
        "summary": "MultiThreadedHttpConnectionManager daemon Thread never GC'd",
        "description": "One of my colleagues was invoking HttpClient by way of a loop something like this:\n\nfor (int i = 0; i < 300; i++) {\n    GetMethod method = new\nGetMethod(\"http://cvs.apache.org/viewcvs/jakarta-commons/httpclient/\");\n    try {\n        HttpClient httpClient = new HttpClient(new\nMultiThreadedHttpConnectionManager());\n        httpClient.executeMethod(method);\n        byte[] bytes = method.getResponseBody();\n    } finally {\n        // always release the connection after we're done\n        method.releaseConnection();\n    }\n}\n\nHe's in the process of revising his code so that he doesn't do this loop, which\nother developers might point out as a non-optimal use, but along the way, he\ndiscovered that the daemon thread that the MultiThreadedHttpConnectionManager\nmakes does not get garbage collected.  Of course, the connection manager itself\nis also never gc'd.  While I think we can avoid this problem in our code, in the\nmore general case, clients may not actually be able to control the number of\nMultiThreadedConnectionManagers they create, which could eventually cause\nproblems.  This makes me think the problem is deserving of a patch.\n\nWe found this problem with 2.0rc2, although presumably it also exists with the\nCVS HEAD.\n\nPatch to follow.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1140",
        "summary": "Infinite loop on basic authentication",
        "description": "Class org.apache.http.impl.client.DefaultRequestDirector has a bug whereby when Authentication fails if the log is not warnEnabled then you will receive a retry request and end up in an infinite loop retrying requests.. This occurred for me when SL4J was being picked up as the implementation but not properly configured.\n\nIn 4.1.2 the line number of the offending code is in the handleResponse method, line 1126, the return null statement requires moving outside of the if statement that checkes if the log is warn enabled.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-563",
        "summary": "Incorrect copyright statements",
        "description": "Most of the copyright statements in http-core are for 1999-2004.  These should\nbe updated with the correct years.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-175",
        "summary": "HttpState cannot differentiate credentials for different hosts with same Realm names",
        "description": "It seems that one needs a separate HttpState per client per host: from the \njavadocs, if (by coincidence or by design) more than one host uses the same \nrealm name, such as \"Private\", then there's an unresolvable conflict, as \nHttpState can only store one set of credentials for a given name...\n\nAccording to Oleg Kalnichevski, it is plausible just to extend the HttpState \nclass with additional methods that would require host to be specified along the\nauthentication realm when dealing with credentials.\n\nSee postings on \"Commons HttpClient Project\" mailing list for more info (dated \n21/03/2003).",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-381",
        "summary": "HttpState#PREEMPTIVE_PROPERTY removed.",
        "description": "Our code no longer compiles as HttpState#PREEMPTIVE_PROPERTY has been removed.\nOur code compiles with 2.0.1.\n\nSee: \nhttp://jakarta.apache.org/commons/httpclient/apidocs/org/apache/commons/httpclient/HttpState.html#PREEMPTIVE_PROPERTY",
        "label": "NUG",
        "classified": "BACKPORT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1152",
        "summary": "org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage should verify class of returned object before casting",
        "description": "org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage\n\nOriginal (in getEntry function): \n  byte[] data = (byte[]) client.get(url);\n\nShould be:\n  Object obj= client.get(url);\n  if (null == obj || !(objinstanceof byte[])) {\n    return null;\n  }\n  byte[] data = (byte[])obj;\n\n\nOriginal (in updateEntry function):\n  byte[] oldBytes = (v != null) ? (byte[]) v.getValue() : null;\n\nShould be:\n  byte[] oldBytes = (v != null && (v.getValue() instanceof byte[])) ? (byte[]) v.getValue() : null;\n\n\n\n  \n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-453",
        "summary": "Virtual host setting does not apply when parsing and matching cookies",
        "description": "Virtual host setting does not apply when parsing and matching cookies.\n\nProblem has been reported on the httpclient-dev list by Dan Levine",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-861",
        "summary": "URI reference resolution fails examples in RFC 3986",
        "description": "org.apache.http.client.utils.URIUtils.resolve(final URI baseURI, URI reference) fails to resolve some examples from RFC 3986 section 5.3 correctly. See TestCase.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-51",
        "summary": "Redefine HttpClient vs HttpMultiClient interface for 2.0",
        "description": "In particular the HttpClient/HttpMultiClient issue must be resolved. \nHttpultiClient functionality should be prefered, but HttpClient is the most\nsuitable name.  Consider impact to other projects.  Is java1.1 compatability\nreally an issue anymore?",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1027",
        "summary": "Some typos in the English Manual",
        "description": "in section 2.8.4\nPer default this implementation will create no more than than 2 concurrent connections per given route and no more 20 connections in total.\nHere are 2 \"than\" in this statement.\n\nin section 3.1\nNetscape engineers used to refer to it as as a \"magic cookie\" and the name stuck.\nAlso, here are 2 \"as\" in the sentence.\n\nin section 5.2 'http.protocol.handle-redirects'\nIf this parameter is not HttpClient will handle redirects automatically.\nhere, a \"set\" should be put after not\n\nin section 6.1\nIn certain situations it may be necessary to customize the way HTTP messages get transmitted across\nthe wire beyond what is possible possible using HTTP parameters in order to be able to deal nonstandard,\nnon-compliant behaviours.\nhere are 2 \"possible\".",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-627",
        "summary": "overhaul connection manager and associated connection interface",
        "description": "MultiThreadedHttpConnectionManager/HttpHostConnection needs to be overhauled to provide a layer on top of OperatedClientConnection.\nPreliminary working names: ThreadSafeClientConnManager/ManagedClientConnection\n\nThis implies some work on former HttpMethodDirector and HttpClient to verify completeness of the new connection management API.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1128",
        "summary": "Provide factory method to create DefaultHttpClient instances pre-configured based on JSSE and networking system properties",
        "description": "Provide factory method or a factory class intended to create DefaultHttpClient instances pre-configured based on JSSE [1] and networking [2] system properties.\n\n[1] http://download.oracle.com/javase/1,5.0/docs/guide/security/jsse/JSSERefGuide.html\n[2] http://download.oracle.com/javase/1.5.0/docs/guide/net/properties.html",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-704",
        "summary": "Exception not caugh in DefaultResponseParser",
        "description": "The method hasProtocolVersion in o.a.h.message.BaseLineParser (httpcore-alpha6) throws an IndexOutOfBoundsException which is not caught by the parseHead method in the o.a.h.impl.conn.DefaultResponseParser.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-70",
        "summary": "Provide more Example Code",
        "description": "- better project samples showing how to use HttpClient in a variety of ways. \nThere is already a src/examples directory which is excellent.  Its in the right\nplace and should be build with a full compile, if only to know how any API\nchanges may effect example code, and that we will be required to keep them\ncurrent.\n- make sure it uses the 2.0 API and no depricated methods!",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-613",
        "summary": "https should check CN of x509 cert",
        "description": "https should check CN of x509 cert\n\nSince we're essentially rolling our own \"HttpsURLConnection\",  the checking provided by \"javax.net.ssl.HostnameVerifier\" is no longer in place.\n\nI have a patch I'm about to attach which caused both createSocket() methods on o.a.h.conn.ssl.SSLSocketFactory to blowup:\n\ntest1: javax.net.ssl.SSLException: hostname in certificate didn't match: <vancity.com> != <www.vancity.com>\ntest2: javax.net.ssl.SSLException: hostname in certificate didn't match: <vancity.com> != <www.vancity.com>\n\nHopefully people agree that this is desirable.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-130",
        "summary": "HttpMethodBase does not compile on JDK prior to 1.3",
        "description": "reason is the use of URL.getPath() and URL.getQuery() within method\nprocessRedirectResponse.\n\nshould use URIUtil.getPath and URIUtil.getQuery instead.\n\nso, HttpMethodBase around line 952:\n\n//update the current location with the redirect location\nsetPath(URIUtil.getPath(redirectUrl.toString()));\nsetQueryString(URIUtil.getQuery(redirectUrl.toString()));\n\nthanks,\n\nmarius",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-752",
        "summary": "version.properties",
        "description": "If we're not going to split it, there should be only one version.properties in module-client.\nmodule-httpmime is currently missing a version.properties file.\n",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1127",
        "summary": "Deadlock between SingleClientConnManager.releaseConnection() and SingleClientConnManager.shutdown()",
        "description": "It's possible to create a deadlock within SingleClientConnectionManager.\n\nWhen JMeter interrupts a test, it calls HttpUriRequest.abort(), and as part of thread end processing it calls SingleClientConnManager.shutdown().\n\nSee deadlock details below.\n\nI don't yet know why the shutdown is called before the abort finishes; that is probably a bug.\n\nHowever, there may be a issue with the locking strategy within SCCM, hence this report.\n\n\"Thread-18\":\n        at org.apache.http.impl.conn.SingleClientConnManager.releaseConnection(SingleClientConnManager.java:258)\n        - waiting to lock <0x19e00118> (a org.apache.http.impl.conn.SingleClientConnManager)\n        at org.apache.http.impl.conn.AbstractClientConnAdapter.abortConnection(AbstractClientConnAdapter.java:323)\n        - locked <0x19e00148> (a org.apache.http.impl.conn.SingleClientConnManager$ConnAdapter)\n        at org.apache.http.client.methods.HttpRequestBase.abort(HttpRequestBase.java:161)\n        at org.apache.jmeter.protocol.http.sampler.HTTPHC4Impl.interrupt(HTTPHC4Impl.java:1090)\n        at org.apache.jmeter.protocol.http.sampler.HTTPSamplerProxy.interrupt(HTTPSamplerProxy.java:77)\n        at org.apache.jmeter.threads.JMeterThread.interrupt(JMeterThread.java:580)\n        at org.apache.jmeter.engine.StandardJMeterEngine.tellThreadsToStop(StandardJMeterEngine.java:552)\n        at org.apache.jmeter.engine.StandardJMeterEngine.access$2(StandardJMeterEngine.java:547)\n        at org.apache.jmeter.engine.StandardJMeterEngine$StopTest.run(StandardJMeterEngine.java:284)\n        at java.lang.Thread.run(Thread.java:662)\n\"Thread Group 1-1\":\n        at org.apache.http.impl.conn.AbstractPooledConnAdapter.detach(AbstractPooledConnAdapter.java:106)\n        - waiting to lock <0x19e00148> (a org.apache.http.impl.conn.SingleClientConnManager$ConnAdapter)\n        at org.apache.http.impl.conn.SingleClientConnManager.shutdown(SingleClientConnManager.java:342)\n        - locked <0x19e00118> (a org.apache.http.impl.conn.SingleClientConnManager)\n        at org.apache.jmeter.protocol.http.sampler.HTTPHC4Impl.closeThreadLocalConnections(HTTPHC4Impl.java:1076)\n        at org.apache.jmeter.protocol.http.sampler.HTTPHC4Impl.threadFinished(HTTPHC4Impl.java:1065)\n        at org.apache.jmeter.protocol.http.sampler.HTTPSamplerProxy.threadFinished(HTTPSamplerProxy.java:71)\n        at org.apache.jmeter.threads.JMeterThread$ThreadListenerTraverser.addNode(JMeterThread.java:553)\n        at org.apache.jorphan.collections.HashTree.traverseInto(HashTree.java:986)\n        at org.apache.jorphan.collections.HashTree.traverse(HashTree.java:969)\n        at org.apache.jmeter.threads.JMeterThread.threadFinished(JMeterThread.java:528)\n        at org.apache.jmeter.threads.JMeterThread.run(JMeterThread.java:308)\n        at java.lang.Thread.run(Thread.java:662)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-712",
        "summary": "improve HttpRoute API",
        "description": "Some of the constructors of HttpRoute have three boolean parameters.\nUse enumerations to reduce the potential for confusion.\n\nThe flags for tunnelled and layered are not independent, since layered implies tunnelled.\nThese can be combined to a 3-valued enum.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-359",
        "summary": "StringRequestEntity.getContentLength wrong for multibyte chars",
        "description": "When setting up a PostMethod containing a StringRequestEntity with umlauts and\ncharset UTF-8 the content-length header is wrong. It should be the number\nof bytes, but is the number of chars by now.\n\n(e.g.\nContent-Type: text/xml; charset=UTF-8\nbody='\u00c3\u00a4\u00c3\u00b6\u00c3\u00bc\u00c3\u009f\u00c3\u0084\u00c3\u0096\u00c3\u009c')\n\nBug-location: org.apache.commons.httpclient.methods.StringRequestEntity",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-343",
        "summary": "[API Doc] Compile new preference architecture and HTTP parameterization guide",
        "description": "Document the new preference architecture based on the hierarchy of HttpParams\ncollections, as well as available parameters and options",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-332",
        "summary": "Connection timeout logic redesign",
        "description": "Changelog:\n\n* CreateSocket method with timeout parameter added to the ProtocolSocketFactory\ninterface\n\n* TimeoutController related code factored out of HttpConnection class and moved\ninto ControllerThreadSocketFactory helper class\n\n* ReflectionSocketFactory helper class added. This factory encapsulates\nreflection code to call JDK 1.4 Socket#connect method if supported\n\n* All protocol socket factories now attempt to initially use\nReflectionSocketFactory if required to create a socket within a given limit of\ntime. If reflection fails protocol socket factories fall back onto the good ol'\nControllerThreadSocketFactory\n\nBenefits:\n\n* HttpConnection code got a lot cleaner\n* When running in modern JREs expensive timeout controller thread per connection\nattempt is no longer needed\n* Ugly code intended to work around limitations of the older JREs is now\nconfined to a few helper classes that can be easily thrown away once we move\nonto Java 1.4\n\nLet me know what you think\n\nOleg",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-687",
        "summary": "DefaultRedirectHandler does not access correct HttpParams",
        "description": "In the getLocationURI(HttpResponse, HttpContext) method, the HttpParams for determining REJECT_RELATIVE_REDIRECT and ALLOW_CIRCULAR_REDIRECTS are retrieved with:\n\nHttpParams params = response.getParams();\n\nThe response HttpParams do not contain these values, however the request HttpParams do. The correct implementation is:\n\nHttpRequest request = (HttpRequest) context.getAttribute(HttpExecutionContext.HTTP_REQUEST);\nHttpParams params = request.getParams();\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-643",
        "summary": "Provide fail-over for multi-home remote servers (if one server in a farm goes down)",
        "description": "The HTTP Client does not provide automatic fail-over for multi-home remote servers (web-farm) if one server in a farm goes down",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-767",
        "summary": "Static variables need to be final (or access should be synchronised):",
        "description": "Static variables need to be final (or access should be synchronised):\n\nIndex: module-client/src/main/java/org/apache/http/conn/params/HttpConnectionManagerParams.java\n===================================================================\n--- module-client/src/main/java/org/apache/http/conn/params/HttpConnectionManagerParams.java\t(revision 652021)\n+++ module-client/src/main/java/org/apache/http/conn/params/HttpConnectionManagerParams.java\t(working copy)\n@@ -53,7 +53,7 @@\n     public static final int DEFAULT_MAX_TOTAL_CONNECTIONS = 20;\n \n     /** The default maximum number of connections allowed per host */\n-    private static ConnPerRoute DEFAULT_CONN_PER_ROUTE = new ConnPerRoute() {\n+    private static final ConnPerRoute DEFAULT_CONN_PER_ROUTE = new ConnPerRoute() {\n         \n         public int getMaxForRoute(HttpRoute route) {\n             return ConnPerRouteBean.DEFAULT_MAX_CONNECTIONS_PER_ROUTE;\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-459",
        "summary": "Document the problem with MS impl of digest authentication with older JREs and stale connection check",
        "description": "It seems like digest authentication, when used with a username of the format:\ndomain\\username fails in httpclient-3.0-rc2.\n\nI did confirm that digest authentication does work by connecting to a local\nApache HTTP 2.0 server, using just a username and password (no domain\\username).\nHowever, it does not support the MD5-sess algorithm, and the server I am getting\nthe failure from is using MD5-sess. \n\nIt may turn out the username is not causing the problem, but one thing is\nconsistent--I can connect to the site in the logs below using httpclient-2.0.2.\nIt fails when I use identical Java code, with the addition of AuthScope, when\nusing httpclient-3.0-rc2. I will also attach Java code that reproduces the problem.\n\nThe following are wire and debug logs from httpclient-2.0.2 and\nhttpclient-3.0-rc2 respectively. The first one connects and gets an 'HTTP 200'\nresponse. The second one, using 3.0-rc2 fails with an 'HTTP 401'.\n\nLOGS\n===============================================================\ncommons-httpclient-2.0.2 (works):\n2005/05/13 11:05:15:185 EDT [DEBUG] HttpClient - Java version: 1.3.1\n2005/05/13 11:05:15:185 EDT [DEBUG] HttpClient - Java vendor: IBM Corporation\n2005/05/13 11:05:15:185 EDT [DEBUG] HttpClient - Java class path: \n2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - Operating system name: Windows XP\n2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - Operating system architecture: x86\n2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - Operating system version: 5.1\n2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - SUN 1.2: SUN (DSA key/parameter\ngeneration; DSA signing; SHA-1, MD5 digests; SecureRandom; X.509 certificates;\nJKS keystore)\n2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - SunJCE 1.22: SunJCE Provider\n(implements DES, Triple DES, Blowfish, PBE, Diffie-Hellman, HMAC-MD5, HMAC-SHA1)\n2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - SunJSSE 1.0303: Sun JSSE\nprovider(implements RSA Signatures, PKCS12, SunX509 key/trust factories, SSLv3,\nTLSv1)\n2005/05/13 11:05:20:893 EDT [DEBUG] HttpConnection - HttpConnection.setSoTimeout(0)\n2005/05/13 11:05:20:893 EDT [DEBUG] HttpMethodBase - Execute loop try 1\n2005/05/13 11:05:20:913 EDT [DEBUG] header - >> \"GET\n/CustomerData-30/CustomerDataService.asmx HTTP/1.1[\\r][\\n]\"\n2005/05/13 11:05:20:913 EDT [DEBUG] HttpMethodBase - Adding Host request header\n2005/05/13 11:05:20:913 EDT [DEBUG] header - >> \"User-Agent: Jakarta\nCommons-HttpClient/2.0.2[\\r][\\n]\"\n2005/05/13 11:05:20:913 EDT [DEBUG] header - >> \"Host:\nmappoint-css.partners.extranet.microsoft.com[\\r][\\n]\"\n2005/05/13 11:05:21:173 EDT [DEBUG] header - >> \"[\\r][\\n]\"\n2005/05/13 11:05:21:273 EDT [DEBUG] header - << \"HTTP/1.1 401 Unauthorized[\\r][\\n]\"\n2005/05/13 11:05:21:273 EDT [DEBUG] header - << \"Content-Length: 1656[\\r][\\n]\"\n2005/05/13 11:05:21:283 EDT [DEBUG] header - << \"Content-Type: text/html[\\r][\\n]\"\n2005/05/13 11:05:21:283 EDT [DEBUG] header - << \"Server: Microsoft-IIS/6.0[\\r][\\n]\"\n2005/05/13 11:05:21:283 EDT [DEBUG] header - << \"WWW-Authenticate: Digest\nqop=\"auth\",algorithm=MD5-sess,nonce=\"b2a83a38cd57c501af3ad2c91f189512060524424ffc2b818c9920db15cd247a9d47cf5a789d63c6\",opaque=\"1704373a505e74c4ec692978e5c1a539\",charset=utf-8,realm=\"Digest\"[\\r][\\n]\"\n2005/05/13 11:05:21:283 EDT [DEBUG] header - << \"X-Powered-By: ASP.NET[\\r][\\n]\"\n2005/05/13 11:05:21:283 EDT [DEBUG] header - << \"Date: Fri, 13 May 2005 15:05:37\nGMT[\\r][\\n]\"\n2005/05/13 11:05:21:283 EDT [DEBUG] HttpMethodBase - Authorization required\n2005/05/13 11:05:21:283 EDT [DEBUG] HttpAuthenticator - Authenticating with the\n'Digest' authentication realm at mappoint-css.partners.extranet.microsoft.com\n2005/05/13 11:05:21:283 EDT [DEBUG] DigestScheme - Using qop method auth\n2005/05/13 11:05:21:283 EDT [DEBUG] HttpMethodBase - HttpMethodBase.execute():\nServer demanded authentication credentials, will try again.\n2005/05/13 11:05:21:293 EDT [DEBUG] HttpMethodBase - Resorting to protocol\nversion default close connection policy\n2005/05/13 11:05:21:293 EDT [DEBUG] HttpMethodBase - Should NOT close\nconnection, using HTTP/1.1.\n2005/05/13 11:05:21:293 EDT [DEBUG] HttpMethodBase - Execute loop try 2\n2005/05/13 11:05:21:293 EDT [DEBUG] header - >> \"GET\n/CustomerData-30/CustomerDataService.asmx HTTP/1.1[\\r][\\n]\"\n2005/05/13 11:05:21:293 EDT [DEBUG] HttpMethodBase - Request to add Host header\nignored: header already added\n2005/05/13 11:05:21:293 EDT [DEBUG] header - >> \"User-Agent: Jakarta\nCommons-HttpClient/2.0.2[\\r][\\n]\"\n2005/05/13 11:05:21:293 EDT [DEBUG] header - >> \"Host:\nmappoint-css.partners.extranet.microsoft.com[\\r][\\n]\"\n2005/05/13 11:05:21:293 EDT [DEBUG] header - >> \"Authorization: Digest\nusername=\"domain\\user\", realm=\"Digest\",\nnonce=\"b2a83a38cd57c501af3ad2c91f189512060524424ffc2b818c9920db15cd247a9d47cf5a789d63c6\",\nuri=\"/CustomerData-30/CustomerDataService.asmx\", qop=\"auth\",\nalgorithm=\"MD5-sess\", nc=00000001, cnonce=\"393a8abf65cd20f85ffdf46a9273b28b\",\nresponse=\"854bf54261112caf2e86652276cb2ce6\",\nopaque=\"1704373a505e74c4ec692978e5c1a539\"[\\r][\\n]\"\n2005/05/13 11:05:21:293 EDT [DEBUG] header - >> \"[\\r][\\n]\"\n2005/05/13 11:05:21:994 EDT [DEBUG] header - << \"HTTP/1.1 200 OK[\\r][\\n]\"HTTP\nresult: 200\n\n===========================================================\n\ncommons-httpclient-3.0-rc2 (does not work):\n2005/05/13 11:16:54:881 EDT [DEBUG] DefaultHttpParams - -Set parameter\nhttp.useragent = Jakarta Commons-HttpClient/3.0-rc2\n2005/05/13 11:16:54:881 EDT [DEBUG] DefaultHttpParams - -Set parameter\nhttp.protocol.version = HTTP/1.1\n2005/05/13 11:16:54:881 EDT [DEBUG] DefaultHttpParams - -Set parameter\nhttp.connection-manager.class = class\norg.apache.commons.httpclient.SimpleHttpConnectionManager\n2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter\nhttp.protocol.cookie-policy = rfc2109\n2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter\nhttp.protocol.element-charset = US-ASCII\n2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter\nhttp.protocol.content-charset = ISO-8859-1\n2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter\nhttp.method.retry-handler =\norg.apache.commons.httpclient.DefaultHttpMethodRetryHandler@5048d78c\n2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter\nhttp.dateparser.patterns = [EEE, dd MMM yyyy HH:mm:ss zzz, EEEE, dd-MMM-yy\nHH:mm:ss zzz, EEE MMM d HH:mm:ss yyyy, EEE, dd-MMM-yyyy HH:mm:ss z, EEE,\ndd-MMM-yyyy HH-mm-ss z, EEE, dd MMM yy HH:mm:ss z, EEE dd-MMM-yyyy HH:mm:ss z,\nEEE dd MMM yyyy HH:mm:ss z, EEE dd-MMM-yyyy HH-mm-ss z, EEE dd-MMM-yy HH:mm:ss\nz, EEE dd MMM yy HH:mm:ss z, EEE,dd-MMM-yy HH:mm:ss z, EEE,dd-MMM-yyyy HH:mm:ss\nz, EEE, dd-MM-yyyy HH:mm:ss z]\n2005/05/13 11:16:54:911 EDT [DEBUG] HttpClient - -Java version: 1.3.1\n2005/05/13 11:16:54:911 EDT [DEBUG] HttpClient - -Java vendor: IBM Corporation\n2005/05/13 11:16:54:911 EDT [DEBUG] HttpClient - -Java class path: \n2005/05/13 11:16:54:941 EDT [DEBUG] HttpClient - -Operating system name: Windows XP\n2005/05/13 11:16:54:941 EDT [DEBUG] HttpClient - -Operating system architecture: x86\n2005/05/13 11:16:54:941 EDT [DEBUG] HttpClient - -Operating system version: 5.1\n2005/05/13 11:16:54:941 EDT [DEBUG] HttpClient - -SUN 1.2: SUN (DSA\nkey/parameter generation; DSA signing; SHA-1, MD5 digests; SecureRandom; X.509\ncertificates; JKS keystore)\n2005/05/13 11:16:54:951 EDT [DEBUG] HttpClient - -SunJCE 1.22: SunJCE Provider\n(implements DES, Triple DES, Blowfish, PBE, Diffie-Hellman, HMAC-MD5, HMAC-SHA1)\n2005/05/13 11:16:54:951 EDT [DEBUG] HttpClient - -SunJSSE 1.0303: Sun JSSE\nprovider(implements RSA Signatures, PKCS12, SunX509 key/trust factories, SSLv3,\nTLSv1)\n2005/05/13 11:16:54:961 EDT [DEBUG] HttpConnection - -Open connection to\nmappoint-css.partners.extranet.microsoft.com:443\n2005/05/13 11:17:00:629 EDT [DEBUG] header - ->> \"GET\n/CustomerData-30/CustomerDataService.asmx HTTP/1.1[\\r][\\n]\"\n2005/05/13 11:17:00:629 EDT [DEBUG] HttpMethodBase - -Adding Host request header\n2005/05/13 11:17:00:639 EDT [DEBUG] header - ->> \"User-Agent: Jakarta\nCommons-HttpClient/3.0-rc2[\\r][\\n]\"\n2005/05/13 11:17:00:639 EDT [DEBUG] header - ->> \"Host:\nmappoint-css.partners.extranet.microsoft.com[\\r][\\n]\"\n2005/05/13 11:17:00:639 EDT [DEBUG] header - ->> \"[\\r][\\n]\"\n2005/05/13 11:17:00:989 EDT [DEBUG] header - -<< \"HTTP/1.1 401 Unauthorized[\\r][\\n]\"\n2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< \"Content-Length: 1656[\\r][\\n]\"\n2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< \"Content-Type: text/html[\\r][\\n]\"\n2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< \"Server: Microsoft-IIS/6.0[\\r][\\n]\"\n2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< \"WWW-Authenticate: Digest\nqop=\"auth\",algorithm=MD5-sess,nonce=\"c66759cace57c5016cf5645c6dee5b649ed29067f652939d6aaf7239310bb333eeb0153783ae445f\",opaque=\"e7e259c137b65766c971d6cfc4115789\",charset=utf-8,realm=\"Digest\"[\\r][\\n]\"\n2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< \"X-Powered-By: ASP.NET[\\r][\\n]\"\n2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< \"Date: Fri, 13 May 2005\n15:16:51 GMT[\\r][\\n]\"\n2005/05/13 11:17:00:999 EDT [DEBUG] HttpMethodDirector - -Authorization required\n2005/05/13 11:17:01:009 EDT [DEBUG] AuthChallengeProcessor - -Supported\nauthentication schemes in the order of preference: [ntlm, digest, basic]\n2005/05/13 11:17:01:009 EDT [DEBUG] AuthChallengeProcessor - -Challenge for ntlm\nauthentication scheme not available\n2005/05/13 11:17:01:009 EDT [INFO] AuthChallengeProcessor - -digest\nauthentication scheme selected\n2005/05/13 11:17:01:009 EDT [DEBUG] AuthChallengeProcessor - -Using\nauthentication scheme: digest\n2005/05/13 11:17:01:009 EDT [DEBUG] AuthChallengeProcessor - -Authorization\nchallenge processed\n2005/05/13 11:17:01:009 EDT [DEBUG] HttpMethodDirector - -Authentication scope:\nDIGEST 'Digest'@mappoint-css.partners.extranet.microsoft.com:443\n2005/05/13 11:17:01:009 EDT [DEBUG] HttpMethodDirector - -Retry authentication\n2005/05/13 11:17:01:019 EDT [DEBUG] HttpMethodBase - -Resorting to protocol\nversion default close connection policy\n2005/05/13 11:17:01:019 EDT [DEBUG] HttpMethodBase - -Should NOT close\nconnection, using HTTP/1.1\n2005/05/13 11:17:01:019 EDT [DEBUG] HttpConnection - -Connection is locked. \nCall to releaseConnection() ignored.\n2005/05/13 11:17:01:019 EDT [DEBUG] HttpMethodDirector - -Authenticating with\nDIGEST 'Digest'@mappoint-css.partners.extranet.microsoft.com:443\n2005/05/13 11:17:01:019 EDT [DEBUG] HttpMethodParams - -Credential charset not\nconfigured, using HTTP element charset\n2005/05/13 11:17:01:019 EDT [DEBUG] DigestScheme - -Using qop method auth\n2005/05/13 11:17:01:019 EDT [DEBUG] HttpConnection - -Connection is stale,\nclosing...\n2005/05/13 11:17:01:019 EDT [DEBUG] HttpConnection - -Open connection to\nmappoint-css.partners.extranet.microsoft.com:443\n2005/05/13 11:17:01:110 EDT [DEBUG] header - ->> \"GET\n/CustomerData-30/CustomerDataService.asmx HTTP/1.1[\\r][\\n]\"\n2005/05/13 11:17:01:110 EDT [DEBUG] HttpMethodBase - -Adding Host request header\n2005/05/13 11:17:01:110 EDT [DEBUG] header - ->> \"User-Agent: Jakarta\nCommons-HttpClient/3.0-rc2[\\r][\\n]\"\n2005/05/13 11:17:01:110 EDT [DEBUG] header - ->> \"Authorization: Digest\nusername=\"domain\\user\", realm=\"Digest\",\nnonce=\"c66759cace57c5016cf5645c6dee5b649ed29067f652939d6aaf7239310bb333eeb0153783ae445f\",\nuri=\"/CustomerData-30/CustomerDataService.asmx\",\nresponse=\"9cab4fcdb2d09f57523aec80d7b51e95\", qop=\"auth\", nc=00000001,\ncnonce=\"b27507ee79c880b2bb565d363598ce07\", algorithm=\"MD5-sess\",\nopaque=\"e7e259c137b65766c971d6cfc4115789\"[\\r][\\n]\"\n2005/05/13 11:17:01:120 EDT [DEBUG] header - ->> \"Host:\nmappoint-css.partners.extranet.microsoft.com[\\r][\\n]\"\n2005/05/13 11:17:01:120 EDT [DEBUG] header - ->> \"[\\r][\\n]\"\n2005/05/13 11:17:01:540 EDT [DEBUG] header - -<< \"HTTP/1.1 401 Unauthorized[\\r][\\n]\"\n2005/05/13 11:17:01:540 EDT [DEBUG] header - -<< \"Content-Length: 1539[\\r][\\n]\"\n2005/05/13 11:17:01:540 EDT [DEBUG] header - -<< \"Content-Type: text/html[\\r][\\n]\"\n2005/05/13 11:17:01:550 EDT [DEBUG] header - -<< \"Server: Microsoft-IIS/6.0[\\r][\\n]\"\n2005/05/13 11:17:01:550 EDT [DEBUG] header - -<< \"WWW-Authenticate: Digest\nqop=\"auth\",algorithm=MD5-sess,nonce=\"3296b0dace57c5012fe314f8c6f8cafd10abc7a61c09484b2be5c7ef19ecb3c080da1f82c3f5a532\",opaque=\"87578a7f0871280654aed868cb9497fb\",charset=utf-8,realm=\"Digest\"[\\r][\\n]\"\n2005/05/13 11:17:01:550 EDT [DEBUG] header - -<< \"X-Powered-By: ASP.NET[\\r][\\n]\"\n2005/05/13 11:17:01:550 EDT [DEBUG] header - -<< \"Date: Fri, 13 May 2005\n15:17:19 GMT[\\r][\\n]\"\n2005/05/13 11:17:01:550 EDT [DEBUG] HttpMethodDirector - -Authorization required\n2005/05/13 11:17:01:550 EDT [DEBUG] AuthChallengeProcessor - -Using\nauthentication scheme: digest\n2005/05/13 11:17:01:550 EDT [DEBUG] AuthChallengeProcessor - -Authorization\nchallenge processed\n2005/05/13 11:17:01:550 EDT [DEBUG] HttpMethodDirector - -Authentication scope:\nDIGEST 'Digest'@mappoint-css.partners.extranet.microsoft.com:443\n2005/05/13 11:17:01:550 EDT [DEBUG] HttpMethodDirector - -Credentials required\nHTTP result: 401\n2005/05/13 11:17:01:550 EDT [DEBUG] HttpMethodDirector - -Credentials provider\nnot available\n2005/05/13 11:17:01:580 EDT [INFO] HttpMethodDirector - -Failure authenticating\nwith DIGEST 'Digest'@mappoint-css.partners.extranet.microsoft.com:443\n2005/05/13 11:17:01:580 EDT [DEBUG] HttpMethodBase - -Buffering response body\n2005/05/13 11:17:01:580 EDT [DEBUG] HttpMethodBase - -Resorting to protocol\nversion default close connection policy\n2005/05/13 11:17:01:580 EDT [DEBUG] HttpMethodBase - -Should NOT close\nconnection, using HTTP/1.1\n2005/05/13 11:17:01:580 EDT [DEBUG] HttpConnection - -Releasing connection back\nto connection manager.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-54",
        "summary": "Handle Null Arguments consistantly",
        "description": "Consider throwing a NullPointerException or InvalidArgumentException for null\nargument when they are not allowed.  Be consistant and document behaviour.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-536",
        "summary": "misleading lack of javadoc in StringRequestEntity",
        "description": "When using httpclient2, we were doing the following:\n\n\t// Add the Content-type header.  This sets the charset to UTF-8.\n\tmethod.setRequestHeader( \"Content-type\", \"text/xml; charset=UTF-8\" );\n\t// The given string is converted internally by the post method into\n\t// a UTF-8 encoded byte array.\n\tmethod.setRequestBody( xmlstring );\n\nThe comments show that this was the way we used to obtain a UTF-8 encoded XML\ndocument (if this was wrong, that may be the origin of the problem?).\n\n\nWhen upgrading to httpclient3 and killing deprecated code, this was converted to:\n\n\t// Add the Content-type header.  This sets the charset to UTF-8.\n\tmethod.setRequestHeader( \"Content-type\", \"text/xml; charset=UTF-8\" );\n\t// The given string is converted internally by the post method into\n\t// a UTF-8 encoded byte array.\n        method.setRequestEntity( new StringRequestEntity( xmlstring ) );\n\nwhich went without problem during the tests on my machine and on test production\nmachine.. because platforms charset were UTF-8, which is not the case for\nproduction machines :(\n\nI think the javadoc of the used StringRequestEntity constructor should strongly\nstate that it uses String#getBytes for the content, which uses the platform\ncharset. Also, I didn't notice any \"upgrade to 3.x\" documentation which would\nhave helped me :/",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-124",
        "summary": "MultipartPost closes input stream",
        "description": "This is something of a collection of issues that are all interrelated.\n\n1. MultipartPost calls close on the outputstream it retrieved from \nHttpConnection which causes an exception to be thrown later on.  This call \nshould be replaced with a call to flush().\n\n2. The MultipartPost classes do not have any logging in them.  We should add \ntrace statements at a minimum.\n\n3. new FilePart(String, File) throws a null pointer exception.\n\n4. The tests in TestPartsNoHost are broken.\n\nI'll attach patches for these fixes in a moment, broken down as much as \npossible.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-156",
        "summary": "NullPointerException thrown when invalid header encountered",
        "description": "If a server returns a header with no name but with a value (ie: an invalid line in the headers), HttpClient throws a NullPointerException instead of just skipping that header line or perhaps treating it as a continuation of the previous header (need to consult the RFC to confirm this).\n\nProblem reported by Eduardo Francos on the commons-user list.\n\nA good test URL for this problem is:\n\nhttp://www.pc.ibm.com/us/accessories/monitors/p_allmodelos.html\n\nwhich should return a 404 error but throws the NullPointerException instead.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-22",
        "summary": "shouldn't automatically set Content-Length in request header",
        "description": "currently, httpclient automatically add Content-Length: 0 in the request \nheader, this is causing problems with some web servers, particularly, with\n\nar.atwola.com\n\nTry the following URL\nhttp://ar.atwola.com/file/adsWrapper.js\n\nIt will block indefinitely. This problem can be fixed by not sending the \nContent-Length header, this is the browser's behavior. I'm not sure why this \ncasue problem, but let's conform to a standard browser's practice and avoid \ntroubles.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-113",
        "summary": "NullPointerException in HttpMethodBase.getResponseBodyAsString",
        "description": "The following code in a cocoon component, causes the NPE.\nA delay seems to help sometimes.\n\n-------------\n      int htcode = httpClient.executeMethod( method );\n       \n      // @todo: fix-me\n      // This sleep() is a temporary workaround \n      // to avoid NullPointerException in the next line.\n      Thread.currentThread().sleep( 100 ); \n\n      String ret = method.getResponseBodyAsString();\n---------------------\n\njava.lang.NullPointerException \nat java.lang.String.<init>(String.java:399) \nat org.apache.commons.httpclient.HttpMethodBase.getResponseBodyAsString\n(HttpMethodBase.java:579) \nat org.apache.cocoon.generation.WebServiceProxyGenerator.fetch\n(WebServiceProxyGenerator.java:264)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1097",
        "summary": "BrowserCompatHostnameVerifier and StrictHostnameVerifier should handle wildcards in SSL certificates better",
        "description": "I ran into a problem with SSL wildcard certificates in the class BrowserCompatHostnameVerifier. It handles \"*.example.org\" fine but \"server*.example.org\" fails to work correctly. The javadoc claims that it should behave the same way as curl and FireFox. In Firefox an SSL certificate for \"server*.example.org\" works fine for the host \"server.example.org\", using HttpClient it throws an exception.\n\nHere is an example test (JUnit4):\n\npackage org.example.hb;\n\nimport javax.net.ssl.SSLException;\n\nimport org.apache.http.conn.ssl.BrowserCompatHostnameVerifier;\nimport org.junit.Test;\n\npublic class BrowserCompatHostnameVerifierTest {\n\n\t/**\n\t * Should not throw an exeption in the verify method.\n\t * @throws SSLException\n\t */\n\t@Test\n\tpublic void testVerifyStringStringArrayStringArray() throws SSLException\n\t{\n\t\tBrowserCompatHostnameVerifier hv = new BrowserCompatHostnameVerifier();\n\t\tString host = \"www.example.org\";\n\t\tString[] cns = {\"www*.example.org\"};\n\t\t\n\t\thv.verify(host, cns, cns);\n\t}\n\n}",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1087",
        "summary": "Proxy authentication error: Unexpected state: MSG_TYPE3_GENERATED when using NTLM authentication",
        "description": "Trying to connect to a website that requires basic authentication through a proxy that requires NTLM authentication.\n\nProxy authentication fails with \"Proxy authentication error: Unexpected state: MSG_TYPE3_GENERATED\".\n\nFull wire log attached.  Code to replicate problem follows:\n\n    private void execute() throws HttpException, IOException {\n    \t\n    \tURL targetUrl = new URL(TARGET_URL);\n    \t\n        DefaultHttpClient httpclient = new DefaultHttpClient();\n\n        HttpHost targetHost = new HttpHost(targetUrl.getHost()); \n        HttpHost proxyHost = new HttpHost(PROXY_HOST, PROXY_PORT); \n        \n        httpclient.getParams().setParameter(ConnRoutePNames.DEFAULT_PROXY, \n        \t\tproxyHost);\n\n        CredentialsProvider credProvider = httpclient.getCredentialsProvider();\n        \n        Credentials proxyCredentials = new NTCredentials(PROXY_USER, \n        \t\tPROXY_PASSWORD, PROXY_MACHINE, PROXY_DOMAIN);\n        AuthScope proxyAuthScope = new AuthScope(proxyHost.getHostName(),\n        \t\tproxyHost.getPort());\n        \n        credProvider.setCredentials(proxyAuthScope, proxyCredentials);\n        \n        Credentials targetCredentials = new UsernamePasswordCredentials(\n        \t\tTARGET_USER, TARGET_PASSWORD);\n        AuthScope targetAuthScope = new AuthScope(targetHost.getHostName(),\n        \t\ttargetHost.getPort());\n        \n        credProvider.setCredentials(targetAuthScope, targetCredentials);\n      \n        HttpGet httpget = new HttpGet(targetUrl.getPath());\n\n        HttpResponse response = httpclient.execute(targetHost, httpget);\n        \n        System.out.println(\"response = \" + response);\n        \n       \n    }\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-325",
        "summary": "Deadlock with MultiThreadedHttpConnectionManager",
        "description": "I'm getting a dealock with the MultiThreadedHttpConnectionManager. Usually, it\nworks fine, but when a web page is redirected, it blocks. \n\nLudovic.\n\n[ERROR] Redirect to http://sourceforge.net/\nFull thread dump Java HotSpot(TM) Client VM (1.4.2_03-b02 mixed mode):\n\n\"MultiThreadedHttpConnectionManager cleanup\" daemon prio=5 tid=0x02d566f0\nnid=0xe14 in Object.wait() [2e9f000..2e9fd8c]\n        at java.lang.Object.wait(Native Method)\n        - waiting on <0x10513be8> (a java.lang.ref.ReferenceQueue$Lock)\n        at java.lang.ref.ReferenceQueue.remove(Unknown Source)\n        - locked <0x10513be8> (a java.lang.ref.ReferenceQueue$Lock)\n        at java.lang.ref.ReferenceQueue.remove(Unknown Source)\n        at\norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ReferenceQueueThread.run(MultiThreadedHttpConnectionManager.java:805)\n\n\"Signal Dispatcher\" daemon prio=10 tid=0x0003da00 nid=0xd44 waiting on condition\n[0..0]\n\n\"Finalizer\" daemon prio=9 tid=0x009bca30 nid=0xce8 in Object.wait()\n[2b5f000..2b5fd8c]\n        at java.lang.Object.wait(Native Method)\n        - waiting on <0x10504b80> (a java.lang.ref.ReferenceQueue$Lock)\n        at java.lang.ref.ReferenceQueue.remove(Unknown Source)\n        - locked <0x10504b80> (a java.lang.ref.ReferenceQueue$Lock)\n        at java.lang.ref.ReferenceQueue.remove(Unknown Source)\n        at java.lang.ref.Finalizer$FinalizerThread.run(Unknown Source)\n\n\"Reference Handler\" daemon prio=10 tid=0x009bb600 nid=0xfa4 in Object.wait()\n[2b1f000..2b1fd8c]\n        at java.lang.Object.wait(Native Method)\n        - waiting on <0x10504be8> (a java.lang.ref.Reference$Lock)\n        at java.lang.Object.wait(Unknown Source)\n        at java.lang.ref.Reference$ReferenceHandler.run(Unknown Source)\n        - locked <0x10504be8> (a java.lang.ref.Reference$Lock)\n\n\"main\" prio=5 tid=0x00035e28 nid=0xf68 in Object.wait() [7f000..7fc3c]\n        at java.lang.Object.wait(Native Method)\n        - waiting on <0x105170e8> (a\norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ConnectionPool)\n        at\norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager.doGetConnection(MultiThreadedHttpConnectionManager.java:388)\n        - locked <0x105170e8> (a\norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ConnectionPool)\n        at\norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager.getConnection(MultiThreadedHttpConnectionManager.java:296)\n        at\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:645)\n        at\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:529)\n        at net.sourceforge.cvsgrab.WebBrowser.executeMethod(WebBrowser.java:201)\n        at net.sourceforge.cvsgrab.WebBrowser.getResponse(WebBrowser.java:257)\n        at net.sourceforge.cvsgrab.WebBrowser.getDocument(WebBrowser.java:295)\n        at\nnet.sourceforge.cvsgrab.CvsWebInterface.loadDocument(CvsWebInterface.java:111)\n        at\nnet.sourceforge.cvsgrab.CvsWebInterface.getDocumentForDetect(CvsWebInterface.java:216)\n        at\nnet.sourceforge.cvsgrab.CvsWebInterface.findInterface(CvsWebInterface.java:86)\n        at net.sourceforge.cvsgrab.CVSGrab.detectWebInterface(CVSGrab.java:688)\n        at net.sourceforge.cvsgrab.CVSGrab.grabCVSRepository(CVSGrab.java:616)\n        at net.sourceforge.cvsgrab.CVSGrab.run(CVSGrab.java:317)\n        at net.sourceforge.cvsgrab.CVSGrab.main(CVSGrab.java:206)\n\n\"VM Thread\" prio=5 tid=0x009f76d0 nid=0x550 runnable\n\n\"VM Periodic Task Thread\" prio=10 tid=0x009f8208 nid=0x560 waiting on condition\n\"Suspend Checker Thread\" prio=10 tid=0x009bed88 nid=0xe84 runnable",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-992",
        "summary": "cache should not generate stale responses to requests explicitly requesting first-hand or fresh ones",
        "description": "The current implementation will serve a stale response in the case that it has a stale cache entry but revalidation with the origin fails. However, the RFC says we SHOULD NOT do this if the client explicitly requested a first-hand or fresh response (via no-cache, max-age, max-stale, or min-fresh).\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1009",
        "summary": "http client cache: SizeLimitedResponseReader is not setting content type for InputStreamEntity in constructResponse()",
        "description": "the newly created InputStreamEntity should be populated with content-encoding and content-type.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-176",
        "summary": "Unusual Http status line",
        "description": "The web server at http://alces.med.umn.edu/Candida.html returns the following\nstatus line:\n\nHTTP 200 Document follows\n\nThis page loads in the 3 browsers I tried (though Safari actually rendered the\nheaders).  The current version of HttpClient reads through the whole page\nlooking for a line that starts with HTTP/.  I don't know how big of a problem\nthis is, but it's a fairly easy fix.  Patch to follow.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-177",
        "summary": "reusing connections is unreliable",
        "description": "HttpConnection reuse is unreliable. Because of the following:\n\n1) There is currently no way to determine if a connection is still open on the\nserver side.\n2) If an IOException occurs while writing to a connection it cannot be reused.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-583",
        "summary": "Build.xml - add log level definitions",
        "description": "The default log level is debug, which produces quite a lot of output when testing.\n\nThe patch allows separate definition of wire and other log levels (assuming SimpleLog is used)",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-405",
        "summary": "HostConfiguration.setHost(String) causes NullPointerException",
        "description": "Calling setHost(String) on a HostConfiguration object causes a null pointer\nexception.\n\nAs far as I can tell, this is due to it incorrectly calling the deprecated\nsetHost(String, String, int, Protocol) method, rather than setHost(String, int,\nProtocol)\n\nSo:\n\npublic synchronized void setHost(final String host) {\n  Protocol defaultProtocol = Protocol.getProtocol(\"http\"); \n  setHost(host, null, defaultProtocol.getDefaultPort(), defaultProtocol);\n}\n\nshould become :\n\npublic synchronized void setHost(final String host) {\n    Protocol defaultProtocol = Protocol.getProtocol(\"http\"); \n    setHost(host, defaultProtocol.getDefaultPort(), defaultProtocol);\n}",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-772",
        "summary": "typo in RFC reference in web site",
        "description": "Quoting from <http://hc.apache.org/httpcomponents-client/index.html>:\n\n\"Standards Compliance\n\nHttpClient strives to conform to the following specifications endorsed by the Internet Engineering Task Force (IETF) and the internet at large:\n\n    * RFC 1945 - Hypertext Transfer Protocol -- HTTP/1.0\n    * RFC 2116 - Hypertext Transfer Protocol -- HTTP/1.1\n    * RFC2617 HTTP Authentication: Basic and Digest Access Authentication\n    * RFC2109 HTTP State Management Mechanism (Cookies)\n    * RFC2965 HTTP State Management Mechanism (Cookies v2)\"\n\nNote the typo in the reference to HTTP/1.1.\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-985",
        "summary": "cache module should populate Via header to capture upstream and downstream protocols",
        "description": "Because the cache module is currently implemented as a decorator that behaves like a transparent caching proxy, we need it to correctly populate the Via header so that we can preserve the record of which protocol versions were used upstream and downstream from the caching module.\n\nThis is a MUST per the RFC:\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.45",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-260",
        "summary": "Authentication does not respond to stale nonce",
        "description": "When using digest authentication, HTTP allows the server to mark the nonce value\nas stale. The client then must re-authenticate with a new nonce value provided\nby the server. Currently, HttpClient does not support this functionality. I've\ncreated a patch that allows HttpClient to support stale nonce values. It is\nattached below. The patch should be applied to HttpMethodBase.java\n\n\n***\n/home/scohen/downloads/httpclient-src/commons-httpclient-2.0-rc1/src/java/org/apache/commons/httpclient/HttpMethodBase.java\n2003-07-31 22:15:26.000000000 -0400\n--- org/apache/commons/httpclient/HttpMethodBase.java   2003-08-20\n17:22:52.000000000 -0400\n***************\n*** 1351,1384 ****\n       *\n       * @throws IOException when errors occur reading or writing to/from the\n       *         connection\n       * @throws HttpException when a recoverable error occurs\n       */\n!     protected void addAuthorizationRequestHeader(HttpState state,\n!                                                  HttpConnection conn)\n!     throws IOException, HttpException {\n!         LOG.trace(\"enter HttpMethodBase.addAuthorizationRequestHeader(\"\n!                   + \"HttpState, HttpConnection)\");\n   \n          // add authorization header, if needed\n!         if (getRequestHeader(HttpAuthenticator.WWW_AUTH_RESP) == null) {\n!             Header[] challenges = getResponseHeaderGroup().getHeaders(\n!                                                HttpAuthenticator.WWW_AUTH);\n!             if (challenges.length > 0) {\n!                 try {\n!                     AuthScheme authscheme =\nHttpAuthenticator.selectAuthScheme(challenges);\n                      HttpAuthenticator.authenticate(authscheme, this, conn, state);\n!                 } catch (HttpException e) {\n!                     // log and move on\n!                     if (LOG.isErrorEnabled()) {\n!                         LOG.error(e.getMessage(), e);\n!                     }\n                  }\n              }\n          }\n      }\n                                                                                \n      /**\n       * Adds a <tt>Content-Length</tt> or <tt>Transfer-Encoding: Chunked</tt>\n       * request header, as long as no <tt>Content-Length</tt> request header\n       * already exists.\n       *\n--- 1351,1391 ----\n       *\n       * @throws IOException when errors occur reading or writing to/from the\n       *         connection\n       * @throws HttpException when a recoverable error occurs\n       */\n!     protected void addAuthorizationRequestHeader(HttpState state,\nHttpConnection conn)\n!         throws IOException, HttpException {\n!         LOG.trace(\"enter HttpMethodBase.addAuthorizationRequestHeader(\" +\n\"HttpState, HttpConnection)\");\n                                                                                \n          // add authorization header, if needed\n!\n!         Header[] challenges =\ngetResponseHeaderGroup().getHeaders(HttpAuthenticator.WWW_AUTH);\n!         if (challenges.length > 0) {\n!\n!             try {\n!                 AuthScheme authscheme =\nHttpAuthenticator.selectAuthScheme(challenges);\n!                 if (getRequestHeader(HttpAuthenticator.WWW_AUTH_RESP) == null\n!                     || isNonceStale(authscheme) ) {\n                      HttpAuthenticator.authenticate(authscheme, this, conn, state);\n!                 }\n!             } catch (HttpException e) {\n!                 // log and move on\n!                 if (LOG.isErrorEnabled()) {\n!                     LOG.error(e.getMessage(), e);\n                  }\n              }\n          }\n      }\n                                                                                \n+\n+     private boolean isNonceStale(AuthScheme authscheme) {\n+         return authscheme.getSchemeName().equalsIgnoreCase(\"digest\")\n+             && \"true\".equalsIgnoreCase(authscheme.getParameter(\"stale\"));\n+     }\n+\n+\n      /**\n       * Adds a <tt>Content-Length</tt> or <tt>Transfer-Encoding: Chunked</tt>\n       * request header, as long as no <tt>Content-Length</tt> request header\n       * already exists.\n       *\n***************\n*** 2419,2430 ****\n                  buffer.append(port);\n              }\n              buffer.append('#');\n              buffer.append(authscheme.getID());\n              String realm = buffer.toString();\n!\n              if (realmsUsed.contains(realm)) {\n                  if (LOG.isInfoEnabled()) {\n                      LOG.info(\"Already tried to authenticate to \\\"\"\n                               + realm + \"\\\" but still receiving \"\n                               + statusCode + \".\");\n                  }\n--- 2426,2442 ----\n                  buffer.append(port);\n              }\n              buffer.append('#');\n              buffer.append(authscheme.getID());\n              String realm = buffer.toString();\n!\n!                       // check to see if the server has made our nonce stale.\n!                       // if it has, re-auth\n              if (realmsUsed.contains(realm)) {\n+               if ( isNonceStale(authscheme)) {\n+                       return false;\n+               }\n                  if (LOG.isInfoEnabled()) {\n                      LOG.info(\"Already tried to authenticate to \\\"\"\n                               + realm + \"\\\" but still receiving \"\n                               + statusCode + \".\");\n                  }",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1028",
        "summary": "HttpClient Manual Simplified Chinese",
        "description": "During Nov 2010, The Chinese user Nanlei translated the Apache HttpClient manual into Chinese and contribute it to HttpClient project freely. In the future, the Chinese translation of HttpCore manual will be finished and contribute to HttpCore project freely too. ",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-895",
        "summary": "Log creation impairs performance",
        "description": "Running JProfiler on a program that uses HttpClient with a ThreadSafeClientConnManager, revealed that 5% of the time was spent constructing Log instances in class ClientParamsStack.\n\nOleg did some further investigation and found that DefaultRequestDirector also has the same problem.\n\nA simple solution would be to make the Log a static member variable, and do this on all classes for consistency.  However this might not be the best solution for interoperating with some frameworks (see http://wiki.apache.org/jakarta-commons/Logging/StaticLog)\n\nAnother solution would be to simply remove the Log from the affected classes, although they are presumably there for a reason...\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-797",
        "summary": "o.a.h.conn.scheme.PlainSocketFactory is not a true Singleton",
        "description": "The class \"org.apache.http.conn.scheme.PlainSocketFactory\" has a factory method, getSocketFactory(), and clearly indicates in the Javadocs that it expects to be a Singleton; however, the presence of public constructors makes it quite possible that this is not the case.\n\nTo protect the Singleton status of the class, the constructors should be private, or, at the very least, default (package) access. This will force access to the single instance through the factory method.",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-636",
        "summary": "Revise internal data structures of ThreadSafeClientConnManager",
        "description": "ThreadSafeClientConnManager internal data structures can be improved:\n- keep track of issued connections with weak references\n- use class derived from WeakReference instead of a lookup table for callbacks from ReferenceThread\n  (or drop ReferenceThread in favor of occasionally polling the issued connections for leaks)\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-745",
        "summary": "no classes with default visibility",
        "description": "There should be no classes with default (package) visibility. They cause problems when classes using them are extended. All classes should either be public, or nested with protected visibility where they are used. Nesting with private visibility may be acceptable in certain cases, for example in final classes.\n",
        "label": "NUG",
        "classified": "TASK",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-871",
        "summary": "Add FileBody constructor with explicit filename",
        "description": "FileBody does not allow the filename field in the Content-Disposition header to be overriden, the filename taken from the File object - I have software that creates temporary files and needs to assign an implicit logical filename.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-146",
        "summary": "Error from maven when generating the task list",
        "description": "This message scrolls by when runing the site:generate goal.\n\ntasklist:generate:\nNon-fatal error while parsing file:\n/home/jsdever/cvs-commit/jakarta-commons/httpclient/src/java/org/apache/commons/httpclient/HeaderElement.java\nNon-fatal error while parsing file:\n/home/jsdever/cvs-commit/jakarta-commons/httpclient/src/java/org/apache/commons/httpclient/URI.java",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1153",
        "summary": "org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage uses URL as cache key - shouldn't.",
        "description": "Spy memcached has 250 defined as max key length:\nhttp://dustin.github.com/java-memcached-client/apidocs/constant-values.html#net.spy.memcached.MemcachedClientIF.MAX_KEY_LENGTH\n\nURLs can be (and often are) much longer than 250 characters.\n\nURLs should be hashed before being used as keys.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-291",
        "summary": "Cookie docs are outdated.",
        "description": "The cookie docs do not reflect the latest code changes.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-360",
        "summary": "questionable default value for BufferedOutputStream size in HttpConnection",
        "description": "From the dev list\n\n--\n\nHi Eric\n\nThanks for bringing this up. HttpClient 3.0 allows for parameterization\nof SO_SNDBUF and SO_RCVBUF settings. For HttpClient 2.0 (as well as for\n3.0 when falling back onto the system defaults), however, it would make\nsense to set a cap on the size of the send and receive buffers.\n\nFeel free to open a ticket for this issue with Bugzilla\n\nOleg\n\n\nOn Fri, 2004-07-02 at 18:39, Eric Bloch wrote:\n\n>> Hi httpclient folks,\n>> \n>> I've been looking at 2.0 source code and the default value for the \n>> BufferedOutputStream that is used in an HttpConnectionn is coming from \n>> socket.getSendBufferSize().  My hunch, is that, in general, this is \n>> bigger than you'd want.\n>> \n>> Most HTTP \"sends\" are less than 1KByte ('cept for big POSTs).\n>> The default value I get for socket.getSendBufferSize for this is 8192.\n>> I would think a better default for this buffer would be 1K, no?\n>> \n>> Also, fyi, if someone happens to dork the system send buffer size hi \n>> (say MB) and you are using the MultiThreadedConnectionManager in 2.0 \n>> (dunno about 3.0), you will use up a lot of memory for each connection \n>> since the pool doesn't let idle connections (or their buffers) be gced. \n>>   I just got bit bad by that.\n>> \n>> -Eric\n>> \n>",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-713",
        "summary": "remove RoutedRequest from ClientRequestDirector interface",
        "description": "Remove the RoutedRequest from ClientRequestDirector.execute, pass the request and route/target separately.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-991",
        "summary": "cache module produces improperly formatted Warning header when revalidation fails",
        "description": "The warning header currently attached to a stale response by the caching module when validation with the origin server fails is not a properly-formatted Warning header.\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.46",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-95",
        "summary": "Proxy authentication does not handle multiple multiple authentication schemes",
        "description": "My proxy server returns the following header lines in the response:\n\n    Proxy-Authenticate: NTLM\n    Proxy-Authenticate: Basic realm=\"10.105.20.201\"\n\ni.e., it returns two Proxy-Authenticate header lines. Unfortunately this does \nnot work. In line 253 of class Authenticator (method: authenticate(HttpMethod, \nHttpState, Header, String)) I see this comment:\n\n    // FIXME: Note that this won't work if there is more than one realm within \nthe challenge\n\nso it looks like this is something that isn't yet implemented. In the log, I \ncan see that the Authenticator attempts to parse the realm, but it looks like\nthis is not being done correctly:\n\n   411 DEBUG Attempting to authenticate challenge: Proxy-Authenticate: NTLM, \nBasic realm=\"10.105.20.201\"\n\n   411 DEBUG Parsed realm \"ealm=\"10.105.20.201\" from challenge \"NTLM, Basic \nrealm=\"10.105.20.201\"\".\n   421 WARN  Exception thrown authenticating\njava.lang.UnsupportedOperationException: Authentication type \"NTLM,\" is not \nrecognized.\n    at org.apache.commons.httpclient.Authenticator.authenticate\n(Authenticator.java:274)\n    at org.apache.commons.httpclient.Authenticator.authenticateProxy\n(Authenticator.java:178)\n    at \norg.apache.commons.httpclient.HttpMethodBase.processAuthenticationResponse\n(HttpMethodBase.java:580)\n    at org.apache.commons.httpclient.HttpMethodBase.execute\n(HttpMethodBase.java:668)\n    at org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:355)\n    at com.cmg.httptest.Main.main(Main.java:34)\n\nIt looks wrong to me that the realm name seems to be parsed as: \nealm=\"10.105.20.201\n\nI understand that Authenticator does not know what NTLM is but I would like it \nto use Basic authentication in this case.\n\nIf there are more authentication methods possible, how can I specify which one \nI want to use?\n\nJesper de Jong",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-489",
        "summary": "Request is retried if preemptive authentication fails",
        "description": "Hello,\n\nI'm using premptive authentification from an Axis client using BASIC Http\nauthentification. When the user isn't authenticated/authorized by server (in my\ncase, credentials are expired), httpclient runs a \"Chalenge\" that produces a\nsecond request to server with same credentials.\n\nwhen using preemptive mode, chalenge should be skipped if authentication scheme\nhasn't changed !",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-334",
        "summary": "Per socket SOCKS proxies",
        "description": "HttpClient requires a way of allowing a SOCKS proxy to be used on some\nconnections without requiring that all created Sockets go through the proxy.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-190",
        "summary": "SetCookie / DateParser failing to parse non-standard date format",
        "description": "I'm receiving the following expiration date in SetCookie which DateParser \ndoesn't handle:\n\nexpires=Sat,19-Apr-03 04:28:07 GMT\n\nThe lack of a space between ',' and '19' is causing the problem. Is it possible \nto add the following lines to DatePattern?\n\n\"EEE,dd-MMM-yy HH:mm:ss z\"\n\"EEE,dd-MMM-yyyy HH:mm:ss z\"",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-99",
        "summary": "Requests are retried 3 times unconditionaly",
        "description": "Using the 20020811 tarball and jdk1.4.0, a get or post will retry as soon\nas it finishes sending the request. I turned on logging and verified that\nas soon as the last \\r\\n hits the wire, it starts on the next retry. For\nexample:\n\n08-10 09:53:12 [main] httpclient.wire: >> [\\r\\n]\n08-10 09:53:12 [main] httpclient.methods.PostMethod: enter\nPostMethod.writeRequestBody(HttpState, HttpConnection)\n08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter\nHttpConnection.write(byte[], int, int)\n08-10 09:53:12 [main] commons.httpclient.HttpMethod: Attempt number 3 to write\nrequest\n08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter\nHttpMethodBase.writeRequest(HttpState, HttpConnection)\n08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter\nHttpMethodBase.writeRequestLine(HttpState, HttpConnection)\n08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter\nHttpMethodBase.generateRequestLine(HttpConnection, String, String, String,\nString)\n08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter\nHttpConnection.print(String)\n08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter\nHttpConnection.write(byte[])\n08-10 09:53:12 [main] httpclient.wire: >> \"POST /lookup.jsp HTTP/1.1\" [\\r\\n]\n\nThe top line is the end of the second post and the last line is the start\nof the third post.\n\nTo make sure the server really wasn't sending something back, I wrote a\nquick server that would listen for a request and send a 404 as soon as it\nread a post or get line (but would keep reading and dumping info). In the\nhttpclient log, it still shoots off 3 requests before it receives the\nresponse and the server got all three requests. (client and server are\nrunning on the same machine)\n\nSo why is httpclient sending three requests without waiting for a\nresponse?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-317",
        "summary": "HTTP Client doesn't support multipart/related content-type",
        "description": "It is not possible to sent data easely as a multipart/related content-type (as \ndiscribed in rfc 2387) using Http Client.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-609",
        "summary": "Use TRACE logging instead of DEBUG for the absolute nitty-gritties",
        "description": "[This is basically a copy of the Spring improvement request SPR-2873: http://opensource.atlassian.com/projects/spring/browse/SPR-2873 )\n\nGiven a developer situation: Much of the DEBUG information in the log of HttpClient is very un-interesting as long as it works. Some of these lines are however of much bigger importance than others (thus turning off DEBUG globally for HttpClient isn't good either).\n\nTRACE and DEBUG are the two developer-centric logging levels of log4j and commons logging (the rest are \"production levels\"). Since log4j-1.2.12, TRACE have existed. Clogging have always had trace, but before release 1.1 mapped Log.trace to log4j's DEBUG, but 1.1 (released May 9. 2006) now maps to log4j's TRACE.\n\nI think that HttpClient's logging would benefit a lot by using TRACE level extensively, in that developers could turn all of httpclient's logging down to DEBUG, but still see \"major developer events\" like connections being opened, the request being sent, and e.g. the response's status line, size of headers and body, keep-alive vs. closing of connection.\n\nCandidates for TRACE level include:\n  * httpclient.wire.*\n  * org.apache.commons.httpclient.params.DefaultHttpParams\n  * org.apache.commons.httpclient.HttpMethodBase\n  * .. and probably a bunch of others that doesn't bring the developer in the standard \"good flow mode\" any highly interesting information. \n\nPlease note that I do NOT view these lines as worthless. It is however in _normal_ developer circumstances not valuable information, and it would ease development if it was possible to turn these ultra-verbose loglines off easily. When things just aren't working out, and your exciting REST-based query doesn't work out, or your charset encodings just doesn't give what you're expecting, you'd turn on TRACE to really get down to the hard core. You'd find the problem, fix it, and set it to DEBUG again.\n\nIn addition, the lines that were left on the DEBUG level should obviously be as informative as possible, and thus maybe somewhat more verbose than now, trying to \"aggregate\" some pieces of information that now are output over several DEBUG lines..\n\nI do realize that I could achive a lot of this with a rather extensive log configuration, that also had to include raw text filters, but I do believe that this affects more developers than me!\n\nPS: it wouldn't hurt either if all of httpclient's log-lines came from a common root, e.g. \"HttpClient\", or \"org.apache.commons.httpclient\", instead of having several roots. This would however be a somewhat \"backward incompatible\" change, since it now has (at least?) two roots.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-859",
        "summary": "BasicCookieStore treats cookies of the same name from the same host as duplicates, even if they have different paths",
        "description": "The DefaultHttpClient is not handling cookies correctly when a single host returns multiple cookies of the same name but with separate paths.  For example, if a single instance of the client is used to access two different webapps on the same server, it may receive two different JSESSIONID cookies:\n\nCookie: [version: 0][name: JSESSIONID][value: F832C01D23F501CE5EEB296B602700C1][domain: lglom139.example.com][path: /msa-adrenalina][expiry: null]\nCookie: [version: 0][name: JSESSIONID][value: 0FC660347391B93267168F84F2B520F5][domain: lglom139.example.com][path: /maps][expiry: null]\n\nBecause the CookieIdentityComparator class does not test the cookie path when determining equality, each new JSESSIONID received replaces the previous one instead of adding a new cookie to the store.  This results in \"disconnecting\" the client from its sessions on the prior webapps.\n\nI've confirmed that adding a path test to CookieIdentityComparator resolves this problem.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-975",
        "summary": "add support to caching module for RFC 5861 (stale-on-error and stale-while-revalidate)",
        "description": "These are Cache-Control extensions that allow an origin server to specify some additional behavior for stale cache entries. Stale-on-error configurations allow a cache to continue serving stale content for a certain period of time if a revalidation fails, and stale-while-revalidate similarly allows revalidation to occur asynchronously. Some reverse proxies such as Squid can be configured to understand these headers, which means that some origin servers are probably sending them, and that we can likewise take advantage of them.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-216",
        "summary": "Cookies with null path attribute are rejected in the compatibility mode",
        "description": "Weblogic sends cookies with path empty, httpclient emits a warning\nand doesn't send back the cookie to server.\n\nMaybe httpclient works in the RFC's ways but this doesn't reproduce\ncommon web browsers behaviours. Our application works well with IE,\nOpera and Netscape, httpunit also sends back the cookie to the server.\n\nWhen receving the response, httpclient emits the followin warning :\n\n[WARN] HttpMethod - -Invalid cookie header: \"JTD=O%\n2FdF13CDb1W7H2GNfUTS2YQ3Zt6bCW6ZKZRvVJ9FwaadQLxXVI7rgii%2FwbxeCsqym7dcWKDxSj%\n2Bg1ubJRSVRhYGb7wRLjp5c0v2R3QrCIXVhMKDjuwuXDXnjbH3LHSWG7bfzJSmS7nXk9R%\n2FqMIRHb5najLQkU7WkuPGgXUnUln%2BF51TajkVmXkrLMYN7MHDT48BEHvFQFNXBlmSRejWqrd%\n2Fiiao0flObOrT3HcaWI09B1vekpAcPmgvMD2oZzXQWJwjDZIX6QoVVD6U8CXPSvVQjITyaxf6AqaS%\n2BAFJgRsqbZBc0%2BV5G%2FnzE87ggOVIozfPFn99ny0kxiPGBEisJIy%3D%3D; Version=1; \nPath=; Max-Age=604800\". Missing value for path attribute\n\nThat's right, maybe the http header is not correct, but I think httpclient\nshould handle this case without error in order to have the same behaviour\nas common browsers. We have no way to give a better value to this path.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1005",
        "summary": "API surface of caching module can be reduced",
        "description": "While the caching module can currently be considered functional and useful for folks as-is, there are several near-term enhancements planned that could change the exposed binary API of the caching module (although it is not yet clear whether they would or not). In an effort to allow the 4.1 GA release to go forward while hedging bets against future development, we should consider drastically reducing the exposed binary API of the caching module, and not exposing extension points until someone explicitly asks for them.\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-740",
        "summary": "AbstractConnPool constructor calls thread.Start()",
        "description": "AbstractConnPool constructor calls thread.Start()\n\nFindbugs says:\n\nConstructor invokes Thread.start()\n\nThe constructor starts a thread. This is likely to be wrong if the class is ever extended/subclassed, since the thread will be started before the subclass constructor is started.\n\nThe class is not final (and the constructor is protected) which suggests that the class is intended to be extended...",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-729",
        "summary": "move HttpRoute and related classes to separate package",
        "description": "The route-related stuff in o.a.h.conn is detached from the rest of the connection management API.\nMove HttpRoute, RouteTracker, HttpRouteDirector, HttpRoutePlanner to o.a.h.conn.route or ...routing.\nImplementation classes have a dependency on Scheme and SchemeRegistry in o.a.h.conn,\nbut that does not introduce a recursive dependency between packages.\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-765",
        "summary": "String.toLowerCase() / toUpperCase() should specify Locale.ENGLISH",
        "description": "There are quite a few instances of String.toLowerCase() - and some of toUpperCase() - method calls which don't specify the Locale.\n\nThese should probably mostly/all use Locale.ENGLISH, otherwise there may be problems in some Locales.\ne.g. Turkey, where \"i\".toUpperCase() is not equal to \"I\" - and vice-versa.\n\nThe isSpecialDomain() method in NetscapeDomainHandler is one instance where the code won't always work in Turkey.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-31",
        "summary": "user need a way to control cookie policy",
        "description": "User need a way to control what cookie can be accepted and what should be \nrejected. It would be nice to provide a cookie filter interface, so the user \ncan change the cookie policy by implementing his own filter.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-674",
        "summary": "use VersionInfo of core",
        "description": "With core alpha5, a version detection scheme was introduced.\nReplace the preliminary version detection of client alpha1 with that in core.\nThat means new version.properties files, at least one per JAR, maybe one per potential JAR.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-981",
        "summary": "CachingHttpClient returns a 411 respones when executing a POST (HttpPost) request ",
        "description": "The CachingHttpClient validates requests prior executing them, by calling RequestProtocolCompliance.requestIsFatallyNonCompliant(..).\n\nWhen executing an HttpPost, this method considers the request is invalid because it does not contain (yet) a content-length header. Indeed, I observed that this header is generated at the time the DefaultHttpClient fires the request.\n\nNB: i'm using the Cache 4.1-alpha2 plugged over the HttpClient 4.0.1-final. I can't use the latest version for both because I need to rely on a stable version if there's any. I would be curious to know if we get the same behaviour in 4.1...\n\nAnyway, I would see two fixes for that issue:\n- make HttpPost set the content-length at the time the entity is set,\n- or remove the validation step on the CachingHttpClient side.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-368",
        "summary": "[PATCH]character encoding handling is invalid at multipart",
        "description": "Hi,\n\nCommons-Httpclient handle character encoding incorrect at multipart. This is \nsignificant problem for other than English people like me. Multipart has two \nencoding. First is header encoding which specify header of each part. Second \nis it's body encoding. Body encoding works well but header encoding is fixed \nas 'asc-ii'. This problem user following situation.\n\n* upload file which file name is described by other than \"asc-ii\".\n* use parameter which include other than \"asc-ii\" character.\n\nUnfortunately , It seems RFC doesn't define header encoding for multipart but \na lot of people needs set header encoding for thier own laungage. I attached\nthe patch. Please fix this problem.\n\nregards,\n\nTakashi Okamoto",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-693",
        "summary": "DEFAULT_HEADERS not added to subsequent requests",
        "description": "DEFAULT_HEADERS are added to the original request only, not to subsequent requests for redirects or authentication.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-103",
        "summary": "ChunkedInputStream incorrectly handles chunksize without semicolon",
        "description": "ChunkedInputStream does not correctly read the chunk size when a semicolon does\nnot appear in the first line of the chunk.  If whitespace exists between the\nchunk size value and the end of line and no semicolon is present, the whitespace\nis not removed before parseInt is called resulting in an IOException \"Bad chunk\nsize\"\n\nI can not tell from RFC2616 if whitespace is legal here, but I have received it\nfrom at least one web server.  The relevant section is 3.6.1.\n\nA small patch repairs the problem.  I will attach it immediately.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-497",
        "summary": "Logger (Category) names don't follow common pattern",
        "description": "The Wire class uses two loggers named unexpected. The \"org.apache.commons.\"\nprefix is missing - so you can't mute all debug level statements with a\none-liner in you log4j.properties for example:\n\n  log4j.logger.org.apache.commons.httpclient INFO\n\nYou have to add this, too:\n\n  log4j.logger.httpclient INFO\n\nPlease prepend the \"org.apache.commons.\" before both names.\n\nCheers,\nChristian\n\n<code>\nclass Wire {\n\n    public static Wire HEADER_WIRE = new\nWire(LogFactory.getLog(\"httpclient.wire.header\"));\n    \n    public static Wire CONTENT_WIRE = new\nWire(LogFactory.getLog(\"httpclient.wire.content\"));\n\n</code>\n\nhttp://svn.apache.org/viewcvs.cgi/jakarta/commons/proper/httpclient/trunk/src/java/org/apache/commons/httpclient/Wire.java?rev=155418&view=markup",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-283",
        "summary": "Invalid cookie causing IllegalArgumentException",
        "description": "The bug reported by Oliver K\u00c3\u00b6ll <listen at quimby.de> on HttpClient mailing list\n\n<quote>\nI'm dealing with a site that serves invalid Cookies in various kind of  \nways. In some cases the Cookie values contain \",\" characters, which  \nreally confuses the Header/Cookie parsers and eventually leads to  \nIllegalArgumentExceptions thrown by the Cookie constructor:\n\njava.lang.IllegalArgumentException: Cookie name may not be blank\n   at org.apache.commons.httpclient.Cookie.<init>(Cookie.java:142)\n   at  \norg.apache.commons.httpclient.cookie.CookieSpecBase.parse(CookieSpecBase \n.java:192)\n   at  \norg.apache.commons.httpclient.cookie.CookieSpecBase.parse(CookieSpecBase \n.java:256)\n   at  \norg.apache.commons.httpclient.HttpMethodBase.processResponseHeaders(Http \nMethodBase.java:1826)\n   at  \norg.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase \n.java:1939)\n   at  \norg.apache.commons.httpclient.HttpMethodBase.processRequest(HttpMethodBa \nse.java:2631)\n   at  \norg.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java \n:1085)\n   at  \norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:6 \n74)\n   at  \norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:5 \n29)\n   at my.code.Test.getHttp(Test.java:114)\n\nWhat bothers me, is that these IllegalArgumentExceptions are never  \ncaught in the HttpClient code, making it effectivily impossible to  \nhandle these responses.\n\n</quote>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-711",
        "summary": "bad route computed for redirected requests",
        "description": "BasicRouteDirector appears to miscalculate complex routes. Example to follow. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-15",
        "summary": "redirect not handled correctly if location header doesn't have a protocol",
        "description": "Http redirect is not handled correctly if the location header doesn't have a \nprotocol, e.g.:\n\nLocation: web/tbghome.nsf/pages/index\n\na java.net.MalformedURLException is throw in this case. The correct behavior is \nto inherit the protocol from current URL.\n\nThe relevant code is in HttpMethodBase.execute()",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-911",
        "summary": "Support underscore in domain name, or provide better exception",
        "description": "\nWhen calling on HttpClient.execute with a url that contain underscore ('_'), you get NullPointerException.\nTracing it down show that java.net.Uri complains that it is illegal name. Which is true according to the RFC.\nBut it seems that most browser allow it, and some companies support it.\n\nI think HttpClient should either support underscores, or atleast provide a better exception.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-104",
        "summary": "Incorrect debug message in HttpMethodBase",
        "description": "HttpMethodBase.addContentLengthRequestHeader has the wrong debug message.  See\nattached patch.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-236",
        "summary": "URI.normalize() error",
        "description": "code:\n\n----------------------------\nimport org.apache.commons.httpclient.URI;\n\nclass Main {\n  publi\u00f1 static void main(String[] args) throws Exception {\n    URI uri = new URI(\"http\", null, \"host\", -1, \"/tmp/../yo\", null, null);\n    uri.normalize();\n    System.out.println(uri);\n  }\n} /// end of Main\n----------------------------\n\nprints:\n\nhttp://host/tmp/../yo\n\ninstead of\n\nhttp://host/yo",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-178",
        "summary": "MultiThreadedHttpConnectionManager never reclaims unused connectons",
        "description": "There is no limit on the number of connections that will get created by the\nMultiThreadedHttpConnectionManager.  Unused connections are never destroyed.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-509",
        "summary": "need members of MultipartRequestEntity to be \"protected\" instead of \"private\" to make it extendable for multipart/related",
        "description": "As explained in the mailing-list[1], I'd like to have some of \nMultipartRequestEntity move from \"private\" visibility to \"protected\" visibility,\nto be able to extend as MultipartRelatedRequestEntity. Namely, the attribute\n\"parts\" and the method \"getMultipartBoundary\" would be needed.\n\nThank you.\n\n[1]\nhttp://mail-archives.apache.org/mod_mbox/jakarta-httpclient-dev/200510.mbox/%3c87irw18ndm.fsf@meuh.mnc.ch%3e",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-781",
        "summary": "Respect Keep-Alive Header",
        "description": "HttpClient currently does not respect the 'Keep-Alive' header tokens (timeout, max, etc..) and continues to use the persistent connection beyond limits the server requests.  This leads to failure and falling back to HttpRequestRetryHandler, when it should instead just use a new connection explicitly.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-53",
        "summary": "Handle Returning Null consistantly",
        "description": "Consider returning empty arrays instead of null consistantly.  eg:\ngetResponseBody().  There may be good reason for both null and empty array\ndepending on the circumstannces.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-631",
        "summary": "String constants should be final",
        "description": "RFC2109Spec - SET_COOKIE_KEY\n\nRFC2965Spec - SET_COOKIE2_KEY\n\nboth should be final.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-719",
        "summary": "Clone support",
        "description": "It would be nice to have a clone method for some of the classes that don't have getters & setters exposed for all of their fields. Where relevant, the clone method could be in the interface, so that it doesn't matter which implementing class is being used. The main interfaces that I would like to clone are HttpRequest and Cookie. I know that HttpRequest is technically part of HttpCore, but the primary implementations of it are in HttpClient, so I thought I would post it here. \n\nThanks,\nDavid Byrne",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-898",
        "summary": "Improve multihome support",
        "description": "MultihomePlainSocketFactory is basically broken and should be deprecated. Multihome logic needs to be moved to the DefaultClientConnectionOperator",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-881",
        "summary": "AbstractClientConnAdapter doesn't ensure that only one of ConnectionReleaseTrigger.abortConnection, .releaseConnection has effect",
        "description": "If HttpUriRequest.abort() is called at about the same time that the request completes, it's possible for an aborted connection to be returned to the pool.  The next time the connection is used, HttpClient.execute fails without retrying, throwing this exception:\n\njava.io.IOException: Connection already shutdown\n\tat org.apache.http.impl.conn.DefaultClientConnection.opening(DefaultClientConnection.java:112)\n\tat org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:120)\n\tat org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:147)\n\tat org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:101)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:381)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:641)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:576)\n\nSteps to reproduce:\n1) Set a breakpoint in ThreadSafeClientConnManager.releaseConnection just after \"reusable\" is set (and found to be true).\n2) Run to the breakpoint in releaseConnection.\n3) Call HttpUriRequest.abort.\n4) Let releaseConnection complete.\n\nWhen the connection is next used, the exception will be thrown.\n\nSnippet from ThreadSafeClientConnManager:\n    public void releaseConnection(ManagedClientConnection conn, long validDuration, TimeUnit timeUnit) {\n\t\t...\n            boolean reusable = hca.isMarkedReusable();\n            if (log.isDebugEnabled()) {                             // breakpoint here\n                if (reusable) {\n                    log.debug(\"Released connection is reusable.\");\n                } else {\n                    log.debug(\"Released connection is not reusable.\");\n                }\n            }\n            hca.detach();\n            if (entry != null) {\n                connectionPool.freeEntry(entry, reusable, validDuration, timeUnit);\n            }\n        }\n    }\n\n\nI think that AbstractClientConnAdapter should be modified as follows:\n\n1) Add \"released\" flag:\n\n    /** True if the connection has been released. */\n    private boolean released;\n\n2) Modify abortConnection:\n\n    public void abortConnection() {\n        synchronized(this) {\n            if (aborted || released) {\n                return;\n            }\n            aborted = true;\n        }\n        unmarkReusable(); // this line and all that follow unchanged\n\n3) Modify releaseConnection:\n\n    public void releaseConnection() {\n        synchronized(this) {\n            if (aborted || released) {\n                return;\n            }\n            released = true;\n        }\n        if (connManager != null) {\n            connManager.releaseConnection(this, duration, TimeUnit.MILLISECONDS);\n        }\n    }\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1123",
        "summary": "Implement a way to override or resolve DNS entries defined in the OS",
        "description": "When working with HttpClient in restrictive environments, where the user doesn't have the permissisions to edit the local /etc/hosts file or the DNS configuration, can be eased with an DNS Overrider capability. \n\nThis can be useful with JMeter which can follow redirects automatically and resolve some of the redirected hosts against its configuration. Another example is a custom forward proxy, written in Java and based on httpclient, which can be deployed is such a restricted environment that would ease the development of various web solutions for some developers. ",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-1098",
        "summary": "Populating exception message with InetSocketAddress.getHostName() can take a long time",
        "description": "In the PlainSocketFactory class, when a SocketTimeoutException occurs a call is made to InetSocketAddress.getHostName() when generating the exception message. Unfortunately, this call can take a long time. In my case, the address I am specifying is an IP address, which InetSocketAddress attempts to perform a reverse-lookup on to determine the hostname; however, since  the address does not have a hostname assigned to it, the operation takes a long time to return.\n\nI'm attaching a patch for trunk with my proposed fix. Viewing the source history, it looks like the code used to have the behavior I'm proposing, but it was changed in revision 1070943. Based on the source commits and linked issues, I cannot determine a specific reason for the change. If there is a reason the code needs to be the way it is, then I apologize for inconvenience I have caused.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-874",
        "summary": "Override method MultipartEntity.addPart so that applications may use FormBodyPart",
        "description": "FormBodyPart is similar to Part in HttpClient 3.x in that it couples the form name with the value.  Some applications may find this useful, but cannot really utilize these objects since there is only MultipartEntity.addPart(String name,ContentBody) and FormBodyPart does not have a getContent method:\n\n  entity.addPart(part.getName(), part.getContent()); // Almost but there is no getContent method\n\nHow about overriding addPart to take a FormBodyPart object:\n\n  entity.addPart(part);",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1166",
        "summary": "URIUtils.extractHost(...) throws a NumberFormatException line 310",
        "description": "Original Jboss-seam-wicket-booking application in Jboss-4.2.3.GA started, post a login request thanks httpclient, then NumberFormatException.\n\n\n\nregarding this page :\nhttp://hc.apache.org/httpcomponents-client-dev/httpclient/clover/org/apache/http/client/utils/URIUtils.html\n\n305 \t   \t// Extract the port suffix, if present\n306 \t   \tif (host != null) {\n307 \t  \t   int colon = host.indexOf(':');\n308 \t   \t   if (colon >= 0) {\n309 \t   \t      if (colon+1 < host.length()) {\n310 \t   \t          port = Integer.parseInt(host.substring(colon+1));\n311 \t   \t      }\n312 \t  \t   host = host.substring(0,colon);\n313 \t   \t   }\n314 \t   \t}\n\nresolving the port throw a NumberFormatException\n\njava.lang.NumberFormatException: For input string: \"8080;jsessionid=9E9EDA0B6E1CDD499A0A15C4A8F212D8\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)\n\tat java.lang.Integer.parseInt(Integer.java:458)\n\tat java.lang.Integer.parseInt(Integer.java:499)\n\tat org.apache.http.client.utils.URIUtils.extractHost(URIUtils.java:310)\n\tat org.apache.http.impl.client.AbstractHttpClient.determineTarget(AbstractHttpClient.java:764)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:754)\n\tat org.tagbrowser.api.TagBrowser.request(TagBrowser.java:109)\n\n\nanother case of this problem canbe found hier :\nhttps://gitorious.org/yacy/rc1/commit/8b0920b0b5eb67ae17eec24c1bf3a059543cb6e8/diffs",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-824",
        "summary": "Review the use of BaiscHttpParams and HttpProtocolProcessor in HttpClient",
        "description": "Review the use of BaiscHttpParams and HttpProtocolProcessor in HttpClient and replace with thread-safe implementations where necessary.\n\nOleg",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "HTTPCLIENT-274",
        "summary": "default behaviour of useExpectHeader",
        "description": "I suggest to set the ExpectContinueMethod.setUseExpectHeader per default to\nfalse or to arrange that per default it is not used. We lost an awfull lot of\ntime in a project in which we used MultipartPostMethod via a proxy. Everthing\nworked fine in dev, however as soon as we started to use the proxy in production\nor testing environment we had severe problems. We lost several manday looking\nfor the problem, including sniffing and logging op the proxy. It ended up to be\nthe useexpectheader which was true per default. Putting in on false ended our\nproblems...\n\nIn my opinion it is a bit hard to make something default behaviour if the\njavadoc warns : <snip>\nhandshake should be used with caution, as it may cause problems with HTTP\nservers and proxies that do not support HTTP/1.1 protocol.\n</snip>\n\nregards\ndirkp",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-66",
        "summary": "RFC 2965 Support (Port sensitive cookies)",
        "description": "RFC 2109 doesn't consider port numbers when matching and filtering cookies. RFC\n2965 does. Modify the Cookie class so that it (optionally?) supports RFC 2965,\nwhile maintaining support for RFC 2109-style (portless) cookies.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-232",
        "summary": "Make MultiThreadedHttpConnectionManager defaults public statics.",
        "description": "Could the defaults for MultiThreadedHttpConnectionManager be made public\nconstants? I would do it my self since I have karma as a contributer to [lang]\nand [codec] but I do not want to step on anyones toes. ;-)\n\nPatch attached.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-196",
        "summary": "httpClient failed to reconnect after keep-alive connection timed out",
        "description": "Description:\n\nWhen using httpClient with https tunnelling througha proxy server, after keep-\nalive connection timed out on server side.  The httpClient code was unable to \nestablish the connection again.\n\nCause:\n\nThe HttpMethodBase.processRequest's retry loop retries the connection without \ngoing through the \"CONNECT\" request to the proxy server.  Our proxy server \nreturns 407 error code.  In case of tunnelling connection, proper reconnect \nshould be done by first doing the \"CONNECT\" sequence to get authenticated \nthrought the proxy.\n\nTemp fix and Work around:\n\nWe implemented some work around to do the retry from the application layer.  In \norder to detect the situation, we have to rely on the error message contained \nin the HttpRecoverableException.  We are checking the text \"Connection aborted \nby peer: socket write error\".  We also have to modify the HttpMethodBase code \nto throw the HttpRecoverableException out to the application.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1182",
        "summary": "Add a constructor to org.apache.http.conn.ssl.SSLSocketFactory to allow for directly wrapping a javax.net.ssl.SSLSocketFactory socketfactory",
        "description": "Our application use Java Webstart for deployment.  Amoung other things, Webstart gives us the ability to access the system's (in our case, Windows) certificate system.  For instance, one of our client is using certificate based authentication to their webserver.  This is done through a hardware device they attach to their system.  Window's already has a way to interface with this device, and Webstart has a way to interface with the Windows API.\n\nI don't think we can get by with using any SocketFactory that we create.  (We would have to check with Oracle to be sure.)  I think we need to use the one that is set as the default in HttpsURLConnection.\n\nWhat I am suggesting is that another constructor be added to allow for just wrapping this one.  I was not planning on putting a dependancy on HttpsURLConnection, but rather just add the ability to wrap any javax.net.ssl.SSLSocketFactory.\n\nThis will not be a big change to the API.  I will get a patch ready soon.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-941",
        "summary": "Standardize on a common mocking framework (either EasyMock or Mockito)",
        "description": "We are currently using EasyMock in the caching module and Mockito in the main module. While Mockito appears to have a somewhat nicer API, the sheer number of test cases based on EasyMock in the caching module makes it much simpler to replace Mockito with EasyMock than the other way around.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-978",
        "summary": "provide an ehcache implementation for HttpCache",
        "description": "Provide an implementation of the HttpCache interface that stores cache entries in ehcache.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-252",
        "summary": "Cookie Strict Mode independent of regular Strict Mode",
        "description": "Hi,\n\nI'm having a problem where a web site I'm trying to access is using strict \ncookies (on one line) and a 302 redirect that fails in strict mode.  So I \ncannot access this website because in strict mode it fails because of the 302 \nredirect and in non-strict mode the website doesn't recognize the Cookies on \nseparate lines.\n\nI'd love to see this added for the next release candidate.\n\nThanks,\n\nBrent",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-640",
        "summary": "contrib.ssl.HostConfigurationWithHostFactory",
        "description": "I'd like to contribute an example specialized HostConfiguration, to replace the one I contributed in HTTPCLIENT-634.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1038",
        "summary": "AbstractHttpClient.determineTarget(HttpUriRequest)",
        "description": "Issue with 4.1 beta1 fails to parse the right host from the URL, eg. http://my.site.com/search/?for=http://other.site.com\nThis fails request for eg. REST that has a param value with ':' or '?' or '/'.\n\nAbstractHttpClient.determineTarget(HttpUriRequest)\nhttpcomponents-client-4.0.3:\n    private HttpHost determineTarget(HttpUriRequest request) {\n        // A null target may be acceptable if there is a default target.\n        // Otherwise, the null target is detected in the director.\n        HttpHost target = null;\n\n        URI requestURI = request.getURI();\n        if (requestURI.isAbsolute()) {\n            target = new HttpHost(\n                    requestURI.getHost(),\n                    requestURI.getPort(),\n                    requestURI.getScheme());\n        }\n        return target;\n    }\n\n\nhttpcomponents-client-4.1-beta1:\n    private HttpHost determineTarget(HttpUriRequest request) throws ClientProtocolException {\n        // A null target may be acceptable if there is a default target.\n        // Otherwise, the null target is detected in the director.\n        HttpHost target = null;\n\n        URI requestURI = request.getURI();\n        if (requestURI.isAbsolute()) {\n            String ssp = requestURI.getSchemeSpecificPart();\n            ssp = ssp.substring(2, ssp.length()); //remove \"//\" prefix\n            int end = ssp.indexOf(':') > 0 ? ssp.indexOf(':') :\n                    ssp.indexOf('/') > 0 ? ssp.indexOf('/') :\n                    ssp.indexOf('?') > 0 ? ssp.indexOf('?') : ssp.length();\n            String host = ssp.substring(0, end);\n\n            int port = requestURI.getPort();\n            String scheme = requestURI.getScheme();\n            if (host == null || \"\".equals(host)) {\n                throw new ClientProtocolException(\n                        \"URI does not specify a valid host name: \" + requestURI);\n            }\n            target = new HttpHost(host, port, scheme);\n        }\n        return target;\n    }\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-8",
        "summary": "LogSource.setLevel incorrectly uses entrySet",
        "description": "When I call LogSource.setLevel, I get the following exception:\n\njava.lang.ClassCastException: java.util.HashMap$Entry\n\tat org.apache.commons.httpclient.log.LogSource.setLevel\n(LogSource.java:158)\n\nThe calling code is :\n\n    LogSource.setLevel (Log.OFF);\n\nThe error (I believe) is that you should get the value set from the map, not \nthe entry set (in LogSource):\n\n    static public void setLevel(int level) {\n        Iterator it = _logs.entrySet().iterator(); <-- should be _logs.values()\n        while(it.hasNext()) {\n            Log log = (Log)(it.next());\n            log.setLevel(level);\n        }\n    }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-373",
        "summary": "Allow configuration of SO_LINGER",
        "description": "There is currently no way to configure the SO_LINGER option on a socket.\n\nPlease change the HttpClient class to allow the configuration of the SO_LINGER\noption on a socket, similar to the way the SO_TIMEOUT can be configured.\n\nSuggested extension to the interface of the HttpClient class:\n- Add method setSoLinger() to set the current setting for SO_LINGER. The method\ncould accept one argument. A negative value could indicate that the SO_LINGER\nshould be disabled.\n- Add method getSoLinger() that returns the current setting for SO_LINGER. A\nnegative value would indicate that the SO_LINGER option is disabled.\n\nSee:\nhttp://java.sun.com/j2se/1.4.2/docs/api/java/net/Socket.html#setSoLinger(boolean,%20int)",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-158",
        "summary": "Empty response body is not properly handled when chunked encoding is used",
        "description": "IIS 5.0 server, when returning no content in response to an HTTP/1.1 request,\nstill includes \"Transfer-Encoding: chunked\" response header. As HttpClient\nalways expects chunk-encoded stream to be properly terminated, an\nHttpRecoverableException exception results, when no content is sent back\n\n=====================================================================\n\nPOST /someurl.aspx HTTP/1.1\nContent-Length: 1132\nHost: xxx.xxx.xxx.xxx\nUser-Agent: Jakarta Commons-HttpClient/2.0alpha2\nContent-Type: multipart/form-data; boundary=----------------314159265358979323846\n\n------------------314159265358979323846\nContent-Disposition: form-data; name=\"nmFile\"; filename=\"xxxxxxxxx.xml\"\nContent-Type: application/octet-stream\n\n<... content removed ...>\n\n------------------314159265358979323846--\n\nHTTP/1.1 200 OK\nServer: Microsoft-IIS/5.0\nDate: Sat, 08 Feb 2003 15:22:26 GMT\nTransfer-Encoding: chunked\nCache-Control: private\nContent-Type: text/html\n\n=====================================================================\n\nBug reported by Jim Crossley",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-822",
        "summary": "HttpClient throws java.net.SocketException instead of org.apache.http.conn.ConnectionTimeoutException when connection timeout occurs",
        "description": "When sending an http request a connection timeout occurs, the HttpClient.execute method throws a java.net.SocketException instead of a org.apache.http.conn.ConnectionTimeoutException.\n\njava.net.SocketTimeoutException: connect timed out\n        at java.net.PlainSocketImpl.socketConnect(Native Method)\n        at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)\n        at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)\n        at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)\n        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)\n        at java.net.Socket.connect(Socket.java:519)\n        at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:119)\n        at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:129)\n        at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:164)\n        at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119)\n        at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:349)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:555)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:487)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:465)\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-426",
        "summary": "httpclient doesn't read and parse response from certain types of proxy servers when POST method is used",
        "description": "It was determined that when sending post data to server via Squid proxy server\nof version 2.4.STABLE2 and Squid responds \nwith \"407 proxy authentication required\" response, httpclient doesn't read this\nresponse in order to parse, but rather\nfails with soket exception \"java.net.SocketException: Software caused connection\nabort: recv failed\".\n\nThis behaviour is reproduced with the latest nigtly build of httpclient version\n3.0. (from 9 of February 2005) as\nwell as 3.0. RC1, 2.0.2 and 2.0.\n\nThis is the piece of code that sends post data using httpclient:\n\ntry\n{\n\tHttpClientParams httpClientParams = new HttpClientParams();\n\tHttpClient client = new HttpClient(httpClientParams);\n\n\tHostConfiguration hostconfig = new HostConfiguration();\n\thostconfig.setProxy(\"db00-devl.eps.agfa.be\", 3128); // SQUID proxy server\nversion 2.4.STABLE2\n\tclient.setHostConfiguration(hostconfig);\n\tPostMethod postMethod = new\nPostMethod(\"http://brugge.eps.agfa.be/portal03/servlet/selectFiles\");\n\n\tpostMethod.addParameter(\"data\", \"some data\");\n\tint status = client.executeMethod(postMethod);\n\tSystem.out.println(\"status = \" + status);\n\tif (status == HttpStatus.SC_OK)\n\t\tSystem.out.println(\"Ok\");\n\telse if (status == HttpStatus.SC_PROXY_AUTHENTICATION_REQUIRED)\n\t\tSystem.out.println(\"Proxy authentication required.\");\n}\ncatch (Exception e)\n{\n\tSystem.out.println(\"Socket exception.\");\n\te.printStackTrace();\n}\n\nLook at \"debug log of the problem\" attachment to see all output from httpclient\nand mentioned piece of code.\nIn \"problem_request_response_interaction\" attacment it is possible to see\ninteraction beetween httpclient and Squid proxy server: httpclient sends initial\nrequest and headers, then squid responds with \"proxy authentication required\"\nresponse and afterwards httpclient tries to send post data(without reading the\nresponse) but fails because connection is already closed.\n\nFor more details look at \"ethereal_problem\" attachment for all network traffic\nduring running of mentioned piece of code:\nEthereal protocol analyzer can be used to open this file(http://www.ethereal.com/).\n\nMost likely this particular version of Squid closes connection after it sends\nproxy athentication response back,\nwhich causes httpclient to fail while sending post data.\n\nLet's have a look at what writeRequest(...) method of HttpMethodBase class does:\n\n1) sends request line and headers to server,\n2) handles 'Expect: 100-continue' handshake if needed,\n3) sends post data to server.\n\nMy question is should HTTPClient send initial request and headers before data\neven if it is not going to read \na response from the server(proxy server), or this should be done only in case of\n'Expect: 100-continue' handshake \n(this seems the only case when HTTPClient is going to listen to server\nin-between of steps 1 and 3)?\n\nMy understanding is that the command\n\n        // make sure the status line and headers have been sent\n        conn.flushRequestOutputStream();\n        \nwhich actually splits sending of data in two parts are needed only for 'Expect:\n100-continue' handshake case.\nJust by moving \"flush\" command to appropriate place inside 'Expect:\n100-continue' handshake case:\n\t\t.....\n                try {\n\t            conn.flushRequestOutputStream(); // moved\n                    conn.setSocketTimeout(RESPONSE_WAIT_TIME_MS);\n\t\t.....\nit is posible to solve described problem.\n\nI created PostMethodEx that overrides writeRequest(...) method of\nHttpMethodBase(look at \"PostMethodEx\" attachment) \nand for all cases but the 'Expect: 100-continue' handshake it sends request\nline, headers and post data to server \nat once.\n\nWhen mentioned piece of code(with PostMethod changed to PostMethodEx) is\nexecuted everyting works fine:\nlook at \"debug log of the fix\", \"fix_request_response_interaction\" and\n\"ethereal_fix\"(all network trafic) \nattachments.\n\nAccording to mentioned logs httpclient sends all post data at once and then\nreads and parses \"proxy authentication required\" \nresponse from squid and sets status code to 407. Correct.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-188",
        "summary": "recoverable exceptions when reading are not retried",
        "description": "If a recoverable exception occurs after a request is written then the method is\nnot retried.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-352",
        "summary": "Allow polymorphic use of addParameter",
        "description": "I have some common code (in a reverse proxy server) that uses addParameter on \ninstances of both PostMethod and MultipartPostMethod\n\nIt would be great if either addParameter were made an abstract method on \nExpectContinueMethod or both were made to implement a common base class. Here's \nmy workaround:\n\n    private void addPostParameter(ExpectContinueMethod method, String name, \nString value) {\n        if (method instanceof PostMethod) {\n            ((PostMethod)method).addParameter(name, value);\n        } else if (method instanceof MultipartPostMethod) {\n            ((MultipartPostMethod)method).addParameter(name, value);\n        } else {\n            throw new IllegalArgumentException(\"addPostParameter is only \ndefined for PostMethod and MultipartPostMethod\");\n        }\n        \n    }\n    // whoa - smells pretty bad",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-314",
        "summary": "New socket timeout value wont have effect if connection is reused",
        "description": "Reported by Teemu Tingander <Teemu.Tingander at tecnomen.fi> on The Jakarta\nCommons HttpClient Developer List:\n\n<snip>\nChanging read timeout ()wont affect after successful method execution using\nsame connection.. \n\nThis seems to be a bug in HttpClient class method\nexecuteMethod(HostConfiguration ...)..\n\nThe problematic section seems to be if section checking if connection is\nopen\n\t\n\t\tmethod.setStrictMode(strictMode);\n        \t\t        \n            if (!connection.isOpen()) {                \n                connection.setConnectionTimeout(connectionTimeout);\n-->\t\t    connection.setSoTimeout(soTimeout);\n                connection.open();\n                if (connection.isProxied() && connection.isSecure()) {\n                    method = new ConnectMethod(method);\n                }\n            }\n \nProblem can be solved by moving the line out of if section\n\n\t\tmethod.setStrictMode(strictMode);\n\n\t\tconnection.setSoTimeout(soTimeout);\t\n        \t\t        \n            if (!connection.isOpen()) {                \n                connection.setConnectionTimeout(connectionTimeout);\n                connection.open();\n                if (connection.isProxied() && connection.isSecure()) {\n                    method = new ConnectMethod(method);\n                }\n            }\n</snip>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-669",
        "summary": "introduce HttpRoutePlanner interface",
        "description": "Define an interface to determine a route for a given target host.\nCreate default implementation replacing DefaultHttpClient.determineRoute(...);\nImplementations will need access to params and/or request.\n\nThe interface fits into HttpConn, but DHC.dR(...) uses client parameters.\nEither move parameters to HttpConn, or keep default implementation in HttpClient.\n\nAlternative implementations could evaluate Java system properties related to proxy settings.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-237",
        "summary": "wire logger skips empty line",
        "description": "When logging with \norg.apache.commons.logging.simplelog.log.httpclient.wire=debug, HttpConnection \nskips one line of server output in logs -- CRLF line between headers and body.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-269",
        "summary": "HttpConnection.isResponseAvailable() calls setSoTimeout() but does not catch IOException",
        "description": "HttpConnection.isResponseAvailable() can throw an IOException when setting the\nsoTimeout but should probably just return false in this case.\n\n<http://marc.theaimsgroup.com/?t=106268485100002&r=1&w=2>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-670",
        "summary": "add an interface for plugable dns clients",
        "description": "Currently Httpclient implicitly uses InetAddress.getByName() for DNS resolution.\nThis has some drawbacks. One is that the DNS cache of Java per default caches entries forever.\n\nSo I'd like to be able to replace InetAddress.getByName() with another DNS client implementation.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-478",
        "summary": "HttpConnectionParams.setConnectionTimeout(int) has no effect if host unreachable",
        "description": "I have just modified MultiThreadedExample.java by adding\nhttpClient.getHttpConnectionManager().getParams().setConnectionTimeout(5000); in\norder to set a connection timeout on the client side. Then I have added a LAN\nurl to urisToGet array. The ip of this url (\"http://192.168.254.1/\") is not\nassigned to any computer.\n\nAfter running the client, I get the expected message ( error:\norg.apache.commons.httpclient.ConnectTimeoutException: The host did not accept\nthe connection within timeout of 5000 ms) but only after 20 seconds.\n\nI use java version \"1.5.0_04\". This is not a JVM bug since normal connection\nprocedure times out after 5 seconds as expected:\n        SocketAddress addr = new InetSocketAddress(\"192.168.254.1\", 80);\n        try {\n            \n            SocketChannel channel = SocketChannel.open();\n            channel.socket().connect(addr, 5000);            \n            System.out.println(\"connected\");\n            \n        } catch (Exception e) {\n            e.printStackTrace();\n        }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-238",
        "summary": "HeaderElement#parse(String) implementation is not optimal",
        "description": "The cookie setted by the LocalDirector 416 Version 4.2.3 has a bug.\nIt sets for Tuesday and Thursday \"Tues\" and \"Thur\" instead of the \ncanonical \"Tue\" and \"Thu\". This break the parsing stage and stop HttpClient to \nwork for 2 days a week. Of course I modified the parse method in HeaderElement \nclass, but everytime I download a new version, I have to remake the jar....\nIt's possible to include this into the CVS files ?",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-5",
        "summary": "Cookie.parse exception when parsing expiry date in single quotes",
        "description": "A Netscape-Enterprise/3.6 SP3 server sends a cookie where the parameter expires='Thu, 05-Dec-\n2002 12:07:45 GMT'. \nCookie.parse throws an exception because none of the four built-in formats \nmatches - I have tested that the parse code works OK if the single quotes are omitted from the value \nbeing parsed.\n\nResolution: If the value of the 'expires' parameter starts and ends with a \nsingle quote then strip the first and last character before parsing.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1100",
        "summary": "Missing Content-Length header makes cached entry invalid",
        "description": "A cached entry whose original response didn't carry a Content-Length header, should not be rejected for considered invalid because the length of its cached content is different from the non-existing Content-Length header value. The attached patch only verifies the lengths if the header was originally present.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-356",
        "summary": "[API DOC] Authentication guide update: alternate authentication",
        "description": "Add a section on alternate authentication.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-411",
        "summary": "Checking of stale connections is broken",
        "description": "HttpConnections that went stale (dropped by server) throw SocketExceptions\ninstead of silently re-opening themselves, as has been the case with earlier\nversions of HttpClient.\n\nI think the problem for this can be found in HttpConnection:\n\n  public boolean closeIfStale() throws IOException {\n    if (used && isOpen && isStale()) {\n      LOG.debug(\"Connection is stale, closing...\");\n      close();\n      return true;\n    }\n    return false;\n  }\n\nstaleness is only checked if used = true, but there is no code in HttpConnection\nthat sets the used flag. In other words: used is always false and isStale() is\nnever called.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-297",
        "summary": "DigestScheme.authenticate returns invalid authorization string when algorithm is null",
        "description": "DigestScheme.authenticate returns invalid authorization string when algorithm \nis null. \nI traced the bug and found the following from the method call:\nauthenticate(Credentials credentials, String method, String uri) calls\nauthenticate(UsernamePasswordCredentials credentials,\n            Map params) calls\ncreateDigest(String uname, String pwd,\n            Map params)\n  and properly defaults algorithm to MD5 if null\nbut the final call to createDigestHeader(String uname, Map params,\n            String digest) does not default algorithm to MD5 if null",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-324",
        "summary": "[API Doc] Document exceptions thrown on execute methods",
        "description": "There should be more detailed documentation on HttpClient::executeMethod and\nHttpMethod::execute about exceptions thrown in which cases.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1075",
        "summary": "ContentEncodingHttpClient.execute(HttpGet, ResponseHandler<T>) throws IOException when reading compressed response",
        "description": "The following snippet:\n\n    String url = \"http://yahoo.com\";\n    HttpClient httpClient = new ContentEncodingHttpClient();\n    HttpGet get = new HttpGet(url);\n    String content = httpClient.execute(get, new BasicResponseHandler());\n\nthrows:\n\njava.io.IOException: Attempted read from closed stream.\n\tat org.apache.http.impl.io.ChunkedInputStream.read(ChunkedInputStream.java:126)\n\tat java.util.zip.CheckedInputStream.read(CheckedInputStream.java:42)\n\tat java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:205)\n\tat java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:197)\n\tat java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:136)\n\tat java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:58)\n\tat java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:68)\n\tat org.apache.http.client.entity.GzipDecompressingEntity.getContent(GzipDecompressingEntity.java:63)\n\tat org.apache.http.conn.BasicManagedEntity.getContent(BasicManagedEntity.java:88)\n\tat org.apache.http.util.EntityUtils.consume(EntityUtils.java:65)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:974)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:919)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:910)\n\tat tv.adap.service.HttpPoolTest.testChunkedGzip(HttpPoolTest.java:41)\n\nwhereas the following snippet runs fine:\n\n    String url = \"http://yahoo.com\";\n    HttpClient httpClient = new ContentEncodingHttpClient();\n    HttpGet get = new HttpGet(url);\n    HttpResponse response = httpClient.execute(get);\n    HttpEntity entity = response.getEntity();\n    String content = EntityUtils.toString(entity);\n\nThese two snippets should be functionally the same (putting the entity body into content). Creating a JIRA per the recommendation of Oleg from httpclient-users.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-469",
        "summary": "Stale connection check does not work with IBM JSSE/JRE",
        "description": "OS: Windows/AIX\nJRE: IBM JRE 1.4.1\nJSSE: IBM's implementation (SSLite?)\nHttpClient Library: 2.0.2 release\n\nMy code enabled connection pooling feature to gain performance improvement in \nthe SSL Handshake area. The code works perfectly on Sun JRE 1.4.2 with a think \ntime of 60seconds between requests, but the same code fails on IBM JRE. On IBM \nJRE, the code fails to detech stale connections, thus causing down the stream \nsetSoTimeout() call to fail.\n\nFurther debugging into the library code revealed difference in the way the \nHTTPConnection.isStale() behaves. With in that method, particularly, the \ninputStream.isAvailable() method returns 0 with Sun JRE but -1 with IBM JRE.\n\nI made a small code change to HttpConnection.isStale() method by moving the try\n{}finally{} block outside of the if(inputStream.isAvailable()==0) check in the \nfollowing code and BINGO, everything started working on IBM JVM\u0092s. It did not \nbreak anything on Sun\u0092s JVM.\n\n============== CODE BEGIN\n    protected boolean isStale() {\n    \tLOG.debug(\"##SUBBA## HttpConnection.isStale() got called. soTimeout=\" \n+ soTimeout);\n        boolean isStale = true;\n        if (isOpen) {\n        \tLOG.debug(\"##SUBBA## HttpConnection.isStale() got called. \nisOpen=\" + isOpen);        \t\n            // the connection is open, but now we have to see if we can read it\n            // assume the connection is not stale.\n            isStale = false;\n\n                try {         \n                    if (inputStream.available() == 0) {\t\t// ALWAYS \nRETURNS -1 on IBM JVM \u0085 0 on SUN\n                    \t\n\t\t  // try {\t\t// SUBBA \u0096 MOVED OUTSIDE IF\n\t                \tsocket.setSoTimeout(1);\n\t                  \tLOG.debug(\"##SUBBA## HttpConnection.isStale() \ngot called. setSoTimeout(1)\");                    \t\n\t                    \n\t                    inputStream.mark(1);\n\t                    int byteRead = inputStream.read();\n\t                \tLOG.debug(\"##SUBBA## HttpConnection.isStale() \ngot called. bytesRead=\" + byteRead);                    \t\n\t                    \n\t                    if (byteRead == -1) {\n\t                    \tLOG.debug(\"##SUBBA## HttpConnection.isStale() \ngot called. SETTING isStale to TRUE HERE\");                    \t\n\t                    \t\n\t                        // again - if the socket is reporting all data \nread,\n\t                        // probably stale\n\t                        isStale = true;\n\t                    } else {\n\t                        inputStream.reset();\n\t                    }\n\t\t    // SUBBA \u0096 MOVED OUTSIDE IF\n                //} finally {\n                //\tLOG.debug(\"##SUBBA## HttpConnection.isStale() got \ncalled. finally block - BEGIN \" + soTimeout);                    \t\n                //    socket.setSoTimeout(soTimeout);\n                //\tLOG.debug(\"##SUBBA## HttpConnection.isStale() got \ncalled. finally block - DONE\");                        \n               // }\n\n\t\n                    }                        \n                } finally {\n                \tLOG.debug(\"##SUBBA## HttpConnection.isStale() got \ncalled. finally block - BEGIN \" + soTimeout);                    \t\n                    socket.setSoTimeout(soTimeout);\n                \tLOG.debug(\"##SUBBA## HttpConnection.isStale() got \ncalled. finally block - DONE\");                        \n                }\n.....\n.....\n.....\n========================== CODE END\n\n\nI've attached logs captured before and after the change on both the JRE's for \nyour review:\n\n==================================\nIBM\u0092s LOG (after change):\n==================================\n<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> \n<apache.commons.httpclient.MultiThreadedHttpConnectionManager:700> <Getting \nfree connection, hostConfig=HostConfiguration\n[host=uatservices30.ilab.fnfismd.com, protocol=https:443, port=443]>\n<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:492> <##SUBBA## \nHttpConnection.isStale() got called. soTimeout=0>\n<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:495> <##SUBBA## \nHttpConnection.isStale() got called. isOpen=true>\n<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:500> <##SUBBA## \nHttpConnection.isStale() got called. [class \njava.io.BufferedInputStream].available=-1>\n<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:523> <##SUBBA## \nHttpConnection.isStale() got called. finally block - BEGIN 0>\n<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:532> <An error occurred while \nreading from the socket, is appears to be stale>\njava.net.SocketException: Socket is closed\n\tat java.net.Socket.setSoTimeout(Socket.java:927)\n\tat com.ibm.sslite.bf.setSoTimeout(Unknown Source)\n\tat com.ibm.jsse.bg.setSoTimeout(Unknown Source)\n\tat org.apache.commons.httpclient.HttpConnection.isStale\n(HttpConnection.java:524)\n\tat org.apache.commons.httpclient.HttpConnection.isOpen\n(HttpConnection.java:436)\n\tat \norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection\nAdapter.isOpen(MultiThreadedHttpConnectionManager.java:1122)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:626)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:497)\n\tat \ncom.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest\n(ApacheHttpClient.java:69)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest\n(MsWSManager.java:86)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo\nad(MsWSManager.java:114)\n\tat com.touchpoint.pia.services.transactions.msp.MsWSManager.main\n(MsWSManager.java:179)\n<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:540> <##SUBBA## \nHttpConnection.isStale() return=true>\n<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:437> <Connection is stale, \nclosing...>\n\n==================================\nIBM\u0092s LOG (before change):\n==================================\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.MultiThreadedHttpConnectionManager:666> <enter \nHttpConnectionManager.ConnectionPool.getHostPool(HostConfiguration)>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.MultiThreadedHttpConnectionManager:700> <Getting \nfree connection, hostConfig=HostConfiguration\n[host=uatservices30.ilab.fnfismd.com, protocol=https:443, port=443]>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:492> <##SUBBA## \nHttpConnection.isStale() got called.>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:495> <##SUBBA## \nHttpConnection.isStale() got called. isOpen=true>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:500> <##SUBBA## \nHttpConnection.isStale() got called. [class \njava.io.BufferedInputStream].available=-1>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:538> <##SUBBA## \nHttpConnection.isStale() return=false>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:599> <HttpConnection.setSoTimeout(0)>\n<Jun 10, 2005 1:07:29 PM EDT> <WARN> \n<apache.commons.httpclient.HttpConnection:607> <##SUBBA## Socket Exception>\njava.net.SocketException: Socket is closed\n\tat java.net.Socket.setSoTimeout(Socket.java:927)\n\tat com.ibm.sslite.bf.setSoTimeout(Unknown Source)\n\tat com.ibm.jsse.bg.setSoTimeout(Unknown Source)\n\tat org.apache.commons.httpclient.HttpConnection.setSoTimeout\n(HttpConnection.java:603)\n\tat \norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection\nAdapter.setSoTimeout(MultiThreadedHttpConnectionManager.java:1296)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:633)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:497)\n\tat \ncom.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest\n(ApacheHttpClient.java:69)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest\n(MsWSManager.java:86)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo\nad(MsWSManager.java:114)\n\tat com.touchpoint.pia.services.transactions.msp.MsWSManager.main\n(MsWSManager.java:179)\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:1151> <enter \nHttpConnection.releaseConnection()>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.MultiThreadedHttpConnectionManager:513> <enter \nHttpConnectionManager.releaseConnection(HttpConnection)>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.MultiThreadedHttpConnectionManager:791> <Freeing \nconnection, hostConfig=HostConfiguration[host=uatservices30.ilab.fnfismd.com, \nprotocol=https:443, port=443]>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.MultiThreadedHttpConnectionManager:666> <enter \nHttpConnectionManager.ConnectionPool.getHostPool(HostConfiguration)>\n<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> \n<apache.commons.httpclient.MultiThreadedHttpConnectionManager:774> <Notifying \nno-one, there are no waiting threads>\njava.net.SocketException: Socket is closed\n\tat java.net.Socket.setSoTimeout(Socket.java:927)\n\tat com.ibm.sslite.bf.setSoTimeout(Unknown Source)\n\tat com.ibm.jsse.bg.setSoTimeout(Unknown Source)\n\tat org.apache.commons.httpclient.HttpConnection.setSoTimeout\n(HttpConnection.java:603)\n\tat \norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection\nAdapter.setSoTimeout(MultiThreadedHttpConnectionManager.java:1296)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:633)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:497)\n\tat \ncom.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest\n(ApacheHttpClient.java:69)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest\n(MsWSManager.java:86)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo\nad(MsWSManager.java:114)\n\tat com.touchpoint.pia.services.transactions.msp.MsWSManager.main\n(MsWSManager.java:179)\njava.net.SocketException: Socket is closed\n\tat java.net.Socket.setSoTimeout(Socket.java:927)\n\tat com.ibm.sslite.bf.setSoTimeout(Unknown Source)\n\tat com.ibm.jsse.bg.setSoTimeout(Unknown Source)\n\tat org.apache.commons.httpclient.HttpConnection.setSoTimeout\n(HttpConnection.java:603)\n\tat \norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection\nAdapter.setSoTimeout(MultiThreadedHttpConnectionManager.java:1296)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:633)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:497)\n\tat \ncom.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest\n(ApacheHttpClient.java:69)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest\n(MsWSManager.java:86)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo\nad(MsWSManager.java:114)\n\tat com.touchpoint.pia.services.transactions.msp.MsWSManager.main\n(MsWSManager.java:179)\nException in thread \"main\" java.net.SocketException: Socket is closed\n\tat java.net.Socket.setSoTimeout(Socket.java:927)\n\tat com.ibm.sslite.bf.setSoTimeout(Unknown Source)\n\tat com.ibm.jsse.bg.setSoTimeout(Unknown Source)\n\tat org.apache.commons.httpclient.HttpConnection.setSoTimeout\n(HttpConnection.java:603)\n\tat \norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection\nAdapter.setSoTimeout(MultiThreadedHttpConnectionManager.java:1296)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:633)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:497)\n\tat \ncom.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest\n(ApacheHttpClient.java:69)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest\n(MsWSManager.java:86)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo\nad(MsWSManager.java:114)\n\tat com.touchpoint.pia.services.transactions.msp.MsWSManager.main\n(MsWSManager.java:179)\n\n\n============================================\n**SUN\u0092s LOG (after change = before change):\n============================================\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.MultiThreadedHttpConnectionManager:700> <Getting \nfree connection, hostConfig=HostConfiguration\n[host=uatservices30.ilab.fnfismd.com, protocol=https:443, port=443]>\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:492> <##SUBBA## \nHttpConnection.isStale() got called. soTimeout=0>\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:495> <##SUBBA## \nHttpConnection.isStale() got called. isOpen=true>\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:500> <##SUBBA## \nHttpConnection.isStale() got called. [class \njava.io.BufferedInputStream].available=0>\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:506> <##SUBBA## \nHttpConnection.isStale() got called. setSoTimeout(1)>\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:510> <##SUBBA## \nHttpConnection.isStale() got called. bytesRead=-1>\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:513> <##SUBBA## \nHttpConnection.isStale() got called. SETTING isStale to TRUE HERE>\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:523> <##SUBBA## \nHttpConnection.isStale() got called. finally block - BEGIN 0>\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:532> <An error occurred while \nreading from the socket, is appears to be stale>\njava.net.SocketException: Socket Closed\n\tat java.net.PlainSocketImpl.setOption(PlainSocketImpl.java:177)\n\tat java.net.Socket.setSoTimeout(Socket.java:924)\n\tat com.sun.net.ssl.internal.ssl.SSLSocketImpl.setSoTimeout(DashoA12275)\n\tat org.apache.commons.httpclient.HttpConnection.isStale\n(HttpConnection.java:524)\n\tat org.apache.commons.httpclient.HttpConnection.isOpen\n(HttpConnection.java:436)\n\tat \norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection\nAdapter.isOpen(MultiThreadedHttpConnectionManager.java:1122)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:626)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:497)\n\tat \ncom.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest\n(ApacheHttpClient.java:69)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest\n(MsWSManager.java:86)\n\tat \ncom.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo\nad(MsWSManager.java:114)\n\tat com.touchpoint.pia.services.transactions.msp.MsWSManager.main\n(MsWSManager.java:179)\n<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> \n<apache.commons.httpclient.HttpConnection:540> <##SUBBA## \nHttpConnection.isStale() return=true>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-612",
        "summary": "FileRequestEntity in SVN does not close input file",
        "description": "FileRequestEntity.java in SVN does not close input file - however the version on the web page:\n\nhttp://jakarta.apache.org/commons/httpclient/performance.html\n\nhas a finally clause that closes the file ;-) - perhaps the source code should too...!",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-306",
        "summary": "Redesign of HTTP authentication framework",
        "description": "The existing HTTP authentication framework has got a few glaring deficiencies:\n- Authentication headers management evolved (or degraded) into a some sort of\nblack art and proved very error-prone.\n- Existing logic intended to deal with authentication failures and\nauthentication failure recovery is flawed. The resolution of the HTTPCLIENT-213 did\nappear possible without a better approach than the one based on AuthScheme#getID.\n\nOn top of that authentication logic got quite messy with the series of attempts\nto fix breakages in complex authentication schemes (the latest being NTLM proxy\n+ basic host fix) \n\nThe patch I am about to attach is an attempt to address all the shortcomings\nmentioned above. It builds upon my previous patch that enabled authentication\nschemes to maintain authentication state and presents a complete redesign of the\nexisting HTTP authentication framework.\n\nBasically there's no authentication code left untouched, so please do take a\ncloser look. Critique, comments, suggestions welcome.\n\nOleg",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-35",
        "summary": "[HttpClient] Better proxy support in HttpMultiClient",
        "description": "If proxy requires authentication, it sends status 407 (Proxy Authentication \nRequired) and the response header \"Proxy-Authenticate\" (see RFC2616; e.g. Squid \ncan be configured to do so).\nHttpClient doesn't yet process this response.\nBehavior should be similar to processing of status 401 (Unauthorized).",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-953",
        "summary": "ConnPoolByRoute driving RouteSpecificPool to IllegalState",
        "description": "Hi all,\n\nI encountered an issue on ConnPoolByRoute / RouteSpecificPool on HTTPClient 4.0.1, akin to HTTPCLIENT-747 (it also leads to a java.lang.IllegalStateException: No entry created for this pool. HttpRoute[{}XXX] ), but it is not a concurrency issue (no race condition, just a logic error if I understood it correctly).\n\nFrom my understanding, the error lies in ConnPoolByRoute#getEntryBlocking\nQuoting from the code (line 309-314) :\nRouteSpecificPool rospl = getRoutePool(route, true);\n... \n} else if (hasCapacity && !freeConnections.isEmpty()) {\n\ndeleteLeastUsedEntry();\nentry = createEntry(rospl, operator);\n\n} else { ...\n\nThe short version of the issue is : under certain circumstances, #deleteLeastUsedEntry can remove rospl from the map of known RootSpecificPool. But as this code still holds on to the rospl instance, it will modify its state in a way the pool will never recover from later, not having any other way to access this instance when the connection gets released.\n\nA Step by Step guide to what's going wrong.\n0) You have to be in a condition that leads to the execution of said code extract (i.e. no free entry on the current route - but the route already is registered to the global pool -, current Route has capacity, max connections reached for the global pool, but there are free connections to destroy).\n2) We arrive in deleteLeastUsedEntry(). We get the last entry from a queue. It can be that this entry is bound to the same (hashCode() wise) Route that the one we are getting a connection to (i.e. rospl instance held in the #getEntryBlocking context)\n3) this entry can be the last of its pool, thus at this point, rospl.isUnused() == true\n4) As a consequence, deleteEntry() will remove rospl from the routeToPool map\n5) Back in the getEntryBlocking method, we do entry = createEntry(rospl, operator), which will do createdEntry() on the \"locally-scoped\" rospl instance that has just been removed from routeToPool \n6) When the connexion from this new entry is released at some point in the future, the rospl instance that got the createdEntry() does not exist anymore, and it is a new one that gets the freeEntry() call\n7) App breaks : this newly created RouteSpecificPool throws IllegalStateException.\n\nStep 0, though, is a rare condition that I only reached during stress tests, and on a SSL client-auth server. This is so because this is the only condition that I know of in HTTPClient, where there is a keep-alive connection in the RouteSpecificPool that can not be reused (when the State is set to the X500 principals of the client cert in the pool, but not in the request).\n\nPossible fix (from what I understand) :\nThe rospl instance variable in the context of getEntryBlocking() should be protected against the consequences of #deleteLeastUsedEntry().\nNot being confortable with all issues at hand, nor with the code base, the simplest thing I can think of would be to preemptively reset the rospl variable after deleteLeastUsedEntry(), thus writing the previous code extract as :\n\n} else if (hasCapacity && !freeConnections.isEmpty()) {\n\ndeleteLeastUsedEntry();\n// delete may have made deprecated the RouteSpecificPool instance\nrospl = getRoutePool(route, true);\nentry = createEntry(rospl, operator);\n\n} else { ...\n\n\nI have a test case that I will attach to this issue ASAP.\nIt is a simple example that triggers the above conditions with 3 HttpGet calls, in a serial fashion. As stated previsouly, these calls need nothing particular, except that one of these calls must go to a HTTPS server with client-side certificate authentication (I guess NTLM would be OK, anything that will place a non null state along with the route in BasicEntryPool).\n\nI hope code is self-explainatory. I get 100% failure in my setup. Just configure your 2 URLS, configure classpath, set your keystores system properties, and launch.\n\nWorkaround :\nBest workaround I found is : do not get to step 0.\nThe most robust way I found to do that (i.e. a way that does not involve things like setting max pool size to a gigantic number that can never be reached, ...) is to actively set the ClientContext.USER_TOKEN attribute in an exec context while submitting the request to the client.\nStep 0 triggers when there is an idle connection that waits, and when this idle connection can not be reused, which can only happen if the request's \"USER_TOKEN\" does not match the BasicPoolEntry#getState(). As, in the SSL case, the state is the SSL Cert's X500PrincipalName, and I know it in advance, it's easy to set up front.\n\nBy the way, this taught me that I never could benefit from connection reuse strategies in this SSL case, as connections would always get into the pool with a USER_TOKEN that my requests never had. Don't know if it's mentionned somewhere in the documentation, but this is a noteworthy fact to me.\n\nPlease feel free to comment / correct any mistakes.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-47",
        "summary": "User definable default headers support",
        "description": "Provide the ability to set default headers to be sent on every request.  Should\nbe used whenever an object is created or recycled.  Needs to be user\nconfigurable.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-163",
        "summary": "HttpClient does not compile 'out of the box' in IBM's VisualAge IDE",
        "description": "This was observed with IBM VisualAge 3.5, which runs JDK1.2.2:\n\nImporting the HTTPClient source code into the IDE brings up a\ncompilation error in \n\norg.apache.commons.httpclient.HttpMethodBase.\n\nThe initialization of \"private ResponseConsumedWatcher m_responseWatcher\"\nusing an anyonymous inner class seems to cause some trouble. Implicated code:\n\nprivate ResponseConsumedWatcher m_responseWatcher = new ResponseConsumedWatcher\n() {\n\tpublic void responseConsumed() {\n\t\tresponseBodyConsumed();\n\t}\n};\n\nThe error message is: \"Field initialization: The constructor invoked to create\norg.apache.commons.httpclient.HttpMethodBase$1 with arguments () is not defined\"\n\n...but only in the context of HttpMethodBase(String uri) constructor, i.e.\nthe HttpMethodBase() constructor *can* be compiled, HttpMethodBase(String uri)\n*cannot* be compiled with error \"Cannot create constructor due to incorrect\nfield initialization\".\n\nI interpret this to mean that the compiler is looking for a parameterless\nconstructor for the anonymous class in the context of \nHttpMethodBase(String uri). The message did not really make sense to me. \nChecked the syntax, checked in the Language Definition whether setting up an\nanonymous class like that is permitted; found nothing obviously wrong.\n\nFix:\n\nThe code above is equivalent to constructing the instance at the beginning\nof each constructor of the enclosing class. A copy and paste of the\nconstruction code into each of the two constructors fixes things...until\nthe next update.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1111",
        "summary": "Setting SSLSocket parameters",
        "description": "In HttpClient 4.0.3, it was easy to subclass SSLSocketFactory, and set SSLSocket options (e.g. setEnabledCipherSuites() or setSSLParameterse()) before the SSL handshake happened. This way it was possible to e.g. restrict cipher suites on per-HttpClient basis (instead of JVM-wide system properties).\n\nIn HttpClient 4.1.1, the design has changed quite a lot, and copy-pasting of several long methods is needed. \n\nIdeally, SSLSocketFactory should support applying SSLParameters to the socket. However, SSLParameters is Java 1.6, so if we want to keep compatibility with 1.5, that's out.\n\nHowever, it'd be nice to at least have a method (e.g. \"protected SSLSocket prepareSSLSocket(SSLSocket s)\") that would get called immediately after a socket is retrieved from the socket factory. The default implementation could be just \"return s;\", but subclasses could do something like s.setEnabledCipherSuites() s.setSSLParameters().",
        "label": "NUG",
        "classified": "BACKPORT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-173",
        "summary": "Multiple DIGEST authentication attempts with same credentials",
        "description": "HttpMethodBase's processAuthenticationResponse uses a set of realms to which\nattempts to authenticate have already been made. The elements of the set are a\nconcatenation of the requested path and the value of the Authentication response\nheader.\n\nFor digest authentication this response header contains a nonce value, which is\nuniquely generated by the server each time a 401 response is made. This makes it\nimpossible to recognize that authentication against this realm has been\nattempted before and so all 100 attempts are made before returning. The nonce\nshould probably not be used in the realmsUsed element\n\nReported by Rob Owen <Rob.Owen@sas.com>",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-936",
        "summary": "NullPointerException in NegotiateScheme",
        "description": "- server is configured to allow client to authenticate with kerberos with principal foobar\n- client, using httpclient with a registered authscheme SPNEGO set as a NegotiateSchemeFactory\n\n- when the client authenticate with the (correct) principal foobar, it works !\n- when the client authenticate with the (wrong) principal fooba, it fails with a NPE below.\n\n\nException in thread \"main\" java.lang.NullPointerException\n\tat org.apache.commons.codec.binary.Base64.encodeBase64(Base64.java:233)\n\tat org.apache.commons.codec.binary.Base64.encode(Base64.java:521)\n\tat org.apache.http.impl.auth.NegotiateScheme.authenticate(NegotiateScheme.java:240)\n\tat org.apache.http.client.protocol.RequestTargetAuthentication.process(RequestTargetAuthentication.java:99)\n\tat org.apache.http.protocol.ImmutableHttpProcessor.process(ImmutableHttpProcessor.java:108)\n\tat org.apache.http.protocol.HttpRequestExecutor.preProcess(HttpRequestExecutor.java:167)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:460)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:689)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:624)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:602)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-326",
        "summary": "MultiThreadedConnectionManager should provide a shutdown",
        "description": "MultiThreadedConnectionManager should provide a shutdown() method to release \nall its resources, it is currently using daemon threads that cannot be stopped \nand HTTP connections that cannot be released.\nThis is annoying when the pool of connection is created within a web \napplication that is undeployed and re-deployed (i.e. the JVM is not restarted) \nconsuming resources on local and remote servers.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-311",
        "summary": "getScheme() and getPort() return wrong defaults for HttpsURL",
        "description": "getScheme(), if called on an instance of HttpsURL, wrongly returns http instead\nof https. That's because dynamic data binding doesn't work for final static\nfields (see DEFAULT_SCHEME).",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-63",
        "summary": "Response handlers",
        "description": "Perhaps plugin handlers should be used to handle various ranges of http\nresponses.  Could be used to respond, auto-forward, resubmit ... Could solve the\ndifficulty in handling a 303 response.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-152",
        "summary": "Ensure the features.html and index.html adequately give httpclient enough credit",
        "description": "See the email thread started by Eric Johnson.\nhttp://archives.apache.org/eyebrowse/BrowseList?listId=128&by=thread&from=316092\n\nInitial post:\nBased on the recent URI discussion, and some other points, it strikes me that we\ncould take a little more credit for the work that has gone into HttpClient.\n\nOn the HttpClient home page\n(http://jakarta.apache.org/commons/httpclient/index.html) four RFCs are listed.\n\nGiven all the discussion about URIs being thrown around, I think it might be\nreasonable to add RFC 2396 - for URI compliance.  Then there is RFC 1867, for\nmultipart/form-data POST requests (I think I got the right number there).  Are\nthere RFCs corresponding to our \"cookie\" compliance? Any other RFCs we can claim\ncredit for conforming to?\n\nWith the recent \"Protocol\" changes, I think we've made it relatively\nstraightforward for clients of HttpClient to plug in their own secure sockets\nimplementations, making it easier to use third party, non-Sun solutions.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1103",
        "summary": "GzipDecompressingEntity (and therefore ContentEncodingHttpClient) not consistent with EntityUtils.consumeEntity",
        "description": "Invoking EntityUtils.consume( entity ) after a previous call to entity.getContent (and subsequent processing of the content) throws a java.io.EOFException when gzip decompression support is enabled via ContentEncodingHttpClient or some similar mechanism.  I invoke EntityUtils.consume in a 'finally' block - maybe I'm not using the API correctly ... ?  \n\njava.io.EOFException\n\tat java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:207)\n\tat java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:197)\n\tat java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:136)\n\tat java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:58)\n\tat java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:68)\n\tat org.apache.http.client.entity.GzipDecompressingEntity.getContent(GzipDecompressingEntity.java:63)\n\tat org.apache.http.conn.BasicManagedEntity.getContent(BasicManagedEntity.java:88)\n\tat org.apache.http.util.EntityUtils.consume(EntityUtils.java:65)\n\nI believe the problem is that the underlying DecompressingEntity allocates a new GzipInputStream for each call to getContent, rather than caching the stream created by the first getContent call.  \n       http://svn.apache.org/repos/asf/httpcomponents/httpclient/trunk/httpclient/src/main/java/org/apache/http/client/entity/DecompressingEntity.java\nThe \"CustomProtocolInterceptors\" example has the same bug:  http://hc.apache.org/httpcomponents-client-ga/examples.html\n\nI worked around the problem implementing the example with my own GzipDecompressingEntity (scala code - lazy value not evaluated till accessed):\n\n  class GzipDecompressingEntity( entity:http.HttpEntity) extends http.entity.HttpEntityWrapper(entity) {\n    private lazy val gzipStream = new GZIPInputStream( entity.getContent() )\n    \n    /** \n     * Wrap entity stream in GZIPInputStream\n     */\n    override def getContent():java.io.InputStream = gzipStream\n\n    /**\n     * Return -1 - don't know unzipped content size\n     */\n    override def getContentLength():Long = -1L\n  }\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-734",
        "summary": "request.abort() should interrupt thread waiting for a connection",
        "description": "Calls to HttpRequestBase.abort() will not unblock a thread that is still waiting for a connection and therefore has no ConnectionReleaseTrigger yet.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-524",
        "summary": "Provide feedback mechanism to CredentialsProvider",
        "description": "If the remote server is using BASIC or NT authentication and you pass in \ninvalid credentials you get stuck in an infinite for loop, repeatedly sending \nthe same authentication request again and again to the server.  The for loop is \nin the executeMethod method of the HttpMethodDirector class.\n\nSample code:\n=================================================================\n\n\nimport org.apache.commons.httpclient.Credentials;\nimport org.apache.commons.httpclient.NTCredentials;\nimport org.apache.commons.httpclient.UsernamePasswordCredentials;\nimport org.apache.commons.httpclient.HttpClient;\nimport org.apache.commons.httpclient.methods.GetMethod;\nimport org.apache.commons.httpclient.auth.*;\n\nimport java.io.IOException;\nimport java.io.BufferedInputStream;\nimport java.io.ByteArrayOutputStream;\n\n/**\n * Created by IntelliJ IDEA.\n * User: dmartineau\n * Date: Nov 8, 2005\n * Time: 1:43:21 PM\n */\npublic class ShowProblem\n{\n\n    private String location;\n    private String user;\n    private String pass;\n    private String domain;\n\n    public ShowProblem(String location, String user, String pass, String domain)\n    {\n        this.location = location;\n        this.user=user;\n        this.pass=pass;\n        this.domain=domain;\n\n    }\n\n    public int getFile()\n    {\n        int status = 500;\n        HttpClient client = new HttpClient();\n        client.getParams().setParameter(\n            CredentialsProvider.PROVIDER, new CProvider(user,pass,domain));\n        GetMethod httpget = new GetMethod(location);\n        httpget.setDoAuthentication(true);\n\n        try\n        {\n            // execute the GET\n            status = client.executeMethod(httpget);\n            if (status==200)\n            {\n                BufferedInputStream bin = new BufferedInputStream\n(httpget.getResponseBodyAsStream());\n\n                ByteArrayOutputStream bos = new ByteArrayOutputStream();\n                int bytesRead = 0;\n                byte[] buff = new byte[16384];\n\n                while ( (bytesRead = bin.read(buff)) != -1) {\n                    bos.write(buff, 0, bytesRead);\n                }\n\n                // display the results.\n                System.out.println(new String(bos.toByteArray()));\n            }\n        }\n        catch (Throwable t)\n        {\n            t.printStackTrace();\n        }\n        finally\n        {\n            // release any connection resources used by the method\n            httpget.releaseConnection();\n        }\n        return status;\n\n    }\n\n    public static void main(String[] args)\n    {\n        ShowProblem showProblem = new ShowProblem(args[0],args[1],args[2],args\n[3]);\n        int response = showProblem.getFile();\n        \n    }\n\n\n\n    class CProvider implements CredentialsProvider\n    {\n        private String user;\n        private String password;\n        private String domain;\n\n        public CProvider(String user, String password, String domain)\n        {\n            super();\n            this.user = user;\n            this.password = password;\n            this.domain = domain;\n        }\n\n        public Credentials getCredentials(final AuthScheme authscheme,final \nString host,int port,boolean proxy)\n        throws CredentialsNotAvailableException\n        {\n            if (authscheme == null)\n            {\n                return null;\n            }\n            try\n            {\n                if (authscheme instanceof NTLMScheme)\n                {\n                    return new NTCredentials(user, password, host, domain);\n                }\n                else if (authscheme instanceof RFC2617Scheme)\n                {\n                    return new UsernamePasswordCredentials(user, password);\n                }\n                else\n                {\n                    throw new CredentialsNotAvailableException(\"Unsupported \nauthentication scheme: \" +\n                        authscheme.getSchemeName());\n                }\n            }\n            catch (IOException e)\n            {\n                throw new CredentialsNotAvailableException(e.getMessage(), e);\n            }\n        }\n\n    }\n}",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-904",
        "summary": "HttpMime StringBody constructor throws specification unnecessarily declares UnsupportedEncodingException",
        "description": "The string body constructors that take a charset unnecessarily throw UnsupportedEncodingException - if you have Charset, the encoding is by definition supported:\n\n    public StringBody(\n            final String text, \n            final String mimeType, \n            Charset charset) throws UnsupportedEncodingException {\n        super(mimeType);\n        if (text == null) {\n            throw new IllegalArgumentException(\"Text may not be null\");\n        }\n        if (charset == null) {\n            charset = Charset.defaultCharset();\n        }\n        this.content = text.getBytes(charset.name());\n        this.charset = charset;\n    }\n    \n    public StringBody(final String text, Charset charset) throws UnsupportedEncodingException {\n        this(text, \"text/plain\", charset);\n    }\n    \nI suggest to change this to\n\n    public StringBody(\n            final String text, \n            final String mimeType, \n            Charset charset)  {\n        super(mimeType);\n        if (text == null) {\n            throw new IllegalArgumentException(\"Text may not be null\");\n        }\n        if (charset == null) {\n            charset = Charset.defaultCharset();\n        }\n        this.content = text.getBytes(charset);\n        this.charset = charset;\n    }\n    \n    public StringBody(final String text, Charset charset) {\n        this(text, \"text/plain\", charset);\n    }\n\nThe important change is to change\n\n        this.content = text.getBytes(charset.name());\n\nto \n\n        this.content = text.getBytes(charset);\n\nwhich will not throw and hence the throws specifications can be removed.\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-514",
        "summary": "Preemptive auth flags disregarded during ssl tunnel creation",
        "description": "Using a Squid2.4 proxy, the connection is dropped when trying to connect to a \nssl site. In order for the connection to remain open, preemptive authorization \nis needed for the proxy. The preemptive authorization flags are not propagated \ndown to where the ssl tunnel is created in HttpMethodDirectors executeConnect \nmethod. A new ConnectMethod object is created for the tunnel but the preemptive \nflags set as parameters are not being set on the new ConnectMethod object.\n\nHere is the code that would replicate the problem using a Squid(2.4) proxy :\n\nHttpClient client = new HttpClient();\nclient.getHostConfiguration().setProxyHost(new ProxyHost(\"someproxy\", 3128));\nclient.getParams().setAuthenticationPreemptive(true);\nclient.getState().setProxyCredentials(AuthScope.ANY, new \nUsernamePasswordCredentials(\"user\", \"password\"));\nGetMethod httpget = new GetMethod(\"https://www.verisign.com/\");\nhttpget.getProxyAuthState().setPreemptive();\nclient.executeMethod(httpget);\nhttpget.releaseConnection();",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-790",
        "summary": "Protocol interceptors not called when executing CONNECT methods",
        "description": "When the DefaultRequestDirector tries to establish a route via a proxy to a https target, registered protocol interceptors aren't being called in the createTunnelToTarget method. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-932",
        "summary": "SSLSocketFactory.connectSocket(...) possible NPE",
        "description": "    public Socket connectSocket(\n            final Socket sock,\n            final InetSocketAddress remoteAddress,\n            final InetSocketAddress localAddress,\n            final HttpParams params) throws IOException, UnknownHostException, ConnectTimeoutException {\n...\n\n        SSLSocket sslsock = (SSLSocket) (sock != null ? sock : createSocket()); // ==> sock may be null\n        if (localAddress != null) {\n            sock.setReuseAddress(HttpConnectionParams.getSoReuseaddr(params)); // ==> NPE if sock is null\n            sslsock.bind(localAddress);\n        }\n\nShould sock.setReuseAddress be sslsock.setReuseAddress?\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-780",
        "summary": "ProxyHost/HttpHost: Checks for null when javadoc document null ok",
        "description": "The constructor javadocs for ProxyHost and HttpHost all state that null is an allowed value - but there's an check in the HttpHost constructor for this which throws IllegalArgumentException.\n\n(Actually allowing null as documented would also allow for a spring wiring remaining the same when using a proxy or not - steering the values from a propertyfile.)",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-427",
        "summary": "Implement a cache to perform real request only when needed",
        "description": "Browsers may cache received content according to the values of different\nresponse headers. It would be great if HttpClient could do the same.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-128",
        "summary": "Redirection of a POST method",
        "description": "I execute a PostMethod to an URL which redirects me to a HTML page. If I set \nfollow redirects to true the HttpClient wants to execute once more a POST. Of \ncourse a POST is not allowed to HTML pages. I think the HttpClient should \nexectue a GET method instead. That's also what is in the RFC2616:\n\n10.3 Redirection 3xx\n\n   This class of status code indicates that further action needs to be\n   taken by the user agent in order to fulfill the request.  The action\n   required MAY be carried out by the user agent without interaction\n   with the user if and only if the method used in the second request is\n   GET or HEAD. A client SHOULD detect infinite redirection loops, since\n   such loops generate network traffic for each redirection.\n\n      Note: previous versions of this specification recommended a\n      maximum of five redirections. Content developers should be aware\n      that there might be clients that implement such a fixed\n      limitation.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-454",
        "summary": "Connection with the proxy is not reopened if an proxy auth failure occurs while SSL tunnel is being established",
        "description": "Connection with the proxy is not reopened if an proxy auth failure occurs while\nSSL tunnel is being established.\n\nThis problem has been reported by on the httpclient-user by Gebhard Gaukler\n<gebhard.gaukler at db.com>.\n\nMy bad.\n\nOleg",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-208",
        "summary": "Netscape proxy problem wtih POST",
        "description": "Description:\n\nWhen using httpClient to POST to a http url through a Netscape proxy server, \nthe httpClient failed due to read error when reading status line.  The log seem \nto indicate that the proxy is talking HTTP/1.0 and does not expect the POST \ndata to come.  I am using a modified version of the ClientApp from examples.  I \nwill attach both the test program and log files.\n\nWorkaround:\n\nIf use PostMethod.setUseExpect (true), it will work.  But in many cases, it \nwould be slower.\n\nRelated issues:\n\nIn doing the test, I also found out that the httpClient PostMehtod does not \nwork when the request body is NOT set (not calling setRequestBody).  It also \ndoes not work with empty body (setRequestBody (\"\")).  The attached \nclientApp.properties file has flags to test each case and I will attach the \nlogs as well.  Excuse my ignorance, I do not know for sure what the HTTP spec. \nsays about the body in the POST method.  But at least if the caller/app is \nwrong in not setting the body, some exception should be thrown.  It could also \nbe my server's problem, please let me know if that is the case (I am using \nweblogic server 6.1).",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-167",
        "summary": "SSL Tunneling does not work with MultiThreadedHttpConnectionManager",
        "description": "The HttpConnection is released prematurely when doing SSL tunneling with the\nMultiThreadedHttpConnectionManager.  The ConnectMethod releases the connection\nin responseBodyConsumed() before it can be used by the real method.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-335",
        "summary": "Handling sub-domain cookies.",
        "description": "I noticed a difference in behaviour between httpclient and most common browsers \n(IE/Mozilla). If a web site sets a cookie for \"beta.gamma.com\", this cookie is \nnot sent in requests to \"alpha.beta.gamma.com\". \n  I am not sure what the cookie specs say, but Mozilla, IE and even \nHTTP::Cookies module in LWP seem to behave differently from HttpClient. \nHttpClient seems to rely on the leading dot in the domain name \n(like \".beta.gamma.com\").",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-191",
        "summary": "NTLM Authentication Fails",
        "description": "NTLM Authentication requires multiple request/responses for the authentication\nto succeed.  Since HttpMethodBase is now using just the host, port and realm to\nidentify whether or not authentication has been attempted the second pass for\nNTLM authentication is never performed.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-310",
        "summary": "Memory leak in MultiThreadedHttpClient caused by bad .equals()",
        "description": "Note: I have '2.0 release candidate 1'; I'm not sure which version this\ntranslates into.  The bug is definitely present in the current source.\n\nMultiThreadedHttpClient uses the following code:\n\n// Look for a list of connections for the given config\nHostConnectionPool listConnections = (HostConnectionPool) \n    mapHosts.get(hostConfiguration);\nif (listConnections == null) { \n    // First time for this config\n    listConnections = new HostConnectionPool();\n    listConnections.hostConfiguration = hostConfiguration;\n    mapHosts.put(hostConfiguration, listConnections);\n}\n\n\nThe hash map relys on HostConfiguration's .equals() to resolve equality &\ndetermine if there is a mapping for the configuration.\n\nHostConfiguration has the following in it's .equals() method:\n\nif (!protocol.equals(config.getProtocol())) {\n    return false;\n}\n\n. . . and Protocol has:\n\nif (obj instanceof Protocol) {\n            \n    Protocol p = (Protocol) obj;\n            \n    return (\n        defaultPort == p.getDefaultPort()\n        && scheme.equalsIgnoreCase(p.getScheme())\n        && secure == p.isSecure()\n        && socketFactory.equals(p.getSocketFactory()));\n\n}\n\nHowever, there is no .equals() method in any of the ProtocolSocketFactory\nobjects, and there isn't any note in the interface about the necessity of the\n.equals() method.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-169",
        "summary": "Cookies with null value are not formatted correctly",
        "description": "I have a server that sets a bunch of empty cookies:\n\n2003/03/06 16:28:52:055 PST [DEBUG] wire - -<< \"Set-Cookie: list%2ESince=; \npath=/[\\r][\\n]\"\n2003/03/06 16:28:52:055 PST [DEBUG] wire - -<< \"Set-Cookie: search%2EPhoneSDA=; \npath=/[\\r][\\n]\"\n\n\n  On subsequent requests, httpclient attaches these cookies thusly:\n\n2003/03/06 16:28:55:480 PST [DEBUG] wire - ->> \"Cookie: $Version=0; list%\n2ESince=null; $Path=/[\\r][\\n]\"\n2003/03/06 16:28:55:480 PST [DEBUG] wire - ->> \"Cookie: $Version=0; search%\n2EPhoneSDA=null; $Path=/[\\r][\\n]\"\n\n\n  I'm not sure how to read this portion of wirelog, but seems that actual\nvalues containing the string \"null\" are being sent as part of the request.\nIn the response to my request, the server now echos cookies with \"null\"\nvalues back to me.\n\n\n2003/03/06 16:28:55:660 PST [DEBUG] wire - -<< \"Set-Cookie: search%\n2EPhoneSDA=null; path=/[\\r][\\n]\"\n2003/03/06 16:28:55:660 PST [DEBUG] wire - -<< \"Set-Cookie: list%2ESince=null; \npath=/[\\r][\\n]\"\n\n\n  This isn't good.  Basically, the list.Since= cookie is being\nconverted to list.Since=null.  This causes the server's script to\ncrash:\n\n<p>Microsoft VBScript runtime </font> <font face=\"Arial\" \nsize=2>error '800a000d'</font>\n<p>\n<font face=\"Arial\" size=2>Type mismatch: 'CINT'</font>\n<p>\n<font face=\"Arial\" size=2>/listCust.asp</font><font face=\"Arial\" size=2>, line \n283</font> \n\n\n  I guess the script tries to assign the string \"null\" to an integer, and\ndies.\n\nReported by Tom Samplonius <tom@sdf.com>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-663",
        "summary": "New Gump projects for HttpComponents 4.0",
        "description": "Create new Gump definitions for the 4.0 code base, both core and client.\nThere are other Maven-based projects in Gump to learn from, for example Apollo and Excalibur.\n\n",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "HTTPCLIENT-1144",
        "summary": "Caching client has a class for common headers that was not being used consistently in the code",
        "description": "The HttpCachingClient has a class called HeaderConstants that contains all the cache interesting headers that are used in the code base.  This class of string constants was not being used consistently in the code base.  The attached patch cleans this up.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-628",
        "summary": "AutoCloseInputStream.available() throws IOException when auto-closed",
        "description": "ACIS auto-close itself as soon as EOF is detected. That leads to IOExceptions being throw in response to calls that are valid for a stream that has reached EOF.\nACIS should instead close the _underlying_ stream and switch itself into an EOF mode that does not throw exceptions until it is closed explicitly.\n\nreported by Tom Lipkis on the developer mailing list\nhttp://mail-archives.apache.org/mod_mbox/jakarta-httpcomponents-dev/200702.mbox/%3c200702101905.l1AJ5MeK027997@fw3.pss.com%3e",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-865",
        "summary": "HttpClient OSGi Export-Package doesn't specify version",
        "description": "The \"Export-Package\" manifest entry doesn't specify the version of the package being exported.  This means that packages importing it can't specify a version to import.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-521",
        "summary": "SimpleHttpConnectionManager is used incorrectly by tutorial code",
        "description": "Using pretty well standard (from the tutorial) code causes the \nSimpleHttpConnectionManager to print its \"being used incorrectly\" warning if \nthe connection times out (or other I/O exception occurs).\n\nI will attach a simple test I made to demonstrate this.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-330",
        "summary": "[PATCH] Wirelog corrections",
        "description": "This patch \n\n* fixes the problem reported by Geir H. Pettersen <geir at cellus.no>. See\nhttp://marc.theaimsgroup.com/?t=108072355300004&r=1&w=2 for details\n\n* increases the priority of HTTP request/status line & HTTP headers output from\nDEBUG to INFO. Quite often request/response content generate excessive amount of\noutput in the wirelog and produce no valuable debug information of what so ever.\nBy setting wirelog verbosity to INFO one can turn off the logging of \nrequest/response content.\n\nI believe the patch should be applied to both CVS HEAD and 2.0 branch. Please\nlet me know if you agree\n\nOleg",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-376",
        "summary": "DateParser refactoring; Stateful cookie specs",
        "description": "Presently DateParser is tightly coupled with the DefaultHttpParams class. I find\nthis sub-optimal from the design standpoint. Moreover, I believe that date\npatterns should be specifiable at the method, host, and client levels, not only\nglobal one. Currently this is not the case, and out of sync with the rest of the\npreference framework, which can result in quite a bit of confusion.\n\nWhen refactoring the DateParser class I also realized that the cookie specs were\nshared by all the HttpMethod instances and as such had to be stateless. Even\nthough it is presently the case, technically there's nothing that prevents the\nuser from implementing a stateful cookie spec, plugging it into HttpClient, and\nby doing so potentially causing quite unpleasant concurrency issues. Therefore,\nI believe pluggable cookie specs MAY NOT be shared. There should be a cookie\nspec instance created per method invocation \n\nOleg",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-98",
        "summary": "PUT method blocks against older servers",
        "description": "To reproduce, attempt a PUT request against an appropriate servlet under TC3.2\n(yes I know that needs an upgrade - sigh)\n\nRFC 2616 says:\n\"Because of the presence of older implementations, the protocol allows ambiguous\nsituations in which a client may send \"Expect: 100- continue\" without receiving\neither a 417 (Expectation Failed) status or a 100 (Continue) status. Therefore,\nwhen a client sends this header field to an origin server (possibly via a proxy)\nfrom which it has never seen a 100 (Continue) status, the client SHOULD NOT wait\nfor an indefinite period before sending the request body.\"\n\nThis isn't how HttpClient behaves. After sending the headers,\nPutMethod.writeRequestBody() returns false. HttpMethodBase then calls\nreadStatusCode(), which blocks waiting for a read (or I guess you could time out\nthe whole request). Right now this makes it impossible to use HttpClient to PUT\nto older Http 1.1 implementations.\n\nA suggested resolution: since the spec allows for clients to avoid waiting if\nthey know the 100 response will not arrive, why not simply provide a boolean\nflag to allow the 'wait for 100' behaviour in PutMethod.writeResponseBody() to\nbe turned off, on a per-request basis? This solution puts the burden of knowing\n\"origin server[s]...from which it has never seen a 100 (Continue) status\" on the\nuser of HttpClient. Less than perfect as you can only find out that this has\nhappened by trial and error.\n\nA more correct solution, is to maintain a list of servers that ignore the Expect\nheader in PutMethod, and override PutMethod.readStatusCode() to time out, send\nthe body, remember this server is buggy, and read the status code again.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-690",
        "summary": "Provide access to SSLSession in ManagedClientConnection",
        "description": "Provide access to the wrappedConnection in org.apache.http.impl.conn.AbstractClientConnAdapter via some interface in order to access the socket from within an HttpProcessor. Currently the org.apache.http.conn.OperatedClientConnection has a getSocket() method, but the connection implementation returned by\n\n  context.getAttribute(ExecutionContext.HTTP_CONNECTION) \n\n(org.apache.http.impl.conn.tsccm.BasicPooledConnAdapter) does not provide access to the wrappedConnection.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-759",
        "summary": "DefaultClientRequestDirector doesn't release connections back to ClientConnectionManager on exceptions",
        "description": "See HTTPCLIENT-747 for more info.  Basically the deal is that an entry is always allocated, but currently it's only released if execute(..) completes normally.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-909",
        "summary": "Upgrade all default socket factories to use SO_REUSEADDR parameter",
        "description": "See HTTPCORE-209",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-387",
        "summary": "DefaultHttpParamsFactory.getDefaultParams() is not thread safe",
        "description": "The method getDefaultParams() in \norg.apache.commons.httpclient.params.DefaultHttpParamsFactory is not thread \nsafe.  In this code:\n\n    public HttpParams getDefaultParams() {\n        if (httpParams == null) {\n            httpParams = createParams();\n        }\n\n        return httpParams;\n    }\n\nit is possible that httpParams will be called by one thread which will set \nhttpParams, then a second thread may call it and may find httpParams is \nnon-null.  However, under both the old (Java Language Spec chapter 17) and \nnew Java Memory Models, the second thread won't necessarily see the values \nthe first thread has set in the referenced HttpParams object.\n\nThe easiest way to fix this for all JVMs and memory models is by declaring \ngetDefaultParams() to be synchronized.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-735",
        "summary": "allow unsetting of DEFAULT_PROXY and FORCED_ROUTE parameters in the client stack",
        "description": "Since we don't want to delay client alpha3 until HTTPCORE-139 is solved in beta2, we need a parameter specific solution for unsetting these client parameters on the request level.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-132",
        "summary": "New Preferences Architecture",
        "description": "An architectural solution is needed to configure various aspects of HttpClient,\nMethods and Connections. \n\nFeatures:\n- can configure certain properties per request / per connection\n- all configuration is done in a consistant way \n- do not use system properties\n- configuration is completely optional: default values should be used if no\nconfiguration is made\n\nThis is a refactoring request / reminder. File configuration issues as\ndependencies of this bug.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-193",
        "summary": "Buffered output to socket",
        "description": "--Posted by Slavik Markovich:\n\nHi all,\n\nThis is probably a known issue (but I haven't found the answer for it yet).\nI'm using httpclient to post data to a remote server but as far as I can see\n(using ethereal) the client is writing every line to the wire without buffering.\nAfter examining the code, I can see that the HttpConnection class is using the\noutput stream received from the socket directly.\nIs there a reason for the direct writing?\nThis is a problem for me 'cause the remote server sets a very low timeout and\nreturns a bad request response after receiving the request line (without any\nother header line or request body).\n\nCan I easily add a buffered behavior to the http client?\n\n10x",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-969",
        "summary": "BasicCookieStore.getCookies() returns non-threadsafe collection",
        "description": "BasicCookieStore.getCookies() is a simple method.  It's synchronized, and it returns an unmodifiable wrapper around the underlying cookie list.  If the caller were to then iterate over it as another thread were to manipulate the cookie list via BasicCookieStore, this would create a thread un-safe situation because both threads aren't doing their reading/writing with the same lock (the reader doesn't even have a lock).\n\nI suggest fixing this by using CopyOnWriteArrayList, or by making a defensive copy in getCookies()\n\nThis issue might apply to some of the other basic implementations of some of the interfaces but I haven't checked.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-726",
        "summary": "review TSCCM for spurious wakeups",
        "description": "Review the code of the TSCCM/ConnPoolByRoute for places where spurious wakeups may happen.\nVerify that this case is dealt with correctly. Unit test by giving invalid wakeup signals?",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-309",
        "summary": "[RFE] Allow streaming of POST methods via chunked transfer encoding.",
        "description": "This is an RFE with a possible implementation attached. The implementation does\nnot modify any existing code.\n\nWe're using HTTP POST to send a large amount of data with an unknown size. We\ndon't want to buffer the entire request, so we implemented a streaming POST\nmethod. The implementation has 3 classes: StreamedPostMethod,\nBufferedChunkedOutputStream and OutputStreamWriter. The bulk of the code is in\nthe BufferedChunkedOutputStream, which may be a good target for replacing\nChunkedOutputStream from the main distribution.\n\nBufferedChunkedOutputStream has the following charactersitics:\n1) It has an internal 2K buffer. Without the buffer, chunk sizes would be too\nsmall in many cases (e.g. ObjectOutputStream likes to call write(byte[]) with 4\nbyte long arguments). 2K was chosen to minimize the chunk overhead to less than 1%.\n2) If the entire entity body fits within the 2K buffer, it does not use\nchunking. This implies that the headers are only sent out when the first chunk\n(or the entire body) has to be written, but no sooner.\n3) The chunk size is not limited to 2K: if write(byte[]) is called with a large\nargument, the internal buffer and the new request are sent out as a single chunk.\n4) Because of (2) it's tightly coupled to StreamedPostMethod.reallyWriteHeaders.\n5) StreamedPostMethod calls BufferedChunkedOutputStream.finish() to write the\nlast buffer and ending chunk.\n\nBecause of 4 and 5, we didn't want to touch ChunkedOutputStream. Interestingly,\nEntityEnclosingMethod is already tightly coupled to ChunkedOutputStream because\nit has to call writeClosingChunk. There is probably some room for refactoring here.\n\nThe package is just a suggestion; feel free to move the files as appropirate.\nThis code was written against 2.0rc2. We're hoping it will get included in time\nfor the 2.1 release.\n\nTo use the code, you must implement OutputStreamWriter and pass it to\nStreamedPostMethod's constructor. Execute the method as usual.\n\nCaveats: StreamedPostMethod does not implement Expect/continue logic. We had no\nway to test this. It is also strictly for POST. In general, the same methodology\nis applicable to PUT, etc. It should be fairly simple to generalize.\n\nLegal: Goldman, Sachs & Co. is making this code available under the Apache License.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-331",
        "summary": "[PATCH] HttpClient#getHost & HttpClient#getPort methods are misleading",
        "description": "HttpClient#getHost & HttpClient#getPort methods are misleading, accompanied by\nobsolete, factually wrong javadocs and as such should be deprecated.\n\nOleg",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-386",
        "summary": "Catch SocketTimeoutException not InterruptedIOException",
        "description": "There are a couple of places where you're catching InterruptedIOException \nthat should catch SocketTimeoutException instead.  For example, from \nHttpConnection:\n\n    protected boolean isStale() {\n        boolean isStale = true;\n        if (isOpen) {\n            // the connection is open, but now we have to see if we can \nread it\n            // assume the connection is not stale.\n            isStale = false;\n            try {\n                if (inputStream.available() == 0) {\n                    try {\n                        socket.setSoTimeout(1);\n                        inputStream.mark(1);\n                        int byteRead = inputStream.read();\n                        if (byteRead == -1) {\n                            // again - if the socket is reporting all data \nread,\n                            // probably stale\n                            isStale = true;\n                        } else {\n                            inputStream.reset();\n                        }\n                    } finally {\n                        socket.setSoTimeout(this.params.getSoTimeout());\n                    }\n                }\n            } catch (InterruptedIOException e) {\n                // aha - the connection is NOT stale - continue on!\n\nHere the catch of InterruptedIOException is intended to happen when \ninputStream.read() terminates due to the socket.setSoTimeout() time being \nreached.  However, it could also occur because Thread.interrupt() has been \ncalled, in which case \"continue on\" is not what should happen, instead, the \nrequest should terminate.\n\nThere are legitimate reasons why someone might want to interrupt the \nhttpclient code, for example, httpclient does not provide a hard timeout on \nthe total length of time a request may take, including connecting, sending \nthe request, and receiving the complete response, so to enforce a hard \ntimeout it is necessary to run the request in a worker thread and interrupt \nit if it hasn't completed before the timeout expires (the technique used in \nyour TimeoutController class).\n\nNote that SocketTimeoutException was added in 1.4.  For compatibility with \nolder jdk versions, the code can catch InterruptedIOException and use \ngetClass() to see whether it is a SocketTimeoutException.\n\nThere are probably other places in the code where InterruptedIOException is \ncaught and interpreted as a socket timeout, and where Thread.interrupt() \nwill not have the proper effect of causing the request to terminate ASAP, \nbut I'm not familiar enough with the code to find them all.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-686",
        "summary": "Maven 2 POM includes junit in default \"compile\" scope, rather than \"test\" scope",
        "description": "The POM at the URL above declares a dependency on JUnit in the default scope, rather than the \"test\" scope.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-285",
        "summary": "Ability to ignore (reject) cookies altogether",
        "description": "I was looking for a way to ignore cookies altogether, but there doesn't appear\nto be one.  I could definitely use this capability right now, and I can see\nothers making use of it at times.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-328",
        "summary": "Proxy tunneling/auth with CONNECT for non-HTTP protocols",
        "description": "HttpClient would be even more useful if it supported connections tunneled \nthrough proxies and proxy authentication for non-HTTP protocols. E.g. Binary \nprotocols such as SSH or JXTA-TCP could be tunneled through a web proxy if \nHttpClient provided access to the underlying Socket after the negotiations \n(auth, CONNECT) with the web proxy were complete.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-455",
        "summary": "Feature Request: include contributed code for Plugin Proxy Detection",
        "description": "Attached is a zip file containing two classes - PluginProxyUtil and\nProxyDetectionException.  I've tested\nPluginProxyUtil.detectProxy(URL) on Windows XP(JRE's 1.3/1.4/1.5 with IE) and\nSolaris (JRE 1.4 with Netscape)\nand it correctly detects browser plugin settings.  I don't have access to MacOS\nX  to try it, but I doubt that\nit works there anyway based on Dmitri's comments here:\n\nhttp://forum.java.sun.com/thread.jspa?threadID=364342&tstart=120\n\nPlease change the header and package as necessary to include it in the contrib\nsection.  I plan to contribute\nan example Applet that uses this code at some point - our app is way too\ncomplicated to use as an example.\nIf you want to wait until that is done to include it, that's fine too.  Just\nwanted to offer this up now in case\nanyone else is looking for it.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-12",
        "summary": "double encoding of URLs",
        "description": "In HttpMethodBase.generateRequestLine(HttpConnection connection, String name, \nString reqPath, String qString, String protocol)\n\nthe path is always encoded using URIUtil.encode(reqPath,URIUtil.pathSafe()). \nHowever, if the path already contains an encoding space, i.e. %20, the % will \nbe encoded again, so we get %2520. This behavior is not correct. We shouldn't \nencode any % signs.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-336",
        "summary": "ArrayIndexOutOfBoundsException in HttpStatus.getStatusText(508)",
        "description": "Try the following:\n\n    System.out.println(\"Status text = \" + HttpStatus.getStatusText(507));\n    try {\n      System.out.println(\"Status text = \" + HttpStatus.getStatusText(508));\n    }\n    catch (Exception ex) {\n      System.err.println(\"Exception! msg = \" + ex.getMessage());\n      ex.printStackTrace();\n    }\n    System.out.println(\"Status text = \" + HttpStatus.getStatusText(509));\n\n507 -> returns a message as expected\n508 -> ArrayIndexOutOfBoundsException\n509 -> null as expected",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-868",
        "summary": "Add <a name=\"\"> anchors to documentation sections",
        "description": "In all docs, sections are missing <a name> anchors. I see that the xdocs stylesheet in the repository is supposed to generate them, yet the site is missing them at this moment.\n\nSee https://svn.apache.org/repos/asf/jakarta/site/xdocs/stylesheets/site.xsl \ntemplate match=\"section\"",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-440",
        "summary": "Exception in HttpConnection because of unchecked buffer size",
        "description": "From the httpclient-dev mailing list:\n\nDate: Tue, 8 Mar 2005 19:08:35 +0100\nSubject: Error with multiple connections\n\nHello,\n\n \n\nI am having some problems while trying multiple connections over a\nHttpClient object with a MultiThreadedHttpConnectionManager. I am\nlaunching 10 threads and each thread executes some GetMethods using this\nHttpClient object.\n\n \n\nSome times I got an error like this:\n\n \n\njava.lang.IllegalArgumentException: Buffer size <= 0\n\n      at java.io.BufferedInputStream.<init>(Unknown Source)\n\n      at\norg.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:70\n3)\n\n      at\norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpCon\nnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1170)\n\n      at\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:6\n28)\n\n      at\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:4\n97)\n\n      at Main$Hilo.run(Main.java:58)\n\n \n\nDoes anybody have any idea? \n\n \n\nThanks in advance,\n\nJorge",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-635",
        "summary": "Port fix for HTTPCLIENT-633 to 4.0",
        "description": "The fix for MultiThreadedHttpConnectionManager from HTTPCLIENT-633 should be ported to ThreadSafeClientConnManager in 4.0.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-853",
        "summary": "Wrong cookie matching port number reported when using a proxy",
        "description": "Following the example given in https://issues.apache.org/jira/browse/HTTPCLIENT-852 and the route HttpRoute[{}->http://xyz.webfactional.com:7295->http://www.seoconsultants.com]:\n\none of the new cookies is reported to be added as:\n\n[java] 2009/05/28 19:58:23:398 CEST [DEBUG] RequestAddCookies - Cookie [version: 0][name: ASPSESSIONIDCSARBQBA][value: MAMPAMKCBDJJFKNAAPKPMDAA][domain: www.seoconsultants.com][path: /][expiry: null] match [www.seoconsultants.com:7295/]\n\nwhereas it should be:\n\n[java] 2009/05/28 19:57:46:667 CEST [DEBUG] RequestAddCookies - Cookie [version: 0][name: ASPSESSIONIDCSARBQBA][value: AAMPAMKCMBINHNEHPFEBFADA][domain: www.seoconsultants.com][path: /][expiry: null] match [www.seoconsultants.com:80/]\n\ni.e. the same as without using a proxy. 7295 is the port number used to access the proxy. The target domain www.seoconsultants.com is accessed through the regular HTTP port number 80, thus the cookie matching should also refer to port 80 and not the proxy's port.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-963",
        "summary": "client cache does not respect 'Cache-Control: no-store' on requests",
        "description": "\"The purpose of the no-store directive is to prevent the inadvertent release or retention of sensitive information (for example, on backup tapes). The no-store directive applies to the entire message, and MAY be sent either in a response or in a request. If sent in a request, a cache MUST NOT store any part of either this request or any response to it.\"\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.2\n\nThe current implementation will incorrectly cache responses to requests containing 'Cache-Control: no-store'.",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-391",
        "summary": "Deprecate and replace TestWebapp with the SimpleHttpServer based testing framework",
        "description": "Basically TestWebapp based testcases test functionality of Tomcat, rather than\nthat of HttpClient. They tend to get broken with every major release of Tomcat\nand have proven more of a burden than any good",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-82",
        "summary": "HttpURLConnection wrapper",
        "description": "Initial comments from Vincent Massol for this feature:\n\nI am moving Jakarta Cactus from using the JDK HttpURLConnection to\nCommons HttpClient. However, I have some public interface that return\nHttpURLConnection and I cannot break that contract with Cactus users.\n\nI propose to write a HttpURLConnection wrapper for HttpMethod (I have\nactually already written it but I am currently testing it on Cactus and\nwill make a proper donation once I am sure it works - i.e all the Cactus\ntests pass as before ... ).\n\nI attach a preview of it for those interested.\n\nWhat do you think of including it in HttpClient distribution ?\n\nThanks\n-Vincent",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-402",
        "summary": "DefaultMethodRetryHandler bug",
        "description": "DefaultMethodRetryHandler does not seem to test correctly for the number of\nattempts to retry a given method. It seems to bail out one attempt too early:\n\nif (executionCount >= this.retryCount) {\n  // Do not retry if over max retry count\n  return false;\n}\n\nFor example, if I set the retryCount to 1, HttpClient does not retry the method\nat all. At least that's what I'm seeing when I step through it with a debugger.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-249",
        "summary": "please log allocation of new connections to support debugging, testing",
        "description": "I'd like to suggest that the MultiThreaded connection manager emit a trace-level log when it \nallocates a new HttpConnection to support debugging and testing.  I added one while working on \nmy integration in Apache Axis (see org.apache.axis.transport.http.CommonsHTTPSender) and \nfigured this would be of general use.  I'll attach a patch with the oh-so-minor addition after \nsubmitting this enhancement request.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-235",
        "summary": "HttpMethodBase logger uses wrong class.",
        "description": "I just noticed a minor error in HttpMethodBase: it initializes its Log object\nwith HttpMethod.class instead of HttpMethodBase.class.  No big deal, but it\nprobably ought to be fixed at some point.  I'll attach the patch.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-38",
        "summary": "Header Connection Close - Closes the Connection",
        "description": "If the connectionHeader equals Close the conection imediateley closes, without \nwaiting for the responce back from the server. \n\nIf the client is pulling data from a CGI script which has not sent the Content \nLength - most servers will send a Connection Close header. For example \n\n-----------------------------------------\nHTTP/1.1 200 OK\nDate: Fri, 21 Jun 2002 17:08:46 GMT\nServer: Apache/1.3.14 (Unix)\nConnection: close\nContent-Type: text/html\n \n<html>\n      <head>\n            <title>thegumtree.com - London's online community for Aussies, Kiwis\n and South Africans</title>\n                           <meta http-equiv=\"Content-Type\" content=\"text/html; c\nharset=iso-8859-1\">\n                   </head>\n\n--------------------------------\n\nI do not yet have a work arround apart from commenting out the the following \ncode in \n\nHeader connectionHeader = getResponseHeader(\"connection\"); etc\n\nin HttpMethodBase",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1160",
        "summary": "LayeredSchemeSocketFactory.createLayeredSocket() should have access to HttpParams",
        "description": "We use a custom implementation of LayeredSchemeSocketFactory that manages a keystore location through HttpParams. That allows us to use different keystores on a per connection basis.\n\nWhen a proxy is used LayeredSchemeSocketFactory.createLayeredSocket() is invoked which does not have a parameter that passes the HttpParams along. In consequence certificate authentication fails in our implementation. Is there a reason why all other factory methods in the super class have an HttpParams parameter except for LayeredSchemeSocketFactory.createLayeredSocket()?\n\nThe downstream bug is here:\n\n369805: certificate authentication with custom keystore fails behind proxy\nhttps://bugs.eclipse.org/bugs/show_bug.cgi?id=369805\n\nAny input would be greatly appreciated.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-464",
        "summary": "An HTTP \"204 NO CONTENT\" response results in dropped connection",
        "description": "After receiving a \"204 NO CONTENT\" response, HttpClient always closes the \nconnection.\n\nThis did not happen in earlier versions and appears to have been caused by a \nrecent fix to bug# 34262.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-807",
        "summary": "ContentBody doesn't currently have a setMimeType method.",
        "description": "ContentBody and therefore FileBody, StringBody and InputStreamBody do not have a setMimeType method so you can't set the Mime Type, it always defaults. \nCurrent workaround is to subclass and override getMimeType.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-988",
        "summary": "cache module should strip 'Content-Encoding: identity' from responses",
        "description": "Per the RFC, the \"identity\" content coding SHOULD NOT be used in the Content-Encoding header:\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.5\n\nThe current implementation will pass 'Content-Encoding: identity' through unchanged, although it would be simple enough to filter this out.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-223",
        "summary": "URI path resolution problems.",
        "description": "URI does not completely conform to RFC 2396.  In particular it does not handle the following \nrelative URIs correctly:\n\n../../../g\n../../../../g",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-639",
        "summary": "Add OSGi bundle metadata to manifest",
        "description": "See this discussion on the Felix mailing list:\nhttp://www.mail-archive.com/felix-dev@incubator.apache.org/msg04041.html\n\nIf there is an easy way to generate the information required for an OSGi bundle into the manifest of our distributable JAR, we should do it.\nThe runtime and API are not affected, it is only a modification of the build process.\nI'll follow up on this when I have information about the required tooling.\n\ncheers,\n  Roland\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-944",
        "summary": "In case of SocketTimeoutException and using HttpRequestRetryHandler the execution is always +1",
        "description": "If my request encounter a SocketTimeoutException, the HttpRequestRetryHandler#retryRequest will be called with an executionCount with a value +1.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-179",
        "summary": "HTTPS Post Does Not Work",
        "description": "Using Java 1.4.1_01 on Windows 2000. An HTTPS Post results in HTTP/100-Continue \nmessages. The same code posting to a non HTTPS URL works. The code populates \nthe request body using a NameValuePair array.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-450",
        "summary": "TestExcetions never run",
        "description": "In one of the testcases of HttpClient, TestExcetions, it reads:\n\n    // ------------------------------------------------------------------- Main\n    public static void main(String args[]) {\n        String[] testCaseName = { TestChallengeParser.class.getName() };\n        junit.textui.TestRunner.main(testCaseName);\n    }\n\n    // ------------------------------------------------------- TestCase Methods\n\n    public static Test suite() {\n        return new TestSuite(TestChallengeParser.class);\n    }\n\nWhere \"TestChallengeParser\" should be \"TestExcetions\".",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-463",
        "summary": "Occasional \"Host connection pool not found\"",
        "description": "I'm using HttpClient with MultiThreadedHttpConnectionManager in a crawler\napplication. The application issues requests to many hosts, in 10-20 parallel\nrequest threads. Each thread creates a new GetMethod, but all threads use the\nsame instance of HttpClient, created once with a multi-threaded manager.\n\nThe code in each thread looks like this:\n\nGetMethod get = new GetMethod(url);\ntry {\n  int code = getSharedHttpClient().executeMethod(get);\n  // ... read response, do stuff\n} finally {\n  get.releaseConnection();\n}\n\n\nFrom time to time I get an error like this:\n\nHost connection pool not found, hostConfig=HostConfiguration[host=http://a.b.c]\n\nwhere the url is a random url from my fetch list. I looked into the source code\nof the nightly release (MultiThreadedHttpConnectionManager.java:979), but the\ncomment there is not enlightening... ;-) Any help or suggestions for further\ndebugging would be appreciated.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-584",
        "summary": "Remove lib directory from SVN trunk",
        "description": "build.xml expects to find junit.jar in the lib directory for building and running tests.\n\nThe jar is not included in SVN, but nor is the jar ignored, so when it is downloaded it shows up as an unversioned file.\n\nThe file should be included in or excluded from SVN.\n\n==\n\nNote: In JMeter we use a lib/opt directory.\nThis is present in SVN - but all contents are ignored.\n\nThis can be used for extra jars that cannot be or are not included in SVN.\n\nCould use the same approach for junit.jar...",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "HTTPCLIENT-1086",
        "summary": "Use Iterable<? extends UrlEncodedFormEntity> instead of List<? extends UrlEncodedFormEntity> in URLEncodedUtils.format and UrlEncodedFormEntity",
        "description": "UrlEncodedFormEntity requires a List<? extends UrlEncodedFormEntity> to pass it to URLEncodedUtils.format. It would be nice to use Iterable<? extends UrlEncodedFormEntity> to be able to use other collections, e.g. a Set<? extends UrlEncodedFormEntity>",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-287",
        "summary": "Setting CONNECTION_TIMEOUT and SO_TIMEOUT on a per-method basis",
        "description": "The capability of setting connection timeout and socket timeout on a per-method\nbasis should be provided. This would enable different threads, sharing the same\nHttpClient, to set different timeouts for their methods executions.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-501",
        "summary": "Minor RFC 2109 / 2965 violation",
        "description": "Hi all,\n\nwe received this bug report for the debian commons-httpclient\npackage:\n\n<debian_bugreport>\nThe following bug is present in upstream, 2.0.2 and 3.0RC3, at least as far\nas I can tell by testing.\n\nThe specification grammar for the Cookie and Cookie2 HTTP headers\n(specified by RFC 2109 section 4.3.4, and RFC 2965 section 3.3.4,\nrespectively) require that the ordering of pairs is \"Version, NAME, path,\ndomain\" (and, in RFC 2965, \"port\" after \"domain\"). However, HTTPClient\nproduces a cookie string with the domain pair appearing before, rather\nthan after, the path pair. The RFCs specifically *do not* use either the\ngrammar or the clarifying text (\"can occur in any order\") that occurs in\nthe sections that define the Set-Cookie and Set-Cookie2 headers (4.2.2 and\n3.2.2, respectively).\n\nSince the sections in question do not, in fact, discuss the issue of pair\nordering in Set-Cookie/Set-Cookie2 at all (other than in using a grammar\nthat clearly expresses the requirement), and since the complimentary\nheader explicitly permits them to occur in any order, it seems likely\nthat HTTPClient is not the only client with this issue, and that most\nservers will accomodate this situation (in fact, for it to have gone\nunnoticed for this long, it seems likely that either I'm badly misreading\nthe specification, or no major server has a problem coping with this).\n</debian_bugreport>\n\nFor your reference the debian bug number:\nhttp://bugs.debian.org/cgi-bin/bugreport.cgi?bug=329245\n\nRegards,\n\nWolfgang",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1035",
        "summary": "cache should invalidate obsoleted entries mentioned in Content-Location",
        "description": "From http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.6:\n\nIf a cache receives a successful response whose Content-Location field matches that of an existing cache entry for the same Request-URI, whose entity-tag differs from that of the existing entry, and whose Date is more recent than that of the existing entry, the existing entry SHOULD NOT be returned in response to future requests and SHOULD be deleted from the cache.\n\nCurrent caching module doesn't do this (yet). As this is a recommendation (SHOULD) and not a requirement (MUST) I am marking this as an improvement rather than a bug.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-835",
        "summary": "Thread safety and visibility Improvements",
        "description": "AbstractAuthenticationHandler.DEFAULT_SCHEME_PRIORITY is not protected against external changes.\n\nAlthough the field is private, subclasses can obtain a reference to it and so may be able to change it.\n\nConsider making the list read-only, or returning a copy instead.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-605",
        "summary": "junit dependency in pom.xml with default compile scope",
        "description": "The dependency set as defined in:\nhttp://www.ibiblio.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.pom\nincludes junit, but not with a <scope>test</test>. I suppose the junit dependency should have a test scope. Could someone fix this? Because of this my application is packaged including junit 3.8.1, which adds 118KiB for nothing.\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-389",
        "summary": "Provide Date Header Util Methods",
        "description": "Hello,\n\nIt would be really nice to have util methods that help with setting date\nheaders.  For instance, like the servlet spec's setDateHeader() method.  This\nallows for the client of HttpClient to not have to deal with formatting the date\ninto the correct string.  There is a parseDate method that turns a String into a\nDate.  It would be nice to have the opposite method.\n\nThanks!\nSeth",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-60",
        "summary": "Handle virtual hosts, relative urls, multi-homing",
        "description": "Need to be able to open a socket to one ipaddress (or hostname) and then include\na virtual hostname in the Host header. Use InetAddress class perhaps.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1032",
        "summary": "cache revalidation of variants does not update original variant entry",
        "description": "When the cache stories multiple variant entries due to Vary headers in responses, the cache correctly sends a conditional request containing the etags of any existing variants on a \"variant miss\" (incoming request does not match the request variants already cached). In addition, when it receives a 304 response, it correctly returns the indicated variant to the request that causes the variant miss. However, it does not update the pre-existing variant cache entry as recommended by RFC 2616.\n\nFor example:\n\nrequest 1, User-Agent: agent1 results in a 200 OK with Etag: etag1 and Vary: User-Agent.\nrequest 2, User-Agent: agent2 causes an If-None-Match to the origin; if it returns 304 Not Modified with Etag: etag1\nrequest 3, User-Agent: agent1 results in a 200 OK but gets the (outdated) entry that resulted from request 1\n\nin other words, the origin response from request 2 does not update the variant for \"agent1\".\n\nThis does not cause incorrect behavior (this is a SHOULD) but does miss out on some caching opportunities here.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-119",
        "summary": "[PATCH] FilePart fails to send data on second call to send",
        "description": "When using a FilePart with the MultipartPostMethod and a server that requires \nauthentication, the first call to FilePart.send() sends the data correctly and \nHttpClient receives an unauthorized response from the server.  If HttpClient is \nset to automatically handle authentication attempts it then attempts to send \nthe FilePart again at which time the InputStream FilePart reads from is empty \nso it doesn't send any data.\n\nDue to this, the data actually sent by HttpClient doesn't match the content \nlength specified so the server continues to wait for the data and doesn't \nrespond, leaving HttpClient to timeout while waiting for a response.\n\nThis occurs with the latest source from CVS as of 16 October 2002.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-135",
        "summary": "Possible HttpClient codepage issue (ascii/ebcdic) on WebSphere z/OS",
        "description": "I am working with Cactus 1.4.1 on WebSphere NT and also WebSphere z/OS\n(mainframe). The problem seems to be with HTTPClient. I have tried with the\nnuild on the 7th December.\n\nI am trying to get basic cactus servlet tests working on WebSphere z/OS.\nEverything works fine through WebSphere NT, however, when the same application\nis deployed to WebSphere z/OS then we get the following error:\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?><?xml-stylesheet type=\"text/xsl\"\nhref=\"junit-noframes.xsl\"?><testsuites><testsuite name=\"TestCactusServlet\"\ntests=\"1\" failures=\"0\" errors=\"1\" time=\"10.184\"><testcase name=\"testNeal\"\ntime=\"10.182\"><error message=\"Error in parsing the status  line from the\nresponse: unable to find line starting with &quot;HTTP/&quot;\"\ntype=\"org.apache.commons.httpclient.HttpRecoverableException\">org.apache.commons.httpclient.HttpRecoverableException:\nError in parsing the status  line from the response: unable to find line\nstarting with &quot;HTTP/&quot;\n\tat\norg.apache.commons.httpclient.HttpMethodBase.readStatusLine(HttpMethodBase.java:1791)\n\tat\norg.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1559)\n\tat\norg.apache.commons.httpclient.HttpMethodBase.processRequest(HttpMethodBase.java:2219)\n\t... etc ...\n\nI have verified that the Application Server on WebSPhere z/OS is working fine. I\nset the logging on the cactus to DEBUG and noticed that the data that the\nHTTPClient is retrieving from the connection is scrambled in some way. For example:\n\n16:06:20,213 [WebSphere t=009d7920] DEBUG ent.HttpClientConnectionHelper  -\n>getCookieString = [null] \n16:06:20,317 [WebSphere t=009d7920] DEBUG httpclient.wire                 - >> \"\u00c7\u00c5\u00e3@a\u00e3?\u00a2\u00a3\u00c3?? etc...\n\nOn WebSphere NT the data at this point looks OK.\n\nWhat springs to mind is maybe ascii/ebcdic conversion problem. z/OS uses unicode\n for java, as it should. However, the HTTPClient creates it own socket\nconnection to the app server and therefore it is connecting to non java code. In\nsuch a situation codepage conversion is necessary.\n\nCould anybody adsvise on how to get this to work?\n\nRegards,\n\nNeal Johnston-Ward",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-523",
        "summary": "SPNEGO authentication scheme",
        "description": "Consider integrating the SPNEGO auth scheme from Commons HttpClient contrib package into HttpClient 4.0",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-929",
        "summary": "Request with two forward slashes for path fails",
        "description": "The following code demonstrates the problem:\n        DefaultHttpClient client = new DefaultHttpClient();\n        client.execute(new HttpGet(\"http://www.google.com//\"));\n\nWhen a request is made, the DefaultRequestDirector invokes rewriteRequestURI(). I don't fully understand why this method does what it does. For a non-proxied request, it attempts to render the URI to a relative URI. In doing so, it tries to create a relative URI whose content is \"//\". Per RFC 2396 section 5 (Relative URI References), a relative URI that begins with \"//\" is a network-path reference, and the \"//\" must be immediately followed by an authority. Therefore, while \"http://www.google.com//\" is a valid absolute URI, \"//\" is not a valid relative one. The resulting exception:\n\n[...]\nCaused by: org.apache.http.ProtocolException: Invalid URI: http://www.google.com//\n\tat org.apache.http.impl.client.DefaultRequestDirector.rewriteRequestURI(DefaultRequestDirector.java:339)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:434)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:641)\n\t... 31 more\nCaused by: java.net.URISyntaxException: Expected authority at index 2: //\n\tat java.net.URI$Parser.fail(URI.java:2809)\n\tat java.net.URI$Parser.failExpecting(URI.java:2815)\n\tat java.net.URI$Parser.parseHierarchical(URI.java:3063)\n\tat java.net.URI$Parser.parse(URI.java:3024)\n\tat java.net.URI.<init>(URI.java:578)\n\tat org.apache.http.client.utils.URIUtils.createURI(URIUtils.java:106)\n\tat org.apache.http.client.utils.URIUtils.rewriteURI(URIUtils.java:141)\n\tat org.apache.http.client.utils.URIUtils.rewriteURI(URIUtils.java:159)\n\tat org.apache.http.impl.client.DefaultRequestDirector.rewriteRequestURI(DefaultRequestDirector.java:333)\n\t... 33 more\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-533",
        "summary": "CookiePolicy.registerCookieSpec(CookiePolicy.DEFAULT, <Some CookieSpec>); does not work as documented",
        "description": "I use HtmlUnit to access some quote information. Cookies shall be ignored,so I\nset the default policy to CookiePolicy.IGNORE_COOKIES. Nevertheless I get error\nmessages after starting my program. \n\nThe code reads:\n---------------------------------------\nCookiePolicy.registerCookieSpec(CookiePolicy.DEFAULT, IgnoreCookiesSpec.class);\nfinal WebClient webClient = new WebClient();\nfinal URL url = new URL(\"http://de.finance.yahoo.com/q?s=CB3569.SG\");\nfinal HtmlPage page = (HtmlPage) webClient.getPage(url);\n----------------------------------------\n\nThe error messages are:\n----------------------------------------\nWARNUNG: Cookie rejected: \"$Version=0; PRF=&t=CB3569.SG; $Domain=finance.yahoo.c\nom; $Path=/\". Domain attribute \"finance.yahoo.com\" violates RFC 2109: domain mus\nt start with a dot\n30.11.2005 10:28:20 org.apache.commons.httpclient.HttpMethodBase processResponse\nHeaders\nWARNUNG: Cookie rejected: \"$Version=0; B=7fkoh9l1oqs4h&b=3&s=hb; $Domain=.yahoo.\ncom; $Path=/\". Domain attribute \".yahoo.com\" violates RFC 2109: host minus domai\nn may not contain any dots\n----------------------------------------",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1002",
        "summary": "Stale connections are never detected when wireLog.isDebugEnabled() == true",
        "description": "When wireLog.isDebugEnabled() == true SessionInputBuffer is wrapped with LoggingSessionInputBuffer which doesn't implement EofSensor that AbstractHttpClientConnection.isStale() is relying on. This causes stale connections to be never detected and attempted to use.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-753",
        "summary": "move class Scheme and friends to a separate package",
        "description": "We currently have a recursive dependency between packages o.a.h.conn and o.a.h.conn.routing, because routing depends on Scheme/SchemeRegistry. While these classes are used throughout the connection management code, they are not really part of the connection management itself and would therefore fit nicely into a separate package.\n\npreliminary list of classes and interfaces to move:\n- Scheme\n- SchemeRegistry\n- SocketFactory\n- LayeredSocketFactory\n- PlainSocketFactory\n\nsuggested package name: o.a.h.conn.scheme\n\nPackage o.a.h.conn.ssl can stay where it is, it only changes its dependency from conn to the new package.\n\ncheers,\n  Roland\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-948",
        "summary": "IdleConnectionHandler can leave closed connections in a inconsistent state",
        "description": "IdleConnectionHandler when shutting down 'stale' connection does not update the state of AbstractPoolEntry thus causing an inconsistency between the state of the connection (closed) and that of the pool entry (still assumed open). The problem is mitigated by the fact that the pooling manager usually evicts closed connections almost immediately. There is a small window of time in the ThreadSafeClientConnManager#closeIdleConnection method, at which a connection can be closed by the IdleConnectionHandler and immediately leased from the pool by another thread in an inconsistent state before the main thread gets a chance to re-acquire the pool lock and clean out closed connections.\n\nFor 4.0.x the problem can be worked around by retaining the pool lock for the entire span of the #closeIdleConnection. For the 4.1 branch a better solution should be devised. This probably means a complete rewrite or deprecation of IdleConnectionHandler.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1056",
        "summary": "Wrong creation of AuthScope object",
        "description": "Class Name: org.apache.http.client.protocol.RequestAuthCache\nLine #: 118-119\n\nIssue: Want to create a new Object of AuthScope by passing host name, port and scheme name but due to incorrect constructor call, Getting a object with realm name as scheme name.\nCurrent Code: Credentials creds = credsProvider.getCredentials(new AuthScope(host.getHostName(), host.getPort(), null, schemeName));",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-987",
        "summary": "cache module does not recognize equivalent URIs",
        "description": "http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.2.3\n\n\"When comparing two URIs to decide if they match or not, a client SHOULD use a case-sensitive octet-by-octet comparison of the entire URIs, with these exceptions:\n  * A port that is empty or not given is equivalent to the default port for that URI-reference;\n  * Comparisons of host names MUST be case-insensitive;\n  * Comparisons of scheme names MUST be case-insensitive;\n  * An empty abs_path is equivalent to an abs_path of \"/\".\nCharacters other than those in the \"reserved\" and \"unsafe\" sets (see RFC 2396 [42]) are equivalent to their \"\"%\" HEX HEX\" encoding.\n\nFor example, the following three URIs are equivalent:\n      http://abc.com:80/~smith/home.html\n      http://ABC.com/%7Esmith/home.html\n      http://ABC.com:/%7esmith/home.html\"\n\nThe current implementation does not canonicalize the URIs it uses for cache keys, and so is missing potential cache hits. More importantly, though, required invalidations due to PUT/POST/DELETE to a URI (as well as those mentioned in Location or Content-Location headers) may not occur properly due to this bug.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-39",
        "summary": "Authorization credentials should be sent pre-emptively",
        "description": "When a web browser receives a <i>401: Unauthorized</i> response code, the\nbrowser prompts for the user and password credentials for the requested\nauthentication realm.  An Authorization header is then sent for this request. \nHttpClient models this behaviour quite well.\n\nAfter the web browser has the authentication credentials for a given host, port\nand realm, it then sends the Authorization header for subsequent requests\npre-emptively, whithout need for a 401 response.  HttpClient always reqires a\n401 response before it will send out the Authorization header.\n\nAs <code>HttpClient.startSession()</code> will take a <code>Credentials</code>\nobject as a parameter as the default credentials, the default credentials should\nbe sent as part of every request in that session.  Some mechanisim for\nover-riding the default credentials should also be provided to be sent\npre-emptively.\n\nThe point of this enhancement request is to minimize the number of unnecessisary\n401 responses.\n\nIt appears that the simple solution might be to modify the logic of when\n<code>Authenticator.authenticate()</code> gets called in\n<code>HttpMethodBase.addAuthorizationRequestHeader()</code>",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-383",
        "summary": "HostConfiguration handling requires cleanup",
        "description": "As discussed on the mailing list, the host configuration handling currently\nappears faulty:\n\nhttp://marc.theaimsgroup.com/?t=109644952000001&r=1&w=2\n\nOleg",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1130",
        "summary": "New LaxRedirectStrategy class should probably call the super method first.",
        "description": "LaxRedirectStrategy extends the defaulRedirect class but does not call the super method as one would expect.\n\nJust adding a patch to make sure it gets called.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1143",
        "summary": "CachingHttpClient leaks connections with stale-if-error",
        "description": "If you are using the \"stale-if-error\" Cache-control header and CachingHttpClient decides to use a stale cached response it does not clean up the existing backend response.\n\nThis bug causes connections to leak from the connection pool each time the stale-if-error flow is executed.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-725",
        "summary": "TSCCM code cleanup",
        "description": "The ThreadSafeClientConnectionManager, or rather it's ConnPoolByRoute, needs plenty of cleanup.\n- use long + TimeUnit for timeout intervals (Java 5 style)\n- compute timeout end date once instead of remaining interval\n- review which methods should acquire the pool lock,\n  and which should expect the caller to have done that\n- use factory methods to instantiate some of the helper objects\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-632",
        "summary": "Possible NPE in HttpHost",
        "description": "HttpHost line 167 says:\n        if (this.port != this.protocol.getDefaultPort()) {\n\nHowever, a few lines above, protocol is checked for null.\n\nLine 167 should probably read:\n\n        if (this.protocol != null && this.port != this.protocol.getDefaultPort()) {\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-741",
        "summary": "AbstractClientConnAdapter prone to concurrency issues",
        "description": "AbstractClientConnAdapter is currently prone to all sorts of concurrency issues. (1) Access to internal state is not properry synchronized making the class prone  to race conditions. Presently none of the instance variables is even declared volatile. (2) AbstractClientConnAdapter treats aborted connection as one in an illegal state, which is not quite right.\n\nOleg",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-942",
        "summary": "ClientConnectionRelease example is incorrect",
        "description": "http://svn.apache.org/repos/asf/httpcomponents/httpclient/tags/4.0.1/httpclient/src/examples/org/apache/http/examples/client/ClientConnectionRelease.java\n\nis incorrect: \n\n1. if error happens in BufferedReader constructor (OutOfMemoryError, StackOverflowError), reader.close() is not called and connection is not released\n\n2. if error happens in reader.readLine(), reader.close() is called, but httpget.abort() is not.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-773",
        "summary": "Parsing expires",
        "description": "Seeing this very often:\n\n Invalid cookie header: \"Set-Cookie: _asid=011e7014f5e7718e02d893335aa5a16e; path=/; expires=Wed, 16 May 2018 17:13:32 GMT\". Unable to parse expires attribute: Wed, 16 May 2018 17:13:32 GMT",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-378",
        "summary": "HttpState.setCookiePolicy() is completely ignored",
        "description": "Though this method is deprecated, it currently has no effect and gives no warning that it does nothing.  \nA patch that fixes this problem is coming shortly.\n\nMike",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-106",
        "summary": "Path should not be encoded in HttpMethodBase",
        "description": "I suggest to change the protocol or add a new method for this one\n\nprotected static String generateRequestLine(HttpConnection connection,\n\tString name, String reqPath,\n\tString qString, String protocol);\nso that we can choose to use URIUtil.encode(reqPath, URIUtil.pathSafe()) or not\n\nThe reason is that after the encoding process, some server cannot recognize this\nActually, I am handling a project of the Method Propfind(for getting mail from \nHotmail) and I find that the restriction of Hotmail server is quite high, and \nif the address is encoded, it does not work.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-365",
        "summary": "StatusLine IndexOutOfBounds",
        "description": "Reported by Sam Berlin on the developers mailing list:\n\nI'm not sure if this problem is still on CVS HEAD, but we're seeing it  \nagainst 2.0rc2.  In StatusLine (line 139 in my version), when it walks  \nthrough the spaces, it is possible that the entire line was spaces (and  \nthus a malformed response).  The code will throw an  \nStringIndexOutOfBoundsException now instead of the correct  \nHttpException.  See the following bug:\n\nhttp://bugs.limewire.com/bugs/ \nsearching.jsp?disp1=l&disp2=c&disp3=o&disp4=j&l=151&c=204&m=416_205\n\nThanks,\n  Sam",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-915",
        "summary": "Provide a clean mechanism to attatch user define attributes to connections",
        "description": "It would be nice to have a way to attach user defined attributes to a connection.\nIdeally it'd be nice if such support could be added to HttpClientConnection, but understandably this may not be possible due to back-compatibility issues.\nSo, we could have something like HttpConnectionContext perhaps (or similar) with:\n\nHttpConnectionContext#setAttribute(String name, Object value)\nObject HttpConnectionContext#getAttribute(String name)\n\nThis would be made available in the HttpContext of a request (like the connection is today):\n\nHttpConnectionContext connectionContext = (HttpConnectionContext) httpContext.getAttribute(ExecutionContext.HTTP_CONNECTION_CONTEXT);\n\nThis would make a few things much cleaner to implement than they are today: The most obvious being my current use case of wanting connection isolated cookies.\n\nCurrently to achieve this goal we need to provide custom client connection + connection operator + connection manager implementations. Then there is no clean way to currently obtain the actual connection instance created by a custom operator in the HttpContext: As it's wrapped by the connection pool and #getWrappedConnection is protected - so we need to resort to reflection in interceptors.\n\nProviding a clean mechanism for attaching user defined attributes to a connection instance as described above would make such implementations far far simpler.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-625",
        "summary": "shutdown of MultiThreadedHttpConnectionManager",
        "description": "- declare 'shutdown' attributes volatile\n- interrupt cleanup thread to avoid polling\n- don't use iterator on WeakHashMap, ConcurrentModificationException\n  might be triggered by garbage collection\n\npatch follows\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-819",
        "summary": "HttpParams doesn't document its key values",
        "description": "http://hc.apache.org/httpcomponents-core/httpcore/apidocs/org/apache/http/params/HttpParams.html should either list the meaningful parameter names with the meanings of their values, or should link to the other classes like HttpClientParams and AuthParams that make it usable. Probably, each class that uses HttpParams should also describe the meaningful values so that human readers find the descriptions however we look for them.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-610",
        "summary": "HttpMethodBase.getResponseBodyAsString(long limit)",
        "description": "Currently HttpMethodBase.getResponseBodyAsString() prints warning in log, and suggests using getResponseStream(). However getResponseBodyAsString() is extremely useful (as it is easy to use). So my wish is to have method\n\ngetResponseBodyAsString(long limit)\n\nthat should throw HttpException if response size exceeds specified limit.\n\nSame things with getResponseBody(long limit) .\n\nOriginal methods should be deprecated because of danger, explained in javadoc.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-696",
        "summary": "java.util.logging configuration examples does not work as intended",
        "description": "java.util.logging configuration examples do not work as intended. Those can be found here: http://jakarta.apache.org/httpcomponents/httpclient-3.x/logging.html\n\nSteps to reproduce:\n1. Create a simple project using HttpClient (see listing below) and JDK 1.6 (I suppose it is JDK 1.4 or higher, but I did not test anything other than 1.6). Without log4j in the classpath and without any commons-logging system properties set, java.util.logging is automatically selected by commons-logging.\n2. Create logging.properties file as shown in any of the java.util.logging examples\n3. Run a program, passing -Djava.util.logging.config.file=logging.properties argument to the JVM\n\nExpected results:\nQuite a few log messages should be sent to System.err\n\nActual results:\nUnless there is an I/O error encountered, no log messages are sent to System.err\n\nThe problem, as far as I can see, is caused by the default logging level of java.util.logging.ConsoleHandler, which is set to INFO. In order for any log messages to go through, the log hadler log level needs to be lower than logged messages log level. Adding the following line to all java.util.logging examples should fix the problem:\n\njava.util.logging.ConsoleHandler.level = ALL\n\n--- Get.java -----------------------------------------\n\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.io.Reader;\n\nimport org.apache.commons.httpclient.HostConfiguration;\nimport org.apache.commons.httpclient.HttpClient;\nimport org.apache.commons.httpclient.HttpException;\nimport org.apache.commons.httpclient.HttpMethodBase;\nimport org.apache.commons.httpclient.methods.GetMethod;\n\n\npublic class Get {\n\n\t/**\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\t\n \t\tHttpClient client = new HttpClient();\n\t\tHttpMethodBase get = new GetMethod(\"http://www.apache.org\");\n\t\t\n\t\ttry {\n\t\t\tint code = client.executeMethod(get);\n\t\t\tSystem.out.println(\"Status code: \" + code);\n\t\t\t\n\t\t\tString csn = get.getResponseCharSet();\n\t\t\tSystem.out.println(\"Charset is: \" + csn);\n\t\t\t\n\t\t\tlong len = get.getResponseContentLength();\n\t\t\tSystem.out.println(\"Length is: \" + len);\n\t\t\tlen = len < 0 ? 200 : len;\n\t\t\t\n\t\t\tStringBuilder buf = new StringBuilder((int)len);\n\t\t\tReader r = new InputStreamReader(get.getResponseBodyAsStream(), csn);\n\t\t\tfor (int c = r.read(); c >= 0; c = r.read()) {\n\t\t\t\tbuf.append((char)c);\n\t\t\t}\n\t\t\t\n\t\t\tSystem.out.println(\"Body:\");\n\t\t\tSystem.out.println(buf.toString());\t\t\t\n\t\t\t\n\t\t} catch (HttpException e) {\n\t\t\te.printStackTrace();\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\tget.releaseConnection();\n\t\t}\t\t\t\t\n\t}\n}\n\n--- logging.properties ----- From examples ----------------------\n\n.level=INFO\n\nhandlers=java.util.logging.ConsoleHandler\njava.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter\n\nhttpclient.wire.header.level=FINEST\norg.apache.commons.httpclient.level=FINEST\n\n--------------------------------------------------------------------------------\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-842",
        "summary": "Link javadocs of HttpClient, HttpCore and HttpMime",
        "description": "Presently the javadocs for HttpCore, HttpClient and HttpMime are isolated from each other.  For new users this can create a great deal of confusion and the appearance of limited functionality of HttpClient.  Please set the javadoc creation task to link the javadoc of these three projects together.  ",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-500",
        "summary": "Dependency URL broken for commons-logging",
        "description": "On http://jakarta.apache.org/commons/httpclient/dependencies.html there is a \ntypo in the href to the logging dependency, this should be\n\nhttp://jakarta.apache.org/commons/logging/",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-230",
        "summary": "Contributed utility for determing content type from file type extension",
        "description": "/*\n * ====================================================================\n *\n * The Apache Software License, Version 1.1\n *\n * Copyright (c) 2002-2003 The Apache Software Foundation.  All rights\n * reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in\n *    the documentation and/or other materials provided with the\n *    distribution.\n *\n * 3. The end-user documentation included with the redistribution, if\n *    any, must include the following acknowlegement:\n *       \"This product includes software developed by the\n *        Apache Software Foundation (http://www.apache.org/).\"\n *    Alternately, this acknowlegement may appear in the software itself,\n *    if and wherever such third-party acknowlegements normally appear.\n *\n * 4. The names \"The Jakarta Project\", \"Commons\", and \"Apache Software\n *    Foundation\" must not be used to endorse or promote products derived\n *    from this software without prior written permission. For written\n *    permission, please contact apache@apache.org.\n *\n * 5. Products derived from this software may not be called \"Apache\"\n *    nor may \"Apache\" appear in their names without prior written\n *    permission of the Apache Group.\n *\n * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED\n * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR\n * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF\n * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT\n * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n * ====================================================================\n *\n * This software consists of voluntary contributions made by many\n * individuals on behalf of the Apache Software Foundation.  For more\n * information on the Apache Software Foundation, please see\n * <http://www.apache.org/>.\n *\n * [Additional notices, if required by prior licensing conditions]\n *\n */\n\npackage org.apache.commons.httpclient.contrib.utils;\n\nimport java.io.File;\nimport java.io.IOException;\n\n/**\n * This class provides mappings from file name extensions to content types.\n *\n * @author <a href=\"mailto:emdevlin@charter.net\">Eric Devlin</a>\n * \n * DISCLAIMER: HttpClient developers DO NOT actively support this component.\n * The component is provided as a reference material, which may be inappropriate\n * to be used without additional customization.\n */\n\npublic class ContentType {\n\n\t/** Mime Type mappings 'liberated' from Tomcat4.1.18/conf/web.xml*/\n\tpublic static final String[][] MIME_TYPE_MAPPINGS =\t\n\t\t{\t{ \"abs\",\t\t\"audio/x-mpeg\" },\n\t\t\t{ \"ai\",\t\t\t\"application/postscript\" },\n\t\t\t{ \"aif\",\t\t\"audio/x-aiff\" },\n\t\t\t{ \"aifc\",\t\t\"audio/x-aiff\" },\n\t\t\t{ \"aiff\",\t\t\"audio/x-aiff\" },\n\t\t\t{ \"aim\",\t\t\"application/x-aim\" },\n\t\t\t{ \"art\",\t\t\"image/x-jg\" },\n\t\t\t{ \"asf\",\t\t\"video/x-ms-asf\" },\n\t\t\t{ \"asx\",\t\t\"video/x-ms-asf\" },\n\t\t\t{ \"au\",\t\t\t\"audio/basic\" },\n\t\t\t{ \"avi\",\t\t\"video/x-msvideo\" },\n\t\t\t{ \"avx\",\t\t\"video/x-rad-screenplay\" },\n\t\t\t{ \"bcpio\",\t\t\"application/x-bcpio\" },\n\t\t\t{ \"bin\",\t\t\"application/octet-stream\" },\n\t\t\t{ \"bmp\",\t\t\"image/bmp\" },\n\t\t\t{ \"body\",\t\t\"text/html\" },\n\t\t\t{ \"cdf\",\t\t\"application/x-cdf\" },\n\t\t\t{ \"cer\",\t\t\"application/x-x509-ca-cert\" },\n\t\t\t{ \"class\",\t\t\"application/java\" },\n\t\t\t{ \"cpio\",\t\t\"application/x-cpio\" },\n\t\t\t{ \"csh\",\t\t\"application/x-csh\" },\n\t\t\t{ \"css\",\t\t\"text/css\" },\n\t\t\t{ \"dib\",\t\t\"image/bmp\" },\n\t\t\t{ \"doc\",\t\t\"application/msword\" },\n\t\t\t{ \"dtd\",\t\t\"text/plain\" },\n\t\t\t{ \"dv\",\t\t\t\"video/x-dv\" },\n\t\t\t{ \"dvi\",\t\t\"application/x-dvi\" },\n\t\t\t{ \"eps\",\t\t\"application/postscript\" },\n\t\t\t{ \"etx\",\t\t\"text/x-setext\" },\n\t\t\t{ \"exe\",\t\t\"application/octet-stream\" },\n\t\t\t{ \"gif\",\t\t\"image/gif\" },\n\t\t\t{ \"gtar\",\t\t\"application/x-gtar\" },\n\t\t\t{ \"gz\",\t\t\t\"application/x-gzip\" },\n\t\t\t{ \"hdf\",\t\t\"application/x-hdf\" },\n\t\t\t{ \"hqx\",\t\t\"application/mac-binhex40\" },\n\t\t\t{ \"htc\",\t\t\"text/x-component\" },\n\t\t\t{ \"htm\",\t\t\"text/html\" },\n\t\t\t{ \"html\",\t\t\"text/html\" },\n\t\t\t{ \"hqx\",\t\t\"application/mac-binhex40\" },\n\t\t\t{ \"ief\",\t\t\"image/ief\" },\n\t\t\t{ \"jad\",\t\t\"text/vnd.sun.j2me.app-\ndescriptor\" },\n\t\t\t{ \"jar\",\t\t\"application/java-archive\" },\n\t\t\t{ \"java\",\t\t\"text/plain\" },\n\t\t\t{ \"jnlp\",\t\t\"application/x-java-jnlp-\nfile\" },\n\t\t\t{ \"jpe\",\t\t\"image/jpeg\" },\n\t\t\t{ \"jpeg\",\t\t\"image/jpeg\" },\n\t\t\t{ \"jpg\",\t\t\"image/jpeg\" },\n\t\t\t{ \"js\",\t\t\t\"text/javascript\" },\n\t\t\t{ \"jsf\",\t\t\"text/plain\" },\n\t\t\t{ \"jspf\",\t\t\"text/plain\" },\n\t\t\t{ \"kar\",\t\t\"audio/x-midi\" },\n\t\t\t{ \"latex\",\t\t\"application/x-latex\" },\n\t\t\t{ \"m3u\",\t\t\"audio/x-mpegurl\" },\n\t\t\t{ \"mac\",\t\t\"image/x-macpaint\" },\n\t\t\t{ \"man\",\t\t\"application/x-troff-man\" },\n\t\t\t{ \"me\",\t\t\t\"application/x-troff-me\" },\n\t\t\t{ \"mid\",\t\t\"audio/x-midi\" },\n\t\t\t{ \"midi\",\t\t\"audio/x-midi\" },\n\t\t\t{ \"mif\",\t\t\"application/x-mif\" },\n\t\t\t{ \"mov\",\t\t\"video/quicktime\" },\n\t\t\t{ \"movie\",\t\t\"video/x-sgi-movie\" },\n\t\t\t{ \"mp1\",\t\t\"audio/x-mpeg\" },\n\t\t\t{ \"mp2\",\t\t\"audio/x-mpeg\" },\n\t\t\t{ \"mp3\",\t\t\"audio/x-mpeg\" },\n\t\t\t{ \"mpa\",\t\t\"audio/x-mpeg\" },\n\t\t\t{ \"mpe\",\t\t\"video/mpeg\" },\n\t\t\t{ \"mpeg\",\t\t\"video/mpeg\" },\n\t\t\t{ \"mpega\",\t\t\"audio/x-mpeg\" },\n\t\t\t{ \"mpg\",\t\t\"video/mpeg\" },\n\t\t\t{ \"mpv2\",\t\t\"video/mpeg2\" },\n\t\t\t{ \"ms\",\t\t\t\"application/x-wais-source\" },\n\t\t\t{ \"nc\",\t\t\t\"application/x-netcdf\" },\n\t\t\t{ \"oda\",\t\t\"application/oda\" },\n\t\t\t{ \"pbm\",\t\t\"image/x-portable-bitmap\" },\n\t\t\t{ \"pct\",\t\t\"image/pict\" },\n\t\t\t{ \"pdf\",\t\t\"application/pdf\" },\n\t\t\t{ \"pgm\",\t\t\"image/x-portable-graymap\" },\n\t\t\t{ \"pic\",\t\t\"image/pict\" },\n\t\t\t{ \"pict\",\t\t\"image/pict\" },\n\t\t\t{ \"pls\",\t\t\"audio/x-scpls\" },\n\t\t\t{ \"png\",\t\t\"image/png\" },\n\t\t\t{ \"pnm\",\t\t\"image/x-portable-anymap\" },\n\t\t\t{ \"pnt\",\t\t\"image/x-macpaint\" },\n\t\t\t{ \"ppm\",\t\t\"image/x-portable-pixmap\" },\n\t\t\t{ \"ps\",\t\t\t\"application/postscript\" },\n\t\t\t{ \"psd\",\t\t\"image/x-photoshop\" },\n\t\t\t{ \"qt\",\t\t\t\"video/quicktime\" },\n\t\t\t{ \"qti\",\t\t\"image/x-quicktime\" },\n\t\t\t{ \"qtif\",\t\t\"image/x-quicktime\" },\n\t\t\t{ \"ras\",\t\t\"image/x-cmu-raster\" },\n\t\t\t{ \"rgb\",\t\t\"image/x-rgb\" },\n\t\t\t{ \"rm\",\t\t\t\"application/vnd.rn-\nrealmedia\" },\n\t\t\t{ \"roff\",\t\t\"application/x-troff\" },\n\t\t\t{ \"rtf\",\t\t\"application/rtf\" },\n\t\t\t{ \"rtx\",\t\t\"text/richtext\" },\n\t\t\t{ \"sh\",\t\t\t\"application/x-sh\" },\n\t\t\t{ \"shar\",\t\t\"application/x-shar\" },\n\t\t\t{ \"smf\",\t\t\"audio/x-midi\" },\n\t\t\t{ \"snd\",\t\t\"audio/basic\" },\n\t\t\t{ \"src\",\t\t\"application/x-wais-source\" },\n\t\t\t{ \"sv4cpio\",\t\"application/x-sv4cpio\" },\n\t\t\t{ \"sv4crc\",\t\t\"application/x-sv4crc\" },\n\t\t\t{ \"swf\",\t\t\"application/x-shockwave-\nflash\" },\n\t\t\t{ \"t\",\t\t\t\"application/x-troff\" },\n\t\t\t{ \"tar\",\t\t\"application/x-tar\" },\n\t\t\t{ \"tcl\",\t\t\"application/x-tcl\" },\n\t\t\t{ \"tex\",\t\t\"application/x-tex\" },\n\t\t\t{ \"texi\",\t\t\"application/x-texinfo\" },\n\t\t\t{ \"texinfo\",\t\"application/x-texinfo\" },\n\t\t\t{ \"tif\",\t\t\"image/tiff\" },\n\t\t\t{ \"tiff\",\t\t\"image/tiff\" },\n\t\t\t{ \"tr\",\t\t\t\"application/x-troff\" },\n\t\t\t{ \"tsv\",\t\t\"text/tab-separated-values\" },\n\t\t\t{ \"txt\",\t\t\"text/plain\" },\n\t\t\t{ \"ulw\",\t\t\"audio/basic\" },\n\t\t\t{ \"ustar\",\t\t\"application/x-ustar\" },\n\t\t\t{ \"xbm\",\t\t\"image/x-xbitmap\" },\n\t\t\t{ \"xml\",\t\t\"text/xml\" },\n\t\t\t{ \"xpm\",\t\t\"image/x-xpixmap\" },\n\t\t\t{ \"xsl\",\t\t\"text/xml\" },\n\t\t\t{ \"xwd\",\t\t\"image/x-xwindowdump\" },\n\t\t\t{ \"wav\",\t\t\"audio/x-wav\" },\n\t\t\t{ \"svg\",\t\t\"image/svg+xml\" },\n\t\t\t{ \"svgz\",\t\t\"image/svg+xml\" },\n\t\t\t{ \"wbmp\",\t\t\"image/vnd.wap.wbmp\" },\n\t\t\t{ \"wml\",\t\t\"text/vnd.wap.wml\" },\n\t\t\t{ \"wmlc\",\t\t\"application/vnd.wap.wmlc\" },\n\t\t\t{ \"wmls\",\t\t\"text/vnd.wap.wmlscript\" },\n\t\t\t{ \"wmlscriptc\",\t\"application/vnd.wap.wmlscriptc\" },\n\t\t\t{ \"wrl\",\t\t\"x-world/x-vrml\" },\n\t\t\t{ \"Z\",\t\t\t\"application/x-compress\" },\n\t\t\t{ \"z\",\t\t\t\"application/x-compress\" },\n\t\t\t{ \"zip\",\t\t\"application/zip\" } };\n\n    /**\n     * Get the content type based on the extension of the file name<br>\n     *\n     * @param fileName for which the content type is to be determined.\n     *\n     * @return the content type for the file or null if no mapping was\n     * possible.\n     */\n\tpublic static String get( String fileName  ) {\n\t\tString contentType = null;\n\n\t\tif ( fileName != null ) {\n\t\t\tint extensionIndex = fileName.lastIndexOf( '.' );\n\t\t\tif ( extensionIndex != -1 ) {\n\t\t\t\tif ( extensionIndex + 1 < fileName.length() ) {\n\t\t\t\t\tString extension = fileName.substring( \nextensionIndex + 1 );\n\t\t\t\t\tfor( int i = 0; i < \nMIME_TYPE_MAPPINGS.length; i++ ) {\n\t\t\t\t\t\tif ( extension.equals( \nMIME_TYPE_MAPPINGS[i][0] ) ) {\n\t\t\t\t\t\t\tcontentType = \nMIME_TYPE_MAPPINGS[i][1];\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn contentType;\n\t}\n\n    /**\n     * Get the content type based on the extension of the file name<br>\n     *\n     * @param file for which the content type is to be determined.\n     *\n     * @return the content type for the file or null if no mapping was\n     * possible.\n     *\n     * @throws IOException if the construction of the canonical path for \n\t * the file fails.\n     */\n\tpublic static String get( File file ) \n\t\tthrows IOException\n\t{\n\t\tString contentType = null;\n\n\t\tif ( file != null ) {\n\n\t\t\tcontentType = get( file.getCanonicalPath() );\n\t\t}\n\n\t\treturn contentType;\n\t}\n}",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-18",
        "summary": "Can't use proxy server with https",
        "description": "There doesn't seem to be a way to configure HttpClient to use both HTTPS and a\nproxy server at the same time.  It's not clear if this was just an oversight or\nif there was a deliberate decision to not support this combination for some reason.\n\nAssuming that it was an oversight, the fix seems to just require one more\nvariation of startSession() in HttpClient.java which would be the following:\n\n   public void startSession(String host, int port,\n                            String proxyhost, int proxyport, boolean https) {\n       connection = new HttpConnection(proxyhost,proxyport,host,port,https);\n   }",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-410",
        "summary": "Typos in MultiThreadedHttpConnectionManager",
        "description": "I've done a review of the MultiThreadedHttpConnectionManager class in 3.0-beta1,\nespecially focussing on the documentation. In general, it could use a lot of\nimprovement, IMHO.\n\nThis bug report only deals with some typos I found in the class, and some\nminimal style improvements that are compatible with the other classes.\n\nI will attach a proposed patch.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-832",
        "summary": " MalformedCookieException: distinguish cookie syntax errors from cross-domain errors",
        "description": "MalformedCookieException is used for both cookies with syntax errors,\nand for cookies which are invalid for the particular context - e.g.\ncross-domain cookies.\n\nI think it would be helpful to be able to distinguish these without\nneeding to examine the message text.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-452",
        "summary": "DateUtil.formatDate() uses default timezone instead of GMT",
        "description": "DateUtil.formatDate() uses default timezone instead of GMT.  In section 3.3.1,\nRFC 2616 states:  \"All HTTP date/time stamps MUST be represented in Greenwich\nMean Time (GMT), without exception.\"\n\nTo reproduce, run the following snippet:\n\n   public static void main(String[] args) {\n      TimeZone tz = TimeZone.getTimeZone(\"GMT\");\n      GregorianCalendar gc = new GregorianCalendar(tz);\n      gc.set(1900 + 104, GregorianCalendar.JANUARY, 1, 0, 0, 0);\n      System.out.println(DateUtil.formatDate(gc.getTime()));\n      \n   }\n\nExpected result:\nThu, 01 Jan 2004 00:00:00 GMT\n\nActual result (if your default timezone is PST):\nWed, 31 Dec 2003 16:00:00 PST",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-823",
        "summary": "Make it possible to adjust MaxTotalConnections parameter dynamicaly",
        "description": "Make it possible to adjust MaxTotalConnections parameter at run time. Document behaviour of MaxTotalConnections and MaxConnectionsPerRoute behaviour (latter cannot be changed for allocated pools)\n\nOleg",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-322",
        "summary": "Deprecate and replace SimpleHttpConnection with the SimpleHttpServer based testing framework",
        "description": "Thanks to Christian Kohlschuetter and Odi we now have a very flexible testing\nframework, which enables us to emulate pretty much all the aspects of a HTTP\nserver functionality including non-compliant behavior and various vendor\nspecific implementation quirks. \n\nMany, many thanks go to Christian Kohlschuetter for having contributed the\noriginal code. \n\nI propose SimpleHttpConnection be deprecated and eventually be phased out. I\ntook the first steps toward this goal by migrating Basic authentication test\ncases. I urge all committers and contributors to use SimpleHttpServer for all\nthe new cases from now on. Ideally in the future we should even be able to get\nrid of Tomcat as a dependency for testing.\n\nI also took liberty of tweaking the SimpleHttpServer API a little. I factored\nSimpleRequest and SimpleResponse classes out and provided a new interface called\nHttpService, which can be used instead of HttpRequestHandler to implement test\ncases in a way very similar to writing servlets. \n\nI'll commit the patch shortly as it does not really touch any _productive_ code. \n\nOleg",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-117",
        "summary": "Move to the new URIUtil class",
        "description": "Depricate httpclient.URIUtil class and methods\nMove all URIUtil calls to httpclient.util.URIUtil",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-347",
        "summary": "MultiThreadedConnectionManager Accounting Problems",
        "description": "getConnectionsInPool() is certainly a more intutive name. \nAt the same, as you already mentioned, certainly there need to be a connection killer method: \nMultiThreadedHttpConnectionManager.destroyIdleConnections(long idleTime) \n\nAlso, I would recommend one method which could spit out connection statistics at any time for the \ngiven Connection Manager. This will be great method for testing purpose as well. \nMultiThreadedHttpConnectionManager.displayCurrentStatistics(); \n----------------------------------\nCurent Connection Statistics\n----------------------------------\nTotal connectinos in Pool = 10\nOpen connectinos          = 3\nClose connections         = 5\nStale connections         = 2 \nAnd, if are even more adventurous we could extend our report to: \nAverage wait time for connection = 1356 ms\nMaximum wait time for connectino = 1892 ms",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-760",
        "summary": "Abort Before Execute & Various Other Times Fails",
        "description": "With svn commit #639506, a few more scenarios become testable & can be fixed.  These are: aborting before HttpClient.execute is called, aborting between setting the connection request for aborting and setting the connection release trigger, and aborting after a redirected route uses a new connection request.  As of r639506, those three scenarios fail to abort correctly.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1159",
        "summary": "HttpClientUtils  - Helper methods to release resources of HttpClient / HttpResponse after use ",
        "description": "Found myself writing this boiler plate code in various httpclient related projects , to release resources , and wanted to provide a simpler way to release resources similar to IOUtils.closeQuietly as opposed to maintaining the same in my code. \n\nNew class: \n\no.a.http.client.utils.HttpClientUtils added: \n<pre>\n  public static void closeQuietly(final HttpResponse response); \n  public static void closeQuietly(final HttpClient httpClient); \n</pre>\n\nwith 2 methods ( as above ) in the same, to help release resources: \n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-210",
        "summary": "Exception handling in HttpClient requires redesign",
        "description": "When I use httpclient2.0-alpha3 and setTimeout(60000), after the specified \ntime, I would like to see InterruptedIOException thrown, but I got \nHttpRecoverableException instead, which is pretty general. I would like to see \nthe original exception. Thanks",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-834",
        "summary": "Transparent Content Coding support",
        "description": "I would like to see HttpClient features brought up to parity with other libraries, both in Java and other languages. c.f. Python's httplib2 (not yet in the standard library, but many would like to see it in there). That library transparently handles gzip and compress content codings.\n\nThis issue is to capture possible solutions to providing this sort of innate functionality in HttpClient, so that users aren't required to know RFC2616 intimately. The HttpClient library should do the right thing and use the network in the most efficient manner possible.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-157",
        "summary": "migrate to commons-codec Base64",
        "description": "Commons Codec is now the authoritative source for Base64 functionality.  The\nBase64 in HttpClient is now deprecated and should be removed in 2.1.  This will\nalso add a new dependancy for HttpClient on the commons-codec package.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-962",
        "summary": "client cache may be a shared cache but is caching responses to requests with Authorization headers",
        "description": "\"      When a shared cache (see section 13.7) receives a request\n      containing an Authorization field, it MUST NOT return the\n      corresponding response as a reply to any other request, unless one\n      of the following specific exceptions holds:\n\n      1. If the response includes the \"s-maxage\" cache-control\n         directive, the cache MAY use that response in replying to a\n         subsequent request. But (if the specified maximum age has\n         passed) a proxy cache MUST first revalidate it with the origin\n         server, using the request-headers from the new request to allow\n         the origin server to authenticate the new request. (This is the\n         defined behavior for s-maxage.) If the response includes \"s-\n         maxage=0\", the proxy MUST always revalidate it before re-using\n         it.\n\n      2. If the response includes the \"must-revalidate\" cache-control\n         directive, the cache MAY use that response in replying to a\n         subsequent request. But if the response is stale, all caches\n         MUST first revalidate it with the origin server, using the\n         request-headers from the new request to allow the origin server\n         to authenticate the new request.\n\n      3. If the response includes the \"public\" cache-control directive,\n         it MAY be returned in reply to any subsequent request.\"\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.8\n\nIt isn't clear whether the CachingHttpClient is a shared cache or not (it depends on where it gets used), so the conservative compliant behavior is to assume we are a shared cache. The current implementation is caching responses regardless of whether the original requests had Authorization headers or not.\n\nPatch and discussion forthcoming.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-516",
        "summary": "Javadoc: does not mention Expires; clarify validate",
        "description": "The Expires attribute processing is not mentioned in any of the Javadoc, as far\nas I can tell. \n\nAlso, the public method parseAttribute() actually handles the attributes, but\ndoes not contain the details. It would be useful if there was at least a\nbacklink to the parse() documentation.\n\nIt's not clear from the Javadoc whether parse() automatically calls validate()\nor not. It doesn't.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-189",
        "summary": "Set-Cookie2 and Set-Cookie",
        "description": "Acording to RFC2965 9.1:\n                                                 User agents that\n   receive in the same response both a Set-Cookie and Set-Cookie2\n   response header for the same cookie MUST discard the Set-Cookie\n   information and use only the Set-Cookie2 information.\n\nthis is read that the header for a cetain cookie, but not all cookie.\nSo, Server can send only Set-Cookie header for some cookies and,\nfor cookies send Set-Cookie2,Set-cookie both.\n\nBut httpclient implementation handles this that if find any set-cookie2 header,\nthen ignores all Set-cookie header.\nI know some sites use set-cookie2 only for cookies which needs\n more flexible exiration handling, and for other cookies use only\nSet-Cookie. One of exmaples of such sites I know is \nTDNet Database service provided by Tokyo Stock Exchange.\n\nSo, the preferred implementation is that if set-cookie2 header\n found for a certain cookie then cookie value is set from set-cookie2 header, if\nnot, then from Set-Cookie header.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-307",
        "summary": "An IOException or RuntimeException leaves the underlying socket in an undetermined state",
        "description": "If an application level IOException or RuntimeException occurs, the underlying\nsocket will be in an undetermined state. In many cases, this will lead to zombie\nconnections in the pool that do not respond properly.\n\nSimple example: uploading a file via POST. If we promise the server 1MB of data.\nShortly after starting the transfer an IOException occurs (e.g. the NFS server\nthe file was residing on stops responding). The connection is returned to the\npool (see HTTPCLIENT-302) but the the server is still expecting close to 1MB of data\non that socket. The next request on that socket (e.g. a GET) will send the HTTP\nheader but  the server thinks the header is part of the old stream and doesn't\nrespond.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-544",
        "summary": "Digest auth uses incorrect URI",
        "description": "This bug seems to be strongly related to #36918. But in this case, I don't have \nproxy and it is GET method.\n\nThe problem is that when a GET request with query parameters is sent to the \nserver, uri does not count in the parameters.  The server (Apache 1.3) then \nresponds with HTTP/1.1 400 Bad Request. In the error log, the server writes:  \nDigest: uri mismatch - </query.cgi> does not match request-uri \n</query.cgi?format=advanced&js=1&rememberjs=1>\n\nAs far as I can tell, the problem is with the following line of code:\n------------ cut DigestScheme.java\npublic String authenticate(Credentials credentials, HttpMethod method)\n....\ngetParameters().put(\"uri\", method.getPath());\n....\n------------ cut\n\nI am inclined to quick-hack this and add method.getQueryString() to the uri; \nbut to make it right it probably needs some refactoring, esp. considering issue \n#36918.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-375",
        "summary": "Chunked Stream Encoding Problems Fails to throw Exceptions",
        "description": "Using the HttpClient 2.0.1 with Sun's JDK 1.4.1_01 and connecting to a site \nthat appareantly has problems generating proper chunked output causes the http \nclient to catch and log an exception then return null data. Ideally the http \nclient should throw the IOException to the calling class so that it can be \nhandled by the programmer. It's not a problem that an exception is being \ngenerated it is a bug that the exception is being trapped in the somewhere in \nthe httpclient code.\n\n2004-08-27 21:19:01,013 main HttpMethodBase [ERROR]: I/O failure reading \nresponse body\njava.io.IOException: chunked stream ended unexpectedly\n        at \norg.apache.commons.httpclient.ChunkedInputStream.getChunkSizeFromInputStream\n(ChunkedInputStream.java:234)\n        at org.apache.commons.httpclient.ChunkedInputStream.nextChunk\n(ChunkedInputStream.java:205)\n        at org.apache.commons.httpclient.ChunkedInputStream.read\n(ChunkedInputStream.java:160)\n        at java.io.FilterInputStream.read(FilterInputStream.java:111)\n        at org.apache.commons.httpclient.AutoCloseInputStream.read\n(AutoCloseInputStream.java:110)\n        at java.io.FilterInputStream.read(FilterInputStream.java:90)\n        at org.apache.commons.httpclient.AutoCloseInputStream.read\n(AutoCloseInputStream.java:129)\n        at org.apache.commons.httpclient.HttpMethodBase.getResponseBody\n(HttpMethodBase.java:685)\n        at com.algorim.ei.cets.EmailPreProcessor.processMessage\n(EmailPreProcessor.java:565)\n        at com.algorim.ei.cets.EmailUpdate.run(EmailUpdate.java:332)\n        at com.algorim.ei.cets.EmailUpdate.main(EmailUpdate.java:89)\n\nRequest and response that are causing the error:\nGET /aeq.aspx?k=32226&k=sb1313@xcorp5.com HTTP/1.1\nUser-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0; .NET CLR \n1.1.4322)\nHost: 38.117.227.56\n\nHTTP/1.1 200 OK\nDate: Fri, 27 Aug 2004 20:55:27 GMT\nServer: Microsoft-IIS/6.0\nX-Powered-By: ASP.NET\nX-AspNet-Version: 1.1.4322\nTransfer-Encoding: chunked\nCache-Control: private\nContent-Type: text/html; charset=utf-8\n\n179\n<html><head><META HTTP-EQUIV=Refresh CONTENT=\"1; \nURL=http://www.datingresults.com/default.asp?\np=7090&PRM=38664\"</head><body><script>win2=win\ndow.open('http://m.qmct.com/images/d.html?\na=1', 'newwin','toolbar=0,width=730,height=500');if (win2 != null) win2.blur\n();window.focus();wind\now.location = 'http://www.datingresults.com/default.asp?\np=7090&PRM=38664';</script></body></html>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-412",
        "summary": "Document SINGLE_COOKIE_HEADER param in the cookie guide",
        "description": "Included is some sample code that shows the behaviour when loading pages from a phpBB powered \nsite. Here are the results as i see them on my machine:\n\n==== start results\n\n==================================\nPolicy: rfc2109\n==================================\n\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?t=12&view=next&mforum=str\n        Response status code: 200\n        Present cookies: \n                ForumSetCookie=str\n                phpbb_str_data=a%3A0%3A%7B%7D\n                phpbb_str_sid=c8da590cc4b1683b9079da3d82f4efa6\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?p=24&mforum=str\n        Response status code: 200\n        Present cookies: \n                phpbb_str_data=a%3A0%3A%7B%7D\n                phpbb_str_sid=c8da590cc4b1683b9079da3d82f4efa6\n                ForumSetCookie=str\n\n        URL: http://www.sgboards.com/forums/posting.php?mode=quote&p=24&mforum=str\n        Response status code: 200\n        Present cookies: \n                phpbb_str_data=a%3A0%3A%7B%7D\n                phpbb_str_sid=c8da590cc4b1683b9079da3d82f4efa6\n                ForumSetCookie=str\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?p=25&mforum=str\n        Response status code: 200\n        Present cookies: \n                phpbb_str_data=a%3A0%3A%7B%7D\n                phpbb_str_sid=c8da590cc4b1683b9079da3d82f4efa6\n                ForumSetCookie=str\n\n==================================\nPolicy: netscape\n==================================\n\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?t=12&view=next&mforum=str\n        Response status code: 200\n        Present cookies: \n                phpbb_str_sid=e2604334a0022283333153f6879feb70\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?p=24&mforum=str\n        Response status code: 200\n        Present cookies: \n                phpbb_str_sid=e2604334a0022283333153f6879feb70\n\n        URL: http://www.sgboards.com/forums/posting.php?mode=quote&p=24&mforum=str\n        Response status code: 200\n        Present cookies: \n                phpbb_str_sid=e2604334a0022283333153f6879feb70\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?p=25&mforum=str\n        Response status code: 200\n        Present cookies: \n                phpbb_str_sid=e2604334a0022283333153f6879feb70\n\n==================================\nPolicy: compatibility\n==================================\n\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?t=12&view=next&mforum=str\n        Response status code: 200\n        Present cookies: \n                ForumSetCookie=str\n                phpbb_str_data=a%3A0%3A%7B%7D\n                phpbb_str_sid=d156f6dbfa605320b5a250129fa0b22e\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?p=24&mforum=str\n        Response status code: 200\n        Present cookies: \n                ForumSetCookie=str\n                phpbb_str_data=a%3A0%3A%7B%7D\n                phpbb_str_sid=d5d5a46fd27fd783cdb4e324992bc9d2\n\n        URL: http://www.sgboards.com/forums/posting.php?mode=quote&p=24&mforum=str\n        Response status code: 200\n        Present cookies: \n                phpbb_str_data=a%3A0%3A%7B%7D\n                phpbb_str_sid=b4312fee4250f767cd1b34b11afadb3d\n                ForumSetCookie=str\n\n        URL: http://www.sgboards.com/forums/viewtopic.php?p=25&mforum=str\n        Response status code: 200\n        Present cookies: \n                ForumSetCookie=str\n                phpbb_str_data=a%3A0%3A%7B%7D\n                phpbb_str_sid=daf72685d35d851c3eec68b6b3bc3705\n\n==== end results\n\nAs you can see the only cookie policy that ISN'T successfully tracking sessions is the COMPATIBILITY \nsetting. There are a lot of these phpBB sites around, so that's where I've noticed the behaviour most. \nTrying another random php powered site I see that all policies work as expected.\n\nIt would be nice to know what's messing up the cookie handing on these phpBB sites. If you can't rely \non the compatibility setting to reliably maintain session variables (and hence truly imitate a browser) \nthen life get's a little complicated.\n\nBoth 3.0beta1 and the CVS version show the same behaviour.\n\nMany thanks,\n\nGarry\n\nExample code below.\n\n====== begin code\nimport org.apache.commons.httpclient.Cookie;\nimport org.apache.commons.httpclient.HttpClient;\nimport org.apache.commons.httpclient.HttpState;\nimport org.apache.commons.httpclient.cookie.CookiePolicy;\nimport org.apache.commons.httpclient.methods.GetMethod;\n\n\npublic class CookieProbe {\n\tstatic final String[] urls = {\n\t\t\"http://www.sgboards.com/forums/viewtopic.php?t=12&view=next&mforum=str\",\n\t\t\"http://www.sgboards.com/forums/viewtopic.php?p=24&mforum=str\",\n\t\t\"http://www.sgboards.com/forums/posting.php?mode=quote&p=24&mforum=str\",\n\t\t\"http://www.sgboards.com/forums/viewtopic.php?p=25&mforum=str\"\n\t};\n\tstatic final String[] urls2 = {\n\t\t\"http://www.virginmobilelouder.com/live/index.php\",\n\t\t\"http://www.virginmobilelouder.com/live/index.php?page_id=214\",\n\t\t\"http://www.virginmobilelouder.com/live/index.php?page_id=3\",\n\t\t\"http://www.virginmobilelouder.com/live/index.php?page_id=116\"\n\t};\n\t\n\tstatic final String[] policies = {\n\t\tCookiePolicy.RFC_2109, \n\t\tCookiePolicy.NETSCAPE, \n\t\tCookiePolicy.BROWSER_COMPATIBILITY, \n\t};\n\t\n\t\n\tpublic static void main(String[] args) {\n\t\ttry {\n\t\t\tfor (int i = 0; i < policies.length; i++) {\n\t\t\t\tSystem.out.println(\"\\n==================================\");\n\t\t\t\tSystem.out.println(\"Policy: \" + policies[i]);\n\t\t\t\tSystem.out.println(\"==================================\\n\");\n\t\t\t\ttryPolicy(policies[i]);\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace(System.err);\n\t\t}\n\t}\n\t\n\tpublic static void tryPolicy(String policy) throws Exception {\n\t\tHttpState initialState = new HttpState();\n\t\tHttpClient httpclient = new HttpClient();\n\t\thttpclient.getHttpConnectionManager().\n\t\t\tgetParams().setConnectionTimeout(30000);\n\t\thttpclient.setState(initialState);\n\t\t\n\t\thttpclient.getParams().setCookiePolicy(policy);\n\t\tfor (int i = 0; i < urls.length; i++) {\n\t\t\tSystem.out.println(\"\\n\\tURL: \" + urls[i]);\n\t\t\ttryURL(httpclient, urls[i]);\n\t\t\tThread.sleep(1000); // give server a break\n\t\t}\n\t\t\t\n\t}\n\n\tpublic static void tryURL(HttpClient httpclient, String strURL) throws Exception {\n\t\tGetMethod httpget = new GetMethod(strURL);\n\t\tint result = httpclient.executeMethod(httpget);\n\t\tSystem.out.println(\"\\tResponse status code: \" + result);\n\t\t// Get all the cookies\n\t\tCookie[] cookies = httpclient.getState().getCookies();\n\t\tSystem.out.println(\"\\tPresent cookies: \");\n\t\tfor (int i = 0; i < cookies.length; i++) {\n\t\t\tSystem.out.println(\"\\t\\t\" + cookies[i].toExternalForm());\n\t\t}\n\t\t// Release current connection to the connection pool once you are done\n\t\thttpget.releaseConnection();\n\t}\n}\n====== end code",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-125",
        "summary": "empty host header with ip address",
        "description": "file: HttpMethodBase.java method: addHostRequestHeader\n\nHttpClient writes an empty Host header if the host is referred using IP address.\nHTTP 1.1 RFC is not too clear what should be used in this case. However, other\nHTTP 1.1 implementations (e.g. Java 1.4.0) uses IP address instead of dns name\nin the header.\n\nFurthermore, some HTTP server implementations (e.g. Jetty) will return \"400 bad\nrequest\" if it encounters an empty Host header. That may be a bug in Jetty, but\nit might be a good idea to use IP address in Host header to increase compability.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-758",
        "summary": "Wrong method signatures in AbstractHttpClient",
        "description": "The method signatures for removeRequestInterceptorByClass and removeResponseInterceptorByClass in AbstractHttpClient are wrong. Must be\n\npublic void removeRequestInterceptorByClass(Class<? extends\nHttpRequestInterceptor> clazz);\n\nand\n\npublic void removeResponseInterceptorByClass(Class<? extends\nHttpRequestInterceptor> clazz);",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-197",
        "summary": "Problem with redirect on HEAD when (bad, naughty) server returns body content",
        "description": "I've been testing/using HttpClient 2.0a3 with Resin 2.1.9. I've found that when\nusing a HEAD request on a JSP, Resin returns the body content along with the\nheaders.\n\nIn this case, something in the HttpClient breaks. Looking at the httpclient\nlogs, it looks like:\n\n1) HttpClient does a HEAD against the original URL\n2) Resin returns valid status line and headers\n3) HttpClient parses the headers and recognizes the redirect header\n4) HttpClient does a HEAD against the new URL (from the Location header)\n5) HttpMethodBase calls readStatusLine, which (eventually) calles readRawLine in\nHttpConnection (which reads from the internal inputStream)\n6) readRawLine returns the first line in the body from the original HEAD request\nin (1).\n\nIt looks like the original body content (in response to the first HEAD) is being\nbuffered somewhere, but I can't figure out where.\n\nI know that this is invalid behavior on the server's part, but I would like to\nbe able to recover from it.\n\n\n\n---- redir_test.jsp ----\n<?xml version=\"1.0\"?>\n<% \n  response.setStatus(response.SC_MOVED_TEMPORARILY);\n  response.setHeader(\"Location\", \"redirect_pass.xml\");\n%>\n<some>\n  <dummy>\n    <data attr=\"yea, well\"/>\n  </dummy>\n</some>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-630",
        "summary": "URI.java readObject()/writeObject() must be private",
        "description": "In the class org.apache.commons.httpclient.URI, the readObject/writeObject methods are currently protected - they need to be private, or Java will not invoke them.",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-491",
        "summary": "nonce-count in digest auth should not be quoted",
        "description": "In 3.0rc3 nonce-count (nc) is enclosed in quote marks. According to rfc2617 this\nis wrong, nonce-count shouldn't be enclosed in quote marks.\n\n> 3.2.2 The Authorization Request Header\n> \n>    The client is expected to retry the request, passing an Authorization\n>    header line, which is defined according to the framework above,\n>    utilized as follows.\n> \n>        credentials      = \"Digest\" digest-response\n>        digest-response  = 1#( username | realm | nonce | digest-uri\n>                        | response | [ algorithm ] | [cnonce] |\n>                        [opaque] | [message-qop] |\n>                            [nonce-count]  | [auth-param] )\n> \n>        username         = \"username\" \"=\" username-value\n>        username-value   = quoted-string\n>        digest-uri       = \"uri\" \"=\" digest-uri-value\n>        digest-uri-value = request-uri   ; As specified by HTTP/1.1\n>        message-qop      = \"qop\" \"=\" qop-value\n>        cnonce           = \"cnonce\" \"=\" cnonce-value\n>        cnonce-value     = nonce-value\n>        nonce-count      = \"nc\" \"=\" nc-value\n>        nc-value         = 8LHEX\n>        response         = \"response\" \"=\" request-digest\n>        request-digest = <\"> 32LHEX <\">\n>        LHEX             =  \"0\" | \"1\" | \"2\" | \"3\" |\n>                            \"4\" | \"5\" | \"6\" | \"7\" |\n>                            \"8\" | \"9\" | \"a\" | \"b\" |\n>                            \"c\" | \"d\" | \"e\" | \"f\"",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-121",
        "summary": "Cookie.java blowing up on cookies from \"country code\" domains",
        "description": "The following exception is thrown from Cookie.java when receiving a cookie from\na \"country code\" domain such as amazon.ca.\n\n     [java] INFO: Cookie.parse(): Rejecting set cookie header\n\"session-id=702-1613649-9326458; path=/; domain=\n.amazon.ca; expires=Tuesday, 29-Oct-2002 08:00:00 GMT,\nsession-id-time=1035878400; path=/; domain=.amazon.ca;\nexpires=Tuesday, 29-Oct-2002 08:00:00 GMT\" because \"session-id\" has an illegal\ndomain attribute (\".amazon.ca\")\n for the given domain \"www.amazon.ca\".  It violoates the Netscape cookie\nspecification for non-special TLDs.\n     [java] Oct 22, 2002 9:32:37 AM org.apache.commons.httpclient.HttpMethodBase\nprocessResponseHeaders\n     [java] SEVERE: Exception processing response headers\n     [java] org.apache.commons.httpclient.HttpException: Bad Set-Cookie header:\nsession-id=702-1613649-9326458\n; path=/; domain=.amazon.ca; expires=Tuesday, 29-Oct-2002 08:00:00 GMT,\nsession-id-time=1035878400; path=/; do\nmain=.amazon.ca; expires=Tuesday, 29-Oct-2002 08:00:00 GMT Illegal domain\nattribute .amazon.ca\n     [java]     at org.apache.commons.httpclient.Cookie.parse(Cookie.java:944)\n     [java]     at\norg.apache.commons.httpclient.HttpMethodBase.processResponseHeaders(HttpMethodBase.java:141\n9)\n     [java]     at\norg.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1504)\n     [java]     at\norg.apache.commons.httpclient.HttpMethodBase.processRequest(HttpMethodBase.java:2128)\n     [java]     at\norg.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:790)\n     [java]     at\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:442)\n\n\nThe http response that caused this exception is below.\n\nHTTP/1.1 302 Found\nDate: Tue, 22 Oct 2002 13:30:11 GMT\nServer: Stronghold/2.4.2 Apache/1.3.6 C2NetEU/2412 (Unix)\nSet-Cookie: session-id=702-8591055-5561622; path=/; domain=.amazon.ca;\nexpires=Tuesday, 29-Oct-2002 08:00:00 GMT\nSet-Cookie: session-id-time=1035878400; path=/; domain=.amazon.ca;\nexpires=Tuesday, 29-Oct-2002 08:00:00 GMT\nLocation: http://www.amazon.ca/exec/obidos/tg/browse/-/915398/702-8591055-5561622\nConnection: close\nTransfer-Encoding: chunked\nContent-Type: text/html\n\nI've seen this problem with other .ca domains so this isn't a problem unique to\namazon.ca.\n\nMy guess would be that the problem is on line 929 of Cookie.java:\n\nint domainParts = new StringTokenizer(cookie.getDomain(), \".\").countTokens();\n\nWhere domainParts would be 2 for a domain like \".amazon.ca\" instead of the 3\nthat the code is expecting.  I'm not that familiar with the cookie spec so I\ncould be completely wrong ;-)\n\nThe results above were done with the Oct 20/2002 gump build.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-32",
        "summary": "querystring still not set in Url*Method constructors",
        "description": "The queryString is still not set in various Url*Method's constructors. It does \nget set in setUrl. The simplest fix is to call setUrl in these constructors.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-259",
        "summary": "[Maven] Migrate checkstyle.properties to XML",
        "description": "Newer Checkstyle versions (used with latest Maven builds) can not use the old\nproperties configuration file. They work with XML configuration files.\ncheckstyle.properties must be migrated in order to use a current version of Maven.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-866",
        "summary": "HttpClient depends on jcip-annotations.jar",
        "description": "When using Java 5 to compile code that uses HttpClient, jcip-annotations.jar must be in the classpath or else you get a compiler error:\n\n    [javac] /path/to/src/SomeFile.java:129: cannot access net.jcip.annotations.GuardedBy\n    [javac] file net/jcip/annotations/GuardedBy.class not found\n    [javac]         DefaultHttpClient httpclient = new DefaultHttpClient();\n    [javac]                                        ^\n\n\nWith Java 6, you get a bunch of warnings instead.\n    [javac] org/apache/http/impl/client/AbstractHttpClient.class(org/apache/http/impl/client:AbstractHttpClient.class): warning: Cannot find annotation method 'value()' in type 'net.jcip.annotations.GuardedBy': class file for net.jcip.annotations.GuardedBy not found\n\n\nThis requirement doesn't seem to be documented anywhere, and jcip-annotations.jar is not included in the \"httpcomponents-client-4.0-bin-with-dependencies\" package.\n",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-264",
        "summary": "Crashes when it gets a redirect",
        "description": "I get the following crash when VFS (not my code) calls HttpClient. This code \nworked with some older version of HttpClient (is my belief) but doesn't appear \nto work with CVS HEAD, hence this posting.\n\nNote: I'm sorry, but I don't know which Method it was calling, but hopefully a \nredirect is a redirect and the bug stands irrespective of that.\n\nThis is major to me (and Ruper) 'cos it is the first thing it does before \nattempting to read the contents of that location.\n\nregards,\n\nAdam\n\njava.lang.NullPointerException\n\tat \norg.apache.commons.httpclient.HttpMethodDirector.processRedirectResponse\n(HttpMethodDirector.java:454)\n\tat org.apache.commons.httpclient.HttpMethodDirector.isRetryNeeded\n(HttpMethodDirector.java:639)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeMethod\n(HttpMethodDirector.java:145)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:378)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod\n(HttpClient.java:268",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-487",
        "summary": "ParameterParser parse method for authentication headers does not appear to deal with empty value strings",
        "description": "Hi, I have found an issue with HTTPClient due to the way it parses parameter \nstrings.\n\nIn particular, consider the following WWW-Authenticate header:\n\nWWW-Authenticate: Digest realm=\"\", algorithm=MD5, qop=\"auth\", \ndomain=\"/content\", nonce=\"0e11dcf146563c3a89e5327f0c5f5bad\"\n \nThe realm is definitely specified, but is equal to the empty string.  It is not \na null value.\n\nHowever, the extractParams method of AuthChallengeParser which in turn calls \nParameterParser will actually parse the value as Null \u0096 instead of an empty \nstring.\n\nThis is due to parseQuotedToken getToken(true) call which essentially returns a \nnull String result \u0096 as the condition i2>i1 fails :-\n\n        String result = null;\n        if (i2 > i1) {\n            result = new String(chars, i1, i2 - i1);\n        }\n        return result;\n\nAs the processChallenge method of DigestScheme throws an exception when \ngetParameter(\"realm\") == null, HTTPClient is not able to process the digest \nrequest when an empty string realm value is present.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-889",
        "summary": "Should USE_EXPECT_CONTINUE be false by default?",
        "description": "It seems the point of USE_EXPECT_CONTINUE is to improve performance when posting large data. \nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html says:\n\n<< The purpose of the 100 (Continue) status (see section 10.1.1) is to allow a client that is sending a request message with a request body to determine if the origin server is willing to accept the request (based on the request headers) before the client sends the request body. In some cases, it might either be inappropriate or highly inefficient for the client to send the body if the server will reject the message without looking at the body. >>\n\nThere's nothing wrong with HttpClient performing well by default, however, every other HTTP client library I've used does not behave like this (PHP curl, Perl LWP). The default is always to do one request, including the body. Maybe dumb, but simple.\n\nIt seems to me HttpClient's default behavior should the simplest, most compatible with all HTTP-speaking services out there. \"100 Continue\" is somewhat advanced, and may not be correctly implemented by all services. (That's of course how I found out about it -- my server doesn't implement it.)\n\nIf USE_EXPECT_CONTINUE is used only for performance reasons, it seems like it would be simpler (and therefore maybe more \"correct\") to have it \"off\" by default. And only enable it when needed, when there is a good reason to.\n\nJust my thoughts. And a wish. Thanks! \n\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-1001",
        "summary": "CacheEntryUpdater does not properly update cache entry resource",
        "description": "CacheEntryUpdater#updateCacheEntry() copies the old cache entry's resource, though I believe it should only do so if the response is a 304.  Otherwise it should take the response from the server to update the entry.  This method gets called when validating a cache entry and the server returns a 200 or 304.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-461",
        "summary": "HttpClient does not correctly handle escaped characters in HTTP header elements",
        "description": "An excerpt from Microsoft's \"How Digest Authentication Works\":\nhttp://www.microsoft.com/technet/prodtechnol/windowsserver2003/library/TechRef/717b450c-f4a0-4cc9-86f4-cc0633aae5f9.mspx\n\n<quote>\n* RFC 2617-compliant Digest Authentication challenges and responses must also\ncomply with RFC 2616: Hypertext Transfer Protocol -- HTTP/1.1 quoted string\nrequirements. This requirement particularly affects the use of backslash (\\) and\nembedded double quotes. Both must be preceded (escaped) with a backslash.\n\n* For example, domain\\username according to RFC 2616 is read as domainusername.\nThis reading is important because if an application sends information in this\nformat rather than as domain\\\\username, authentication fails.\n\n* However, because this is a known issue with domain\\username , if\nauthenticating with backslash encoding fails, Digest SSP attempts to\nauthenticate the response and assumes that the backslash is part of the string.\nThis behavior can be turned off by setting the ServerCompat registry key.\n</quote>\n\nReview and fix the ParameterParser class and classes implemeting CookieSpec or\nAuthScheme interfaces\n\nSee also PR #34909",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-645",
        "summary": "Cookie.compare(...) uses single instance STRING_COLLATOR to do blocking compares",
        "description": "I am using a MultiThreadedHttpConnectionManager with a single HttpClient instance and multiple GetMethod objects.  I have a 500 thread max.  I recently noticed that all 500 threads are in the same place and seem to be blocking each other - the stack trace is below.  I dug into the Cookie.compare(...) method and saw that it is using STRING_COLLARTOR.compare(c1.getPath(), c2.getPath()).  STRING_COLLATOR is defined as a single instance object, 'private static final RuleBasedCollator STRING_COLLATOR = (RuleBasedCollator) RuleBasedCollator.getInstance(new Locale(\"en\", \"US\", \"\"));'.  I also saw that RuleBasedCollator.compare is synchronized.  That means that every thread that is trying to make a request is getting blocked while it tries to add cookies to the request method.  I do not see a workaround because this is the same static final object in every Cookie instance.  So, the more threads, the more synchronized comparisons.  At times I am fetching URLs all from the same site so I am going through this code a lot.  I need it to be much faster than it currently is because all of my threads are getting eaten up on this call and backlogging my system.  Can a different RuleBasedCollator be used for each compare (use the RuleBasedCollator.getInstance() for every compare?  I think that would solve things.\n\nName: pool-1-thread-1443: 72.21.206.5\nState: BLOCKED on java.text.RuleBasedCollator@190330a owned by: pool-1-thread-1867: 72.21.206.5\nTotal blocked: 9,598  Total waited: 381\n\nStack trace: \njava.text.RuleBasedCollator.compare(RuleBasedCollator.java:396)\norg.apache.commons.httpclient.Cookie.compare(Cookie.java:484)\norg.apache.commons.httpclient.cookie.CookieSpecBase.addInPathOrder(CookieSpecBase.java:578)\norg.apache.commons.httpclient.cookie.CookieSpecBase.match(CookieSpecBase.java:557)\norg.apache.commons.httpclient.HttpMethodBase.addCookieRequestHeader(HttpMethodBase.java:1179)\norg.apache.commons.httpclient.HttpMethodBase.addRequestHeaders(HttpMethodBase.java:1305)\norg.apache.commons.httpclient.HttpMethodBase.writeRequestHeaders(HttpMethodBase.java:2036)\norg.apache.commons.httpclient.HttpMethodBase.writeRequest(HttpMethodBase.java:1919)\norg.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:993)\norg.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:397)\norg.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:170)\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:396)\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:324)",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-437",
        "summary": "method.getURI()  returns escaped URIs but it shouldn't",
        "description": "Hi guys,\n\nPlease, consider the following imaginary and simplified code:\n\n\nURI u = new URI(\"http://some.host.com/%41.html\", true);\nHttpClient httpClient = new HttpClient();\nGetMethod method = new GetMethod();\nmethod.setURI(u);\nURI u2 = method.getURI();\n\nSystem.out.println(\"1. \" + u);\nSystem.out.println(\"2. \" + new String(u.getRawURI()));\nSystem.out.println(\"3. \" + u.getURI());\nSystem.out.println(\"4. \" + u2);\nSystem.out.println(\"5. \" + new String(u2.getRawURI()));\nSystem.out.println(\"6. \" + u2.getURI());\n\n\nThe result that you'll get is:\n\n1. http://some.host.com/%41.html\n2. http://some.host.com/%41.html\n3. http://some.host.com/A.html\n4. http://some.host.com/%2541.html\n5. http://some.host.com/%2541.html\n6. http://some.host.com/%41.html\n\n\nYou can see that for lines 4, 5, and 6, the URI suddenly gets escaped (the \npercent sign gets converted to %25).\n\nWhy is that? Am I doing something wrong? Is this the desired behaviour? I would \nhave expected to get the SAME URI back, without any escaping.\n\nBesides, I have another question:\n\nAfter executing a method -- httpClient.executeMethod(method) -- what will \nmethod.getURI() return? The URI *after* all redirections or the original URI? \nIt seems I get the URI *after* the redirections, which is fine, but the \ndocumentation doesn't say that. It only explicitly says that the getPath() \nmethod has that behaviour.\n\nBest regards and thanks,\nBisser",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-221",
        "summary": "error handling duplicate connection headers",
        "description": "HttpMethodBase.shouldCloseConnection() does not correctly handle the case when\nmore than one connection header exists.  Reported by Ross Rankin.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-105",
        "summary": "ChunkedInputStream broken (2 bugs + fixes, 1 suggestion)",
        "description": "Bug 1.\n\nIn the     \n\nread(byte[] b, int off, int len)  method\n\nof ChunkedInputStream, the number of bytes to read from the underlying \nInputStream is calculated wrongly. In the code this is done by\n\nlen = Math.min(len, chunkSize);\n\nThis could (and will) cause the server (also Apache) to indeed serve that \nnumber of bytes (let's say chunkSize), but it may be that we already had a \nnumber of bytes on the first read. The result is that the input is now NOT \npositioned on the end of a chunk and the rest of the reader fails because it \ncannot find CRLF or a valid chunksize.\n\nProposed fix (works, tested)\nlen = Math.min(len, chunkSize-pos);\n\nBug 2.\n\nIn the calculation of the chunkSize (method getChunkSizeFromInputStream) the \nconversion to int is done by calling             \n\nresult = Integer.parseInt(dataString, 16);\n\nThis is not robust and causes the occasional crash. The fix is simple and in \nfact implements what is done when the chunkSize is commented (see lines in code \nabove)\n\nresult = Integer.parseInt(dataString.trim(), 16);\n\nTested and works.\n\n\n\nSuggestion:\nSame routine, input state machine. Perhaps just being pedantic..change while \nloop to:\n\n        while (state != 2) {\n            int b = in.read();\n            if (b == -1) throw new IOException(\"chunked stream ended \nunexpectedly\");\n            switch (state) {\n                case 0:\n                    if (b == '\\r')\n                      state = 1;\n                    else\n                      baos.write(b);\n                    break;\n                case 1:\n                    if (b == '\\n')\n                      state = 2;\n                    else{\n                     // this was not CRLF, so now write '\\r' + this char\n                      baos.write('\\r');\n                      baos.write(b);\n                      state = 0;\n                    }\n                    break;\n                default: throw new RuntimeException(\"assertion failed\");\n            }\n        }.\n\nIn the     \n\nread(byte[] b, int off, int len)  method\n\nof ChunkedInputStream, the number of bytes to read from the underlying \nInputStream is calculated wrongly. In the code this is done by\n\nlen = Math.min(len, chunkSize);\n\nThis could (and will) cause the server (also Apache) to indeed serve that \nnumber of bytes (let's say chunkSize), but it may be that we already had a \nnumber of bytes on the first read. The result is that the input is now NOT \npositioned on the end of a chunk and the rest of the reader fails because it \ncannot find CRLF or a valid chunksize.\n\nProposed fix (works, tested)\nlen = Math.min(len, chunkSize-pos);\n\nBug 1.\n\nIn the     \n\nread(byte[] b, int off, int len)  method\n\nof ChunkedInputStream, the number of bytes to read from the underlying \nInputStream is calculated wrongly. In the code this is done by\n\nlen = Math.min(len, chunkSize);\n\nThis could (and will) cause the server (also Apache) to indeed serve that \nnumber of bytes (let's say chunkSize), but it may be that we already had a \nnumber of bytes on the first read. The result is that the input is now NOT \npositioned on the end of a chunk and the rest of the reader fails because it \ncannot find CRLF or a valid chunksize.\n\nProposed fix (works, tested)\nlen = Math.min(len, chunkSize-pos);\n\nBug 2.\n\nIn the calculation of the chunkSize (method getChunkSizeFromInputStream) the \nconversion to int is done by calling             \n\nresult = Integer.parseInt(dataString, 16);\n\nThis is not robust and causes the occasional crash. The fix is simple and in \nfact implements what is done when the chunkSize is commented (see lines in code \nabove)\n\nresult = Integer.parseInt(dataString.trim(), 16);\n\nTested and works.\n\n\n\nSuggestion:\nSame routine, input state machine. Perhaps just being pedantic..change while \nloop to:\n\n        while (state != 2) {\n            int b = in.read();\n            if (b == -1) throw new IOException(\"chunked stream ended \nunexpectedly\");\n            switch (state) {\n                case 0:\n                    if (b == '\\r')\n                      state = 1;\n                    else\n                      baos.write(b);\n                    break;\n                case 1:\n                    if (b == '\\n')\n                      state = 2;\n                    else{\n                     // this was not CRLF, so now write '\\r' + this char\n                      baos.write('\\r');\n                      baos.write(b);\n                      state = 0;\n                    }\n                    break;\n                default: throw new RuntimeException(\"assertion failed\");\n            }\n        }.\n\nIn the calculation of the chunkSize (method getChunkSizeFromInputStream) the \nconversion to int is done by calling             \n\nresult = Integer.parseInt(dataString, 16);\n\nThis is not robust and causes the occasional crash. The fix is simple and in \nfact implements what is done when the chunkSize is commented (see lines in code \nabove)\n\nresult = Integer.parseInt(dataString.trim(), 16);\n\nTested and works.\n\n\n\nSuggestion:\nSame routine, input state machine. Perhaps just being pedantic..change while \nloop to:\n\n        while (state != 2) {\n            int b = in.read();\n            if (b == -1) throw new IOException(\"chunked stream ended \nunexpectedly\");\n            switch (state) {\n                case 0:\n                    if (b == '\\r')\n                      state = 1;\n                    else\n                      baos.write(b);\n                    break;\n                case 1:\n                    if (b == '\\n')\n                      state = 2;\n                    else{\n                     // this was not CRLF, so now write '\\r' + this char\n                      baos.write('\\r');\n                      baos.write(b);\n                      state = 0;\n                    }\n                    break;\n                default: throw new RuntimeException(\"assertion failed\");\n            }\n        }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-875",
        "summary": "DefaultClientConnectionOperator doesn't update socket after call to connectSocket(...)",
        "description": "In the DefaultClientConnectionOperator function openConnection(...) it calls SocketFactory.connectSocket(...). The documentation for connectSocket(...) says that it returns:\n   \"the connected socket. The returned object may be different from\nthe sock argument if this factory supports a layered protocol. \"\n\nA quick peek at the source showed:\nIn org.apache.http.impl.conn.DefaultClientConnectionOperator:\n\n117         final SocketFactory sf = schm.getSocketFactory();\n118\n119         Socket sock = sf.createSocket();\n120         conn.opening(sock, target);\n121\n122         try {\n123             sock = sf.connectSocket(sock, target.getHostName(),\n124                     schm.resolvePort(target.getPort()),\n125                     local, 0, params);\n126         } catch (ConnectException ex) {\n127             throw new HttpHostConnectException(target, ex);\n128         }\n129         prepareSocket(sock, context, params);\n130         conn.openCompleted(sf.isSecure(sock), params);\n\nSo DefaultClientConnectionOperator never updates conn with the new version of sock that may have been returned from connectSocket(...).\n\nadding:\n        130         conn.openCompleted(sf.isSecure(sock), params);\n+++ 131         conn.update(sock, target, sf.isSecure(sock), params);\nappears to fix the issue.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-116",
        "summary": "Request/Response race condition when doing multiple requests on the same connection.",
        "description": "If one tries to do multiple request over the same socket connection a race \ncondition occurs in the input/output streams.\neg. \n-- Some request -->\n<- HTTP/1.1 200 OK\n<- Some: Headers\n<- \n<- The body.\n\n-- Next request -->\n<- HTTP/1.1 200 OK\n<- More: Headers\n<- \n<- Some data.\n\nIf the second request is sent, but the second response isn't yet received \nbefore the client starts to try to read it, it'll get \na \"org.apache.commons.httpclient.HttpRecoverableException: Error in parsing the \nstatus  line from the response: unable to find line starting with \"HTTP/\"\" \nexception (it will think \"The body.\" is part of the second response).\n\nThe following code will reproduce the problem:\n\nimport java.io.*;\nimport java.net.*;\nimport java.util.*;\nimport org.apache.commons.httpclient.*;\nimport org.apache.commons.httpclient.methods.*;\n\npublic class HttpClientRaceBug {\n    public static void main(String[] args) {\n        try {\n            SimpleHttpServer.listen(8987);\n            HttpClient client = new HttpClient();\n            client.startSession(\"localhost\", 8987);\n            client.getState().setCredentials(\"Test Realm\",  \n                new UsernamePasswordCredentials(\"foo\", \"bar\"));\n            \n            for (int i = 0; i < 100; i++) {\n                GetMethod meth = new GetMethod();\n                client.executeMethod(meth);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n    \n    private static final class SimpleHttpServer implements Runnable {\n        private Socket socket;\n        public SimpleHttpServer(Socket socket) {\n            this.socket = socket;\n        }\n        public static void listen(final int port) {\n            Thread server = new Thread() {\n                public void run() {\n                    try {\n                        ServerSocket ss = new ServerSocket(port);\n                        while (true) {\n                            new Thread(new \n                                SimpleHttpServer(ss.accept())).start();\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                    }\n                }\n            };\n            \n            server.setDaemon(true);\n            server.start();\n        }\n        public void run() {\n            try {\n                BufferedReader in = new BufferedReader(new \n                    InputStreamReader(this.socket.getInputStream()));\n                \n                int len = 0;\n                boolean auth = false;\n                String line;\n                while ((line = in.readLine()) != null) {\n                    System.out.println(\"> \" + line);\n                    \n                    if (line.trim().equals(\"\")) {\n                        in.read(new char[len]);\n                        doOutput(auth);\n                        auth = false;\n                        len = 0;\n                        \n                    } else if (line.indexOf(':') > -1) {\n                        StringTokenizer tok = new StringTokenizer(line, \":\");\n                        String key = tok.nextToken().toLowerCase();\n                        if (key.equals(\"content-length\")) {\n                            len = Integer.parseInt(tok.nextToken().trim());\n                        } else if (key.equals(\"authorization\")) {\n                            auth = true;\n                        }\n                    }\n                }\n            } catch (Exception e) {}\n        }\n        private static int count = 0;\n        public void doOutput(boolean authorized) throws IOException {\n            Writer out = new OutputStreamWriter(this.socket.getOutputStream());\n            count++;\n            \n            String id = (count < 100) ? \n                ((count < 10) ? \"00\" + count : \"0\" + count) : \"\" + count;\n            if (authorized) {\n                write(out, \"HTTP/1.1 200 OK\\r\\n\");\n            } else {\n                write(out, \"HTTP/1.1 401 Unauthorized\\r\\n\");\n            }\n            write(out, \"WWW-Authenticate: Basic realm=\\\"Test Realm\\\"\\r\\n\");\n            write(out, \"Response-Id: \" + id + \"\\r\\n\");\n            write(out, \"Content-Type: text/html; charset=iso-8859-1\\r\\n\");\n            write(out, \"Content-Length: 17\\r\\n\\r\\n\");\n            write(out, \"My Response (\" + id + \")\");\n            out.close();\n        }\n        private void write(Writer out, String text) throws IOException {\n            System.out.print(\"< \" + text);\n            out.write(text);\n        }\n    }\n}",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-763",
        "summary": "AbstractClientConnAdapter#abortConnection() does not release the connection if called from the main execution thread while there is no blocking I/O operation ",
        "description": "#abortConnection() is usually expected to be  called from a helper thread in order to unblock the main execution thread blocked in an I/O operation. It may be unsafe to call #releaseConnection() from the helper thread, so we have to rely on an IOException thrown by the closed socket on the main thread to trigger the release of the connection back to the connection manager. However, if this method is called from the main execution thread it should be safe to release the connection immediately. Besides, this also helps ensure the connection gets released back to the manager if #abortConnection() is called from the main execution thread while there is no blocking I/O operation.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-174",
        "summary": "Need setURI() methods in HttpMethod interface",
        "description": "I'd like to have the methods setURI( URI ) and setURI( String ) methods. Also a \nmethod like getRequestURI() because the uri I get now with the method getURI() \nchanges if I execute a request which will be automatically forwarded.\n\nThe methods setURI can throw an exception if it has already been executed.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-736",
        "summary": "dependencies for route planner implementations",
        "description": "The implementations of HttpRoutePlanner that we have depend on the ConnectionManager, but use it only to look up the SchemeRegistry. Consider to depend only on the SchemeRegistry.\n\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-546",
        "summary": "MultiThreadedHttpConnectionManager setMaxTotalConnections() method doesn't work",
        "description": "The deprecated setMaxTotalConnections() method in the\nMultiThreadedHttpConnectionManager seems like it has no effect:\n\nHere is the source code in the current version:\n\n    public void setMaxTotalConnections(int maxTotalConnections) {\n        this.params.getMaxTotalConnections();\n    }\n\nShouldn't it look more like this?\n\n    public void setMaxTotalConnections(int maxTotalConnections) {\n        this.params.setMaxTotalConnections(maxTotalConnections);\n    }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-351",
        "summary": "Split the wire log into header and content parts.",
        "description": " ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1054",
        "summary": "HTTPClient per default relentlessly spams to stderr",
        "description": "HTTPClient relentlessly spams to stderr when including it into a project via maven. This is not a decent default behaviour for a libary. Libaries should, per default, communicate their internal state solely and adequatly via their API and let it be up to the application to react to that state (logging it is one such reaction). From some replies to tickets in the same vain I can see that this is perhaps a sensitive topic as some see logging to be a core concern of HTTPClient. I do agree it's helpful as a debugging tool but as such it needs to be opt-in. As a standard error output, the logging of HTTPClient is absolutely useless because it does not and can not describe what the application is trying to do.\n\nWhy this improvement when there is a way to disable HTTClient logging (in fact, there seem to be many ways ... always a bad sign ..)?\n\nDo a google search for: httpclient \"console spam\"\n204 hit for this harsh phrasing alone. Search this phrase for any other libary you like to use and compare the number of hits. Ask youself, how often have you seen the java standard libary write to stdout or stderr?\n\nPersonally, I tried to disable it via JDK14 getLogger(\"org.apache\").setLevel(Level.OFF)  which wouldn't work and now am using a solution I found on Stackoverflow which is:\n\nSystem.setProperty(\"org.apache.commons.logging.Log\", \"org.apache.commons.logging.impl.NoOpLog\"); }\n\nThe problem I have is that I include this lib and suddently my console is useless because httpclient is all over it (writing a system monitor ...). I have to search google to find a solution (http://hc.apache.org/httpcomponents-client-ga/logging.html does not tell you how to turn logging off ...) and the logical one \"turn of the JDK logger\" does not work right away.\n\nIt's really a matter of following the principal of least suprise (a libary is not expected to write to the console which is the observable default behaviour of HTTPClient) and the principal of separation of concerns (logging is a concern for applications and not for libaries).\n\nFollowing at least one of these would substantially increase the joy of working with the HTTPClient libary.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-578",
        "summary": "literal plus (+) character in path components of HttpURL is not preserved.",
        "description": "When a literal plus character is included in the path component of an URL, it is\nnot encoded, but get decoded during getPath() to a space.\n\nReproducible with the following:\n\nHttpURL httpURL = new HttpURL(\"http://localhost/test+test\");\nSystem.out.println(httpURL.getPath());\n\nOutput:\n\"test test\"\n\nThe following path fixes the issue (This patch does not appear to break anything\n else):\n\nPatch against SVN Repo:\nURL: http://svn.apache.org/repos/asf/jakarta/commons/proper/httpclient/trunk\nRepository UUID: 13f79535-47bb-0310-9956-ffa450edef68\nRevision: 405803\n\nIndex: src/java/org/apache/commons/httpclient/URI.java\n===================================================================\n--- src/java/org/apache/commons/httpclient/URI.java (revision 405803)\n+++ src/java/org/apache/commons/httpclient/URI.java (working copy)\n@@ -1552,6 +1552,7 @@\n         allowed_abs_path.or(abs_path);\n         // allowed_abs_path.set('/');  // aleady included\n         allowed_abs_path.andNot(percent);\n+        allowed_abs_path.clear('+');\n     }\n\n\n@@ -1563,6 +1564,7 @@\n     static {\n         allowed_rel_path.or(rel_path);\n         allowed_rel_path.clear('%');\n+        allowed_rel_path.clear('+');\n     }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1073",
        "summary": "cache module generates exceptions for non-compliant responses without consuming response bodies",
        "description": "In the ResponseProtocolCompliance class, the caching module checks the incoming origin response to attempt to make it compliant with RFC2616. However, if there are instances where this is not possible, it currently throws an exception without consuming the origin response body; this causes a connection leak if the general try..catch..finally pattern documented on the HttpClient interface Javadoc is followed.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-788",
        "summary": "Public Suffix List",
        "description": "Hi,\n\nI just found this useful list: http://publicsuffix.org/\nand thought it would be nice to validate cookie domains against it, basically serving as a black list of domain for which never to set any cookies. What do you think about the attached patch? The download/parsing of the list is of course not part of the implementation.\n\nOrtwin",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-574",
        "summary": "Subclasses do not have write access to StatusLine",
        "description": "HttpMethodBase provides the readStatusLine method explicitly designed for\nsubclasses to override. However, any attempt to do so quickly encounters issues\nsince the subclass does not have access to the statusLine member variable in\nHttpMethodBase. The same holds true for several other member variables as well.\n\nRecommend that all access to member variables occur through accessors and that\nmutators be provided to set them. See patch below.\n----------------------------------------------------------\n\nIndex: HttpMethodBase.java\n===================================================================\n--- HttpMethodBase.java\t(revision 390815)\n+++ HttpMethodBase.java\t(working copy)\n@@ -563,7 +563,7 @@\n      * @return the status code associated with the latest response.\n      */\n     public int getStatusCode() {\n-        return statusLine.getStatusCode();\n+        return getStatusLine().getStatusCode();\n     }\n \n     /**\n@@ -577,6 +577,13 @@\n     }\n \n     /**\n+     * @param statusLine The statusLine to set.\n+     */\n+    protected final void setStatusLine(StatusLine statusLine) {\n+        this.statusLine = statusLine;\n+    }\n+\n+    /**\n      * Checks if response data is available.\n      * @return <tt>true</tt> if response data is available, <tt>false</tt>\notherwise.\n      */\n@@ -798,7 +805,7 @@\n      * @return The status text.\n      */\n     public String getStatusText() {\n-        return statusLine.getReasonPhrase();\n+        return getStatusLine().getReasonPhrase();\n     }\n \n     /**\n@@ -920,16 +927,16 @@\n         }\n         LOG.debug(\"Resorting to protocol version default close connection policy\");\n         // missing or invalid connection header, do the default\n-        if (this.effectiveVersion.greaterEquals(HttpVersion.HTTP_1_1)) {\n+        if (getEffectiveVersion().greaterEquals(HttpVersion.HTTP_1_1)) {\n             if (LOG.isDebugEnabled()) {\n-                LOG.debug(\"Should NOT close connection, using \" +\nthis.effectiveVersion.toString());\n+                LOG.debug(\"Should NOT close connection, using \" +\ngetEffectiveVersion().toString());\n             }\n         } else {\n             if (LOG.isDebugEnabled()) {\n-                LOG.debug(\"Should close connection, using \" +\nthis.effectiveVersion.toString());\n+                LOG.debug(\"Should close connection, using \" +\ngetEffectiveVersion().toString());\n             }\n         }\n-        return this.effectiveVersion.lessEquals(HttpVersion.HTTP_1_0);\n+        return getEffectiveVersion().lessEquals(HttpVersion.HTTP_1_0);\n     }\n     \n     /**\n@@ -980,14 +987,14 @@\n         this.responseConnection = conn;\n \n         checkExecuteConditions(state, conn);\n-        this.statusLine = null;\n+        setStatusLine(null);\n         this.connectionCloseForced = false;\n \n         conn.setLastResponseInputStream(null);\n \n         // determine the effective protocol version\n-        if (this.effectiveVersion == null) {\n-            this.effectiveVersion = this.params.getVersion(); \n+        if (getEffectiveVersion() == null) {\n+            setEffectiveVersion(this.params.getVersion()); \n         }\n \n         writeRequest(state, conn);\n@@ -996,7 +1003,7 @@\n         // the method has successfully executed\n         used = true; \n \n-        return statusLine.getStatusCode();\n+        return getStatusCode();\n     }\n \n     /**\n@@ -1048,8 +1055,8 @@\n         getRequestHeaderGroup().clear();\n         getResponseHeaderGroup().clear();\n         getResponseTrailerHeaderGroup().clear();\n-        statusLine = null;\n-        effectiveVersion = null;\n+        setStatusLine(null);\n+        setEffectiveVersion(null);\n         aborted = false;\n         used = false;\n         params = new HttpMethodParams();\n@@ -1586,18 +1593,18 @@\n         \"enter HttpMethodBase.readResponse(HttpState, HttpConnection)\");\n         // Status line & line may have already been received\n         // if 'expect - continue' handshake has been used\n-        while (this.statusLine == null) {\n+        while (getStatusLine() == null) {\n             readStatusLine(state, conn);\n             processStatusLine(state, conn);\n             readResponseHeaders(state, conn);\n             processResponseHeaders(state, conn);\n             \n-            int status = this.statusLine.getStatusCode();\n+            int status = getStatusCode(); \n             if ((status >= 100) && (status < 200)) {\n                 if (LOG.isInfoEnabled()) {\n-                    LOG.info(\"Discarding unexpected response: \" +\nthis.statusLine.toString()); \n+                    LOG.info(\"Discarding unexpected response: \" +\ngetStatusLine().toString()); \n                 }\n-                this.statusLine = null;\n+                setStatusLine(null);\n             }\n         }\n         readResponseBody(state, conn);\n@@ -1675,7 +1682,7 @@\n         if (Wire.CONTENT_WIRE.enabled()) {\n             is = new WireLogInputStream(is, Wire.CONTENT_WIRE);\n         }\n-        boolean canHaveBody = canResponseHaveBody(statusLine.getStatusCode());\n+        boolean canHaveBody = canResponseHaveBody(getStatusCode());\n         InputStream result = null;\n         Header transferEncodingHeader =\nresponseHeaders.getFirstHeader(\"Transfer-Encoding\");\n         // We use Transfer-Encoding if present and ignore Content-Length.\n@@ -1714,7 +1721,7 @@\n         } else {\n             long expectedLength = getResponseContentLength();\n             if (expectedLength == -1) {\n-                if (canHaveBody &&\nthis.effectiveVersion.greaterEquals(HttpVersion.HTTP_1_1)) {\n+                if (canHaveBody &&\ngetEffectiveVersion().greaterEquals(HttpVersion.HTTP_1_1)) {\n                     Header connectionHeader =\nresponseHeaders.getFirstHeader(\"Connection\");\n                     String connectionDirective = null;\n                     if (connectionHeader != null) {\n@@ -1850,19 +1857,19 @@\n         } while(true);\n \n         //create the status line from the status string\n-        statusLine = new StatusLine(s);\n+        setStatusLine(new StatusLine(s));\n \n         //check for a valid HTTP-Version\n-        String versionStr = statusLine.getHttpVersion();\n+        String versionStr = getStatusLine().getHttpVersion();\n         if (getParams().isParameterFalse(HttpMethodParams.UNAMBIGUOUS_STATUS_LINE) \n            && versionStr.equals(\"HTTP\")) {\n             getParams().setVersion(HttpVersion.HTTP_1_0);\n             if (LOG.isWarnEnabled()) {\n                 LOG.warn(\"Ambiguous status line (HTTP protocol version missing):\" +\n-                statusLine.toString());\n+                getStatusLine().toString());\n             }\n         } else {\n-            this.effectiveVersion = HttpVersion.parse(versionStr);\n+            setEffectiveVersion(HttpVersion.parse(versionStr));\n         }\n \n     }\n@@ -1943,9 +1950,9 @@\n                     readResponseHeaders(state, conn);\n                     processResponseHeaders(state, conn);\n \n-                    if (this.statusLine.getStatusCode() ==\nHttpStatus.SC_CONTINUE) {\n+                    if (getStatusCode() == HttpStatus.SC_CONTINUE) {\n                         // Discard status line\n-                        this.statusLine = null;\n+                        setStatusLine(null);\n                         LOG.debug(\"OK to continue received\");\n                     } else {\n                         return;\n@@ -2087,7 +2094,7 @@\n      */\n     private String getRequestLine(HttpConnection conn) {\n         return  HttpMethodBase.generateRequestLine(conn, getName(),\n-                getPath(), getQueryString(), this.effectiveVersion.toString());\n+                getPath(), getQueryString(), getEffectiveVersion().toString());\n     }\n \n     /**\n@@ -2128,6 +2135,13 @@\n     }\n \n     /**\n+     * @param effectiveVersion The effectiveVersion to set.\n+     */\n+    protected final void setEffectiveVersion(HttpVersion effectiveVersion) {\n+        this.effectiveVersion = effectiveVersion;\n+    }\n+\n+    /**\n      * Per RFC 2616 section 4.3, some response can never contain a message\n      * body.\n      *\n@@ -2358,7 +2372,7 @@\n     ) {\n         // set used so that the response can be read\n         this.used = true;\n-        this.statusLine = statusline;\n+        setStatusLine(statusline);\n         this.responseHeaders = responseheaders;\n         this.responseBody = null;\n         this.responseStream = responseStream;",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-940",
        "summary": "impl.conn.Wire uses String.getBytes() which depends on the default charset",
        "description": "impl.conn.Wire uses String.getBytes() which depends on the default charset\n\nThe methods \npublic void output(final String s)\nand\npublic void input(final String s)\n\ncould probably be recoded to avoid this problem, as the output routine uses a StringBuilder.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-25",
        "summary": "[httpclient] Incorrect credentials loop infinitely",
        "description": "If incorrect credentials are assigned to the request, HttpClient will loop \nforever.  It should only try once, and fail with an HttpException if a request \nwith credentials set fails.\n\nIn org.apache.commons.httpclient.HttpMethodBase.execute(), a check is needed to \ntrack if credentials have been sent before.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-205",
        "summary": "HttpMethodBase(String) incorrectly encoding URI",
        "description": "The HttpMethodBase(String) constructor is handling URIs incorrectly. The\nJavadocs indicate that the given URI should already be escaped but the\nconstructor uses the URI constructor for unescaped URIs.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-414",
        "summary": "cookies > 20 years invalidated",
        "description": " ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-139",
        "summary": "isHttp11 should have HttpClient scope",
        "description": "-----Original Message-----\nFrom: Kalnichevski, Oleg [mailto:oleg.kalnichevski@bearingpoint.com] \nSent: Wednesday, January 15, 2003 8:24 AM\nTo: Commons HttpClient Project\nCc: Rob Owen\nSubject: RE: isHttp11 and HTTP/1.0 servers \n\nRob\nYou are basically right hands down. It does make sense for the HTTP version \nflag to have HttpClient scope. We should address this shortcoming as a part of \nthe post-2.0-release redesign\n\nFeel free to file a bug report to make sure the issue does not go forgotten\n\nhttp://nagoya.apache.org/bugzilla/enter_bug.cgi?product=Commons\n\nMany thanks for bring it up\n\nCheers\n\nOleg\n\n-----Original Message-----\nFrom: Rob Owen [mailto:Rob.Owen@sas.com]\nSent: Monday, January 13, 2003 18:31\nTo: Commons HttpClient Project\nSubject: isHttp11 and HTTP/1.0 servers \n\n\nThe boolean variable http11 is set on a method by method basis. For PutMethod, \ndecisions (eg. Expect: 100-continue request header) are made prior to \ndetermining the value for Http11 (chicken and egg problem) and so the default \n(true) is used to produce the request. An HTTP/1.0 server hangs waiting for \nthe extra data on the PUT method body. \n\nFor applications that are using HttpClient (ie. they do not manipulate the \nHTTP methods directly and cannot be expected to set the value of Http11 for \neach method instance), shouldn't http11 have HttpClient scope ? This would \nallow an interaction (eg. OPTIONS) to set http11 and all methods thereafter \nwould use this setting?\n  \n------\nRob Owen\nSAS Institute Inc.\nemail: Rob.Owen@sas.com",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-262",
        "summary": "Minor typo in org.apache.commons.httpclient.Wire 2.0-rc1",
        "description": "Minor typo \"...may noy be null\" in \npublic static final void output(final String s) and\npublic static final void input(final String s)\nof org.apache.commons.httpclient.Wire.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-692",
        "summary": "ClientConnectionManager should throw InterruptedException",
        "description": "For historical reasons, ThreadSafeClientConnectionManager throws an IllegalThreadStateException instead of an InterruptedException if the waiting thread is interrupted from outside. This design was chosen since adding InterruptedException to the HttpConnectionManager in 3.x would have broken the API. This is not a concern for HttpClient 4.0.\n",
        "label": "NUG",
        "classified": "BACKPORT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-539",
        "summary": "UserInfo disapears after creating URI",
        "description": "I tested this using firefox (Where I have configured our proxy server)\nI run the following URI: ftp://username:password@ftp.mytest.test/testdir/\n\nI use a sniffer to look at the GET commond send to the proxy server. It looks as\nfollows:\n\nGET ftp://username:password@ftp.mytest.test/testdir/ HTTP/1.1\nHost: ftp.mytest.test\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.7.12)\nGecko/20050915 Firefox/1.0.7\nAccept:\ntext/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nKeep-Alive: 300\nProxy-Connection: keep-alive\n\nUsing this request we get access to the directory and see the contents displayed.\nHowever, when I try the same in Java (using HttpClient) I get the following GET\nrequest (Java code included below):\n\nGET ftp://ftp.mytest.test/testdir/ HTTP/1.1\nUser-Agent: Jakarta Commons-HttpClient/3.0-rc3\nHost: ftp.mytest.test\nProxy-Connection: Keep-Alive\n\nFinally I get a ACCESS DENIED error. \nThis seems to be because the GET request does not contain the USER / PASSWORD\ninfo in the URL.\n\n/// JAVA CODE:\n\npackage nl.essent.test.ftp.httptest;\n\nimport java.io.IOException;\n\nimport org.apache.commons.httpclient.Credentials;\nimport org.apache.commons.httpclient.DefaultHttpMethodRetryHandler;\nimport org.apache.commons.httpclient.HostConfiguration;\nimport org.apache.commons.httpclient.HttpClient;\nimport org.apache.commons.httpclient.HttpException;\nimport org.apache.commons.httpclient.HttpMethod;\nimport org.apache.commons.httpclient.HttpStatus;\nimport org.apache.commons.httpclient.NTCredentials;\nimport org.apache.commons.httpclient.UsernamePasswordCredentials;\nimport org.apache.commons.httpclient.auth.AuthScope;\nimport org.apache.commons.httpclient.methods.GetMethod;\nimport org.apache.commons.httpclient.params.HttpMethodParams;\nimport org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory;\nimport org.apache.commons.httpclient.protocol.Protocol;\n\npublic class TestClient {\n\n    public static void main(String[] args) {\n        new TestClient().testFtpViaHttp();\n    }\n    \n    public void testFtpViaHttp() {\n        \n        HttpClient client = new HttpClient();\n        \n        HostConfiguration hostConfig = client.getHostConfiguration();\n        hostConfig.setProxy(\"proxy\", 8080);\n        client.setHostConfiguration(hostConfig);\n        \n        Protocol protol = new Protocol(\"ftp\", new\nDefaultProtocolSocketFactory(), 21);\n        Protocol.registerProtocol(\"ftp\", protol);\n        \n        Credentials proxyCreds = new NTCredentials(\"xxxx\", \"xxxxx\",\"\", \"xxxx\" );\n        client.getState().setProxyCredentials(AuthScope.ANY, proxyCreds);\n        \n        GetMethod gmethod = new\nGetMethod(\"ftp://username:password@ftp.mytest.test/testdir/\");\n        \n        gmethod.getParams().setParameter(HttpMethodParams.RETRY_HANDLER, \n                new DefaultHttpMethodRetryHandler(3, false));\n       \n        try {\n            // Execute the method.\n            int statusCode = client.executeMethod(gmethod);\n\n            if (statusCode != HttpStatus.SC_OK) {\n              System.err.println(\"Method failed: \" + gmethod.getStatusLine());\n            }\n\n            // Read the response body.\n            byte[] responseBody = gmethod.getResponseBody();\n\n            // Deal with the response.\n            // Use caution: ensure correct character encoding and is not binary data\n            System.out.println(new String(responseBody));\n\n          } catch (HttpException e) {\n            System.err.println(\"Fatal protocol violation: \" + e.getMessage());\n            e.printStackTrace();\n          } catch (IOException e) {\n            System.err.println(\"Fatal transport error: \" + e.getMessage());\n            e.printStackTrace();\n          } finally {\n            // Release the connection.\n            gmethod.releaseConnection();\n          } \n\n    }\n\n}\n\n//// END JAVA CODE",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-108",
        "summary": "Cookie.java: 'bookean' typo",
        "description": " ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-245",
        "summary": "customize handling of 302 redirects",
        "description": "I tried this with both the beta2 2.0 release, and the nightly build.  The\nfollowing code snippet describes what I am trying to do:\n\nhttpClient.getHostConfiguration().setHost(sHost, 80, \"http\");\nHttpMethod method=null;\nif (sMethod.indexOf(\"POST\")!=-1) {\n     method=new PostMethod(sURLInfo);\n} else {\n     method=new GetMethod(sURLInfo);\n}\nmethod.setFollowRedirects(true);\nhttpClient.executeMethod(method);\n\nAfter this code executes, the \"getFollowRedirects\" method still returns false,\nand any redirects which are sent by the webserver are not followed.  As a\ntemporary workaround, since I want all redirects followed, I commented out the\nfollowing code in the HttpMethodBase class in the \"processRedirectResponse\" method:\n\n/*if (!getFollowRedirects()) {\n     LOG.info(\"Redirect requested but followRedirects is \"\n     + \"disabled\");\n     return false;\n}*/\n\nIf this bug has already been reported, I apologize...I searched for and found\nnothing related to this issue.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-738",
        "summary": "HostnameVerifier shouldn't shadow simple name of implemented interface",
        "description": "public interface HostnameVerifier extends javax.net.ssl.HostnameVerifier.\n\nAs Findbugs says:\n\nClass names shouldn't shadow simple name of implemented interface\n\nThis class/interface has a simple name that is identical to that of an implemented/extended interface, except that the interface is in a different package (e.g., alpha.Foo extends beta.Foo). This can be exceptionally confusing, create lots of situations in which you have to look at import statements to resolve references and creates many opportunities to accidently define methods that do not override methods in their superclasses. \n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-960",
        "summary": "HttpMultipart doesn't generate Content-Type part header in mode BROWSER_COMPATIBLE",
        "description": "Browsers (tested with Firefox 3.6 and IE6) send a Content-Type header for file parts, what org.apache.http.entity.mime.HttpMultipart doesn't do in BROWSER_COMPATIBLE mode.\n\n\nExample:\n\n-----------------------------142889018617181602061216500409\n\nContent-Disposition: form-data; name=\"myFileFieldName2\"; filename=\"webtest.png\"\n\nContent-Type: image/png\n\n\nIn HtmlUnit we wil subclass HttpEntity and MultipartEntity to fix this problem.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-746",
        "summary": "substitute for URLUtils.java",
        "description": "I would like to contribute a substitute for existing URLUtils.java... UrlEncodedUtils.java offer utility methods for dealing with 'urlencoded' data. Main difference with existing class is that parameters are Map <String, List <String>> instead of NameValue pairs and lack of third party dependencies...  It's partially covered with tests which I will further extend to cover all methods of this utility class.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-560",
        "summary": "entities and connection handling incomplete",
        "description": "1. entities can not be explicitly disconnected from the underlying stream\n2. entities do not tell whether they have an underlying stream\n\npatch follows\n\ncheers,\n  Roland",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-820",
        "summary": "AbstractHttpClient.addRequestInterceptor should document in what order the interceptors run",
        "description": "http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/impl/client/AbstractHttpClient.html#addRequestInterceptor(org.apache.http.HttpRequestInterceptor) has no documentation. It should at least say what order new interceptors run in. Presumably they run in order by index, but does the lowest or highest index run first?\n\nThis class or DefaultHttpClient should also say what interceptors are added by default. That is, what would I be getting rid of by calling clearResponseInterceptors()?",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-698",
        "summary": "DefaultRedirectHandler not resolving relative location URI wrt the request URI",
        "description": "The adjustment of a relative URI in the Location header value does not take the request URI into account. So you may want to replace ...\n------------------------------\ntry {\n    uri = new URI(\n            target.getSchemeName(),\n            null,\n            target.getHostName(),\n            target.getPort(),\n            uri.getPath(),\n            uri.getQuery(),\n            uri.getFragment());\n------------------------------\n... with ...\n------------------------------\nHttpRequest request = (HttpRequest) context.getAttribute(ExecutionContext.HTTP_REQUEST);\ntry {\n    URI requestURI = new URI(request.getRequestLine().getUri());\n    URI absoluteRequestURI = new URI(\n            target.getSchemeName(),\n            null,\n            target.getHostName(),\n            target.getPort(),\n            requestURI.getPath(),\n            requestURI.getQuery(),\n            requestURI.getFragment());\n    uri = absoluteRequestURI.resolve(uri);\n------------------------------\n... or get the request URI from somewhere else.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-86",
        "summary": "need to add a default constructor for Cookie",
        "description": "The Cookie class doesn't have a default (no argument) constructor. This is \ncausing problem for some framework which supports marshalling and unmarshalling \nof data types. e.g. a SOAP implementation may need to do this to transfer it \nbetween the SOAP server and SOAP client. It would be nice to add a default \nconstructor, as it won't break anything, follows JavaBean convention, and \npotentially save user some trouble in the future.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1053",
        "summary": "Security issue - DigestScheme uses constant nonce count value",
        "description": "The nonce count value in DigestScheme is static (set to 00000001) and never changes.  (also seen as comment in said file).\n\nThis means that it fails against servers that correctly detect man-in-the-middle or replay attacks, leading to additional 401 requests (every second time), or such servers must be configured to turn such checks off (which is either poor security or poor for performance).\n\nI suggest that at minimum, this count is incremented for every call to DigestScheme#createDigest.  It should also be an instance variable instead of a static, as it really relates to the challenge (assuming cases where instances are cached for reuse).  AtomicInteger is a good choice for implementing this counter.\n\nSee RFC 2617 chapters 3.2.2 and 3.2.3",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-602",
        "summary": "refactor HttpClientConnection and HttpProxyConnection",
        "description": "Instead of trying to define a full abstraction for client connections, let's define only a minimal interface in HttpCore with only those methods actually needed in the core. In particular, the core does not need to open connections (since HTTPCORE-11), and it does not care whether a connection is direct or through a proxy. An abstraction for client connections can be defined in HttpConn.\n\n(original description:)\nAs discussed on the mailing list, separating the responsibility for establishing connections from the connection objects could improve the design and help with proxy support.\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-965",
        "summary": "cache does not honor must-revalidate or proxy-revalidate Cache-Control directives",
        "description": "http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.4\n\nThere are a couple of missed requirements here regarding must-revalidate and proxy-revalidate (which applies only to shared caches).\n1. When a cache entry with this directive is revalidated, it must be an end-to-end revalidation (meaning it must include 'max-age=0' on the request).\n2. If the revalidation with the origin fails, the cache MUST NOT return a stale entry and MUST return a 504 response.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-901",
        "summary": "Add a ContextAwareAuthScheme that has access to the HttpContext in the authenticate method",
        "description": "The interface to be added would be:\n\n/**\n * This interface represents an extended  authentication scheme\n * that requires access to {@link HttpContext} in order to\n * generate an authorization string.\n *\n * @since 4.1\n */\n\npublic interface ContextAwareAuthScheme extends AuthScheme {\n\n    /**\n     * Produces an authorization string for the given set of\n     * {@link Credentials}.\n     *\n     * @param credentials The set of credentials to be used for athentication\n     * @param request The request being authenticated\n     * @param context HTTP context\n     * @throws AuthenticationException if authorization string cannot\n     *   be generated due to an authentication failure\n     *\n     * @return the authorization string\n     */\n    Header authenticate(\n            Credentials credentials,\n            HttpRequest request,\n            HttpContext context) throws AuthenticationException;\n\n}\n\nBinary compatibility can be maintained by doing an instanceof check at the location where AuthScheme.authenticate() is called at the moment, and calling the context aware version if available.\n\nThis interface is necessary for the NegotiateScheme authentication scheme because the service names for the authentication tickets are based on the hostname of the target host or proxy host, depending on whether it's normal or proxy authentication, and this information is only available from the HttpContext.\n\nWithout the HttpContext there is a workaround that works most of the time, which looks like this:\n\n\tString host;\n\tif (isProxy()) {\n\t\t// FIXME this should actually taken from the HttpContext.\n\t\tHttpHost proxy = ConnRouteParams.getDefaultProxy(request.getParams());\n\t\thost = proxy.getHostName();\n\t} else {\n\t\thost = request.getLastHeader(\"Host\").getValue();\n\t}\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-251",
        "summary": "Content-Length & Transfer-Encoding request headers should be handled by entity enclosing methods",
        "description": "Currently 'Content-Length' & 'Transfer-Encoding' request headers are handled by \nthe HttpMethodBase class. This is conceptually wrong and error-prone in my \nopinion. Entity enclosing methods should control 'Content-Length' & 'Transfer-\nEncoding' request headers instead, as they provide request content and \nencapsulate the requisite content transfer logic.",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-743",
        "summary": "Duplicate log of HTTP header",
        "description": "The HTTP header line:\n\n\"HTTP/1.1 200 OK[\\r][\\n]\" \n\nis duplicated in the wire logs. Seems to be because the line is logged at:\n\nHttpParser [line: 131] - readLine(InputStream, String)\n\nand at:\n\nHttpMethodBase [line: 1980] - readStatusLine(HttpState, HttpConnection)\n\nIt looks like the latter log should be removed?",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-341",
        "summary": "HttpUrl does not accept unescaped passwords",
        "description": "- Taken from an email from Gustav Munkby posted to the HttpClient dev mailing list -\n\nIf I do:\n\nHTTPUrl url = new HTTPUrl(\"kurt\", \"nicepass#\", hostname, 80, path);\n\nthrows a URIException with message \"port number invalid\".\n\nFirst of all the message is wrong...\n\nNext attempt was to urlencode the password, which resulted in the above line working, but the \npassword was sent url-encoded to the destination, which can hardly be the desired behaviour?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-730",
        "summary": "Use of Multi-Args URI Causes URI-Rewriting to improperly unescape characters",
        "description": "See: http://www.nabble.com/unable-to-encode-reserved-characters-using-java.net.URI-multi-arg-constructors-td14954679.html for information from the httpclient-dev thread.  The basic idea is that URI's multi-arg constructors break things.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-413",
        "summary": "Cookie with domain .mydomain.com not sent to host mydomain.com",
        "description": "A cookie with for example \n  .mydomain.com \nas domain property is not sent to the host\n  mydomain.com\n(without www. or anything else before \"mydomain.com\")\n\nThis concern all CookieSpec as the relevant code is located in CookieSpecBase:\n\n    public boolean domainMatch(final String host, final String domain) {\n        return host.endsWith(domain);\n    }\n\nIt should be changed for instance to something like:\n\n    public boolean domainMatch(final String host, final String domain) {\n        // take care of host \"myDomain.com\" and domain \".myDomain.com\"\n        return host.endsWith(domain)\n\t|| _host.equals(_domain.substring(1));\n    }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-3",
        "summary": "Http Authentication with invalid credentials causes infinite loop",
        "description": "At HttpMethodBase(460), a break statement is executed only if\nlog.isInfoEnabled(). The break statement needs to be moved outside of the if\nstatement so that it breaks if realms already contains foo. Patch submitted on\nmailing list as per Apache site guidelines.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-215",
        "summary": "Build problem with StrictSSLProtocolSocketFactory",
        "description": "StrictSSLProtocolSocketFactory requires jcert.jar to be in compile.classpath of\nbuild.xml.  Here is a patch that will fix it:\n\nIndex: build.xml\n===================================================================\nRCS file: /home/cvspublic/jakarta-commons/httpclient/build.xml,v\nretrieving revision 1.27\ndiff -u -r1.27 build.xml\n--- build.xml   23 May 2003 02:49:01 -0000      1.27\n+++ build.xml   26 May 2003 04:23:50 -0000\n@@ -98,6 +98,7 @@\n     <pathelement location=\"${build.home}/classes\"/>\n     <pathelement location=\"${junit.jar}\"/>\n     <pathelement location=\"${jsse.jar}\"/>\n+    <pathelement location=\"${jcert.jar}\"/>\n     <pathelement location=\"${jce.jar}\"/>\n     <pathelement location=\"${jnet.jar}\"/>\n     <pathelement location=\"${commons-logging.jar}\"/>",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-739",
        "summary": "CookieIdentityComparator and CookiePathComparator could/should implement Serializable",
        "description": "CookieIdentityComparator and CookiePathComparator could/should implement Serializable\n\nAs Findbugs suggests:\n\n\"Comparator doesn't implement Serializable\n\nThis class implements the Comparator interface. You should consider whether or not it should also implement the Serializable interface. If a comparator is used to construct an ordered collection such as a TreeMap, then the TreeMap will be serializable only if the comparator is also serializable. As most comparators have little or no state, making them serializable is generally easy and good defensive programming. \"\n\nNeither class has any state, so implementing Serializable would be trivial.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1079",
        "summary": "Kerberos cross-realm support is broken",
        "description": "This issue is basically based on the same facts as this issue https://issues.sonatype.org/browse/AHC-71?focusedCommentId=129559#action_129559 \nSince the Kerberos code looks the same, I assume that AHC used your code. The same patch can be applied to fix [this http://hc.apache.org/httpcomponents-client-ga/httpclient/xref/org/apache/http/impl/auth/NegotiateScheme.html#200] defective code.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-644",
        "summary": "Bad request vulnerability ",
        "description": "The HttpParser.readRawLine() method below has no guard code against a post without a end-of-line.  A large post of data without \"\\n\" will be read into the ByteArray.  If this post is large enough, it will deplete the system of free memory.  A DOS attack could easily be played out by submitting several of these post at once.   readRawLine should decide that its not reading character data (basically because character data should never show up over something like a megabyte a line) and report an error.  \n\n   /**\n     * Return byte array from an (unchunked) input stream.\n     * Stop reading when <tt>\"\\n\"</tt> terminator encountered \n     * If the stream ends before the line terminator is found,\n     * the last part of the string will still be returned. \n     * If no input data available, <code>null</code> is returned.\n     *\n     * @param inputStream the stream to read from\n     *\n     * @throws IOException if an I/O problem occurs\n     * @return a byte array from the stream\n     */\n    public static byte[] readRawLine(InputStream inputStream) throws IOException {\n        LOG.trace(\"enter HttpParser.readRawLine()\");\n\n        ByteArrayOutputStream buf = new ByteArrayOutputStream();\n        int ch;\n        while ((ch = inputStream.read()) >= 0) {\n            buf.write(ch);\n            if (ch == '\\n') { // be tolerant (RFC-2616 Section 19.3)\n                break;\n            }\n        }\n        if (buf.size() == 0) {\n            return null;\n        }\n        return buf.toByteArray();\n    }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-494",
        "summary": "Invalid redirects are not corrected",
        "description": "If a get is made to a page with a query argument containing a space, many web\nservers, notably including Tomcat 5 can generate a redirect in which the space\nin the query argument is not escaped correctly.  Most browsers including IE and\nFirefox compensate for this by quoting any included spaces in the redirect\nlocation.  Http client does not.  When this broken URL is presented to a\nsubsequent server, the GET command is interprted incorrectly resulting (usually)\nin a 505.\n\nThe fix is to replace spaces in redirect locations with +'s.  This doesn't\nentirely fix the problem but that is the job of the web server developers.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-217",
        "summary": "httpMethod.abort needed",
        "description": "This is the problem : I use the httpclient to fire many requests. At some point \nof time, the server has queued up requests. So certain requests are waiting for \nresponse. Now when I call httpMethod.releaseConnection, the request should stop \nwaiting for the response and the connection should be closed. However, this \ndoes not happen. The request is only given up after it has timed out.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-69",
        "summary": "User/Developer Documentation",
        "description": "- quotes from user's on why they used it.\n- better project docs, including checkstyle and clover reports, and changelog\n- examples showing how to configure logging and why you may want to\n- Links on HttpClient to 'sister' projects such as Slide, Cactus and Latka to\nshow where how it's being used.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-870",
        "summary": "Incorrect Specification-Title headers in MANIFEST.MF",
        "description": "The Specification-Title headers in MANIFEST.MF should all include the full project name, i.e.\n\nApache HttpComponents ...\n\nThe \"HttpComponents\" qualifier is missing; at present the entries are:\n\nSpecification-Title: Apache HttpClient\nSpecification-Title: Apache HttpMime\n\nIf present, Implementation-Title should follow the same convention.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-466",
        "summary": "URI.parseUriReference treats strings with leading ':' as absolute URIs with zero-length scheme",
        "description": "URI.parseUriReference treats strings with leading ':' as absolute URIs with a\nzero-length scheme. If you then try to derelativize such a URI against a base\nURI, you just get the same URI with leading ':'. \n\nIE and Firefox treat URI strings with a leading ':' as relative URIs. For\nexample, an HREF of \":foo\" in the context of base URI\n\"http://www.example.com/path/page\" would derelativize as\n\"http://www.example.com/path/:foo\". (Only if another character comes before the\ncolon is it interpreted as a URI scheme.)\n\nIt'd be desirable for HTTPClient URI to do the same thing.\n\nExample code to demonstrate:\n\nimport org.apache.commons.httpclient.URI;\nURI base = new URI(\"http://www.example.com/path/page\");\nURI rel1 = new URI(\":foo/boo\");\nSystem.out.println((new URI(base,rel1)).toString()); // displays just \":foo\"\n\nA potential fix would be for URI.parseUriReference() to avoid interpreting a ':'\nin the zero position as indicating a zero-length scheme:\n\n-       if (atColon < 0 || (atSlash >= 0 && atSlash < atColon)) {\n+       if (atColon <= 0 || (atSlash >= 0 && atSlash < atColon)) {\n\nand\n\n-        if (at < length && tmp.charAt(at) == ':') {\n+        if (at > 0 && at < length && tmp.charAt(at) == ':') {",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-770",
        "summary": "Code cleanups for Java 1.5 and more.",
        "description": "I can't resist giving code a good cleansing when I start hacking.  Here's some simple things:\n- Use character constants instead of string contstants\n- Use java 1.5 style for loops\n- Use StringBuilder where appropriate\n- Fix javadocs\n- switch somestring.equals(\"\") to .length() == 0\n-  simplify some boolean expressions\n- eliminate redundant initializers\n- fix some html nits\n- remove final keyword from static methods\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-570",
        "summary": "Failed CONNECT leaves connection in an inconsistent state",
        "description": "Opening a HTTPS Connection over an authenticating Proxy (Basic auth. scheme) \nfails, if proxy credentials are not provided at the first try. \n\nThe following example code will fail:\n\nHttpClient client = new HttpClient(new MultiThreadedHttpConnectionManager());\nURL url = new URL(\"https://examplehttpsurl\");\n  \n//first try \nGetMethod get = new GetMethod(url.toExternalForm());\nHostConfiguration hc = new HostConfiguration();\nhc.setHost(url.getHost(), 443, \"https\");\nhc.setProxy(\"proxyhost\", 4711);\n\ntry {\n  client.executeMethod(hc, get);\n} catch (Exception e){\n  LOG.error(\"\",e);\n} finally {\n  get.releaseConnection();\n}\n\n//returns 407 (expected)\nLOG.debug(\"Answer: \" + get.getStatusLine().toString()); \n\n//retry with credentials (normally requested from the user)\nclient.getState().setProxyCredentials(new AuthScope(\"proxyhost\",4711),\n      new NTCredentials(\"USER\", \"PASS\", \"\", \"\"));\n\nget = new GetMethod(url.toExternalForm());\n\ntry {\n  client.executeMethod(hc, get);\n} catch (Exception e) {\n  e.printStackTrace();\n} finally {\n  get.releaseConnection();\n}\n//should be 200 but is 407\nLOG.debug(\"Answer: \" + get.getStatusLine().toString());\n\n\n\n----------\n\n\nFrom what I see from HttpMethodDirector.executeWithRetry(final\nHttpMethod method), the cause is, that the connection is kept open, and\nthus the connect is never retried:\n\n\nif (!this.conn.isOpen()) {\n  // this connection must be opened before it can be used\n  // This has nothing to do with opening a secure tunnel\n  this.conn.open();\n  if (this.conn.isProxied() && this.conn.isSecure() \n      && !(method instanceof ConnectMethod)) {\n    // we need to create a secure tunnel before we can execute the real method\n    if (!executeConnect()) {\n      // abort, the connect method failed\n      return;\n    }\n  }\n}\n\n\nIf I add a conn.close() before returning on !executeConnect(), the\nabove code will work, the CONNECT is reattempted.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-222",
        "summary": "Via NTLM proxy to SSL Apache/BasicAuth. - worked in may 22nd, but broken in beta1",
        "description": "Hi there,\n\nThis morning I downloaded beta 1 and tried a small piece of code to connect to \na SSLified apache server (using basic authentication) via a MS-Proxy 2.0 with \nNTLM enabled. The sourcecode of my crashme is based on the 1st attachment for \nHTTPCLIENT-153. It differs from the original in using basic authentication for the \nwebserver instead of NTLM.\n\nIt failed with this error:\n\n--\n10-jun-2003 16:39:05 org.apache.commons.httpclient.HttpMethodBase \nprocessAuthenticationResponse\nINFO: Already tried to authenticate to \"website#\" but still receiving 407.\nStatus: 407 : Proxy authentication required\n--\n\nThen I downloaded a fresh night build (commons-httpclient-20030605) which also \nfailed :/\n\nThen I went back to an old build from May (commons-httpclient-20030522) which \nworked like a charm!!!\n\nUsing MSIE I can succesfully connect to the apache server. I know it's not a \nproblem with typos because I have MSIE ask me for all creds.\n\nSeems somethings got broken along the way. If I can help, please ask!\n\nCheers.",
        "label": "NUG",
        "classified": "BACKPORT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1142",
        "summary": "Infinite loop on NTLM authentication",
        "description": "I got an infinite loop on NTLM authentication if the authentication failed (bad credentials).\n\nThe state FAILED of the NTLM sheme is never catched in the method authenticate of the class HttpAuthenticator (line 123).\nI fix temporatily this bug by adding a case for the protocol state HANDSHAKE.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-769",
        "summary": "java.lang.IllegalStateException: Connection already open.",
        "description": "I am seeing many of the same problems noted in HTTPCLIENT-741 using the latest builds from the maven repo.\n\njava.lang.IllegalStateException: Connection already open.\n        at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:150)\n        at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119)\n        at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:308)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:501)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:456)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:422)\n        at com.hi5.os.Hi5RemoteContentFetcher.fetch(Hi5RemoteContentFetcher.java:279)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-573",
        "summary": "Disallow the use of SecureProtocolSocketFactory with ProxyClient",
        "description": "ProxyClient cannot work correctly if SecureProtocolSocketFactory socket factory\nis being used to establish connection with the target server",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-654",
        "summary": "Cookie class cannot handle IPv6 literals",
        "description": "When performing requests using IPv6 literals, Cookie.setDomain() will attempt to trim the port number by cutting off the domain string at the first colon. This leads to MalformedCookieExceptions being thrown by CookieSpecBase later on.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-350",
        "summary": "HttpState#matchCredentials is broken",
        "description": "Credentials matching algorithm is flawed, generates unnecessary garbage by\ninstantiating intermediate object during lookup",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-265",
        "summary": "Error releasing chunked connections with no response body.",
        "description": "HttpMethodBase.releaseConnection() does not successfully release the connection\nif closing the response stream throws an exception.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-161",
        "summary": "MultipartPostMethod Holding File Stream Open?",
        "description": "From: \"Daniel Walsh\" <daniel.walsh13@verizon.net>\nDate: Tue Feb 25, 2003  8:05:49 PM US/Eastern\nTo: \"Commons HttpClient Project\" <commons-httpclient-dev@jakarta.apache.org>\nSubject: MultipartPostMethod Holding File Stream Open?\nReply-To: \"Commons HttpClient Project\" <commons-httpclient-dev@jakarta.apache.org>\n\nI'm using a MultipartPostMethod to upload a file to a servlet:\n\nFile file = new File(strUrl);\n\nHttpClient client = new HttpClient();\nHostConfiguration hostConfig = new HostConfiguration();\nMultipartPostMethod mpPost = new MultipartPostMethod();\n\n hostConfig.setHost(someURL.getHost(), someURL.getPort(), someURL.getProtocol());\nclient.setConnectionTimeout(30000);\nclient.setHostConfiguration(hostConfig);\n\nmpPost.addParameter(\"someName\", \"someValue\");\nmpPost.addParameter(file.getName(), file);\n\nmpPost.setPath(strPath);\nclient.executeMethod(mpPost);\n\nString confirmUpload = tpPost.getResponseBodyAsString();\nmpPost.releaseConnection();\n\nfile.delete();  // this is being blocked.\n\nAfter the upload, I would like to delete the file off of my disk.  Using other\nmethods of uploading the file (in particular a PutMethod), I was able to then\ndelete the file after the upload.  Now that I am using the MultipartPostMethod\nobj for the upload, I am unable to delete the file (the return value is false,\nand there is no SecurityException being thrown - no SecurityManager even set as\nof this point either).\n\nSo, I guess my question is whether there is a call to the MultipartPostMethod\nobj that I'm overlooking that would release it's connection (I'm sure that it is\nopening an InputStream of some sort to read the file contents, in order to form\nthe HTTP message) to the file - so that I can then have unimpeded access to it\nfor other operations?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-856",
        "summary": "Proxy NTLM Authentication  Redirecting to different address fails saying Proxy Auth Required.",
        "description": "The issue has been discussed in,\nhttp://www.nabble.com/redirect-fails-when-NTLM-authentication-is-used-for-proxy-tt23867531.html\n\nThis was found in http client 3.1 release,  where NTLM proxy authentication is must and the server ask the redirect to a new url, in this case, when redirecting, the earlier proxy auth status is not cleared, so, it does not do proxy authentication for the new URL and hence fails.\n\nTarget Host Authenticaiton NTLM authentication - redirect also had problem and fixed as said,\nhttp://issues.apache.org/jira/browse/HTTPCLIENT-211\nProxy Authentication - redirect has to be fixed, \n\nThe wire logs for the release https://repository.apache.org/content/repositories/snapshots/org/apache/httpcomponents/httpclient/4.0-beta3-SNAPSHOT/\nis given below,\n\n[DEBUG] wire - >> \"GET http://verisign.com HTTP/1.1[EOL]\"\n[DEBUG] wire - >> \"Host: verisign.com[EOL]\"\n[DEBUG] wire - >> \"Proxy-Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - >> \"User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]\"\n[DEBUG] wire - >> \"[EOL]\"\n[DEBUG] wire - << \"HTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )[EOL]\"\n[DEBUG] wire - << \"Via: 1.1 lab1[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: Negotiate[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: Kerberos[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: NTLM[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: Basic realm=\"lab1.\"[EOL]\"\n[DEBUG] wire - << \"Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - << \"Proxy-Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - << \"Pragma: no-cache[EOL]\"\n[DEBUG] wire - << \"Cache-Control: no-cache[EOL]\"\n[DEBUG] wire - << \"Content-Type: text/html[EOL]\"\n[DEBUG] wire - << \"Content-Length: 4107  [EOL]\"\n[DEBUG] wire - << \"[EOL]\"\n[DEBUG] wire - << \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">[\\r][\\n]\"\n[DEBUG] wire - << \"<HTML><HEAD><TITLE>Error Message</TITLE>[\\r][\\n]\"\n[DEBUG] wire - << \"<META http-equiv=Content-Type content=\"text/html; charset=UTF-8\">[\\r][\\n]\"\n[DEBUG] wire - << \"<STYLE id=L_default_1>A {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]FONT-WEIGHT: bold; FONT-SIZE: 10pt; COLOR: #005a80; FONT-FAMILY: tahoma[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \"A:hover {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]FONT-WEIGHT: bold; FONT-SIZE: 10pt; COLOR: #0d3372; FONT-FAMILY: tahoma[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \"TD {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]FONT-SIZE: 8pt; FONT-FAMILY: tahoma[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \"TD.titleBorder {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]BORDER-RIGHT: #955319 1px solid; BORDER-TOP: #955319 1px solid; PADDING-LEFT: 8px; FONT-WEIGHT: bold; FONT-SIZE: 12pt; VERTICAL-ALIGN: middle; BORDER-LEFT: #955319 0px solid; COLOR: #955319; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: tahoma; HEIGHT: 35px; BACKGROUND-COLOR: #d2b87a; TEXT-ALIGN: left[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \"TD.titleBorder_x {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]BORDER-RIGHT: #955319 0px solid; BORDER-TOP: #955319 1px solid; PADDING-LEFT: 8px; FONT-WEIGHT: bold; FONT-SIZE: 12pt; VERTICAL-ALIGN: middle; BORDER-LEFT: #955319 1px solid; COLOR: #978c79; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: tahoma; HEIGHT: 35px; BACKGROUND-COLOR: #d2b87a; TEXT-ALIGN: left[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \".TitleDescription {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]FONT-WEIGHT: bold; FONT-SIZE: 12pt; COLOR: black; FONT-FAMILY: tahoma[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \"SPAN.explain {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]FONT-WEIGHT: normal; FONT-SIZE: 10pt; COLOR: #934225[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \"SPAN.TryThings {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]FONT-WEIGHT: normal; FONT-SIZE: 10pt; COLOR: #934225[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \".TryList {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]MARGIN-TOP: 5px; FONT-WEIGHT: normal; FONT-SIZE: 8pt; COLOR: black; FONT-FAMILY: tahoma[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \".X {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]BORDER-RIGHT: #955319 1px solid; BORDER-TOP: #955319 1px solid; FONT-WEIGHT: normal; FONT-SIZE: 12pt; BORDER-LEFT: #955319 1px solid; COLOR: #7b3807; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: verdana; BACKGROUND-COLOR: #d1c2b4[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \".adminList {[\\r][\\n]\"\n[DEBUG] wire - << \"[0x9]MARGIN-TOP: 2px[\\r][\\n]\"\n[DEBUG] wire - << \"}[\\r][\\n]\"\n[DEBUG] wire - << \"</STYLE>[\\r][\\n]\"\n[DEBUG] wire - << \"<META content=\"MSHTML 6.00.2800.1170\" name=GENERATOR></HEAD>[\\r][\\n]\"\n[DEBUG] wire - << \"<BODY bgColor=#f3f3ed>[\\r][\\n]\"\n[DEBUG] wire - << \"<TABLE cellSpacing=0 cellPadding=0 width=\"100%\">[\\r][\\n]\"\n[DEBUG] wire - << \"  <TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"  <TR>[\\r][\\n]\"\n[DEBUG] wire - << \"    <TD class=titleborder_x width=30>[\\r][\\n]\"\n[DEBUG] wire - << \"      <TABLE height=25 cellSpacing=2 cellPadding=0 width=25 bgColor=black>[\\r][\\n]\"\n[DEBUG] wire - << \"        <TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"        <TR>[\\r][\\n]\"\n[DEBUG] wire - << \"          <TD class=x vAlign=center alig\"\n[DEBUG] wire - << \"n=middle>X</TD>[\\r][\\n]\"\n[DEBUG] wire - << \"        </TR>[\\r][\\n]\"\n[DEBUG] wire - << \"        </TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"      </TABLE>[\\r][\\n]\"\n[DEBUG] wire - << \"    </TD>[\\r][\\n]\"\n[DEBUG] wire - << \"    <TD class=titleBorder id=L_default_2>Network Access Message:<SPAN class=TitleDescription> The page cannot be displayed</SPAN> </TD>[\\r][\\n]\"\n[DEBUG] wire - << \"  </TR>[\\r][\\n]\"\n[DEBUG] wire - << \"  </TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"</TABLE>[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] wire - << \"<TABLE id=spacer>[\\r][\\n]\"\n[DEBUG] wire - << \"  <TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"  <TR>[\\r][\\n]\"\n[DEBUG] wire - << \"    <TD height=10></TD></TR></TBODY></TABLE>[\\r][\\n]\"\n[DEBUG] wire - << \"<TABLE width=400>[\\r][\\n]\"\n[DEBUG] wire - << \"  <TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"  <TR>[\\r][\\n]\"\n[DEBUG] wire - << \"    <TD noWrap width=25></TD>[\\r][\\n]\"\n[DEBUG] wire - << \"    <TD width=400><SPAN class=explain><ID id=L_default_3><B>Explanation:</B></ID></SPAN><ID id=L_default_4> There is a problem with the page you are trying to reach and it cannot be displayed. </ID><BR><BR>[\\r][\\n]\"\n[DEBUG] wire - << \"    <B><SPAN class=tryThings><ID id=L_default_5><B>Try the following:</B></ID></SPAN></B> [\\r][\\n]\"\n[DEBUG] wire - << \"      <UL class=TryList>[\\r][\\n]\"\n[DEBUG] wire - << \"        <LI id=L_default_6><B>Refresh page:</B> Search for the page again by clicking the Refresh button. The timeout may have occurred due to Internet congestion.[\\r][\\n]\"\n[DEBUG] wire - << \"<LI id=L_default_7><B>Check spelling:</B> Check that you typed the Web page address correctly. The address may have been mistyped.[\\r][\\n]\"\n[DEBUG] wire - << \"<LI id=L_default_8><B>Access from a link:</B> If there is a link to the page you are looking for, try accessing the page from that link.[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] wire - << \"      </UL>[\\r][\\n]\"\n[DEBUG] wire - << \"<ID id=L_default_9>If you are still not able to view the requested page, try contacting your administrator or Helpdesk.</ID> <BR><BR>[\\r][\\n]\"\n[DEBUG] wire - << \"    </TD>[\\r][\\n]\"\n[DEBUG] wire - << \"  </TR>[\\r][\\n]\"\n[DEBUG] wire - << \"  </TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"</TABLE>[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] wire - << \"<TABLE id=spacer><TBODY><TR><TD height=15></TD></TR></TBODY></TABLE>[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] wire - << \"<TABLE width=400>[\\r][\\n]\"\n[DEBUG] wire - << \"  <TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"  <TR>[\\r][\\n]\"\n[DEBUG] wire - << \"    <TD noWrap width=25></TD>[\\r][\\n]\"\n[DEBUG] wire - << \"    <TD width=400 id=L_default_10><B>Technical Information (for support personnel)</B> [\\r][\\n]\"\n[DEBUG] wire - << \"      <UL class=adminList>[\\r][\\n]\"\n[DEBUG] wire - << \"        <LI id=L_default_11>Error Code: 407 Proxy Authentication Required. The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied. (12209)[\\r][\\n]\"\n[DEBUG] wire - << \"<LI id=L_default_12>IP Address: x.x.x.x[\\r][\\n]\"\n[DEBUG] wire - << \"<LI id=L_default_13>Date: 6/29/2009 11:15:15 AM [GMT][\\r][\\n]\"\n[DEBUG] wire - << \"<LI id=L_default_14>Server: lab1[\\r][\\n]\"\n[DEBUG] wire - << \"<LI id=L_default_15>Source: proxy[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] wire - << \"      </UL>[\\r][\\n]\"\n[DEBUG] wire - << \"    </TD>[\\r][\\n]\"\n[DEBUG] wire - << \"  </TR>[\\r][\\n]\"\n[DEBUG] wire - << \"  </TBODY>[\\r][\\n]\"\n[DEBUG] wire - << \"</TABLE>[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] wire - << \"</BODY>[\\r][\\n]\"\n[DEBUG] wire - << \"</HTML>[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] wire - >> \"GET http://verisign.com HTTP/1.1[EOL]\"\n[DEBUG] wire - >> \"Host: verisign.com[EOL]\"\n[DEBUG] wire - >> \"Proxy-Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - >> \"User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]\"\n[DEBUG] wire - >> \"Proxy-Authorization: NTLM TlRMTVNTUAABAAAAATIAAAgACAAgAAAADgAOACgAAABNWURPTUFJTkpDSUZTMjMwXzg2Xzkx[EOL]\"\n[DEBUG] wire - >> \"[EOL]\"\n[DEBUG] wire - << \"HTTP/1.1 407 Proxy Authentication Required ( Access is denied.  )[EOL]\"\n[DEBUG] wire - << \"Via: 1.1 lab1[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: NTLM TlRMTVNTUAACAAAAAAAAADgAAAABAgACqbXrIWnZ3i4AAAAAAAAAAAAAAAA4AAAABQLODgAAAA8=[EOL]\"\n[DEBUG] wire - << \"Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - << \"Proxy-Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - << \"Pragma: no-cache[EOL]\"\n[DEBUG] wire - << \"Cache-Control: no-cache[EOL]\"\n[DEBUG] wire - << \"Content-Type: text/html[EOL]\"\n[DEBUG] wire - << \"Content-Length: 0     [EOL]\"\n[DEBUG] wire - << \"[EOL]\"\n[DEBUG] wire - >> \"GET http://verisign.com HTTP/1.1[EOL]\"\n[DEBUG] wire - >> \"Host: verisign.com[EOL]\"\n[DEBUG] wire - >> \"Proxy-Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - >> \"User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]\"\n[DEBUG] wire - >> \"Proxy-Authorization: NTLM TlRMTVNTUAADAAAAGAAYAEAAAAAwADAAWAAAABAAEACIAAAAGgAaAJgAAAAcABwAsgAAAAAAAAAAAAAAAQIAAAXLpW40q7jqh7E6FgFnJqy9529ANaSLqfTiwjyF2BrUP9F8ObYOyYsBAQAAAAAAACDgxRg9+skBRt4mUOFFCs0AAAAAAAAAAE0AWQBEAE8ATQBBAEkATgBBAGQAbQBpAG4AaQBzAHQAcgBhAHQAbwByAEoAQwBJAEYAUwAyADMAMABfADgANgBfADkAMQA=[EOL]\"\n[DEBUG] wire - >> \"[EOL]\"\n[DEBUG] wire - << \"HTTP/1.1 301 Unknown reason[EOL]\"\n[DEBUG] wire - << \"Via: 1.1 lab1[EOL]\"\n[DEBUG] wire - << \"Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - << \"Proxy-Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - << \"Content-length: 0[EOL]\"\n[DEBUG] wire - << \"Date: Mon, 29 Jun 2009 11:16:50 GMT[EOL]\"\n[DEBUG] wire - << \"Location: http://www.verisign.com/[EOL]\"\n[DEBUG] wire - << \"Content-type: text/html[EOL]\"\n[DEBUG] wire - << \"Server: Netscape-Enterprise/4.1[EOL]\"\n[DEBUG] wire - << \"[EOL]\"\n[ERROR] RequestProxyAuthentication - Proxy authentication error: Unexpected state: MSG_TYPE3_GENERATED\n[DEBUG] wire - >> \"GET http://www.verisign.com/ HTTP/1.1[EOL]\"\n[DEBUG] wire - >> \"Host: www.verisign.com[EOL]\"\n[DEBUG] wire - >> \"Proxy-Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - >> \"User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]\"\n[DEBUG] wire - >> \"[EOL]\"\n[DEBUG] wire - << \"HTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )[EOL]\"\n[DEBUG] wire - << \"Via: 1.1 lab1[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: Negotiate[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: Kerberos[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: NTLM[EOL]\"\n[DEBUG] wire - << \"Proxy-Authenticate: Basic realm=\"lab1.\"[EOL]\"\n[DEBUG] wire - << \"Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - << \"Proxy-Connection: Keep-Alive[EOL]\"\n[DEBUG] wire - << \"Pragma: no-cache[EOL]\"\n[DEBUG] wire - << \"Cache-Control: no-cache[EOL]\"\n[DEBUG] wire - << \"Content-Type: text/html[EOL]\"\n[DEBUG] wire - << \"Content-Length: 4107  [EOL]\"\n[DEBUG] wire - << \"[EOL]\"\n----------------------------------------\nHTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )\n\nThanks,\nRaj\n\n\n\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-45",
        "summary": "HTTP Version configuration and tracking",
        "description": "HTTP version tracking is currently oversimplified with a single http11 boolean. \nExtend this to handle any http version simply, and efficiently.\n\nPossible suggestion:\n> get rid of setHttp11() an isHttp11\n> void setHttpVersion(String version)\n> String getHttpVersion()\n> boolean isHttpVersion(String version)",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-768",
        "summary": "Publish source/javadoc jar files to the Maven repository",
        "description": "It would be really nice if HttpComponents (Core and Client) published jar files to the Maven repository for not just the bytecode, but also for the source and javadoc (done by defining a \"classifier\" attribute of \"javadoc\" or \"source\" for the jar when publishing with Maven).\n\nHaving these in the Maven repo allows an IDE (like Eclipse) to auto-download and attach the source/javadoc to the HttpComponent jar files - meaning developers will then see the API documentation automatically in their IDE.  This also greatly aids debugging if one needs to step through HttpComponent code, and placing the source in the hands of more developers also means you might see more patches coming back.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-1154",
        "summary": "org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage should allow client to specify custom prefix string for keys",
        "description": "org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage should allow client to specify custom prefix string for keys, so as to ensure collision-avoidance with other memcached keys the client may be using.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1157",
        "summary": "MemcachedHttpCacheStorage should throw IOExceptions instead of Runtime Exceptions",
        "description": "The MemcachedHttpCacheStorage class implements HttpCacheStorage which defines that methods will throw IOExceptions, but the underlying net.spy.memcached.MemcachedClientIF throws runtime exceptions. These exceptions are not caught in the code where IOExceptions are expected causing these exception bubble up to the calling code. It seems like the MemcachedHttpCacheStorage class should treat at least some of these runtime exceptions as IOExceptions so that normal code execution paths can be followed.  \n\nI'm proposing that MemcachedHttpCacheStorage treat a OperationTimeoutException from the memcached client as an IOException. This would allow the existing CachingHttpClient code to catch and log the exception as a warning, instead of bubbling the exception up the calling code.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-142",
        "summary": "Test case failure for testConnTimeout",
        "description": "[java] There was 1 failure:\n     [java] 1)\ntestConnTimeout(org.apache.commons.httpclient.TestHttpConnection)junit.framework.AssertionFailedError:\nShould have timed out\n     [java]     at\norg.apache.commons.httpclient.TestHttpConnection.testConnTimeout(TestHttpConnection.java:118)\n     [java]     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n     [java]     at\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n     [java]     at\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\nThis test has been failing for some time.  It is run with the test-local ant target.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-561",
        "summary": "entity returns the same stream for getContent()",
        "description": "BasicHttpEntity and GzipDecompressingEntity will return the same stream\nwhen getContent() is called multiple times. That is not allowed by the\nHttpEntity interface. They should rather throw an IllegalStateException.\n\nSome tests and EntityUtils rely on getContent to return the same stream\nfor multiple calls.\n\npatch follows,\n  Roland",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-884",
        "summary": "Charset omitted from UrlEncodedFormEntity Content-Type header",
        "description": "UrlEncodedFormEntity sets the Content-Type header to:\n   \"application/x-www-form-urlencoded\"\n\nIt should set the header to:\n   \"application/x-www-form-urlencoded; charset=\" + charset\n\nAs a result, content can be misinterpreted by the recipient (e.g. if the entity content includes multibyte Unicode characters encoded with the \"UTF-8\" charset).\n\nFor a correct example of specifying the charset in the Content-Type header, see StringEntity.java.\n\nHere's the fix:\n\n    public UrlEncodedFormEntity (\n        final List <? extends NameValuePair> parameters, \n        final String encoding) throws UnsupportedEncodingException {\n        super(URLEncodedUtils.format(parameters, encoding),  encoding);\n-        setContentType(URLEncodedUtils.CONTENT_TYPE);\n+        setContentType(URLEncodedUtils.CONTENT_TYPE + HTTP.CHARSET_PARAM +\n+            (encoding != null ? encoding : HTTP.DEFAULT_CONTENT_CHARSET));\n    }\n\n    public UrlEncodedFormEntity (\n        final List <? extends NameValuePair> parameters) throws UnsupportedEncodingException {\n-        super(URLEncodedUtils.format(parameters, HTTP.DEFAULT_CONTENT_CHARSET), \n-            HTTP.DEFAULT_CONTENT_CHARSET);\n-        setContentType(URLEncodedUtils.CONTENT_TYPE);\n+        this(parameters, HTTP.DEFAULT_CONTENT_CHARSET);\n    }\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-401",
        "summary": "HttpState should have methods for clearing all cookies and credentials",
        "description": " ",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-44",
        "summary": "Non-standards configuration and tracking",
        "description": "A simple strict or setLenient is likely inadequate.  Each particular\nnon-standard behaviour should be tagged, and settable from the client.  A mask\nfor particular behavioural features could be provided, with STRICT meaning none\nand LENIENT meaning all.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-775",
        "summary": "download section of website down",
        "description": "maybe you know this, but http://hc.apache.org/downloads.cgi (the downloads for httpcomponents and for httpclient) is broken (500 internal server error)...",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1155",
        "summary": "CachingHttpClient should have similar behavior as AbstractHttpClient when executing with ResponseHandler",
        "description": "When calling execute on the AbstractHttpClient with a  ResponseHandler, the AbstractHttpClient will attempt to Consume the Entity and close any open connections before returning. This behavior is not currently in the CachingHttpClient. \n\nThis can lead to connection leaks when switching to CachingHttpClient, becuase the responsibility to fully consume the entity is now on the ResponseHandler instead on the HttpClient.\n\nHere is the code that does the existing 'auto-close' behavior: \"org.apache.http.impl.client.AbstractHttpClient.java\" lines 1080-1111",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-424",
        "summary": "setAuthPreemptive restricted to BASIC AuthScheme",
        "description": "Pre-emptive authentication is hardcoded to be restricted to the BASIC\nauthentication scheme.  To fully support custom authentication schemes,\npre-emptive authentication should be made configurable, either globally, or on a\nper-scheme basis.  A potential compromise may be to require AuthSchemes to\nreport whether they support pre-emptive capability if we wish to explicitly\nexclude certain schemes from pre-emptive authentication.\n\n(reported against 3.0 RC 1)",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1147",
        "summary": "When HttpClient-Cache cannot open cache file, should act like miss",
        "description": "Set up HttpClient-Cache like this:\nfinal String cacheDir = \"cachedir\";\nHttpClient cachingHttpClient;\nfinal CacheConfig cacheConfig = new CacheConfig();\ncacheConfig.setSharedCache(false);\ncacheConfig.setMaxObjectSizeBytes(262144); //256kb\n\nif(! new File(cacheDir, \"httpclient-cache\").exists()){\n\tif(!new File(cacheDir, \"httpclient-cache\").mkdir()){\n\t\tthrow new RuntimeException(\"failed to create httpclient cache directory: \" + new File(cacheDir, \"httpclient-cache\").getAbsolutePath());\n\t}\n}\nfinal ResourceFactory resourceFactory = new FileResourceFactory(new File(cacheDir, \"httpclient-cache\"));\n\nfinal HttpCacheStorage httpCacheStorage = new ManagedHttpCacheStorage(cacheConfig);\n\ncachingHttpClient = new CachingHttpClient(client, resourceFactory, httpCacheStorage, cacheConfig);\n\nThen make a request:\nfinal HttpGet get = new HttpGet(url);\nfinal HttpResponse response = cachingHttpClient.execute(get);\nfinal StatusLine statusLine = response.getStatusLine();\nif (statusLine.getStatusCode() >= 300) {\n\tif(statusLine.getStatusCode() == 404)\n\t\tthrow new NoResultException();\n    throw new HttpResponseException(statusLine.getStatusCode(),\n            statusLine.getReasonPhrase());\n}\nresponse.getEntity().getContent();\n\nEverything worked as expected.\n\nNow delete the cache directory (\"cachedir/httpclient-cache\" in this example).\n\nAnd make the same request again.\n\nActual:\n Caused by: java.lang.IllegalStateException: Content has been consumed\n\tat org.apache.http.entity.BasicHttpEntity.getContent(BasicHttpEntity.java:84)\n\tat org.apache.http.conn.BasicManagedEntity.getContent(BasicManagedEntity.java:100)\n\nExpected:\nHttpClient shouldn't throw an exception - it should just perform the request again acting like a cache miss.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-118",
        "summary": "Build with JDK 1.4, get many javadoc warnings",
        "description": "Building httpclient \"dist\" ant target, I get lots of \"warning - The first\nsentence is interpreted to be:\".\n\nAs the summary says, I get these warnings when I build using JDK 1.4.  Using JDK\n1.3.1 yields far fewer problems.  I see this with the latest sources as of this\nposting.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-892",
        "summary": "Links in Section \"Example Code\" are broken",
        "description": "Steps to Reproduce: Go to http://hc.apache.org/user-docs.html\nClick of one of the Links in the Section \"Example Code\"",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-460",
        "summary": "Windows specific implementation of the Digest auth scheme",
        "description": "Microsoft Windows 2003 implementation of digest auth scheme is essentially a\nsuperset of RFC 2617 with Windows specific aspects:\nhttp://www.microsoft.com/technet/prodtechnol/windowsserver2003/library/TechRef/717b450c-f4a0-4cc9-86f4-cc0633aae5f9.mspx\n\nProvide a super class of DigestScheme with Windows 2003 specific extensions,\nwhich can be plugged in instead of the standard Digest impl\n\nFor details see PR #34909",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1180",
        "summary": "NullPointerException when using HttpHead and Request/Response interceptors",
        "description": "When you try to execute a HttpHead object instead of a HttpGet object while using the add request/response interceptors, you get a nullpointerexception.\n\nI can replicate the exception when using the ClientGZipContentCompression example that can be found at the HttpClient examples. But instead of using the HttpGet object I execute a HttpHead object. When I comment the interceptor parts out, I don't get the exception. \n\nThis is the error stack trace I get when executing the code in netbeans:\n\nException in thread \"main\" java.lang.NullPointerException\n\tat testhttphead.ClientGZipContentCompression$2.process(ClientGZipContentCompression.java:74)\n\tat org.apache.http.protocol.ImmutableHttpProcessor.process(ImmutableHttpProcessor.java:116)\n\tat org.apache.http.protocol.HttpRequestExecutor.postProcess(HttpRequestExecutor.java:342)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:472)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:820)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:754)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:732)\n\tat testhttphead.ClientGZipContentCompression.main(ClientGZipContentCompression.java:92)\nJava Result: 1\n\nHere is the code that gives me the error:\n\npackage testhttphead;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.zip.GZIPInputStream;\nimport org.apache.http.*;\nimport org.apache.http.client.methods.HttpHead;\nimport org.apache.http.entity.HttpEntityWrapper;\nimport org.apache.http.impl.client.DefaultHttpClient;\nimport org.apache.http.protocol.HttpContext;\nimport org.apache.http.util.EntityUtils;\n\n/**\n * Demonstration of the use of protocol interceptors to transparently modify\n * properties of HTTP messages sent / received by the HTTP client.\n * <p/>\n * In this particular case HTTP client is made capable of transparent content\n * GZIP compression by adding two protocol interceptors: a request interceptor\n * that adds 'Accept-Encoding: gzip' header to all outgoing requests and a\n * response interceptor that automatically expands compressed response entities\n * by wrapping them with a uncompressing decorator class. The use of protocol\n * interceptors makes content compression completely transparent to the consumer\n * of the {@link org.apache.http.client.HttpClient HttpClient} interface.\n */\npublic class ClientGZipContentCompression {\n\n    public final static void main(String[] args) throws Exception {\n        DefaultHttpClient httpclient = new DefaultHttpClient();\n\n        try {\n            httpclient.addRequestInterceptor(new HttpRequestInterceptor() {\n\n                public void process(\n                        final HttpRequest request,\n                        final HttpContext context) throws HttpException, IOException {\n                    if (!request.containsHeader(\"Accept-Encoding\")) {\n                        request.addHeader(\"Accept-Encoding\", \"gzip\");\n                    }\n                }\n            });\n\n            httpclient.addResponseInterceptor(new HttpResponseInterceptor() {\n\n                public void process(\n                        final HttpResponse response,\n                        final HttpContext context) throws HttpException, IOException {\n                    HttpEntity entity = response.getEntity();\n                    Header ceheader = entity.getContentEncoding();\n                    if (ceheader != null) {\n                        HeaderElement[] codecs = ceheader.getElements();\n                        for (int i = 0; i < codecs.length; i++) {\n                            if (codecs[i].getName().equalsIgnoreCase(\"gzip\")) {\n                                response.setEntity(\n                                        new GzipDecompressingEntity(response.getEntity()));\n                                return;\n                            }\n                        }\n                    }\n                }\n            });\n\n            HttpHead httpHead = new HttpHead(\"http://www.howest.be\");\n\n            // Execute HTTP request\n            System.out.println(\"executing request \" + httpHead.getURI());\n            HttpResponse response = httpclient.execute(httpHead);\n\n            System.out.println(\"----------------------------------------\");\n            System.out.println(response.getStatusLine());\n            System.out.println(response.getLastHeader(\"Content-Encoding\"));\n            System.out.println(response.getLastHeader(\"Content-Length\"));\n            System.out.println(\"----------------------------------------\");\n\n            HttpEntity entity = response.getEntity();\n\n            if (entity != null) {\n                String content = EntityUtils.toString(entity);\n                System.out.println(content);\n                System.out.println(\"----------------------------------------\");\n                System.out.println(\"Uncompressed size: \" + content.length());\n            }\n\n        } finally {\n            // When HttpClient instance is no longer needed,\n            // shut down the connection manager to ensure\n            // immediate deallocation of all system resources\n            httpclient.getConnectionManager().shutdown();\n        }\n    }\n\n    static class GzipDecompressingEntity extends HttpEntityWrapper {\n\n        public GzipDecompressingEntity(final HttpEntity entity) {\n            super(entity);\n        }\n\n        @Override\n        public InputStream getContent()\n                throws IOException, IllegalStateException {\n\n            // the wrapped entity's getContent() decides about repeatability\n            InputStream wrappedin = wrappedEntity.getContent();\n\n            return new GZIPInputStream(wrappedin);\n        }\n\n        @Override\n        public long getContentLength() {\n            // length of ungzipped content is not known\n            return -1;\n        }\n    }\n}\n\nWith kind regards,\n\nPeter",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1008",
        "summary": "Send all variants' ETags on \"variant miss\"",
        "description": "From section 13.6 of RFC 2616:\n\nIf an entity tag was assigned to a cached representation, the forwarded request SHOULD be conditional and include the entity tags in an If-None-Match header field from all its cache entries for the resource. This conveys to the server the set of entities currently held by the cache, so that if any one of these entities matches the requested entity, the server can use the ETag header field in its 304 (Not Modified) response to tell the cache which entry is appropriate. If the entity-tag of the new response matches that of an existing entry, the new response SHOULD be used to update the header fields of the existing entry, and the result MUST be returned to the client.\n\nPresently, we simply forward the request to the request without the conditionals.  This improvement would consist of adding the conditionals to the request, and properly handling the response.  An example of such would be the following:\n\n - request resource with \"Accept-Encoding: gzip\", response has \"Etag: etag1\", \"Vary: Accept-Encoding\"\n - request resource with \"Accept-Encoding: deflate\", request is forwarded with \"If-None-Match: etag1\" added, response is 200, with \"ETag: etag2\"\n - request resource with \"Accept-Encoding: gzip, deflate\", request is forwarded with \"If-None-Match: etag1, etag2\" added, response is 304, with \"ETag: etag1\" indicating we should use the first response for this request",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-505",
        "summary": "cipher",
        "description": " ",
        "label": "NUG",
        "classified": "UNKNOWN",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-228",
        "summary": "Request with DIGEST authentication fails when redirected",
        "description": "Request with DIGEST authentication fails when redirected due to invalid URI\nparameter.\n\n-- Client side log ----------------------------------------------------------\n\n[DEBUG] HttpClient - -Java version: 1.2.2\n[DEBUG] HttpClient - -Java vendor: Sun Microsystems Inc.\n[DEBUG] HttpClient - -Operating system name: Linux\n[DEBUG] HttpClient - -Operating system architecture: i386\n[DEBUG] HttpClient - -Operating system version: 2.4.20-13.9-ok\n[DEBUG] HttpClient - -SUN 1.2: SUN (DSA key/parameter generation; DSA signing;\nSHA-1, MD5 digests; SecureRandom; X.509 certificates; JKS keystore)\n[DEBUG] HttpClient - -SunJSSE 1.0301: Sun JSSE provider(implements RSA\nSignatures, PKCS12, SunX509 key/trust factories, SSLv3, TLSv1)\n[DEBUG] HttpConnection - -Creating connection for localhost using protocol http:80\n[DEBUG] HttpConnection - -HttpConnection.setSoTimeout(0)\n[DEBUG] HttpMethod - -Execute loop try 1\n[DEBUG] wire - ->> \"GET /transfer HTTP/1.1[\\r][\\n]\"\n[DEBUG] HttpMethod - -Adding Host request header\n[DEBUG] wire - ->> \"User-Agent: Jakarta Commons-HttpClient/2.0beta1[\\r][\\n]\"\n[DEBUG] wire - ->> \"Host: localhost[\\r][\\n]\"\n[DEBUG] wire - ->> \"[\\r][\\n]\"\n[DEBUG] wire - -<< \"HTTP/1.1 401 Authorization Required[\\r][\\n]\"\n[DEBUG] wire - -<< \"Date: Fri, 20 Jun 2003 08:30:06 GMT[\\r][\\n]\"\n[DEBUG] wire - -<< \"Server: Apache/2.0.40 (Red Hat Linux)[\\r][\\n]\"\n[DEBUG] wire - -<< \"WWW-Authenticate: Digest realm=\"guest realm\",\nnonce=\"ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a\", algorithm=MD5,\ndomain=\"/transfer\", qop=\"auth\"[\\r][\\n]\"\n[DEBUG] wire - -<< \"Vary: accept-language[\\r][\\n]\"\n[DEBUG] wire - -<< \"Accept-Ranges: bytes[\\r][\\n]\"\n[DEBUG] wire - -<< \"Content-Length: 1285[\\r][\\n]\"\n[DEBUG] wire - -<< \"Content-Type: text/html; charset=ISO-8859-1[\\r][\\n]\"\n[DEBUG] HttpMethod - -Authorization required\n[DEBUG] HttpAuthenticator - -Using 'guest realm' authentication realm\n[DEBUG] HttpMethod - -HttpMethodBase.execute(): Server demanded authentication\ncredentials, will try again.\n...\n[DEBUG] HttpMethod - -Resorting to protocol version default close connection policy\n[DEBUG] HttpMethod - -Should NOT close connection, using HTTP/1.1.\n[DEBUG] HttpMethod - -Execute loop try 2\n[DEBUG] wire - ->> \"GET /transfer HTTP/1.1[\\r][\\n]\"\n[DEBUG] HttpMethod - -Request to add Host header ignored: header already added\n[DEBUG] wire - ->> \"User-Agent: Jakarta Commons-HttpClient/2.0beta1[\\r][\\n]\"\n[DEBUG] wire - ->> \"Host: localhost[\\r][\\n]\"\n[DEBUG] wire - ->> \"Authorization: Digest username=\"guest\", realm=\"guest realm\",\nnonce=\"ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a\", uri=\"/transfer\",\nqop=\"auth\", algorithm=\"MD5\", nc=00000001,\ncnonce=\"81d4b905a4e9def944beaed8daf79283\",\nresponse=\"71394edcddf4bcee6237ea4bb50cfaa5\"[\\r][\\n]\"\n[DEBUG] wire - ->> \"[\\r][\\n]\"\n[DEBUG] wire - -<< \"HTTP/1.1 301 Moved Permanently[\\r][\\n]\"\n[DEBUG] wire - -<< \"Date: Fri, 20 Jun 2003 08:30:06 GMT[\\r][\\n]\"\n[DEBUG] wire - -<< \"Server: Apache/2.0.40 (Red Hat Linux)[\\r][\\n]\"\n[DEBUG] wire - -<< \"Location: http://localhost/transfer/[\\r][\\n]\"\n[DEBUG] wire - -<< \"Content-Length: 302[\\r][\\n]\"\n[DEBUG] wire - -<< \"Content-Type: text/html; charset=iso-8859-1[\\r][\\n]\"\n[DEBUG] HttpMethod - -Redirect required\n[DEBUG] HttpMethod - -Redirect requested to location 'http://localhost/transfer/'\n[DEBUG] HttpMethod - -Redirecting from 'http://localhost:80/transfer' to\n'http://localhost/transfer/\n...\n[DEBUG] HttpMethod - -Resorting to protocol version default close connection policy\n[DEBUG] HttpMethod - -Should NOT close connection, using HTTP/1.1.\n[DEBUG] HttpMethod - -Execute loop try 3\n[DEBUG] wire - ->> \"GET /transfer/ HTTP/1.1[\\r][\\n]\"\n[DEBUG] HttpMethod - -Request to add Host header ignored: header already added\n[DEBUG] wire - ->> \"User-Agent: Jakarta Commons-HttpClient/2.0beta1[\\r][\\n]\"\n[DEBUG] wire - ->> \"Host: localhost[\\r][\\n]\"\n[DEBUG] wire - ->> \"Authorization: Digest username=\"guest\", realm=\"guest realm\",\nnonce=\"ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a\", uri=\"/transfer\",\nqop=\"auth\", algorithm=\"MD5\", nc=00000001,\ncnonce=\"81d4b905a4e9def944beaed8daf79283\",\nresponse=\"71394edcddf4bcee6237ea4bb50cfaa5\"[\\r][\\n]\"\n[DEBUG] wire - ->> \"[\\r][\\n]\"\n[DEBUG] wire - -<< \"HTTP/1.1 400 Bad Request[\\r][\\n]\"\n[DEBUG] wire - -<< \"Date: Fri, 20 Jun 2003 08:30:06 GMT[\\r][\\n]\"\n[DEBUG] wire - -<< \"Server: Apache/2.0.40 (Red Hat Linux)[\\r][\\n]\"\n[DEBUG] wire - -<< \"Vary: accept-language[\\r][\\n]\"\n[DEBUG] wire - -<< \"Accept-Ranges: bytes[\\r][\\n]\"\n[DEBUG] wire - -<< \"Content-Length: 973[\\r][\\n]\"\n[DEBUG] wire - -<< \"Connection: close[\\r][\\n]\"\n[DEBUG] wire - -<< \"Content-Type: text/html; charset=ISO-8859-1[\\r][\\n]\"\n\n-- End of client side log -----------------------------------------------------\n\n\n-- Server side log ------------------------------------------------------------\n\n[Fri Jun 20 10:30:06 2003] [error] [client 127.0.0.1] Digest: uri mismatch -\n</transfer> does not match request-uri </transfer/>\n\n-- End of server side log -----------------------------------------------------",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1015",
        "summary": "Support only-if-cached directive",
        "description": "Add support for only-if-cached Cache-Control directive- If the request is not servable from the cache, return a 504 Gateway Timeout.  See http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.4",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-757",
        "summary": "Default proxy set at the client level has no effect",
        "description": "Default proxy set at the client level has no effect, as client parameters are not correctly propagated to the HttpRoutePlanner",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-296",
        "summary": "Basic Authentification fails with non-ASCII username/password characters",
        "description": "http://marc.theaimsgroup.com/?t=106866959500001&r=1&w=2",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-916",
        "summary": "RFE: Make Credentials Serializable",
        "description": "I've been working on upgrading the HtmlUnit library to use HttpClient 4, and I've realized that we could eliminate some hackish internal code if Credentials instances were Serializable. I don't really see a downside, and this would be a huge convenience for us.\n\nThe change would involve making the org.apache.http.auth.Credentials interface extend Serializable, and having org.apache.http.auth.BasicUserPrincipal and org.apache.http.auth.NTUserPrincipal implement Serializable (plus serialVersionUIDs where appropriate, I guess).",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-304",
        "summary": "Cleanup use of EncodingUtil and HttpConstants",
        "description": "HttpConstants has become somewhat irrelevant.  Deprecate HttpConstants and move any existing \nfunctionality to EncodingUtil.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1033",
        "summary": "HttpRoute.equals(Object o) is quite inefficient, as it does not take full advantage of shortcut logic",
        "description": "HttpRoute.equals(Object o) is quite inefficient, as it does not take full advantage of shortcut logic.\n\nIt should return as soon as the first  false is detected.\n\nPatch to follow implements short-circuit checking.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-255",
        "summary": "In J2SDK 1.5.0 (Tiger) enum is a keyword",
        "description": "Hi!\n\nTiger adds extensions to the Java Programming Language (JSR201). One is\n\"Enumerations\", which required to add the new keyword enum.\n\nI just made a grep (grep -lrw) over some sources and found some Apache projects\nusing enum as a word.\n\nTo be compliant with the new specification, please check that enum is not used\nas a variable, field or method name.\n\nRegards,\nRobert",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-439",
        "summary": "Authentication fails when connecting to server with username and password in non ascii characters",
        "description": "Tried connecting to an exchange server using NTLM authentication\nUsername : \u00ed\u00f1\u00eb\u00e4\u00ed\u00f1\u00eb\u00e4\npassword : \u00ed\u00f1\u00eb\u00e4\u00ed\u00f1\u00eb\u00e4\n\nI am getting 401 response.\nAuth failed\nBody: \nError: Access is Denied.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-270",
        "summary": "return value of PostMethod#removeParameter",
        "description": "<HttpClient2.0-rc1>\n\nAbout \npublic boolean removeParameter(String paramName)\n                 throws IllegalArgumentException\nmethod.\n\n-------------------------------------------------\nPostMethod method = new PostMethod(uri);\nmethod.addParameter(\"name\", \"Matsui Hideki\");\nboolean b;\nb = method.removeParameter(\"name\"); // returns \"true\".\nb = method.removeParameter(\"XXXX\"); // returns \"true\". why??? \n---------------------------------------------------\n\nsorry for my poor english.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-591",
        "summary": "Apply the supplied patch. Sets 2 variable in the base class to protected",
        "description": "The patch attached to the main task contains minimal changes to allow the HttpMethodBase class to be overloaded by base class.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-313",
        "summary": "Improper EOL for text files on Windows",
        "description": "version 2.0-rc3. Improper EOL for text files on Windows for README.txt and\nLICENSE.txt, docs/*.txt. The files display as one loooong line in Notepad.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1024",
        "summary": "cache does not validate multiple cached variants",
        "description": "There is a bug in CachingHttpClient, where when we attempt to collect all the etags for existing cached variants so we can send a conditional request to the origin, we accidentally don't find any, and send an unconditional request instead.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-538",
        "summary": "New PostSOAP example (for src/examples)",
        "description": "I have a slightly modified version of PostXML which invokes SOAP requests. The\nonly difference to PostXML is that PostSOAP takes the SOAPAction as an extra\ncommndline arg and adds that as a header into the request.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-154",
        "summary": "Allow redirects between hosts and ports",
        "description": "Redirects to different hosts, ports and protocols are currently prevented. \nHistoricly, HttpMethodBase.checkValidRedirects() is used to prevent these types\nof redirects due how state information was being managed in the connection.  \n\nMuch has changed since then.  We should relax the check and allow for redirects\n between hosts and ports. \n\nRedirects across protocols should not be considered at this time as there are\nother issues related to security that is best left up to the user of HttpClient.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-150",
        "summary": "StringIndexOutOfBound exception in RFC2109 cookie validate when host name contains no domain information and is short in length than the cookie domain.",
        "description": "If the target server is identified by hostname only (no domain) and the domain\nof the cookie is greater in length than the target hostname, a\nStringIndexOutOfBoundsException occurs.\n\nOffending line(s) of code: 174-176 in o.a.c.h.cookie.RFC2109Spec.java",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-329",
        "summary": "[API Doc] Compile performance optimization guide",
        "description": "Performance optimization guide is long overdue and badly needed. The more people\nstart using HttpClient in all sorts of creative ways the more we are going to\nneed it.\n\nOleg",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-308",
        "summary": "Log level for message should be debug instead of error.",
        "description": "In method org.apache.commons.httpclient.HttpMethodBase.getResponseBody() Log\nmessage should be logged as debug instead of error. \n\n717             } catch (IOException e) {\n718                 LOG.error(\"I/O failure reading response body\", e);\n719                 this.responseBody = null;\n720             }\n\nAccording to HTTPCLIENT-57:\n2) Only/always log exception stack traces at the debug level\n        } catch (Exception ex) {\n            log.debug",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-848",
        "summary": "HttpClient:- Connections not released when SSL Tunneling fails.",
        "description": "Trying to use HTTPS, and SSL tunneling fails as expected because the host is not accepted by the squid proxy, so squid proxy return 403. \n\nThe problem I am seeing is that, when ever this happens the connections are not released to the pool. I traced the code and it appears that in \nHttpMethidDirector.java:  executeWithRetry()\nwhen executeConnect() return false and there is no retry, the connections are not released.\n\nIs this expected? Or am I doing something wrong.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-598",
        "summary": "ContentLengthInputStream does not implement available() properly",
        "description": "ContentLengthInputStream should either extend FilterInputStream or should delegate available() to wrappedStream.\n\nOtherwise, available() on the response stream (an instance of AutoCloseInputStream, which is properly extending FilterInputStream, and, therefore, delegating to the ContentLengthInputStream) always returns 0.\n\nThis issue is important for the clients that try to improve performance by processing all data that can be read in a non-blocking way before blocking on the network.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-526",
        "summary": "warn on invalid set-cookie header",
        "description": "I had a problem on a WS server that comes from some proxy misconfiguration...\nresulting in this reponse beeing received by HTTPclient :\n17:26:36,489 DEBUG [header] << \"HTTP/1.1 200 OK[\\r][\\n]\"\n17:26:36,489 DEBUG [header] << \"Set-Cookie: =f448bb59feedbaaabaee; path=/[\\r][\\n]\"\n17:26:36,489 DEBUG [header] << \"Date: Tue, 15 Nov 2005 16:26:36 GMT[\\r][\\n]\"\n17:26:36,489 DEBUG [header] << \"Server: Apache[\\r][\\n]\"\n17:26:36,489 DEBUG [header] << \"Connection: close[\\r][\\n]\"\n17:26:36,489 DEBUG [header] << \"Transfer-Encoding: chunked[\\r][\\n]\"\n17:26:36,489 DEBUG [header] << \"Content-Type: text/xml;charset=utf-8[\\r][\\n]\"\n\nThe set-cookie header is malformed, as cookie has no name, so the HTTP head may\nbe considered invalid.\n\nThis results in an error when building the NEXT request. I'd expect httpclient\nto WARN on malformed header and drop it.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-995",
        "summary": "cache returns cached responses even if validators not consistent with all conditional headers",
        "description": "This is a MUST-level requirement in the RFC, where if both ETags and Last-Modified dates are used as validators in a conditional request, a cache cannot return a cached response unless it is consistent with all the conditional headers in the request. There is a unit test for this already, but it is incorrect (it uses 'If-Unmodified-Since' instead of 'If-Modified-Since' in the test case).\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1051",
        "summary": "SSL connections cannot be established using resolvable IP address",
        "description": "HttpClient 4.1 introduced a regression in establishing SSL connections to remote peers (it seems this is a common regression for major httpclient updates, see HTTPCLIENT-803).\nThe new SSLSocketFactory.connectSocket method calls the X509HostnameVerifier with InetSocketAddress.getHostName() parameter. When the selected IP address has a reverse lookup name, the verifier is called with the resolved name, and so the IP check fails.\n4.0 release checked for original ip/hostname, but this cannot be done with the new connectSocket() method. \nThe TestHostnameVerifier.java only checks 127.0.0.1/.2 and so masked the issue, because the matching certificate has both \"localhost\" and \"127.0.0.1\", but actually only \"localhost\" is matched. A test case with 8.8.8.8 would be better.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-122",
        "summary": "HttpMultiClient reuses closed connections",
        "description": "If a socket times out while sitting in the connection pool, \nHttpConnectionManager still attempts to reuse it resulting in an IOException \nbeing thrown when writing to the socket.  I believe this is a problem with both \nserver side and client side timeouts (ie: we try to reuse a connection that we \ntimed out) though am not certain of that.  At the very least server side \ntimeouts cause the issue.\n\nAs yet I can't see how to fix this.  With the current code there doesn't even \nappear to be a suitable workaround because when the exception is thrown, the \nconnection is added back into the pool to be reused (even though it is closed) \nwhich causes the next attempt to fail as well.\n\nI can't see any reliable way to tell whether or not a connection is open, so \nwould suggest the following as a fix:\n\n1. In HttpMultiClient.executeMethod, close the connection if an exception is \nthrown (optionally, only if an IOException is thrown instead of an \nHttpException, but generally exceptions tend to leave things in an unknown \nstate).\n\n2. (optional) Add a retry loop to executeMethod to retry if an exception occurs \n(possibly only if an IOException is thrown, depending on exactly when a \nHttpException is thrown).\n\nI'll attach a patch which does both of this to help clarify.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-717",
        "summary": "NPE in SimpleHttpConnectionManager.shutdown()",
        "description": "SimpleHttpConnectionManager.shutdown() causes NPE if no connection has been created, whereas MultiThreadedHttpConnectionManager.shutdown() does not.\n\nSimple test case:\n\n\tMultiThreadedHttpConnectionManager cm = new MultiThreadedHttpConnectionManager();\n\tcm.shutdown(); // OK\n\t\t\n\tSimpleHttpConnectionManager sm = new SimpleHttpConnectionManager();\n\tsm.shutdown(); // NPE\n\n\nI came across this in JMeter - a sample was using Post with AutoRedirect, which (correctly) caused an IllegalArgumentException, and so the connection was not created. \n\nThe JMeter code could try to keep track of this, but it would be tedious, and it seems to me that SimpleHttpConnectionManager should ignore the shutdown() if the connection is null.\n\nThe problem does not arise when using closeIdleConnections(timeout) - unless one uses the special value:\n\n      closeIdleConnections(System.currentTimeMillis() - Long.MAX_VALUE)\n\nbut it would probably be sensible to protect against this as well.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-41",
        "summary": "New method to add an array of parameters to PostMethod",
        "description": "When posting a form a web page may have many parameters to post to the \nwebserver.  Currently in PostMethod, if you wanted to add multiple parameters, \nyou would have to call addParameter(name, value) for each one.\n\nA new convinence method should be added to allow for simpler client code by \ntaking an array of NameValuePair objects and adding all parameters in a single \nfunction call.\n\nvoid addParameters(NameValuePair[] parameters) \n\nAlso, the comments for PostMethod functions that deal with parameters \nstate \"Override method of HttpMethodBase ...\" which is incorrect.  More \ninformative comments should be added to this public API.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-214",
        "summary": "HttpClient drops connection to the proxy when an invalid 'connection: close' directive is encountered in 'connection established' response",
        "description": "One of our customer is using our application to connect to our servlet using \nhttps.  We are using httpClient for http protocol handling.  The customer has a \nIBM proxy (see log file).  The connect failed with a null pointer exception.\n\nThe log seem to indicate that the proxy server is returning 200 for \"CONNECT\", \nbut the proxy also sends a \"Connection:close\" header.  The httpClient closed \nthe connection and then tried to create the SSL socket.  If the proxy server is \nincorrect in sending 200 with \"Connection:close\", then httpClient should throw \nexception for invalid state (IllegalStateException ?).\n\nI will attach the log file.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-316",
        "summary": "release is not signed",
        "description": "there are no signatures & checksums available for your latest release",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-280",
        "summary": "Freezes w/ MultiThreadedHttpConnectionManager",
        "description": "My single threaded user of VFS (an HttpClient user, that uses\nMultiThreadedHttpConnectionManager) hangs [I suspect indefinitely] on minor\nactivity.\n\nI've turned on HttpClient debug and I see this, the last line\nbeing the last thing I get...\n\n2003/10/09 09:34:26:482 MDT [DEBUG] wire - -<< \"Content-Type:\ntext/html[\\r][\\n]\"\n2003/10/09 09:34:26:482 MDT [DEBUG] HttpMethodBase - -Resorting to protocol\nversion default close co\nnnection policy\n2003/10/09 09:34:26:492 MDT [DEBUG] HttpMethodBase - -Should NOT close\nconnection, using HTTP/1.1\n2003/10/09 09:34:26:502 MDT [DEBUG] HttpMethodDirector - -Execute loop try 1\n2003/10/09 09:34:26:512 MDT [DEBUG]\nMultiThreadedHttpConnectionManager - -HttpConnectionManager.getC\nonnection:  config = HostConfiguration[host=www.ibiblio.org,\nprotocol=http:80, port=80], timeout = 0\n\n2003/10/09 09:34:26:522 MDT [DEBUG]\nMultiThreadedHttpConnectionManager - -Unable to get a connection\n, waiting..., hostConfig=HostConfiguration[host=www.ibiblio.org,\nprotocol=http:80, port=80]\n\nThis is pretty reproducible. When I hack VFS not to use the\nMultiThreadedHttpConnectionManager I don't get the problem.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-345",
        "summary": "[CONTRIB] SSL authenticating protocol socket factory",
        "description": "Here's the long promised SSL client/server authenticating socket factory. This\nsocket factory can be used to enforce client/server authentication during the\nSSL context negotiation. Let me know what you think. Please, please someone\nproof-read the accompanying javadocs and let me know if the text is comprehensible \n\nI have also tweaked EasySSLProtocolSocketFactory a little\n\nThe patch is against HTTPCLIENT_2_0_BRANCH\n\nOleg",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-826",
        "summary": "Set source and output encoding in POMs",
        "description": "Modification to POM files to explicitly set the source and report encoding. I've set everything to UTF-8, but this may not be appropriate. However, the encoding properties should be set to ensure that source files are compiled correctly, resources are filtered appropriately and that the reports are using a consistent encoding.\n\nRelated info\nhttp://docs.codehaus.org/display/MAVENUSER/POM+Element+for+Source+File+Encoding\nhttp://docs.codehaus.org/display/MAVEN/Reporting+Encoding+Configuration",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-318",
        "summary": "Host configuration properties not updated when the method is redirected",
        "description": "the above uri:\n\nhttp://www.adobe.com/cgi-bin/redirect?http://lists.w3.org/Archives/Public/www-xsl-fo\n\ngenerates two 302 responses:\n\nfrom the original to http://lists.w3.org/Archives/Public/www-xsl-fo\nand from that to http://lists.w3.org/Archives/Public/www-xsl-fo/\n\nthe client accepts and follows these redirects (a trace of the process shows it's working well) but when \nyou ask the getmethod what uri we ended up at using the getURI() method it returns the bastardised \nresult:\n\nhttp://www.adobe.com/Archives/Public/www-xsl-fo/\n\ninstead of the correct \n\nhttp://lists.w3.org/Archives/Public/www-xsl-fo/\n\nthat the client has actually downloaded.\n\nusing cvsup'd copy showing version string \" Jakarta Commons-HttpClient/2.1m1\"",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-295",
        "summary": "HttpClient loops endlessly while trying to retrieve status line",
        "description": "When fed with the wrong URL, for example http://localhost:19/ (chargen port),\nHttpClient will loop endlessly while attempting to read the status line.\n\nThis is caused by a bug in HttpMethodBase.readStatusLine(HttpState, HttpConnection)\n\n(while loop without any exceptional abort condition).\n\nwire log excerpt:\n\n2003/11/10 12:33:04:085 CET [DEBUG] HttpMethodDirector - -Execute loop try 1\n2003/11/10 12:33:04:312 CET [DEBUG] wire - ->> \"GET / HTTP/1.1[\\r][\\n]\"\n2003/11/10 12:33:04:351 CET [DEBUG] HttpMethodBase - -Adding Host request header\n2003/11/10 12:33:04:532 CET [DEBUG] wire - ->> \"User-Agent: Jakarta\nCommons-HttpClient[\\r][\\n]\"\n2003/11/10 12:33:04:554 CET [DEBUG] wire - ->> \"Host: localhost:19[\\r][\\n]\"\n2003/11/10 12:33:04:559 CET [DEBUG] wire - ->> \"[\\r][\\n]\"\n2003/11/10 12:33:04:639 CET [DEBUG] wire - -<<\n\"!\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefgh[\\r][\\n]\"\n2003/11/10 12:33:04:669 CET [DEBUG] wire - -<<\n\"\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghi[\\r][\\n]\"\n2003/11/10 12:33:04:673 CET [DEBUG] wire - -<<\n\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghij[\\r][\\n]\"\n2003/11/10 12:33:04:692 CET [DEBUG] wire - -<<\n\"$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijk[\\r][\\n]\"\n2003/11/10 12:33:04:698 CET [DEBUG] wire - -<<\n\"%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijkl[\\r][\\n]\"\n2003/11/10 12:33:04:703 CET [DEBUG] wire - -<<\n\"&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklm[\\r][\\n]\"\n<snip>",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-26",
        "summary": "need a way to set request body in PostMethod",
        "description": "Currently, there is no way for user to set the request body in PostMethod \ndirectly. The only way to do that is by adding parameters to PostMethod. This \nmakes sense in most cases. However, there are situations that the user actually \nknows the request body and want to set it directly. adding the following method \nfixes this:\n\n    public void setRequestBody(String requestBody)\n    {\n        this.requestBody = requestBody;\n    }",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-390",
        "summary": "SSL + proxy + Host auth + Keep Alive off causes an infinite loop in HttpMethodDirector",
        "description": "The combination of SSL tunnelling, host authentication, and disabled persistent\nconnection support (HTTPD KeepAlive off) causes an infinite loop in\nHttpMethodDirector. \n\nThe problem has been reported on the httpclient-dev list by Rindress MacDonald\n<RMacDona at enterasys.com>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-776",
        "summary": "NPE w/ AbstractPoolEntry.open",
        "description": "java.lang.NullPointerException\n    at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:171)\n    at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119)\n    at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:309)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:501)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:456)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:422)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor.performRequest(DefaultHttpExecutor.java:97)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor.access$000(DefaultHttpExecutor.java:26)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor$MultiRequestor.run(DefaultHttpExecutor.java:135)\n    at org.limewire.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1006)\n    at org.limewire.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:549)\n    at java.lang.Thread.run(Unknown Source)\n\nSeeing a lot of these against Alpha4.  Also seeing still the occassional IllegalStateException of:\n\njava.lang.IllegalStateException: Connection already open.\n    at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:150)\n    at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119)\n    at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:309)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:501)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:456)\n    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:422)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor.performRequest(DefaultHttpExecutor.java:97)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor.access$000(DefaultHttpExecutor.java:26)\n    at com.limegroup.gnutella.http.DefaultHttpExecutor$MultiRequestor.run(DefaultHttpExecutor.java:135)\n    at org.limewire.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1006)\n    at org.limewire.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:549)\n    at java.lang.Thread.run(Unknown Source)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-29",
        "summary": "shouldn't throw exception on bad cookies",
        "description": "Currently, HttpClient throws Exception on bad cookie. This is not expected. The \nuser will expect HttpClient to ignore such cookies, but not getting an \nexception. Once exception is throw, user has no way to know if he can continue.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-589",
        "summary": "Do not consume the remaining response content if the connection is to be closed",
        "description": "I am working on a HttpClient-based application to send and receive potentially large files (up to Gigabytes). When receiving large files the application allows the user to cancel the download, at which time it closes the response input stream behind the scenes.\n\nThe input stream currently provided by HttpMethodBase.getResponseBody() for un-chunked responses with a known content length is a ContentLengthInputStream, which automatically reads the remainder of the wrapped response instead of closing it straight away. This behaviour does not work well with very large files as the data is downloaded unnecessarily and the connection is held open for long very periods.\n\nPer the HTTP 1.1 spec section 14.10 it seems to me that either a server or a client in an HTTP 1.1 connection can use the Connection:close directive to signal that a connection will be non-persistent, and will therefore not require that all data be read before the connection can be released (the cleaning up ContentLengthInputStream performs for persistent connections).\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.10\n\nCould HttpMethodBase be modified to check for this directive, from the server or client, and avoid wrapping the response input stream in ContentLengthInputStream when it is present? It seems straight-forward, though there may be side-effects I am not aware of. \n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-651",
        "summary": "Inconsistent, order dependant behaviour in HttpMethodBase.getResponse*",
        "description": "`getReponseBodyAsString` is storing the body  and may therefore provide a valid result if the code is requesting the body as stream afterwards. If you switch the order and first call getResponseBodyAsStream and afterwards try to `getReponseBodyAsString`, the result will be `null`.\n\nI wrote a unittest which hopefully describes the IMHO confusing behaviour:\n\n    public void testHttpClientBodyVsStream() throws HttpException, IOException {\n        final HttpClient httpClient = new HttpClient();\n        final GetMethod getMethod = new GetMethod(\"http://www.heise.de/\");\n        final String bodyFromStream;\n        final String body;\n        try {\n            httpClient.executeMethod(getMethod);\n            body = getMethod.getResponseBodyAsString();\n            bodyFromStream = IOUtils.toString(getMethod\n                    .getResponseBodyAsStream());\n        } finally {\n            getMethod.releaseConnection();\n        }\n        assertEquals(body, bodyFromStream);\n    }\n    \n    public void testHttpClientStreamVsBody() throws HttpException, IOException {\n        final HttpClient httpClient = new HttpClient();\n        final GetMethod getMethod = new GetMethod(\"http://www.heise.de/\");\n        final String bodyFromStream;\n        final String body;\n        try {\n            httpClient.executeMethod(getMethod);\n            bodyFromStream = IOUtils.toString(getMethod\n                    .getResponseBodyAsStream());\n            body = getMethod.getResponseBodyAsString();\n        } finally {\n            getMethod.releaseConnection();\n        }\n        // ** This will fail **\n        assertEquals(body, bodyFromStream);\n    }\n\nSearching http://svn.apache.org/repos/asf/jakarta/commons/proper/httpclient/trunk/src/java/org/apache/commons/httpclient/HttpMethodBase.java I understand the outcome, but this is confusing.\n\nI would expect the body data to be gone after calling one of the getResponse*-Methods and calling them again not to return null but even to throw an IllegalStateException. I would not store the body at all in the method.\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1113",
        "summary": "Error downloading text file with gzip content encoding",
        "description": "Hello I am getting an exception when I try to download certain files.\n\nI don't have control over the host server, only the client.  Here's my client code:\n\n\t\tHttpParams params = new BasicHttpParams();\n\t\tparams.setParameter(CoreConnectionPNames.CONNECTION_TIMEOUT, 300000L);\n\t\tparams.setParameter(ClientPNames.HANDLE_REDIRECTS, true);\n\n\t\t// This client indicates to servers that it will support 'gzip'\n\t\t// and 'deflate' compressed responses.\n\t\tContentEncodingHttpClient.setDefaultHttpParams(params);\n\t\tContentEncodingHttpClient client = new ContentEncodingHttpClient();\n\n\t\tif (user != null && password != null) {\n\t\t\tString hostname = url.getHost();\n\t\t\tHttpHost hostHttp = new HttpHost(hostname, 80, \"http\");\n\t\t\tHttpHost hostHttps = new HttpHost(hostname, 443, \"https\");\n\t\t\tclient.getCredentialsProvider().setCredentials(\n\t\t\t        new AuthScope(hostname, 80), \n\t\t\t        new UsernamePasswordCredentials(user, password));\n\t\n\t\t\tclient.getCredentialsProvider().setCredentials(\n\t\t\t        new AuthScope(hostname, 443), \n\t\t\t        new UsernamePasswordCredentials(user, password));\n\t\n\t\t\t// Create AuthCache instance\n\t\t\tAuthCache authCache = new BasicAuthCache();\n\t\t\t// Generate BASIC scheme object and add it to the local auth cache\n\t\t\tBasicScheme basicAuth = new BasicScheme();\n\t\t\tauthCache.put(hostHttp, basicAuth);\n\t\t\tauthCache.put(hostHttps, basicAuth);\n\t\n\t\t\t// Add AuthCache to the execution context\n\t\t\tBasicHttpContext localcontext = new BasicHttpContext();\n\t\t\tlocalcontext.setAttribute(ClientContext.AUTH_CACHE, authCache);\n\t\t}\n\t\tHttpGet httpget = new HttpGet(url.toString());\n\t\thttpget.setHeader(\"If-Modified-Since\", lastModified);\n\n\n\t\tHttpResponse response = client.execute(httpget);\n\t\tresponseCode = response.getStatusLine().getStatusCode();\n\t\tHttpEntity entity = response.getEntity();\n\t\tif (responseCode == HttpStatus.SC_NOT_MODIFIED) {\n\t\t\t\n\t\t} else if (responseCode == HttpStatus.SC_OK && entity != null) {\n\t\t\toutStream = new BufferedOutputStream(new FileOutputStream(outFilename));\n\t\t\tentity.writeTo(outStream);\n\t\t}\n\nHere's the log output:\n\nDEBUG [2011-08-02 01:23:01,031] [org.apache.http.impl.conn.SingleClientConnManager:212] Get connection for route HttpRoute[{}->http://<host>]\nDEBUG [2011-08-02 01:23:01,036] [org.apache.http.impl.conn.DefaultClientConnectionOperator:145] Connecting to <host>/<IP>:80\nDEBUG [2011-08-02 01:23:01,057] [org.apache.http.client.protocol.RequestAddCookies:132] CookieSpec selected: best-match\nDEBUG [2011-08-02 01:23:01,057] [org.apache.http.client.protocol.RequestAuthCache:75]   Auth cache not set in the context\nDEBUG [2011-08-02 01:23:01,058] [org.apache.http.impl.client.DefaultRequestDirector:631]        Attempt 1 to execute request\nDEBUG [2011-08-02 01:23:01,058] [org.apache.http.impl.conn.DefaultClientConnection:264] Sending request: GET <file> HTTP/1.1\nDEBUG [2011-08-02 01:23:01,058] [org.apache.http.impl.conn.Wire:63]     >> \"GET <file> HTTP/1.1[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,058] [org.apache.http.impl.conn.Wire:63]     >> \"If-Modified-Since: Mon, 01 Aug 2011 18:26:09 CEST[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,059] [org.apache.http.impl.conn.Wire:63]     >> \"Host: <host>[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,059] [org.apache.http.impl.conn.Wire:63]     >> \"Connection: Keep-Alive[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,059] [org.apache.http.impl.conn.Wire:63]     >> \"User-Agent: Apache-HttpClient/4.1.1 (java 1.5)[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,059] [org.apache.http.impl.conn.Wire:63]     >> \"Accept-Encoding: gzip,deflate[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,060] [org.apache.http.impl.conn.Wire:63]     >> \"[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,060] [org.apache.http.impl.conn.DefaultClientConnection:268] >> GET <file> HTTP/1.1\nDEBUG [2011-08-02 01:23:01,060] [org.apache.http.impl.conn.DefaultClientConnection:271] >> If-Modified-Since: Mon, 01 Aug 2011 18:26:09 CEST\nDEBUG [2011-08-02 01:23:01,060] [org.apache.http.impl.conn.DefaultClientConnection:271] >> Host: <host>\nDEBUG [2011-08-02 01:23:01,061] [org.apache.http.impl.conn.DefaultClientConnection:271] >> Connection: Keep-Alive\nDEBUG [2011-08-02 01:23:01,061] [org.apache.http.impl.conn.DefaultClientConnection:271] >> User-Agent: Apache-HttpClient/4.1.1 (java 1.5)\nDEBUG [2011-08-02 01:23:01,061] [org.apache.http.impl.conn.DefaultClientConnection:271] >> Accept-Encoding: gzip,deflate\nDEBUG [2011-08-02 01:23:01,085] [org.apache.http.impl.conn.Wire:63]     << \"HTTP/1.1 200 OK[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,086] [org.apache.http.impl.conn.Wire:63]     << \"Server: nginx/0.8.54[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,086] [org.apache.http.impl.conn.Wire:63]     << \"Date: Mon, 01 Aug 2011 23:23:01 GMT[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,086] [org.apache.http.impl.conn.Wire:63]     << \"Content-Type: text/plain[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,086] [org.apache.http.impl.conn.Wire:63]     << \"Last-Modified: Wed, 20 Jul 2011 14:39:57 GMT[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,087] [org.apache.http.impl.conn.Wire:63]     << \"Transfer-Encoding: chunked[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,087] [org.apache.http.impl.conn.Wire:63]     << \"Connection: keep-alive[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,087] [org.apache.http.impl.conn.Wire:63]     << \"Vary: Accept-Encoding[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,087] [org.apache.http.impl.conn.Wire:63]     << \"Expires: Wed, 31 Aug 2011 23:23:01 GMT[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,088] [org.apache.http.impl.conn.Wire:63]     << \"Cache-Control: max-age=2592000[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,088] [org.apache.http.impl.conn.Wire:63]     << \"Content-Encoding: gzip[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,088] [org.apache.http.impl.conn.Wire:63]     << \"[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,088] [org.apache.http.impl.conn.DefaultClientConnection:249] Receiving response: HTTP/1.1 200 OK\nDEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:252] << HTTP/1.1 200 OK\nDEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:255] << Server: nginx/0.8.54\nDEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:255] << Date: Mon, 01 Aug 2011 23:23:01 GMT\nDEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:255] << Content-Type: text/plain\nDEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:255] << Last-Modified: Wed, 20 Jul 2011 14:39:57 GMT\nDEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Transfer-Encoding: chunked\nDEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Connection: keep-alive\nDEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Vary: Accept-Encoding\nDEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Expires: Wed, 31 Aug 2011 23:23:01 GMT\nDEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Cache-Control: max-age=2592000\nDEBUG [2011-08-02 01:23:01,091] [org.apache.http.impl.conn.DefaultClientConnection:255] << Content-Encoding: gzip\nDEBUG [2011-08-02 01:23:01,091] [org.apache.http.impl.client.DefaultRequestDirector:477]        Connection can be kept alive indefinitely\nDEBUG [2011-08-02 01:23:01,131] [org.apache.http.impl.conn.Wire:63]     << \"600a[\\r][\\n]\"\nDEBUG [2011-08-02 01:23:01,132] [org.apache.http.impl.conn.Wire:77]     << \"[0x1f]\"\nDEBUG [2011-08-02 01:23:03,838] [org.apache.http.impl.conn.Wire:63]     << \"[\\r][\\n]\"\n\n.... (Content)\n\nDEBUG [2011-08-02 01:23:03,839] [org.apache.http.impl.conn.SingleClientConnManager:267] Releasing connection org.apache.http.impl.conn.SingleClientConnManager$ConnAdapter@2aa3873\nDEBUG [2011-08-02 01:23:03,839] [org.apache.http.impl.conn.SingleClientConnManager:285] Released connection open but not reusable.\nDEBUG [2011-08-02 01:23:03,839] [org.apache.http.impl.conn.DefaultClientConnection:152] Connection shut down\nERROR [2011-08-02 01:23:03,840] [app]        Exception downloading file\njava.io.EOFException\n        at java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:224)\n        at java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:214)\n        at java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:153)\n        at java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:75)\n        at java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:85)\n        at org.apache.http.client.entity.GzipDecompressingEntity.getContent(GzipDecompressingEntity.java:63)\n        at org.apache.http.util.EntityUtils.consume(EntityUtils.java:65)\n        at org.apache.http.conn.BasicManagedEntity.ensureConsumed(BasicManagedEntity.java:98)\n        at org.apache.http.conn.BasicManagedEntity.writeTo(BasicManagedEntity.java:115)\n        at util.FileDownload.download(FileDownload.java:188) <--- my app\n\nDoes this happen because the server doesn't specify the content length?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-182",
        "summary": "httpclient charset encooding loosing problem",
        "description": "file: org\\apache\\commons\\httpclient\\HttpConstants.java \n\n\nline: near 261\n\n\n---------------------------------\n\n\npublic static String getContentString(final byte[] data, String charset) {\n\n\n        return getContentString(data, 0, data.length);\n\n\n    }\n\n\n---------------------------------\n\n\nmust be\n\n\n---\n\n\n        return getContentString(data, 0, data.length, charset);\n\n\n---",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-102",
        "summary": "Unable to get the status line from a http method object",
        "description": "The status line (typically the first line returned from a http connection read)\nis hidden inside httpclient with no way for client code to retrieve it intact.\nreadStatusLine() in HttpMethodBase is where the status line is\nread, but it is never stored and is not available outside the method.\n\nWe could store the status line as a string and add a getStatusLine\nmethod to the HttpMethod interface and HttpMethodBase class.  Alternatively, we\ncould create a header for it with the name StatusLine (or perhaps just null) so\nthat it could be retrieved with getHeader(\"StatusLine\").  This would preserve\nthe interface but would be a bit of a kludge.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-234",
        "summary": "Customizable Cookie Policy",
        "description": "Even if the server is not complying with the cookie specification, sometimes \nyou still need to talk to it.\n\nIt would be nice that when setting the Cookie Policy for the HttpMethod, you \ncould specify a custom policy that implements the CookieSpecBase but may \nhandle certain problems more leniently.  This would be instead of specifying \none of the three hard-coded policies.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-952",
        "summary": "SSLSocketFactory.createSSLContext does not process trust store",
        "description": "org.apache.http.conn.ssl.SSLSocketFactory.createSSLContext() does not process a provided trust store.\nOnly the default (cacerts) is processed. An additional provided trust store is ignored.\nAdding the \"trusted\" certificate to the keystore, the peer is authenticated.\n\nEventually\n        tmfactory.init(keystore);\nneeds to be\n        tmfactory.init(truststore);\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1078",
        "summary": "DecompressingEntity not calling close on InputStream retrieved by getContent",
        "description": "The method DecompressingEntity.writeTo(OutputStream outstream) does not close the InputStream retrieved by getContent().\nAccording to the documentation of HttpEntity.writeTo:\nIMPORTANT: Please note all entity implementations must ensure that\nall allocated resources are properly deallocated when this method\nreturns.\n\n-> imho this is not satisfied in DecompressingEntity.writeTo ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-567",
        "summary": "EasyX509TrustManager no longer checks cert expiry",
        "description": "EasyX509TrustManager was made even \"easier\" by the last commit:  a socket will\nnow be created when talking to a server with an expired certificate.\n\n2 commits ago it looked like this (notice \"return false\" on line 107):\n\n102             try {\n103                 certificate.checkValidity();\n104             }\n105             catch (CertificateException e) {\n106                 LOG.error(e.toString());\n107                 return false;\n108             }\n\n\nNow it looks like this:\n\n102             try {\n103                 certificate.checkValidity();\n104             }\n105             catch (CertificateException e) {\n106                 LOG.error(e.toString());\n107             }\n\n\nI'm proposing we just do:\n\n102             certificate.checkValidity();\n\nNow that we're using Java 1.4 in the contrib code, we'll just let the\nCertificateException fly up the stack.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1058",
        "summary": "SO_TIMEOUT not set early enough for SOCKS proxies in PlainSocketFactory",
        "description": "I've created my own delegating SchemeSocketFactory implementation which supports setting SOCKS proxies on socket creation. In the connectSocket implementation, I previously just delegated to PlainSocketFactory.\n\nThe problem there was, that the SO_TIMEOUT was not set on the socket before the connection was established through the SOCKS proxy. This lead to a stop on the native read0 method because the socket is endlessly waiting for a read to occur from the proxy, so it can continue with the the connect to the actual socket destination through the proxy. I made sure I set the SO_TIMEOUT parameter in HttpParams, but it did not get honored by PlainSocketFactory.\n\nTo fix this and make HttpClient honor SO_TIMEOUT for SOCKS proxies, the following line has to be added:\n  sock.setSoTimeout(HttpConnectionParams.getSoTimeout(params));\nin PlainSocketFactory.connectSocket(...).\n\nHeres the complete fixed method:\n\nPlainSocketFactory:            \n    public Socket connectSocket(\n            final Socket socket,\n            final InetSocketAddress remoteAddress,\n            final InetSocketAddress localAddress,\n            final HttpParams params) throws IOException, ConnectTimeoutException {\n        if (remoteAddress == null) {\n            throw new IllegalArgumentException(\"Remote address may not be null\");\n        }\n        if (params == null) {\n            throw new IllegalArgumentException(\"HTTP parameters may not be null\");\n        }\n        Socket sock = socket;\n        if (sock == null) {\n            sock = createSocket();\n        }\n        if (localAddress != null) {\n            sock.setReuseAddress(HttpConnectionParams.getSoReuseaddr(params));\n            sock.bind(localAddress);\n        }\n        \n        //FIX for SOCKS proxies which get stalled if they don't answer\n        sock.setSoTimeout(HttpConnectionParams.getSoTimeout(params));\n        \n        int timeout = HttpConnectionParams.getConnectionTimeout(params);\n        try {\n            sock.connect(remoteAddress, timeout);\n        } catch (SocketTimeoutException ex) {\n            throw new ConnectTimeoutException(\"Connect to \" + remoteAddress.getHostName() + \"/\"\n                    + remoteAddress.getAddress() + \" timed out\");\n        }\n        return sock;\n    }\n\nCurrently I've implemented this in my delegating SchemeSocketFactory, because PlainSocketFactory misses this setting.\n\nDunno if there are other implementations of SocketFactory in HttpClient, which might need this fix. Anyway I hope this helps other people who get  headaches about halting threads because they use SOCKS proxies. :)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1135",
        "summary": "RandomAccessFile mode \"w\" is not valid",
        "description": "According to the Java docs for RandomAccessFile, mode must be \"r\" \"rw\" \"rws\" or \"rwd\" - anything else results in an IllegalArgumentException. It seems that Sun/Oracle/OpenJDK's don't document it, but supports \"w\" mode that is equivalent to \"rw\" Android does as the Javadocs say, and throws an IllegalArgumentException when mode \"w\" is passed as HttpClientCache does IOUtils.copyFile() (line 70-71).\n\nThis means that HttpClient Cache does not work on Android.",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-540",
        "summary": "Typo in API_CHANGES_3_0.txt",
        "description": "DigestSheme should be DigestScheme :)  Also, why is there not an httpclient\ncomponent in the list?",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-662",
        "summary": "Disentangle commons-httpclient from commons in Gump",
        "description": "Currently, the Gump project for HttpClient 3.x is defined as one of the commons projects.\nIt should be moved to a separate definition, either all by itself or as a new group of HttpComponents Gump projects.\n",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "HTTPCLIENT-72",
        "summary": "Support for NTLM authentication",
        "description": "A late write in for this would be support for NTLM authenticatin as well as\nbasic and digest.  Obviously non-trivial but it would be a very big feature.\n\nAdrian Sutton, Software Engineer\nEphox Corporation\nwww.ephox.com <http://www.ephox.com>",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-319",
        "summary": "ArrayIndexOutOfBounds Exception on invalid content-length",
        "description": "If the server returns an invalid (not parsable to int) content legnth the method\nprotected int getResponseContentLength() in HttpMethodBase walks off the\nend of the Header[] array and throws the ArrayIndexOutOfBoundsException.\n\nThe loop at line 687 in HttpMethodBase.java:\n\n   for (int i = headers.length - 1; i >= 0; i++) {\n\nstarts at the end of the array, but uses ++ intead of -- and so walks off the\nend of the array on the next line if the header is invalid.  If the header is\nvalid the return statement in the try block succeeds so there is no error.\n\nThe fix is simply to change the line to be\n\n   for (int i = headers.length -1; i>=0; i--) {",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-522",
        "summary": "ProxyCredentials disclosed to remote host",
        "description": "I'm using httpclient (svn-trunk of today) to connect to a remote SSL-Host \nvia a proxy. The proxy requires authorization (basic) and I want to use \npreemptive authorization. \n \nSince HTTPCLIENT-514 is fixed the preemptive authorization works, but my traces \nshow that the proxy credentials are also transmitted to the remote host \nthrough the CONNECT-tunnel, thus disclosing sensitive information to the \nremote host. \n \nMy code looks like this: \n \nHttpClient client = new HttpClient(); \nHttpMethod method = new GetMethod(\"https://test\"); \n \nclient.getHostConfiguration().setProxy(\"127.0.0.1\",3128); \nclient.getState().setProxyCredentials( \n                new AuthScope(\"127.0.0.1\", 3128), \n                new UsernamePasswordCredentials(\"proxy\", \"test\")); \nclient.getState().setAuthenticationPreemptive(true); \nclient.executeMethod(method); \n \nThe trace: \n \n2005/11/03 13:53:13:244 CET [DEBUG] HttpMethodDirector - Preemptively \nsending default basic credentials \n2005/11/03 13:53:13:261 CET [DEBUG] HttpMethodDirector - Authenticating \nwith BASIC <any realm>@127.0.0.1:3128 \n2005/11/03 13:53:13:262 CET [DEBUG] HttpMethodParams - Credential charset \nnot configured, using HTTP element charset \n2005/11/03 13:53:13:266 CET [DEBUG] HttpMethodDirector - Authenticating \nwith BASIC <any realm>@test:443 \n2005/11/03 13:53:13:267 CET [WARN] HttpMethodDirector - Required \ncredentials not available for BASIC <any realm>@test:443 \n2005/11/03 13:53:13:267 CET [WARN] HttpMethodDirector - Preemptive \nauthentication requested but no default credentials available \n2005/11/03 13:53:13:268 CET [DEBUG] HttpConnection - Open connection to \n127.0.0.1:3128 \n2005/11/03 13:53:13:279 CET [DEBUG] HttpMethodDirector - Preemptively \nsending default basic credentials \n2005/11/03 13:53:13:280 CET [DEBUG] HttpMethodDirector - Authenticating \nwith BASIC <any realm>@127.0.0.1:3128 \n2005/11/03 13:53:13:280 CET [DEBUG] HttpMethodParams - Credential charset \nnot configured, using HTTP element charset \n2005/11/03 13:53:13:283 CET [DEBUG] header - >> \"CONNECT test:443 HTTP/1.1\" \n2005/11/03 13:53:13:284 CET [DEBUG] HttpMethodBase - Adding Host request \nheader \n2005/11/03 13:53:13:284 CET [DEBUG] header - >> \"Proxy-Authorization: \nBasic cHJveHk6dGVzdA==[\\r][\\n]\" \n2005/11/03 13:53:13:285 CET [DEBUG] header - >> \"User-Agent: Jakarta \nCommons-HttpClient/3.0-rc4[\\r][\\n]\" \n2005/11/03 13:53:13:285 CET [DEBUG] header - >> \"Host: test[\\r][\\n]\"       \n                                                                           \n2005/11/03 13:53:13:286 CET [DEBUG] header - >> \"Proxy-Connection: \nKeep-Alive[\\r][\\n]\" \n2005/11/03 13:53:13:286 CET [DEBUG] header - >> \"[\\r][\\n]\"                 \n                                                                         \n2005/11/03 13:53:13:311 CET [DEBUG] header - << \"HTTP/1.0 200 \nConnection established[\\r][\\n]\"                                            \n2005/11/03 13:53:13:326 CET [DEBUG] ConnectMethod - CONNECT status code 200 \n2005/11/03 13:53:13:327 CET [DEBUG] HttpConnection - Secure tunnel to \ntest:443 \n2005/11/03 13:53:13:418 CET [DEBUG] header - >> \"GET / HTTP/1.1[\\r][\\n]\" \n2005/11/03 13:53:13:420 CET [DEBUG] HttpMethodBase - Adding Host request \nheader \n2005/11/03 13:53:13:423 CET [DEBUG] header - >> \"Proxy-Authorization: \nBasic cHJveHk6dGVzdA==[\\r][\\n]\" \n2005/11/03 13:53:13:424 CET [DEBUG] header - >> \"User-Agent: Jakarta \nCommons-HttpClient/3.0-rc4[\\r][\\n]\" \n2005/11/03 13:53:13:425 CET [DEBUG] header - >> \"Host: test[\\r][\\n]\" \n2005/11/03 13:53:13:425 CET [DEBUG] header - >> \"[\\r][\\n]\" \n2005/11/03 13:53:14:391 CET [DEBUG] header - << \"HTTP/1.1 200 OK[\\r][\\n]\" \n \nAs you can see the proxy credentials are also transmitted through the \nSSL-tunnel to the remote host which is a security risk.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-151",
        "summary": "CookieSpec.formatCookie(Cookie) produces an incorrect cookie header value",
        "description": "Consider the following:\n----------------------------------------------------------------------\nCookie cookie = new Cookie(\".foo.com\", \"name\", \"value\");\ncookie.setVersion(1);\ncookie.setPath(\"/\");\nCookieSpec spec = CookiePolicy.getSpecByPolicy(CookiePolicy.RFC2109);\nSystem.out.println(spec.formatCookie(cookie));                \n----------------------------------------------------------------------\n\nWhen calling CookieSpec.formatCookie(Cookie) the resulting output is:\n\n   name=\"value\"\n\nThe Version attribute is not present as required by RFC2109, nor is the path or\ndomain information included.\n\nIt seems that in this case, only Cookie type 0 output is produced.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1000",
        "summary": "Configure Maximum Connection Lifetimes",
        "description": "Provide a means of configuring a maximum lifetime for HttpClient connections.  Currently, it would appear as long as a connection is used it may persist indefinitely.\n\nThis would be useful for situations where HttpClient needs to react to DNS changes, such as the following situation that may occur when using DNS load balancing:\n - HttpClient maintains connections to example.com which resolves to IP A\n - Machine at IP A fails, and example.com now resolves to backup machine at IP B\n - Since IP A is failing, connections are destroyed, and new connections are made to IP B\n - Machine at IP A recovers, but HttpClient maintains connections to IP B since the connections are still healthy\n\nThe desired behavior would be that connections to IP B will reach their connection lifetime, and new connections could be created back to IP A according to the updated DNS settings.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-148",
        "summary": "Redirect to a relative URL fails",
        "description": "Request the url \nhttp://commerce1.cera.net/discount-pcbooks/catalog/categories.asp?\nsearch_str=0782128092\n\nOn a browser the redirect works, while with HttpClient it doesn't.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-43",
        "summary": "replace the PostMethod parameters HashMap with a List",
        "description": "Propose to change the parameters datastructure in PostMethod from its\ncurrent HashMap to an ArrayList (or Vector) of NameValuePair objects. \nThis change would lead to simpler and more robust code in the PostMethod\nwith more deterministic behaviour for the following reasons:\n\n1) HashMap looses any insertion order.  If the client wants to have the\nencoded parameters to show up in a particular order, they are unable.\n\n2) Hash map requres unique keys where there is no reason that multiple\nparameters with the same name cannot be POSTed.  The current\nimplementation replaces the string value with a List if there is a\naddParameter with a repeated name key.  Every get from the HashMap then\nhas to do an instanceOf to see if the value is a String or a List.\n\n3) Hash maps are no faster than a Vector for typical operations.  They\nboth have O(1) insertions and both do O(n) removal operations to\ngenPropose to change the parameters datastructure in PostMethod from its\ncurrent HashMap to an ArrayList (or Vector) of NameValuePair objects. \nThis change would lead to simpler and more robust code in the PostMethod\nwith more deterministic behaviour for the following reasons:\n\n1) HashMap looses any insertion order.  If the client wants to have the\nencoded parameters to show up in a particular order, they are unable.\n\n2) Hash map requres unique keys where there is no reason that multiple\nparameters with the same name cannot be POSTed.  The current\nimplementation replaces the string value with a List if there is a\naddParameter with a repeated name key.  Every get from the HashMap then\nhas to do an instanceOf to see if the value is a String or a List.\n\n3) Hash maps are no faster than a Vector for typical operations.  They\nboth have O(1) insertions and both do O(n) removal operations to\ngenerate the body.  HashMap is only faster when a search is required,\nsuch as for getParameter(String), setParameter(String, String) and\nremoveParameter(String) which should rarely be called.\n\nI would also move to depricate setParameter(String, String) as it is\nconfusing in the API.  (setParameter overwrites any existing parameter\nof the same name where addParameter accumulates to the list of\nparameters).  The setParameter functionality can also be effected by\ncalling removeParameter then addParameter already.\n\nerate the body.  HashMap is only faster when a search is required,\nsuch as for getParameter(String), setParameter(String, String) and\nremoveParameter(String) which should rarely be called.\n\nI would also move to depricate setParameter(String, String) as it is\nconfusing in the API.  (setParameter overwrites any existing parameter\nof the same name where addParameter accumulates to the list of\nparameters).  The setParameter functionality can also be effected by\ncalling removeParameter then addParameter already.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-220",
        "summary": "HttpClient does not properly handle 'application/x-www-form-urlencoded' encoding",
        "description": "As always I'd like to pass on my thanks, I'm finding HttpClient really useful.\n\nThe problem occurs because I use Struts map based ActionForm and these generate \nrequest parameters of the form:\n\n<input type=\"text\" name=\"searchSelection(c)\">\n\nWhen this is submitted using the PostMethod class the generateRequestBody() is \ncalled and in turn this calls the URI.encode() method with a BitSet of the \nacceptable characters. In this case the '(' and ')' characters are marked as \nacceptable.\n\nThe problem is that this does not work correctly when I submit it to my remote \nserver. If however I issue the request directly (from a webpage rather than \nusing HttpClient) it works and when I examine the request input stream I can see \nthat the parameter has been re-written so that 'select(c)' is displayed as \n'select%28c%29'.\n\nThis may be my error because of encoding problems or the fact I am not setting \nthe content type etc. correctly. Or it could be a bug. I'm afraid my HTTP \nknowledge is not good enough.\n\nChris Mein",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1037",
        "summary": "FormBodyPart code does not agree with ContentDescriptor Javadoc wrt nullability of mimeType and transferEncoding",
        "description": "The FormBodyPart does not agree with ContentDescriptor Javadoc wrt nullability of mimeType and transferEncoding:\n\nThe code in FormBodyPart explicitly allows mimeType and transferEncoding to be null, in which case the relevant header is not generated.\nThis is useful behaviour, as the headers are not necessaruly needed.\n\nHowever the bahaviour disagrees with the Javadoc in the ContentDescriptor interface - null is not allowed.\nAlso, AbstractContentBody does not allow mime-type to be null.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1116",
        "summary": "ResponseCachingPolicy uses integers for sizes",
        "description": "ResponseCachingPolicy currently uses integers for interpreting the size of Content-Length, as well internally.\n\nThis causes issues in attempting to use the module for caching entities that are over 2GB in size, the module does not fail gracefully, but throws a NumberFormatException\n\nI have a patch that fixes this, by promoting the int -> long, which should allow for larger entities to be cached, it also updates the public facing API where possible, I don't think that the promotion should break compatibility massively\n\nThe changes can also be seen here:\nhttps://github.com/GregBowyer/httpclient/commit/1197d3f94bd2eedcec32646cd6146748ca2e6fa1",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-634",
        "summary": "HostConfiguration socketFactory is ignored",
        "description": "HostConfiguration doesn't use its host.protocol to execute an HttpMethod with an absolute URL.  It should, if the Protocol's scheme is the same as the method's URL scheme.\n\nThis bug makes it difficult to integrate a specialized SSL connection algorithm (in a SecureProtocolSocketFactory) with a module implemented on top of HttpClient.  The latter module must not execute methods with absolute URLs.  Of course, this is difficult when one doesn't control that module.  For example, I recently tried to integrate SSL certificate-based client authentication with XFire.  XFire provides a reasonable API for replacing its HttpClient, but one must hack its source code to prevent it from executing methods with absolute URLs.\n\nProtocol.registerProtocol is a possible answer, but it can't support two or more SSL connection algorithms for one HTTPS host and port.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-749",
        "summary": "HttpClient 'ParamBeans' for easier configuration",
        "description": "As I did for a 'core' here I would like to contribute for 'client' part as few 'ParamBeans' for easier external configuration... Any comment or improvement is very welcome...",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-226",
        "summary": "HttpMethod#getResponseBody throws NPE",
        "description": "HttpMethod#getResponseBody throws an NPE if the response from the server was \n204.  Shouldn't getResponseBody return null by contract instead of throwing \nNPE?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-10",
        "summary": "tests-local fails on 3 tests",
        "description": "1)\ntestMultiSendCookieGet(org.apache.commons.httpclient.TestWebappCookie)junit.framework.AssertionFailedError:\n<html>\n<head><title>ReadCookieServlet: GET</title></head>\n<body>\n<p>This is a response to an HTTP GET request.</p>\n<p><tt>Cookie:\n$Version=1;simplecookie=value;$Path=/httpclienttest/cookie;$Domain=localhost</tt></p>\n<tt>$Version=1</tt><br>\n<tt>simplecookie=value</tt><br>\n<tt>$Path=/httpclienttest/cookie</tt><br>\n<tt>$Domain=localhost</tt><br>\n</body>\n</html>\n    at\norg.apache.commons.httpclient.TestWebappCookie.testMultiSendCookieGet(TestWebappCookie.java:348)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n    at\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n2)\ntestDeleteCookieGet(org.apache.commons.httpclient.TestWebappCookie)junit.framework.AssertionFailedError:\n<html>\n<head><title>ReadCookieServlet: GET</title></head>\n<body>\n<p>This is a response to an HTTP GET request.</p>\n<p><tt>Cookie:\n$Version=1;simplecookie=value;$Path=/httpclienttest/cookie;$Domain=localhost</tt></p>\n<tt>$Version=1</tt><br>\n<tt>simplecookie=value</tt><br>\n<tt>$Path=/httpclienttest/cookie</tt><br>\n<tt>$Domain=localhost</tt><br>\n</body>\n</html>\n    at\norg.apache.commons.httpclient.TestWebappCookie.testDeleteCookieGet(TestWebappCookie.java:389)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n    at\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n3)\ntestDeleteCookiePut(org.apache.commons.httpclient.TestWebappCookie)junit.framework.AssertionFailedError:\n<html>\n<head><title>ReadCookieServlet: PUT</title></head>\n<body>\n<p>This is a response to an HTTP PUT request.</p>\n<p><tt>Cookie:\n$Version=1;simplecookie=value;$Path=/httpclienttest/cookie;$Domain=localhost</tt></p>\n<tt>$Version=1</tt><br>\n<tt>simplecookie=value</tt><br>\n<tt>$Path=/httpclienttest/cookie</tt><br>\n<tt>$Domain=localhost</tt><br>\n</body>\n</html>\n    at\norg.apache.commons.httpclient.TestWebappCookie.testDeleteCookiePut(TestWebappCookie.java:464)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n    at\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\nFAILURES!!!\nTests run: 108,  Failures: 3,  Errors: 0\nhttpclient/build.xml [271] Java returned: -1\nBUILD FAILED\nTotal time: 9 seconds",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-867",
        "summary": "Logging documentation refers to nonexisting level ERROR in java.util.logging section",
        "description": "Page \"Logging Practices\"  Section \"java.util.logging Examples\" \n(http://hc.apache.org/httpcomponents-client/logging.html) \nsays:\n\"org.apache.http.level = FINEST\norg.apache.http.wire.level = ERROR\"\n\nHowever, there is no such thing as java.util.logging.Level.ERROR\n\nDid you mean SEVERE as in\nLogger.getLogger(\"org.apache.http.wire\").setLevel(Level.SEVERE);\n\nThanks",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-392",
        "summary": "Provide additional test coverage for HTTP and HTTPS over proxy",
        "description": "HTTP and HTTPS over proxy test coverage is still insufficient",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-914",
        "summary": "Use Apache Codec 1.4",
        "description": "1.4 fixes many bugs and added some nice features: http://commons.apache.org/codec/changes-report.html\n\nIt took me a whiel to find out, that this was the main reason my tests failed (MethodNotFoundException).\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-990",
        "summary": "Allow heuristic freshness caching",
        "description": "I noticed that the CachingHttpClient behaves strangely when it receives responses with only the public cache-control directive, e.g.:\n\nHTTP/1.0 200 OK\nServer: My test server\nCache-control: public\nContent-Length: 1\n\n1\n\n\nUsing a debugger, I could see that the response is cached. But when the response is queried from the cache, it is not considered as \"fresh\".\nAccording to the HTTP RFC, such responses \"may\" be cached (I understand it as a \"should\" in our case)... but there's no reason to put responses in the cache if we don't use them later one.\n\nThe \"freshness of the response is analysed after the response is queried from the cache, thanks to:\nCachedResponseSuitabilityChecker#canCachedResponseBeUsed()\n... calling CacheEntry#isResponseFresh()\n... returning true if the response date (getCurrentAgeSecs()) is lower than its use-by date (getFreshnessLifetimeSecs())\n\nThe issue is that getFreshnessLifetimeSecs() returns 0 when there is no max-age directive.\n\nThis could be fixed by replacing the code of CacheEntry#isResponseFresh() by:\n    public boolean isResponseFresh() {\n        final long freshnessLifetime = getFreshnessLifetimeSecs();\n        if (freshnessLifetime == 0) {\n            return true;\n        }\n        return (getCurrentAgeSecs() < getFreshnessLifetimeSecs());\n    }\n\nBut i'm not 100% confident about not producing some bad side-effects...",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-42",
        "summary": "Open up org.apache.commons.httpclient.Base64 please",
        "description": "I have had several problems lately where I needed to truck backwards and\nforwards between bytes and base64. As I am using HttpClient, I know I have the\ncode in my proect, but I need to duplicate it into my own heirarchy to get\naccess rights. \n\nPlease make appropriate changes to Base64 (can be as simple as marking the\nencode and decode methods public) to allow outside use of Base64.\n\nWould be nice to extend Base64 to deal with multi-line Base64 content too - but\nI know this is outside of Base64 original intended use. But it would be useful. :)",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-399",
        "summary": "Connection not closed after \"Connection: close\" request",
        "description": "In HTTP specification at http://www.w3.org/Protocols/rfc2616/rfc2616-\nsec8.html , under chapter \"Negotiation\", it is stated :\n\"If either the client or the server sends the close token in the Connection \nheader, that request becomes the last one for the connection.\"\n\nHttpClient (v2.0.2 and v3.0 alpha2) is currently closing connection only if \nserver has sent \"Connection: close\" header, and not when request contains it.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-649",
        "summary": "Support multiple proxies",
        "description": "HttpClient supports one proxy currently.\nOur requirement is to suppport more than one proxy. We may need to connect more than one proxies before connects to target resource. \nI found that HttpMethodDirector creates tunnelled socket and there is no easy way to plugin our custom HttpMethodDirector class with HttpClient other than extending HttpClient to override \"public int executeMethod(HostConfiguration hostconfig, final HttpMethod method, final HttpState state\" method.\n\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-34",
        "summary": "optimization in sending request",
        "description": "By doing network sniffering, I noticed that httpclient send the request line \nand headers as separate packages. All other httpclient, including IE, Netscape, \nJava's URLConnection all send it as one package. This can be easily fixed using \nsome buffering in HttpMethodBase.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-633",
        "summary": "MultiThreadedHttpConnectionManager does not properly respond to thread interrupts",
        "description": "MultiThreadedHttpConnectionManager uses interrupts to notify waiting threads when a connection is ready for them. Issues arise if the threads are interrupted by someone else while they are still waiting on a thread, because doGetConnection does not remove the threads from the queue of waiting threads when they are interrupted:\n\n                        connectionPool.wait(timeToWait);\n\n                        // we have not been interrupted so we need to remove ourselves from the \n                        // wait queue\n                        hostPool.waitingThreads.remove(waitingThread);                        connectionPool.waitingThreads.remove(waitingThread);\n                    } catch (InterruptedException e) {\n                        // do nothing                    } finally {\n                        if (useTimeout) {\n                            endWait = System.currentTimeMillis();\n                            timeToWait -= (endWait - startWait);                        }                    }\n\nUnder ordinary circumstances, the queue maintenance is done by the notifyWaitingThread method. However, if the thread is interrupted by any other part of the system, it will (1) not actually be released, since the loop in doGetConnection will force it back to the wait, and (2) will be added the waiting thread to the queue repeatedly, which basically means that the thread will eventually receive the interrupt from notifyWaitingThread at some later point, when it is no longer actually waiting for a connection.\n\nThis code could probably be re-architected to make it less error-prone, but the fundamental issue seems to be the use of interrupts to signal waiting threads, as opposed to something like a notify. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1092",
        "summary": "ClientPNames.VIRTUAL_HOST is used as is; if not provided, the port should be derived from the target URL",
        "description": "The parameter ClientPNames.VIRTUAL_HOST allows the default Host header to be overridden.\n\nCurrently the code uses the HttpHost entry as provided, and does not automatically add the port suffix.\nThis means that user code has to provide the port - but only if it's not the default for the protocol.\n\nIt would be simpler for the user if the port were automatically added.\n\nIf the user does not provide the port, the code should derive it from the target URL.\n\nIf the user does provide a port number, then that should be used (as is done currently). \nThis allows the user to override the port (if that should ever prove necessary).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1120",
        "summary": "DefaultHttpRequestRetryHandler#retryRequest should not retry aborted requests",
        "description": "DefaultHttpRequestRetryHandler#retryRequest incorrectly retries aborted requests; I have seen the following log messages in JMeter:\n\norg.apache.http.impl.client.DefaultHttpClient: I/O exception (java.net.SocketException) caught when processing request: socket closed\norg.apache.http.impl.client.DefaultHttpClient: Retrying request\n\nand\n\norg.apache.http.impl.client.DefaultHttpClient: I/O exception (java.net.BindException) caught when connecting to the target host: Address already in use: connect\norg.apache.http.impl.client.DefaultHttpClient: Retrying connect\n\nThe abort() method sets the isAborted() flag, but the retry handler does not check it.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-964",
        "summary": "no-cache directives with field names are transmitted downstream",
        "description": "\"Field names MUST NOT be included with the no-cache directive in a request.\"\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.4\n\nCurrently, the cache implementation allows a request containing something like:\n    Cache-Control: no-cache=\"Content-Location\"\nto be passed downstream towards the origin.\n\nThis is another one of those tricky situations where our client has passed us a non-compliant request.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-930",
        "summary": "Unencoded redirect URI causes exception when following redirects",
        "description": "When HttpClient is set to follow redirects, the DefaultRedirectHandler gets the redirect location from the appropriate request header and attempts to create a new java.net.URI from it. If the location contains an invalid URI character, creating the URI fails. For example, if the redirect location were \"/foo?bar=<baz/>\", it would fail because the '<' and '>' are not legal in a URI.\n\nI'm not sure if this should actually be considered a bug in HttpClient, since the website in question should probably be responsible for encoding the URI appropriately; however, browsers handle the situation gracefully, and it would be nice if this excellent library would do so as well.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-484",
        "summary": "Fold AuthSSLProtocolSocketFactory into HttpClient proper",
        "description": "Include the functionality of the AuthSSLProtocolSocketFactory class into the\nmain distribution of HttpClient\n\nhttp://svn.apache.org/repos/asf/jakarta/commons/proper/httpclient/trunk/src/contrib/org/apache/commons/httpclient/contrib/ssl/",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-997",
        "summary": "cache module should handle out-of-order validations properly and unconditionally refresh",
        "description": "There is a protocol recommendation that when we attempt to revalidate a cache entry, but we receive a response that has a Date header that's actually *older* than that of our current entry, we SHOULD revalidate again unconditionally with either max-age=0 or no-cache (since some upstream cache would appear to be out-of-date).\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.2.6\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-233",
        "summary": "HttpMethodBase Javadoc patches",
        "description": "Clarify that HTTP 1.1 is the default. Attaching.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-144",
        "summary": "Add a document describing the HttpClient release process",
        "description": "The commons release process (http://jakarta.apache.org/commons/releases.html) is\na good starting place, but is out of date.  When we do our own releases, there\nare some other steps particular to maven, the test-local and the webapp tests\nthat must be documented.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-806",
        "summary": "ConnectException not handled in DefaultHttpMethodRetryHandler",
        "description": "Copied from my mailing list post, Oleg suggested I post it to JIRA for 4.0 fix.\n\ni am using commons-httpclient.3.0.1 and I am sending some requests\nthrough https protocol. I have a problem with a long creation of\nconnection if ip address of remote service is not existing. I think\nproblem is in the situation when https connection is not created and\nConnectException is thrown after connection timeout. This exception is\ncatched in HttpMethodDirector.java in method executeWithRetry. Then\nthe DefaultHttpMethodRetryHandler is called to recognize whether\nconnection creation will be repeated or not.\nI think, that special handling for ConnectException is missing in\nretryMethod of DefaultHttpMethodRetryHandler, because exception is not\nrecognized and connetions are created again.\nOn the other hand, ConnectTimeoutException is thrown after connection\ntimeout for HTTP. This exception is handled in\nDefaultHttpMethodRetryHandler and call is stopped.\n\nThese lines of code handle ConnectTimeoutException in retryMethod of\nDefaultHttpMethodRetryHandler:\nif (exception instanceof InterruptedIOException) {\n            // Timeout\n            return false;\n        }\n\nProbably this is missing for ConnectException:\nif (exception instanceof InterruptedIOException || exception\ninstanceof ConnectException) {\n            // Timeout\n            return false;\n        }\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-475",
        "summary": "Provide support for unconnected sockets",
        "description": "Overview description:\nIf Proxy settings are incorrect or host does not reply, the\nHttpClient.executeMethod() hangs, and HttpMethod.abort() does not stop it. Thus,\nyou cannot assert that the entire application will stop immediately on demand.\n\nExpected Results:\nDuring a HttpMethod.executeMethod(), HttpMethod.abort() should cancel\nimmediately the executeMethod().\n\nActual Results:\nIf HttpMethod.executeMethod() freezes because of Proxy bad settings or not\nresponding hostname (in fact impossible to open the socket), the abort() method\ndoes not do anything.\n\nPlatform:\nI tested it on Windows XP and Linux Debian with HttpClient 3.0 RC2 (but if you\nlook further I point the problem and the source code of the nightly build is\nidentical).\n\nSee comments for the dialogue about the problem, and 2 Test cases. The solution\nis described at the end, but it may implies a change in the API and works only\nsince Java 1.4.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-520",
        "summary": "MultipartEntity incorrectly computes unknown length",
        "description": "If any Part of a MultipartEntity reports an unknown length (-1), MultipartEntity\nreports an erroneous length value. It should report an unknown length (-1) if\nany of the parts is of unknown length, that would cause the POST to be chunked.\n\nSee\nhttp://mail-archives.apache.org/mod_mbox/jakarta-httpclient-user/200510.mbox/ajax/%3ceb3d689c0510250851t2eb78462tbf701135bbf718c9@mail.gmail.com%3e",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1061",
        "summary": "Proxy-Authorization header received on server side",
        "description": "\n \n I'm following example\n http://hc.apache.org/httpcomponents-client-ga/examples.html\n Proxy authentication\n \n but it seems that not only proxy is receiving credentials for proxy.\n In log, which is generated at target.host I can see header\n Proxy-Authorization: Basic ....\n\n--------- HEADER\nHost:target.host:443\nConnection:Keep-Alive\nUser-Agent:Apache-HttpClient/4.1 (java 1.5)\nProxy-Authorization:Basic Z\n--------- POST\n\n\nDusan",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-972",
        "summary": "caching module should use HttpParams-style configuration",
        "description": "The constructor for CachingHttpClient currently accepts combinations of:\n* HttpCache\n* HttpClient\n* integer for max object size in bytes\n\nAs I started looking at being able to configure this for behaving as a non-shared cache, I realized that we actually want to be replacing that last int with an HttpParams argument, and tracking all the various options in that style. I have a patch with this update which I will upload shortly.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-449",
        "summary": "RequestEntity, EntityEnclosingMethod have inconsistent Javadocs, use deprecated variables",
        "description": "Robert Manning <Robert.Manning at collabraspace.com> reported a problem on the\nhttpclient-user list regarding inconsistencies in javadoc of RequestEntity\ninterface and EntityEnclosingMethod class. This prompted me to review the said\nclasses. I have discovered several issues that must be dealt with before 3.0\ngoes final. \n\n(1) There's virtually no test coverage for the EntityEnclosingMethod class\n(2) The code in EntityEnclosingMethod class extensively uses deprecated methods\nand variables beyond what is required to maintain backward compatibility with\n2.0.x API\n(3) Existing code cannot gracefully handle faulty RequestEntity implementations\nif the getContentLength method returns a negative value < -2\n\nI have committed additional test cases to cover the most fundamental\nfunctionality of EntityEnclosingMethod:\nhttp://svn.apache.org/repos/asf/jakarta/commons/proper/httpclient/trunk/src/test/org/apache/commons/httpclient/TestEntityEnclosingMethod.java\n\nI will submit a patch addressing issues (2) and (3) shortly\n\nOleg",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-302",
        "summary": "exception during writeRequest leaves the connection un-released",
        "description": "The execute method has the following (simplified) flow:\n1) get connection\n2) write request\n3) read result\n4) release connection.\nThe release in step 4 happens when the input is completely read, which works fine.\nIf an exception occurs between steps 1 and 2, the connection is also released\nproperly.\nHowever, if an exception occurs during step 2, the connection is never released\nback and the connection manager eventually runs out of connections.\n\nThe easiest way to test this is to make a simple subclass of PostMethod that\noverrides the writeRequest method:\n\npublic class TestConnectionReleaseMethod extends PostMethod\n{\n    protected void writeRequest(HttpState state, HttpConnection conn) throws\nIOException, HttpException\n    {\n         throw new IOException(\"for testing\");\n    }\n}",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-315",
        "summary": "HttpURL creates wrong authority String when user info is changed",
        "description": "When changing the user info on an existing HttpURL which has additional port\ninformation, the new authority String contains a wrong hostname part: instead of\ngetting \"hostname:portnumber\" the string is \"hostnameportnumber\", i.e. the \":\"\nis missing.\nMethods which needs to be changed are:\n\nsetRawPassword(...)\nsetRawUser(...)\nsetRawUserinfo(...)\n\n(look for the line\nString hostport = (_port == -1) ? hostname : hostname + _port;\n)\n\nAndreas F\u00c3\u00a4nger\nESIGN Software GmbH",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-559",
        "summary": "SSL contrib files do not use standard javax.net.ssl package provided from JDK 1.4.2",
        "description": "Hi all,\n\nWhile trying to use ssl on AIX, i found that some of the files contributed in \nsrc/contrib/org/apache/commons/httpclient/contrib/ssl were making hard \nreferences to com.sun.net.ssl package. Since JDK 1.4.2, one shall use the \njavax.net.ssl package instead.\n\nI have then:\n1/ fixed the source files appropriately\n2/ updated the build.xml to also build a commons-http-client-contrib.jar \n\nI will attached to this bug report the resulting unified diff to include in svn",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-129",
        "summary": "multipart feedback",
        "description": "never got a reply on this from 10/20/02 mailing to email address in \"author\" tag, so posting here.\n-----------------------\nMatt and Jeff,\n\nExcuse me for writing directly to the addresses found in the code as authors.  Please feel free to forward this to any list that is more appropriate.\n\nThank you very much for your efforts in making an HTTP client for Java.  It will find great use.  Below are some aspects of the org.apache.commons.httpclient.methods.multipart package that I'd like you to consider.  \n\nFirst, consider making the encoding a parameter.  Currently, the content disposition and other general-purpose headers are written with a String.getBytes () call, which will use the default encoding on whatever client is being used by the customer.  Does the RFC and for HTTP post specify an encoding for these lines?  Perhaps the header information and disposition information should be a standard UTF-8 encoding, and an additional parameter could specify encoding for anything supplied by the users of the library, most notably the StringPart.\n\nSecond, consider that the content length header may not be important for many contexts.  When you receive a post on the server side, can you depend on the content length header?  Some browsers do not supplied this header, and even if all of them did, would you be wise to believe it on the server side?  In fact, common libraries for handling post, most notably http://www.servlets.com/cos/index.html , ignore any content length header that is supplied by the client.  On the server side, content length is calculated from the actual bytes that are received.\n\nWhy do I mention this?  Because it appears that a trade-off has been made in this alpha code such that the content length calculation was more important than polymorphism in Part.java:\n\n    /* The following 2 methods don't need to be final, but they DO need\n     * to be overridden as a pair, and the only way to make sure of that\n     * is to make sure they AREN'T overridden. \n     */\n\n    final public void send(OutputStream out) throws IOException {\n        sendStart(out);\n        sendHeader(out);\n        sendEndOfHeader(out);\n        sendData(out);\n        sendEnd(out);\n    }\n    \n    final public long length() throws IOException {\n        return lengthOfStart() + \n               lengthOfHeader() + \n               lengthOfEndOfHeader() +\n               lengthOfData() + \n               lengthOfEnd();\n    }\n\nThe method send() seems like an important method to be able to override.  For example, consider a situation where the post content is zipped on-the-fly.  The content length is not known when writing the headers.  Further, it would be handy to override certain methods like send() in order to manipulate the output stream. \n\nBasically, since your library will be very general purpose and used widely, the more you can do for easy polymorphism, the more your customers will appreciate your library. Is there a way to make the content length calculation and header writing more flexible, so that it may be avoided when it is not known a priori?\n\nThird, consider making the content type a parameter for a FilePart.  In the example above, the content type for the zipped file should be \"application/x-zip-compressed\" rather than \"application/octet-stream\".\n\nAgain, I was very happy to find your excellent work on this library. Thank you for your contributions to apache jakarta.\n\nlarry hamel",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-382",
        "summary": "Move multipart request to a new RequestEntity type",
        "description": "Multipart posts are currently handled via a separate post method, the MultipartPostMethod.  This \nseparate method is unnecessary given the new RequestEntity mechanism.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1016",
        "summary": "Adding a custom location header extractor method for RedirectStrategy.",
        "description": "Sometimes Web Servers respond to http requests with non-standard location response headers during a server side redirect. (302)  ADding a convenience method to over come this.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-974",
        "summary": "RequestWrapper does not use the headers of the request it wraps.",
        "description": "The RequestWrapper does not use the headers of the request it wraps. Therefore the wrapper appears as having no header, while the wrapped request may have some.\n\nTo work-around that behavior, I have to call resetHeaders() on the wrapper just after having created it.\nThis method does the following:\n    public void resetHeaders()\n    {\n        headergroup.clear();\n        setHeaders(original.getAllHeaders());\n    }\n\nI suggest calling setHeaders directly in the constructor. Or at least highlight in the Javadoc that we should call resetHeaders().",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-241",
        "summary": "Support for handling large files should be added",
        "description": "You should probably change the EntityEnclosingMethod content length field \nto a long in a future release. Currently it's an int.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1131",
        "summary": "Support http URL inline authentication",
        "description": "If you try to execute a method with the httpClient using a valid url, conform to the schema http://username:password@host:port/ the authentication will fail, and you will get a 401 error.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-656",
        "summary": "IP address of the server of a HttpConnection",
        "description": "AFAIK it's not possible to get the IP address of the server of a HttpConnection.\n\nI propose to add a getServerAddress() method to the HttpConnection class that returns the IP address of the server, if the connection has been opened.\nAnd either returns null or throws an Exception if the IP address is not available, i.e. the connection is not open.\n\nBelow is a workaround for getting the IP address in current versions.\n\n-----------------------\npackage org.apache.commons.httpclient;\n\nimport java.io.IOException;\nimport java.net.InetAddress;\n\npublic class InetAddressFetcher {\n\tprivate HttpConnection hc;\n\n\tpublic InetAddressFetcher(HttpConnection hc) {\n\t\tthis.hc = hc;\n\t}\n\n\tpublic InetAddress getInetAddress() throws IOException {\n\t\tif (!hc.isOpen()) {\n\t\t\thc.open();\n\t\t}\n\t\treturn hc.getSocket().getInetAddress();\n\t}\n}",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-530",
        "summary": "Findbugs reports and fixes",
        "description": "Ran findbugs 0.94.rc1 on 3.0RC4. \nFixed a few of the obvious ones (patches to follow) and made notes on the \nremainder - see the //TODO markers in code.\nAlso created a findbugs target in build.xml - see appropriate patch file",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-666",
        "summary": "Replace HttpState with CredentialsProvier and CookieStore interfaces",
        "description": "Replace HttpState, which is a concrete class, with CredentialsProvier and CookieStore interfaces. Provide default impls of those interfaces.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-425",
        "summary": "URI.getHost() generates IllegalArgumentException",
        "description": "Hi guys,\n\nI don't know if I'm doing something wrong or not but the following code:\n\n   URI uri = new URI(\"mailto:eay@cryptsoft.com\", true);\n   System.out.println(uri.getHost());\n\ngenerates the following exception:\n\njava.lang.IllegalArgumentException: Component array of chars may not be null\n\tat org.apache.commons.httpclient.URI.decode(URI.java:1722)\n\tat org.apache.commons.httpclient.URI.getHost(URI.java:2780)\n\nCould you help?\n\nAlso, I'm sorry I put the report under version \"3.0 Final\" but I couldn't find \nan entry for \"3.0-RC1\" (which I'm using at the moment).\n\nThanks a lot!\n\nBisser",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-385",
        "summary": "Access to SO_TIMEOUT for open connections",
        "description": "I'm trying to access a set of pages in order, for which I have a maximum delay\npermissible.  The complete operation includes following all redirects and\nfetching the complete page content.  What I need, which doesn't seem to be\ndoable right now (according to the common-users list) is to reset the SO_TIMEOUT\nproperty of the socket before each read to the inputstream.  I'd need an access\nto the HttpConnection, or a way to set the parameters for that object.\n\nThis is a simplified version of what I'm doing:\n-----\nHttpURL url = new HttpURL(urlString);\nmethod.setURI(url);\nmethod.setFollowRedirects(false);\nmethod.getParams().setSoTimeout(remainingTime);\nHostConfiguration hostConfig = new HostConfiguration();\nhostConfig.setHost(url);\nmethod.setHostConfiguration(hostConfig);\ntimeoutChecker.getRemainingTime());\n\nint statusCode = client.executeMethod(hostConfig, method, state);\nString pageContent;\n\nif (isRedirect(statusCode)) {\n    if (timeoutChecker.isTimeout()) {\n        throw new TimeoutException(\"Total execution time for fetch exceeded\ntimeout parameter\");\n    } else {\n        Header locationHeader = method.getResponseHeader(\"location\");\n        HttpURL nextLocation = new HttpURL(locationHeader.getValue().toCharArray());\n        pageContent = fetchGet(nextLocation.getEscapedURI(), addressHolder,\ntimeoutChecker, state);\n    }\n} else if (isSuccess(statusCode)) {\n    // at least 4K buffers, might be as big as the webpage\n    int responseSize = Math.max(getResponseSize(method), DEFAULT_RESPONSE_SIZE);\n    InputStream response = method.getResponseBodyAsStream();\n    ByteArrayOutputStream outstream = new ByteArrayOutputStream(responseSize);\n    byte[] buffer = new byte[responseSize];\n    int len;\n    do {\n        // ***TODO need to reset the SO_TIMEOUT to the remaining time\n        len = response.read(buffer);\n        outstream.write(buffer, 0, len);\n    while ((len > 0) && !timeoutChecker.isTimeout());\n    outstream.close();\n    pageContent = EncodingUtil.getString(outstream.toByteArray(),\nmethod.getResponseCharSet());\n    response.close();\n} else {\n    ...\n}",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-195",
        "summary": "NTLM authentication failed due to closing of connection",
        "description": "Description:\n\nWhen dealing with a NTLM proxy server that sends response back with lines:\n\n14:51:27:750 << HTTP/1.0 407 Proxy Authentication Required\n14:51:27:796 << Date: Mon, 14 Apr 2003 19:52:43GMT[\\r][\\n]\n14:51:27:796 << Content-Length: 257[\\r][\\n]\n14:51:27:796 << Content-Type: text/html[\\r][\\n]\n14:51:27:796 << Server: NetCache appliance (NetApp/5.3.1R1)[\\r][\\n]\n14:51:27:796 << Connection: keep-alive[\\r][\\n]\n14:51:27:796 << Proxy-Authenticate: NTLM \nTlRMTVNTUAACAAAABgAGACgAAAAGggEAtOoNy4M0g0EAAAAAAAAAAEdMT0JBTA==[\\r][\\n]\n\nThe httpClient code is using the \"HTTP/1.0\" as clue for closing the connection \nand ignored the \"Connection: keep-alive\".  That caused the NTLM authentication \nto fail as the NTLM requires the response to the challenge to be sent back on \nthe same connection.\n\nProposed Fix:\n\nOur fix is to add a flag inProxyAuthenticationRetry (in HttpMethodBase) to \nindicate that the method is doing proxy authentication retry.  When the flag is \ntrue, in \"HttpMethodBase.shouldCloseConnection\", check the \"Connection: keep-\nalive\" before determining to close the connection.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-999",
        "summary": "need tests to guarantee transparency of caching module on end-to-end headers",
        "description": "\"A transparent proxy SHOULD NOT modify an end-to-end header unless the definition of that header requires or specifically allows that.\"\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.5.2\n\nThis is already true of our implementation, but we should have tests to preserve that behavior.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "TEST"
    },
    {
        "key": "HTTPCLIENT-279",
        "summary": "Connections are not release when a recoverable exception occurs.",
        "description": "Please see the url for discussion details.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-996",
        "summary": "SSL does not seem to work at all",
        "description": "Whenever I try to request content via https I get this exception:\n\n\nException in thread \"main\" javax.net.ssl.SSLException: hostname in certificate didn't match: <140.211.11.131> != <*.apache.org>\n\tat org.apache.http.conn.ssl.AbstractVerifier.verify(AbstractVerifier.java:220)\n\tat org.apache.http.conn.ssl.BrowserCompatHostnameVerifier.verify(BrowserCompatHostnameVerifier.java:54)\n\tat org.apache.http.conn.ssl.AbstractVerifier.verify(AbstractVerifier.java:149)\n\tat org.apache.http.conn.ssl.AbstractVerifier.verify(AbstractVerifier.java:130)\n\tat org.apache.http.conn.ssl.SSLSocketFactory.createSocket(SSLSocketFactory.java:399)\n\tat org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:143)\n\tat org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:149)\n\tat org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:108)\n\tat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:415)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:641)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:576)\n\tat org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:554)\n\tat HttpsTest.fails(HttpsTest.java:25)\n\tat HttpsTest.main(HttpsTest.java:12)\n\n\nI can reproduce this whith the following code:\n\n\nimport org.apache.http.client.HttpClient;\nimport org.apache.http.client.methods.HttpGet;\nimport org.apache.http.impl.client.DefaultHttpClient;\n\npublic class HttpsTest {\n\n    public static void main(final String[] args) throws Exception {\n        final HttpClient client = new DefaultHttpClient();\n        final HttpGet req = new HttpGet(\"https://www.apache.org\");\n        client.execute(req);\n    }\n\n}\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-541",
        "summary": "Redesign virtual host API",
        "description": "HttpClient is ignoring an explicity set host.  e.g. if you set the host like\nclient.getHostConfiguration().setHost(\"127.0.0.1\") then execute a method looking\nup say http://google.com then the program will connect to google.com rather than\nthe localhost.\n\nThe fix that works for me:\ndiff -Naur\n../../t2/commons-httpclient/src/java/org/apache/commons/httpclient/HttpClient.java\nsrc/java/org/apache/commons/httpclient/HttpClient.java\n---\n../../t2/commons-httpclient/src/java/org/apache/commons/httpclient/HttpClient.java\n2005-12-22 01:06:54.000000000 +1300\n+++ src/java/org/apache/commons/httpclient/HttpClient.java\t2005-12-22\n19:13:30.000000000 +1300\n@@ -383,7 +383,9 @@\n         if (hostconfig == defaulthostconfig || uri.isAbsoluteURI()) {\n             // make a deep copy of the host defaults\n             hostconfig = new HostConfiguration(hostconfig);\n-            if (uri.isAbsoluteURI()) {\n+\t    // if the host is explicity set already (e.g. to the IP of the virtual host\n+\t    // on which we are executing a method), just leave it\n+            if (uri.isAbsoluteURI()  && hostconfig.getHost()==null) {\n                 hostconfig.setHost(uri);\n             }\n\nNote: Why do we care that the host is specified?  Why not just use the uri\nauthority?  In my case I have a virtual host running on several servers/IPs and\nI need to make sure the request goes through to a specific IP and the response\nthat comes back is for the virtual host I am testing.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-818",
        "summary": "No documentation on how to use CookieSpec",
        "description": "None of http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/cookie/CookieSpec.html, http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/cookie/CookieSpecFactory.html, http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/cookie/CookieSpecRegistry.html, or http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/impl/client/DefaultHttpClient.html explain how to set the CookieSpec that the HttpClient actually uses. It looks like CookieSpecRegistry might be it, but it doesn't document what the \"names\" mean, so I don't know what to pick to make a factory actually get used.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1132",
        "summary": "porting of ProxyClient from 3.1 to 4.x API",
        "description": "With 3.1 version of HttpClient it was possible to establish a tunneled connection to a generic non http server through an authenticated proxy, but since 3.1 version does not support NTLMv2 and Kerberos authentication, that are supported in 4.x version, it is very useful to port the features provided by ProxyClient to 4.x API.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-1031",
        "summary": "Cannot clone BasicClientCookie2 without specified ports",
        "description": "The clone method returns a null pointer exception when called on a BasicClientCookie2 that does not use any ports properties.\nIn other words, it is impossible to clone a BasicClientCookie2 instance without ports specification.\n\nIn the clone() method, they are two main instructions :\n - calling clone() method on super\n - calling clone() method on the ports integer array (which is null)\n\nIt may be a good idea to check whether the array is null or not\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-659",
        "summary": "DateUtils should cache SimpleDateFormat",
        "description": "DateUtils create a SimpleDateFormat for each invocation of #formatDate and #parseDate. This can be optimized if SimpleDateFormat instances are cached. Since SimpleDateFormat is not threadsafe, the cache must be threadlocal.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-552",
        "summary": "Add shutdown method to SimpleHttpConnectionManager",
        "description": "It would be useful to be able to close the connection in the\nSimpleHttpConnectionManager. This could be achieved by adding a shutdown()\nmethod as per the MultiThreadedConnectionManager.\n\nIdeally this would be added to the HttpConnection interface, but this could\nbreak existing implementations.\n\nTo avoid this, perhaps consider introducing a sub-interface with the method in it.\n\n[Could also create an AbstractConnectionManager class - this would make it\neasier to add more functions later]",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1105",
        "summary": "Built-in way to do auto-retry for certain status codes",
        "description": "The HttpRequestRetryHandler mechanism is great.  It allows API users to plug in their own logic to control whether or not a retry should automatically be done, how many times it should be retried, etc.  That works perfectly in scenarios where an exception is caught while issuing the request.  It falls short, however, in this scenario...\n\nIf I'm hitting a service that returns a 503, I want to be able to retry that request automatically as well.  As of right now, I need to write my own logic to accomplish that, and it's clunky trying to integrate it with the httpClient.execute() call, since it's my ResponseHandler impl that ends up getting the 503.  I can see use cases for auto-retrying upon getting other HTTP statuses as well, not just 503.\n\nMy request here is...I would love to be able to configure, either on the HttpClient itself or on a wrapping class or something, that a request should automatically be retried if the HTTP status code is among of a set of statuses that I configure.  It would be nice if you could set the max # of retries, an optional sleep time in between retries (perhaps optional incremental backoff if you want to get fancy).  I'm not sure if this is possible, but it would be nice if -- when this type of status-based retry is enabled -- my ResponseHandler wouldn't even get invoked until retry was successful.\n\nHere's an alternative suggestion, possibly simpler to build, but definitely not as elegant:\n\nIn my ResponseHandler, you could throw a RetryRequestException or something like that, and the calling code would catch that and do as expected.  That might simplify the mechanism so to speak.\n\nAnyway, I would love not to have to roll my own retry code, since I suspect this is something that hundreds (thousands?) of HttpClient users have had to code.  Seems like providing a standardized, well-written way to do it would go a long way to helping many coders out there.\n\nThanks!",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-1041",
        "summary": "Enabling wire logging changes isEof/isStale behavior",
        "description": "If you enable wire logging, DefaultClientConnection wraps the SocketInputBuffer with a LoggingSessionInputBuffer. This hides the EofSensor interface implemented by SocketInputBuffer (but not LoggingSessionInputBuffer), which makes at least AbstractHttpClientConnection.isEof() and isStale() methods behave differently.\n\n(That is, stale connection checks won't really work as intended if wire logging is enabled. Which makes it a bit difficult to debug problems related to stale connections...)\n\nProposed fix: implement EofSensor interface in LoggingSessionInputBuffer (delegating it to wrapped buffer).\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-441",
        "summary": "Cookie.java hashCode method violates contract",
        "description": "org.apache.commons.httpclient.Cookie hashCode() does not meet object.hashCode\n() contract.  Cookie.hashCode() returns different values even though data used \nin equals() comparison is the same.\n\nContract:**Whenever it is invoked on the same object more than once during an \nexecution of a Java application, the hashCode method must consistently return \nthe same integer, provided no information used in equals comparisons on the \nobject is modified.**\n\nBreaks use of cookie within collections such as when using contains().\n\nTraced problem back to parent class NameValuePair.  Cookie.hashCode() calls \nNameValuePair.hashCode() which relies on name/value hashes.  Cookie does not \nrely on value to determine equality.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-50",
        "summary": "User configurable cookie policy",
        "description": "Some user configurable how cookies are handled.  Emulate cookie options in web\nbrowsers.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-616",
        "summary": "HttpMethodDirector.executeWithRetry method fails to close the underlying connection if a RuntimeException is thrown",
        "description": "The following code snippet is from the end of the HttpMethodDirector.executeWithRetry method:\n\n        } catch (IOException e) {\n            if (this.conn.isOpen()) {\n                LOG.debug(\"Closing the connection.\");\n                this.conn.close();\n            }\n            releaseConnection = true;\n            throw e;\n        } catch (RuntimeException e) {\n            if (this.conn.isOpen) {                                             <<<===========================   BAD!  :-)\n                LOG.debug(\"Closing the connection.\");\n                this.conn.close();\n            }\n            releaseConnection = true;\n            throw e;\n        }\n\nWhen an IOException is caught, you can see that the \"open\" status of the connection is accurately checked by calling the \"isOpen()\" method.\n\nWhen a RuntimeException is caught, however, the code mistakenly checks only the \"isOpen\" member field.  In the case where \"conn\" is, for example, a MultiThreadedHttpConnectionManager, the \"isOpen()\" method is overridden to check for a wrapped connection and returns the \"isOpen\" status of that connection.  In cases like that checking the \"isOpen\" member field is obviously wrong and we end up not calling \"close()\" and the connection is not cleaned up.  This causes issues with later calls.\n\nA very difficult bug to diagnose and <steps up on soapbox> one that could have been easily avoided by making member variables private! <steps down>  thank you.  :-)\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-46",
        "summary": "Plug-in authentication modules",
        "description": "Currently only basic authentication is supported.  A Authentication interface\nshould be provided to allow for plug-in support for other authenticaiton\nschemes, some of which may be application specific and therefore have no place\nin httpclient itself, but would be required by some users.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-298",
        "summary": "javadoc often has <code> without </code>",
        "description": "Just to mention it:\nthere are a lot of javadoc comments that read like\n <tt>false</ff> otherwise.\nwhich prints the rest of the document in <tt>\ncan't give a complete list, it happens very often.\nTo check, just go to the bottom of a page and see if it appears in <tt> or \n<code>",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1029",
        "summary": "Update 3.x legacy homepage with end of life notification and pointer to HTTPComponents",
        "description": "If you google for \"http client\" or \"httpclient\" or \"apache http client\" the first result is always legacy Commons-HttpClient page.  If you follow the link, there's no indication whatsoever on the legacy page that its not the latest version, or that it's end-of-lifed.  Unless you're already aware of HttpComponents, there's no obvious way to find it from the legacy page.  The only reference to HttpComponents is actually in the 'History' section.  \n\nThe source for the legacy page should be updated to indicate Commons-HttpClient is an end-of-lifed project and should provide a pointer to the new HttpComponents page in a more prominent location.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-165",
        "summary": "'100-continue' response times out unexpectedly",
        "description": "Entity encosing methods time out (3 seconds) rather than getting the\n100-continue response. Then, after it has send the body, the 100-continue\nresponse is received and returned.\n\nAdding\n\n  method.setUseExpectHeader(false);\n\nseems to fix it.\n\nPlatform 1: Jetty server on Windows XP, Sun JDK 1.4.1_01, \nPlatform 2: Tomcat-4.1.18 + Turbine on Windows 2000 Pro, Sun JDK 1.3.1\nPlatform 3: Tomcat-4.1.18 on Linux if the connection is running over stunnel-4.00\n\nReported by: \n Simon Roberts <simon.roberts@fifthweb.net>\n Aurelien Pernoud <apernoud@sopragroup.com>\n Ingo Brunberg <ib@fiz-chemie.de>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-80",
        "summary": "PostMethod - Chunked requests are not supported at the moment.",
        "description": "For Apache Axis, we'd like send a POST request without needing to calculate the\ncontent-length for HTTP 1.1 based servers. Of course if the server-side does not\nsupport 1.1 then a fallback mechanism could calculate the total size under the\ncovers. \n\nAlso see related request from \"Trevor O'Reilly\" <wtrevor@yahoo.com>:\nhttp://marc.theaimsgroup.com/?l=jakarta-commons-user&m=102719653201792&w=2",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-467",
        "summary": "CookieSpecBase.domainMatch() leaks cookies to 3rd party domains",
        "description": "The change committed for #32833\n<http://issues.apache.org/bugzilla/show_bug.cgi?id=32833> is buggy; it doesn't\nmatch browser behavior and in fact leaks cookies to third party domains. \n\nTo see, try the following:\n\nCookieSpecBase cspec = new CookieSpecBase();\nCookie cookie = new Cookie(\".hotmail.com\",\"foo\",\"bar\",\"/\",Integer.MAX_VALUE,false);\ncspec.match(\"iwanttostealcookiesfromhotmail.com\",80,\"/\",false,cookie);\n\nIt will return true. Testing in Firefox1.0.4 and IE6 show no such similar\nleakage for similar cases. (Indeed, it'd be a headline-making privacy bug if\nthey were to do this.)\n\nThose browsers do, in my limited testing, behave as desired by the filer of\n#32833: a cookie of domain value '.mydomain.com' will be returned to exact host\n'mydomain.com' (. However, the fix that was suggested was overbroad.\n\nI suggest instead for CookieSpecBase.domainMatch():\n\n    public boolean domainMatch(final String host, final String domain) {\n// BUGGY: matches a '.service.com' cookie to hosts like 'enemyofservice.com'\n//        return host.endsWith(domain)\n//            || (domain.startsWith(\".\") && host.endsWith(domain.substring(1)));\n// BETTER: RFC2109, plus matches a '.service.com' cookie to exact host 'service.com'\n        return host.equals(domain)\n            || (domain.startsWith(\".\") \n                    && (host.endsWith(domain)\n                            || host.equals(domain.substring(1))));\n    }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1044",
        "summary": "DefaultHttpRequestRetryHandler is not handling PUT as an idempotent method for retries, though RFC2616 section 9.1.2 clearly defines it to be one.",
        "description": "See attached patch file for a fix:\n\nFix treats PUT requests as idempotent, marking them to be retried when their enclosed HttpEntity is either null or repeatable.\n\n",
        "label": "NUG",
        "classified": "SPEC",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-594",
        "summary": "HttpMethodBase#aborted variable mistakenly declared transient instead of volatile",
        "description": "HttpMethodBase#aborted variable mistakenly declared transient instead of volatile. This is quite nasty. \n\nDo we want to cut an emergency release (3.0.2) because of that or can this wait until 3.1-beta1?\n\nFix attached.\n\nOleg",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-81",
        "summary": "need getResponseContentLength in HttpMethod",
        "description": "We need a way to find out the response content length in HttpMethod",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-880",
        "summary": "Check for correct content-type in URLEncodedUtils not working for encoding-suffixes",
        "description": "Dear DEV-Team,\n\ni am developing an application with the httpclient. Today i found a small problem, related to URLEncodedUtils.\n\nOur Tomcat-Server deliveres for Server-Requests, the HTTP-Header: \"Content-Type=application/x-www-form-urlencoded;charset=UTF-8\", but the httpclient only checks for: \"Content-Type=application/x-www-form-urlencoded\". This failing check results in an empty result of call to the method: URLEncodedUtils.parse(entity);\n\nFollowing source-code causes the prob: \n\npublic class URLEncodedUtils {\n\n    /**\n     * Returns true if the entity's Content-Type header is\n     * <code>application/x-www-form-urlencoded</code>.\n     */\n    public static boolean isEncoded (final HttpEntity entity) {\n        final Header contentType = entity.getContentType();\n        return (contentType != null && contentType.getValue().equalsIgnoreCase(CONTENT_TYPE));\n    }\n}\n\nIMO the method should be changed to:\n\n\npublic class URLEncodedUtils {\n\n    /**\n     * Returns true if the entity's Content-Type header is\n     * <code>application/x-www-form-urlencoded</code>.\n     */\n    public static boolean isEncoded (final HttpEntity entity) {\n        final Header contentType = entity.getContentType();\n        return (contentType != null && contentType.getValue().startsWith(CONTENT_TYPE + \";\"));\n    }\n}\n\nBest Regards,",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-982",
        "summary": "Could we get a way to know if the response has been served from the cache or not ?",
        "description": "Is there a way to know if the response has been served from the cache or not ?\nThat's an information which might be useful for monitoring the activity of the cache.\n\nIf there's no current way, maybe a flag could be added in the request context whenever the response comes from the cache ... ?\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-114",
        "summary": "httpclient build requires jdk 1.4 or jce in classpath",
        "description": "Currently when a 'ant dist'\nis performed httpclient is looking for javax.crypt.* which is in jce.jar\n\nThe build.xml and build.properties.sample need to be patched\nso they allow the jce.jar file to be specified\njust like the jsse.jar is specified.\n\nwill attach two patch files made from todays cvs",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-989",
        "summary": "DefaultHttpRequestRetryHandler must not retry non-idempotent http methods (violates RFC 2616)",
        "description": "In DefaultHttpRequestRetryHandler, in case of NoHttpResponseException, the request is retried, without taking into account whether the http method is idempotent or not. This violates RFC 2616 section 8.1.4 which states :\n{quote}\nThis means that clients, servers, and proxies MUST be able to recover\n   from asynchronous close events. Client software SHOULD reopen the\n   transport connection and retransmit the aborted sequence of requests\n   without user interaction so long as the request sequence is\n   idempotent (see section 9.1.2). Non-idempotent methods or sequences\n   MUST NOT be automatically retried, although user agents MAY offer a\n   human operator the choice of retrying the request(s).\n{quote}\n\nThe fix is simple : at line 94, just remove the {{if (exception instanceof NoHttpResponseException) }} block. This way the idempotency of the method will be taken into account a bit further in the same method.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-943",
        "summary": "CacheClient Javadoc and Constants usage cleanup",
        "description": "CacheClient has some empty public java doc on methods that are not get/set.  These should have some body.  \n\nAlso the HeaderConstants Class has some overlap with the existing HTTP class for header values.  These need cleaning up.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-926",
        "summary": "Add Amazon S3 authentication support",
        "description": "Add support for the the Amazon S3 authentication scheme as defined by the online document: http://docs.amazonwebservices.com/AmazonS3/latest/index.html?RESTAuthentication.html",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-278",
        "summary": "Add the ability to disable the content-type and transfer encoding headers for Parts",
        "description": " ",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-506",
        "summary": "Digest auth uses wrong uri in proxy authentication",
        "description": "I'm having a problem getting httpclient-rc1 to authenticate using\ndigest to our IAS server.  I've tried upgrading to rc3 without any\neffect.  I also got our IT guys to upgrade IAS without luck.  I was\nalso able to have the GET method work under IAS and CONNECT to work\nwith a couple other proxy servers.  After examining ethereal logs for\nmy (commons) code and firefox to the same URLs I noticed that the\nvalue for the \"uri\" setting in the \"Proxy-Authorization\" header was\nthe only significant difference.  After looking at RFC 2617 I noticed\nthat in section 3.2.2 (The Authorization Request Header) it states:\n\ndigest-uri\nThe URI from Request-URI of the Request-Line; duplicated here because\nproxies are allowed to change the Request-Line in transit.\n\nA re-examination of the headers showed that firefox was matching the Request-URI\nwith the digest-uri but that httpclient was not.  I reproduced partial headers\nbelow.  I tried modifying the RC3 source to produce a hard-coded value for \"uri\"\nand demonstrated that it would successfully authenticate to that URI.  I also\nchecked that authentication would fail to any other URI and it did.\n\npartial httpclient header (fails with 407):\nCONNECT gmail.google.com:443 HTTP/1.1\nProxy-Authorization: Digest username=\"proxytest\", realm=\"Digest\",\nnonce=\"503902c343c8c501057a85cea6bad2734378fb44b4cbd1970bf320637871dae85373082cf70ac254\",\nuri=\"/\", response=\"7717d0738332a3d8e83e9102b5ead6b9\", qop=\"auth\", nc=00000001,\ncnonce=\"583aa0469b31290dc2acd7ec6cfc98f1\", algorithm=\"MD5-sess\",\nopaque=\"bb319760fce84856e5648d3536502d81\"\n\npartial firefox header (succeeds with 200):\nCONNECT mail1.combrio.local:443 HTTP/1.1\nProxy-Authorization: Digest username=\"proxytest\", realm=\"Digest\",\nnonce=\"0e61fe645ec8c5015aa3afe8cfe5219488ed473e277a8cddf8225ad66e74fd214f97d9d96ac99991\",\nuri=\"mail1.combrio.local:443\", algorithm=MD5-sess,\nresponse=\"bfac109287273e867531170475172ccf\",\nopaque=\"70cb2a1533b85882d0f1aa1e2ad1fbae\", qop=auth, nc=00000001,\ncnonce=\"b41aecd6e527e774\"",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-293",
        "summary": "Provide support for non-ASCII charsets in the multipart disposition-content header",
        "description": "Because of the the following line in getAsciiBytes \n data.getBytes(\"US-ASCII\");\n\nThe returned string is modified if has Latin Characters.\n\nEx : Document non-control\u00c3\u00a9 -> Document non-control?",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-407",
        "summary": "Errors in character entities in Javadoc for HttpVersion",
        "description": "There are some errors in the Javadoc for the HttpVersion class. This is the\nclass comment:\n\n *  <p>HTTP version, as specified in RFC 2616.</p>\n *  <p>\n *  HTTP uses a \"&ltmajor&gt.&ltminor&gt\" numbering scheme to indicate versions\n *  of the protocol. The protocol versioning policy is intended to allow\n *  the sender to indicate the format of a message and its capacity for\n *  understanding further HTTP communication, rather than the features\n *  obtained via that communication. No change is made to the version\n *  number for the addition of message components which do not affect\n *  communication behavior or which only add to extensible field values.\n *  The &ltminor&gt number is incremented when the changes made to the\n *  protocol add features which do not change the general message parsing\n *  algorithm, but which may add to the message semantics and imply\n *  additional capabilities of the sender. The &ltmajor&gt number is\n *  incremented when the format of a message within the protocol is\n *  changed. See RFC 2145 [36] for a fuller explanation.\n *  </p>\n *  <p>\n *  The version of an HTTP message is indicated by an HTTP-Version field\n *  in the first line of the message.\n *  </p>\n *  <pre>\n *     HTTP-Version   = \"HTTP\" \"/\" 1*DIGIT \".\" 1*DIGIT\n *  </pre>\n *  <p>\n *   Note that the major and minor numbers MUST be treated as separate\n *   integers and that each MAY be incremented higher than a single digit.\n *   Thus, HTTP/2.4 is a lower version than HTTP/2.13, which in turn is\n *   lower than HTTP/12.3. Leading zeros MUST be ignored by recipients and\n *   MUST NOT be sent.\n *  </p>\n\nNote that the character entities for less-than and greater-than are not properly\nended with a semi-colon.\n\nI will attach a proposed fix.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1030",
        "summary": "Implement \"ignoreCookies\" CookieSpec",
        "description": "It would be useful to Implement an \"ignoreCookies\" CookieSpec, as was done in Commons HC 3.1\n\nThis should be registered by DefaultHttpClient.createCookieSpecRegistry().\n\nPatch to follow.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-77",
        "summary": "Implement Connection Timeouts",
        "description": "I was writing test code to use the setSoTimeout(int millis) method to set a\ntimeout value when connecting to a URL.  It appears to me that no matter what I\nset the timeout to be a HttpConnection will try to connect but uses some other\ntimeout value(I'm guessing the OS's default value).  I looked at the code for\nHttpConnection and it uses the Socket(host,port) constructor which tries to\nconnect write away.  I'd like to suggest the following code below so the timeout\nis set before first the connection is even made.\n\n/* Compile the code as is and it should timeout within a sec.  If you\n * uncomment the first two lines after the try statement and comment\n * out the other socket connect statements and run the code again you will\n * notice write away that the timeout is something else because it connects\n * right away in the constructor.  Its like the timeout is worthless at this\n * point.  As a matter a fact the code should never get there.\n * This all assumes that 192.168.168.50 is not on your network.\n */\n\nimport java.io.*;\nimport java.net.*;\n\npublic class SocketTest {\n    public static void main(String[] args) {\n        long start = System.currentTimeMillis();\n\n        try {\n            //Socket socket = new Socket(\"192.168.168.50\",80);\n            //socket.setSoTimeout(1000);\n\n            //Setting timeout before the connection is made.\n            Socket socket = new Socket();\n            InetSocketAddress sAddress =\n                new InetSocketAddress(\"192.168.168.50\",80);\n            socket.connect(sAddress,1000);\n\n        } catch (UnknownHostException e) {\n            System.out.println(e);\n        } catch (SocketException e) {\n            System.out.println(e);\n        } catch (IOException e) {\n            System.out.println(e);\n        }\n\n        System.out.println(System.currentTimeMillis() - start);\n    }\n}",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-547",
        "summary": "Provide access to port of Host header",
        "description": "We use a load balancer that connects to the HTTP server and the HTTP server\nconnects to the application server. We use port translation in our load\nbalancer. So when e.g. a client connects to 90 of the load balancer, the load\nbalancer connects to port 100 of the HTTP server. The load balancer doesn't\nchange the Host request header, so in the host request header is still the\noriginal virtual host name and port, in this case port 90. For this reason, the\nvirtual hosts of the HTTP server and application server are configured based on\nthe external port numbers, so in this case port 90.\n \nFor test purposes, we sometimes want to connect directly to the HTTP server or\nthe application server, bypassing the load balancer. To do this, we need to\nconnect to the same port as the load balancer would, in this example port 100,\nbut the host header of this request should be the same as if the request would\ngo through the load balancer, so in this example port 90, because the HTTP\nserver and application server's virtual hosts are configured for this port.\n\nThe attached patch adds the possibility to specify the port number for virtual\nhosts.\n\nHere's a code snippet that uses the patched code:\n\nHttpClient httpClient = new HttpClient();\nHttpMethod method = new GetMethod();\nHostConfiguration hostConfiguration = new HostConfiguration();\nhostConfiguration.setHost(\"localhost\", 80, \"http\");\nHostParams params = new HostParams();\nparams.setVirtualHost(\"localhost\");\nparams.setVirtualHostPort(100);\nhostConfiguration.setParams(params);\nhttpClient.executeMethod(hostConfiguration, method);\nSystem.out.println(method.getResponseBodyAsString());\nmethod.releaseConnection();",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1011",
        "summary": "CachingHttpClient.execute() does not catch the IOException thrown by HttpCache.getCacheEntry()",
        "description": "The IOException caused by the HttpCache is not caught and thus the whole http request fails. I would expect the response to be retrieved from the backend when the cache fails for some reason.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-615",
        "summary": "Consider making HostConfiguration immutable",
        "description": "HostConfiguration class should be immutable. This should also allow methods of this class to be non-synchronized.\n\nOleg",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-284",
        "summary": "Updates to connectionStaleCheckingEnabled docs.",
        "description": "Comments from Itai Brickner:\n\nIn the Threading section of the UserGuide\n(\nhttp://jakarta.apache.org/commons/httpclient/threading.html\n)\n\nThere is no mentioning of the\n'setConnectionStaleCheckingEnabled'\nI also felt that it wasn't clear from the APIDOC\n(http://jakarta.apache.org/commons/httpclient/apidocs/org/apache/commons/httpclient/MultiThreadedHttpConnectionManager.html)\nthat staleCheckingEnabled will cause a stale\nconnection to be reconnected by the\nMultiThreadedHttpConnectionManager\n\nthanks,\n\nItai",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-789",
        "summary": "Support for passing an SSLContext to the SSLSocketFactory of HttpClient",
        "description": "Would it be possible to use an existing instance of SSLContext to initialise an SSLSocketFactory? This would allow using SSLContexts configured with more options, such as CRLs.\n\n(This follows the thread of the httpclient-commons-dev list: http://marc.info/?l=httpclient-commons-dev&m=121737017814116&w=2 ).",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-472",
        "summary": "No equals operation for Credentials implementations",
        "description": "I tripped across a scenario where I wanted to compare credentials, so I could\nknow to discard connection state (and thus any associated cookies).\n\nPatch to follow shortly.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1069",
        "summary": "HttpClient 4.1 ignores request retry handler and stops retrying when a read timeout is followed by a connection refusal",
        "description": "I encountered an issue while writing unit tests for the RestBackup(tm) API Client Library, https://github.com/mleonhard/restbackup-java .  HttpClient 4.1 is failing to retry when it encounters a read timeout followed by a connection refusal.  This problem occurs on Windows but not on Linux.  Below is a short program that reproduces the problem.  It performs the expected 5 request attempts on Linux but only 2 on Windows.\n\nMy Windows environment is a laptop with Windows 7 Ultimate 64-bit and Oracle Java SE Development Kit Update 21 32-bit.  My Linux environment is Amazon EC2 with Ubuntu 10.04 LTS 32-bit and Oracle Java SE Development Kit Update 21 32-bit.\n\nThis is my first bug report to an Apache project.  I'd like to add that I'm a big fan of the Commons libraries and Http Components.\n\nSincerely,\n-Michael\n\n=== RetryBug.java ===\n\nimport java.io.IOException;\nimport java.net.ServerSocket;\nimport java.util.logging.Logger;\n\nimport org.apache.http.client.HttpRequestRetryHandler;\nimport org.apache.http.client.methods.HttpGet;\nimport org.apache.http.impl.client.DefaultHttpClient;\nimport org.apache.http.params.CoreConnectionPNames;\nimport org.apache.http.protocol.HttpContext;\n\npublic class RetryBug {\n    private static final Logger _log = Logger.getLogger(RetryBug.class.getName());\n\n    public static void main(String[] args) throws IOException {\n        ServerSocket serverSocket = new ServerSocket(0, 1);\n        DefaultHttpClient httpClient = new DefaultHttpClient();\n        HttpRequestRetryHandler retryHandler = new HttpRequestRetryHandler() {\n                public boolean retryRequest(IOException e, int count, HttpContext context) {\n                    _log.info(\"count=\" + count + \" \" + e.toString());\n                    return count < 5;\n                }\n            };\n        httpClient.setHttpRequestRetryHandler(retryHandler);\n        httpClient.getParams().setIntParameter(CoreConnectionPNames.SO_TIMEOUT, 100);\n        try {\n            String url = \"http://127.0.0.1:\" + serverSocket.getLocalPort() + \"/\";\n            httpClient.execute(new HttpGet(url));\n        } finally {\n            serverSocket.close();\n        }\n    }\n}\n\n\n=== Windows 7 ===\n\nC:\\RetryBug>md5sum httpcomponents-client-4.1-bin.zip\n008ad15560249bcde42cfe34fdb4e858 *httpcomponents-client-4.1-bin.zip\n\nC:\\RetryBug>\"c:\\Program Files (x86)\\Java\\jdk1.6.0_21\\bin\\java.exe\" -version\njava version \"1.6.0_21\"\nJava(TM) SE Runtime Environment (build 1.6.0_21-b06)\nJava HotSpot(TM) Client VM (build 17.0-b16, mixed mode)\n\nC:\\RetryBug>\"c:\\Program Files (x86)\\Java\\jdk1.6.0_21\\bin\\javac.exe\" -cp httpcomponents-client-4.1\\lib\\commons-codec-1.4.jar;httpcomponents-client-4.1\\lib\\commons-logging-1.1.1.jar;httpcomponents-client-4.1\\lib\\httpclient-4.1.jar;httpcomponents-client-4.1\\lib\\httpcore-4.1.jar RetryBug.java\n\nC:\\RetryBug>\"c:\\Program Files (x86)\\Java\\jdk1.6.0_21\\bin\\java.exe\" -cp httpcomponents-client-4.1\\lib\\commons-codec-1.4.jar;httpcomponents-client-4.1\\lib\\commons-logging-1.1.1.jar;httpcomponents-client-4.1\\lib\\httpclient-4.1.jar;httpcomponents-client-4.1\\lib\\httpcore-4.1.jar;. RetryBug\nMar 9, 2011 9:14:36 PM RetryBug$1 retryRequest\nINFO: count=1 java.net.SocketTimeoutException: Read timed out\nMar 9, 2011 9:14:36 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out\nMar 9, 2011 9:14:36 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: Retrying request\nException in thread \"main\" org.apache.http.conn.HttpHostConnectException: Connection to http://127.0.0.1:56361 refused\n        at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:158)\n        at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:149)\n        at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:121)\n        at org.apache.http.impl.client.DefaultRequestDirector.tryExecute(DefaultRequestDirector.java:650)\n        at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:454)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:820)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:754)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:732)\n        at RetryBug.main(RetryBug.java:27)\nCaused by: java.net.ConnectException: Connection refused: connect\n        at java.net.PlainSocketImpl.socketConnect(Native Method)\n        at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)\n        at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)\n        at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)\n        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)\n        at java.net.Socket.connect(Socket.java:529)\n        at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:120)\n        at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:148)\n        ... 8 more\n\nC:\\RetryBug>\n\n\n=== Ubuntu 10 ===\n\n$ md5sum httpcomponents-client-4.1-bin.tar.gz\nf043c1cc016cb3b720be9fb020bfa755  httpcomponents-client-4.1-bin.tar.gz\n$ ~/jdk1.6.0_21/bin/java -version\njava version \"1.6.0_21\"\nJava(TM) SE Runtime Environment (build 1.6.0_21-b06)\nJava HotSpot(TM) Client VM (build 17.0-b16, mixed mode, sharing)\n$ ~/jdk1.6.0_21/bin/javac -cp httpcomponents-client-4.1/lib/httpclient-cache-4.1.jar:httpcomponents-client-4.1/lib/commons-logging-1.1.1.jar:httpcomponents-client-4.1/lib/httpcore-4.1.jar:httpcomponents-client-4.1/lib/httpclient-4.1.jar:httpcomponents-client-4.1/lib/httpmime-4.1.jar:httpcomponents-client-4.1/lib/commons-codec-1.4.jar RetryBug.java\n$ ~/jdk1.6.0_21/bin/java -cp httpcomponents-client-4.1/lib/httpclient-cache-4.1.jar:httpcomponents-client-4.1/lib/commons-logging-1.1.1.jar:httpcomponents-client-4.1/lib/httpcore-4.1.jar:httpcomponents-client-4.1/lib/httpclient-4.1.jar:httpcomponents-client-4.1/lib/httpmime-4.1.jar:httpcomponents-client-4.1/lib/commons-codec-1.4.jar:. RetryBug\nMar 9, 2011 1:09:42 PM RetryBug$1 retryRequest\nINFO: count=1 java.net.SocketTimeoutException: Read timed out\nMar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out\nMar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: Retrying request\nMar 9, 2011 1:09:42 PM RetryBug$1 retryRequest\nINFO: count=2 java.net.SocketTimeoutException: Read timed out\nMar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out\nMar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: Retrying request\nMar 9, 2011 1:09:42 PM RetryBug$1 retryRequest\nINFO: count=3 java.net.SocketTimeoutException: Read timed out\nMar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out\nMar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: Retrying request\nMar 9, 2011 1:09:42 PM RetryBug$1 retryRequest\nINFO: count=4 java.net.SocketTimeoutException: Read timed out\nMar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out\nMar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute\nINFO: Retrying request\nMar 9, 2011 1:09:51 PM RetryBug$1 retryRequest\nINFO: count=5 java.net.SocketTimeoutException: Read timed out\nException in thread \"main\" java.net.SocketTimeoutException: Read timed out\n        at java.net.SocketInputStream.socketRead0(Native Method)\n        at java.net.SocketInputStream.read(SocketInputStream.java:129)\n        at org.apache.http.impl.io.AbstractSessionInputBuffer.fillBuffer(AbstractSessionInputBuffer.java:149)\n        at org.apache.http.impl.io.SocketInputBuffer.fillBuffer(SocketInputBuffer.java:110)\n        at org.apache.http.impl.io.AbstractSessionInputBuffer.readLine(AbstractSessionInputBuffer.java:260)\n        at org.apache.http.impl.conn.DefaultResponseParser.parseHead(DefaultResponseParser.java:98)\n        at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:252)\n        at org.apache.http.impl.AbstractHttpClientConnection.receiveResponseHeader(AbstractHttpClientConnection.java:281)\n        at org.apache.http.impl.conn.DefaultClientConnection.receiveResponseHeader(DefaultClientConnection.java:247)\n        at org.apache.http.impl.conn.AbstractClientConnAdapter.receiveResponseHeader(AbstractClientConnAdapter.java:219)\n        at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:298)\n        at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125)\n        at org.apache.http.impl.client.DefaultRequestDirector.tryExecute(DefaultRequestDirector.java:622)\n        at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:454)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:820)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:754)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:732)\n        at RetryBug.main(RetryBug.java:27)\n$",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-885",
        "summary": "URLEncodedUtils fails to parse form-url-encoded entities that specify a charset",
        "description": "If a form-url-encoded HTTP entity specifies a charset in its Content-Type header, then URLEncodedUtils.parse(HttpEntity) fails to parse it.\n\nAn entity with content type \"application/x-www-form-urlencoded; charset=UTF-8\" should be detected as form-url-encoded and parsed as such, honoring the specified character set. Currently the code requires an exact, case-insensitive match with \"application/x-www-form-urlencoded\" for an entity to be detected as form-url-encoded.\n\nIt appears that the author of URLEncodedUtils.parse(HttpEntity) tried to take character sets into account, but expected to find them in the Content-Encoding header instead of as a parameter in the Content-Length header. The HTTP 1.1 spec makes it clear that the Content-Encoding header is for specifying transformations like gzip compression or the identity transformation -- not for specifying the entity's character set.\n\nHere are some helpful links.\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.4\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.5\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.11\n\nThis is related to: https://issues.apache.org/jira/browse/HTTPCLIENT-884",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1020",
        "summary": "Please add maven-notice-plugin to gump-trunk",
        "description": "Hi,\n\nthe httpclient build currently fails in Gump because it cannot find the maven-notice-plugin.  We could grab it from http://svn.apache.org/repos/asf/httpcomponents/maven-notice-plugin/trunk/ but since you have a directory with externals just for Gump it would be a lot easier if you added an external for it as well.\n\nThanks\n\nStefan",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-79",
        "summary": "Preemtive Auth fails whithout credentials",
        "description": "The preemtive authorization causes a HttpException to be thrown in teh\nAuthenticator if no credentials were provided at all. This case should be\nhandled quietly. A test case should be added.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-418",
        "summary": "ALLOW_CIRCULAR_REDIRECTS has no effect if references include query string",
        "description": "ALLOW_CIRCULAR_REDIRECTS parameter in HttpClientParameters has no effect if\ncircular reference contains in URL parameters.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1014",
        "summary": "ByteArrayBody as an alternative to InputStreamBody",
        "description": "InputStreamBody can not determine the content length, which in turn causes requests to be sent with a content length of 0, even though the content is there. .NET Servers have trouble dealing with this.\n\nByteArrayBody provides an alternative that alliviates this limitation.\n\nSource:\n \nimport java.io.IOException;\nimport java.io.OutputStream;\n\nimport org.apache.http.entity.mime.MIME;\nimport org.apache.http.entity.mime.content.AbstractContentBody;\n\n/**\n * Body part that is built using a byte array containing a file.\n * \n * @author Axel Fontaine\n */\npublic class ByteArrayBody extends AbstractContentBody {\n    /**\n     * The contents of the file contained in this part.\n     */\n    private byte[] data;\n\n    /**\n     * The name of the file contained in this part.\n     */\n    private String filename;\n    \n    /**\n     * Creates a new ByteArrayBody.\n     * \n     * @param data The contents of the file contained in this part.\n     * @param mimeType The mime type of the file contained in this part.\n     * @param filename The name of the file contained in this part.\n     */\n    public ByteArrayBody(final byte[] data, final String mimeType, final String filename) {\n        super(mimeType);\n        if (data == null) {\n            throw new IllegalArgumentException(\"byte[] may not be null\");\n        }\n        this.data = data;\n        this.filename = filename;\n    }\n\n    /**\n     * Creates a new ByteArrayBody.\n     * \n     * @param data The contents of the file contained in this part.\n     * @param filename The name of the file contained in this part.\n     */\n    public ByteArrayBody(final byte[] data, final String filename) {\n        this(data, \"application/octet-stream\", filename);\n    }\n\n    @Override\n    public String getFilename() {\n        return filename;\n    }\n\n    @Override\n    public void writeTo(OutputStream out) throws IOException {\n        out.write(data);\n    }\n\n    @Override\n    public String getCharset() {\n        return null;\n    }\n\n    @Override\n    public String getTransferEncoding() {\n        return MIME.ENC_BINARY;\n    }\n\n    @Override\n    public long getContentLength() {\n        return data.length;\n    }\n}\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-471",
        "summary": "DateUtil#formatDate uses default locale instead of US",
        "description": "Problem reported by Yannick <yannick at meudal.net> on the httpclient-user list\n\n==================================================================\nHello,\n\nThis is a bug report.\n\nI'm using Commons HTTPClient (rc2) for generating HTTP requests. I put in \nheaders some specific header, like the If-Modified-Since attribute. \nWhen I generate the date through DateUtil.formatDate method, I get a \nlocalized date, in french. Example: \nIf-Modified-Since: dim., 10 avr. 2005 05:04:08 CEST\n\nI get problems on my http server during parsing the received date. This is \nnot a RFC 2616 compliant date format. It should be:\nIf-Modified-Since: Sun, 10 Apr 2005 05:04:08 CEST\n\nA patch should be applied, by creating a new SimpleDateFormat(pattern, \nLocale.US) instead of SimpleDateFormat(pattern) (like it is done in the \nparse method, line #159).\n\norg.apache.commons.httpclient.util.DateUtil, line #205:\n\n    public static String formatDate(Date date, String pattern) {\n        if (date == null) throw new IllegalArgumentException(\"date is \nnull\");\n        if (pattern == null) throw new IllegalArgumentException(\"pattern \nis null\");\n \n        SimpleDateFormat formatter = new SimpleDateFormat(pattern, \nLocale.US);\n        return formatter.format(date);\n    }\n\n\nRegards,\n\nYannick.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1104",
        "summary": "Add way to check for release of connections back into pool",
        "description": "As the documentation emphasizes, its important to clean up HttpEntities after use, so they don't tie up the default very small number of connections in the pool.\n\nHowever, nothing is provided to HttpClient users with the default classes that allows them to unit test their code to help verify that they are in fact properly releasing the connections under all circumstances. One way this could be done is for the API to expose the number of current leased (taken) connections in the pool, which would be connManager.pool.leasedConnections.size() if not for the necessary fields being protected. If this statistic were published through the API, user unit tests could check that it is zero when they finish.\n\nA workaround is for the user to subclass both the connection manager and ConnPoolByRoute and add getter methods. But its kind of a clunky solution, and I think the API should be written to encourage its users to perform this check.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1039",
        "summary": "AbstractHttpClient.determineTarget does not recognize target host correctly",
        "description": "I am trying to execute an HttpGet with the following URI:\n\"http://www.foo.foo/doSomething.html?url=http://www.bar.bar/doSomethingElse.html\"\n\nThis leads to UnknownHostException\n\nGoing through the internal code, the problem seems to be in the AbstractHttpClient.determineTarget method:\n            String ssp = requestURI.getSchemeSpecificPart();\n            ssp = ssp.substring(2, ssp.length()); //remove \"//\" prefix\n            int end = ssp.indexOf(':') > 0 ? ssp.indexOf(':') :\n                    ssp.indexOf('/') > 0 ? ssp.indexOf('/') :\n                    ssp.indexOf('?') > 0 ? ssp.indexOf('?') : ssp.length();\n            String host = ssp.substring(0, end);\n\nThis code sets the target host to \"www.foo.foo/doSomething.html?url=http\" instead of \"www.foo.foo\". This obviously breaks the execution not far down the line... DefaultClientConnectionOperator.resolveHostname throws an UnknownHostException.\n\nFWIW the AbstractHttpClient.determineTarget method actually has access to the request URI object, which correctly states that the host is \"www.foo.foo\".\n\nSo why does it try to extract the host from the scheme specific part anyway?\n\nI hope this is useful... and if there is any workaround please let me know, as I'm stuck on this one.\n\nMarco",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-321",
        "summary": "wrong charset indication in HttpConstants.getContentString()",
        "description": "Around line 236 in HttpConstants.getConstentString() the charset is wrongly indicated as \n\"DEFAULT_CONTENT_CHARSET\" where it should have been indicated as \"charset\" like in the \ngetContentBytes function.\n\n            if (LOG.isWarnEnabled()) {\n                LOG.warn(\"Unsupported encoding: \" \n                    + DEFAULT_CONTENT_CHARSET // <== should be the variable \"charset\" here\n                    + \". Default HTTP encoding used\");\n            }\n\nWrong copy/paste I guess :-)\n\nZC.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-438",
        "summary": "commons codec not documented as a dependency",
        "description": "Except for some entries on the jdepend-report, commons codec is not documented\nas a dependency for using HttpClient 3.0 RC1.  The only dependency documented is\ncommons logging.\n\njava.lang.NoClassDefFoundError: org/apache/commons/codec/DecoderException\n\tat org.apache.commons.httpclient.HttpMethodBase.<init>(HttpMethodBase.java:217)\n\tat\norg.apache.commons.httpclient.methods.ExpectContinueMethod.<init>(ExpectContinueMethod.java:92)\n\tat\norg.apache.commons.httpclient.methods.EntityEnclosingMethod.<init>(EntityEnclosingMethod.java:114)\n\tat org.apache.commons.httpclient.methods.PostMethod.<init>(PostMethod.java:105)",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-320",
        "summary": "\"Socket Closed\" IOException thrown by HttpConnection",
        "description": "HttpClient.java was modified in version 2.0 Final in method executeMethod().\nThe call to connection.setSoTimeout() used to be in RC3 after the call to\nconnection.isOpen(), but in the final version the call happens before the call \nto isOpen(). The result of the change is that the setSoTimeout() call could \nthrow IOException because of closed socket.\n\nI would fix the problem by adding to HttpConnection.setSoTimeout() (and to \nother similar methods in HttpConnection) an explicit check (a call to isOpen\n()) whether the socket is closed as the existence of socket object does not \nguarantee it. I.e the following code:\n\n    public void setSoTimeout(int timeout)\n        throws SocketException, IllegalStateException {\n        LOG.debug(\"HttpConnection.setSoTimeout(\" + timeout + \")\");\n        soTimeout = timeout;\n        if (socket != null) {\n            socket.setSoTimeout(timeout);\n        }\n    }\n\nwould be changed to\n\n    public void setSoTimeout(int timeout)\n        throws SocketException, IllegalStateException {\n        LOG.debug(\"HttpConnection.setSoTimeout(\" + timeout + \")\");\n        soTimeout = timeout;\n        if (isOpen()) {\n            socket.setSoTimeout(timeout);\n        }\n    }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-715",
        "summary": "remove RoutedRequest from API",
        "description": "Remove RoutedRequest from the Client API. It can be moved to impl, or dropped altogether.\nHttpClient could accept separate request and target arguments instead of RoutedRequest.\nNo routes should be passed in the API. ",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-131",
        "summary": "[HttpClient] Authenticator() - ability to perform alternate authentication",
        "description": "My post to the user group.  The developer replied suggesting I enter an \nenhancement request.\n\n-----Original Message-----\nFrom: Gustafson, Vicki [mailto:vicki.gustafson@us.didata.com]\nSent: Thursday, 12 December 2002 5:03 AM\nTo: Jakarta Commons Users List\nSubject: [HttpClient] Authentication using Basic\n\nIs there a way to specify which authentication scheme you would like the client \nto use if several schemes are returned in the www-auth header?\n\nI'm performing a simple post using the httpClient.  The server returns a 401 at \nwhich point the httpClient tries to authenticate with the server.  The \nfollowing header is received:\n\nAttempting to parse authenticate header: 'WWW-Authenticate: Negotiate, NTLM, \nBasic realm=\"XXXwhateverXXX\"\n\nI need to authenticate using Basic, but the Authenticator class will only try \nthe most secure scheme:  NTLM.  Is there a setting or parameter I can set to \nforce the httpClient to use Basic?\n\nthanks,\nVicki\n\n// determine the most secure request header to add\nHeader requestHeader = null;\nif (challengeMap.containsKey(\"ntlm\")) {\n    String challenge = (String) challengeMap.get(\"ntlm\");\n    requestHeader = Authenticator.ntlm(challenge, method, state,\n    responseHeader);\n} else if (challengeMap.containsKey(\"digest\")) {\n    String challenge = (String) challengeMap.get(\"digest\");\n    String realm = parseRealmFromChallenge(challenge);\n    requestHeader = Authenticator.digest(realm, method, state,\n    responseHeader);\n} else if (challengeMap.containsKey(\"basic\")) {\n    String challenge = (String) challengeMap.get(\"basic\");\n    String realm = parseRealmFromChallenge(challenge);\n    requestHeader = Authenticator.basic(realm, state, responseHeader);\n} else if (challengeMap.size() == 0) {\n    throw new HttpException(\"No authentication scheme found in '\"\n    + authenticateHeader + \"'\");\n} else {\n    throw new UnsupportedOperationException(\n    \"Requested authentication scheme \" + challengeMap.keySet()\n    + \" is unsupported\");\n}\n\n--\nTo unsubscribe, e-mail:   <mailto:commons-user-unsubscribe@jakarta.apache.org>\nFor additional commands, e-mail: <mailto:commons-user-help@jakarta.apache.org>\n\n\n--\nTo unsubscribe, e-mail:   <mailto:commons-user-unsubscribe@jakarta.apache.org>\nFor additional commands, e-mail: <mailto:commons-user-help@jakarta.apache.org>\n\n**********developer response**********************************\n\n\n\nCurrently there isn't, however we probably should be more intelligent about \nfalling back to other authentication schemes based on the type of credentials \nprovided.  Having said this I'm not sure it conforms to the HTTP spec strictly \n(which states that the client must use the strongest authentication scheme it \nsupports, there's a grey area here because if your application doesn't provide \na dialog or similar for the user to enter NTLM credentials it can only support \nbasic or digest authentication, despite HTTPClient supporting NTLM).\n\nWhat I'd like to see happen is:\n\nWhen NTLM authentication is requested as top priority but only \nUsernamePasswordCredentials are available instead of NTLMCredentials we fall \nback to one of the other schemes.  In general this would mean that:\n\nif an authentication scheme is requested and a credentials object of the wrong \ntype is provided, HTTPClient should assume (probably optionally or only in non-\nstrict mode) that the requested authentication scheme is not supported and fall \nthrough to other options.\n\nAchieving this would require a reasonably amount of refactoring of the \nAuthenticator class but shouldn't be impossible.  Unfortunately I don't have \ntime to do it myself at the moment but I'd be happy to help out if you felt \nlike doing it, otherwise logging an enhancement bug in Bugzilla would be a good \nway to record this request until someone has time to actually implement it.\n\nAdrian Sutton, Software Engineer\nEphox Corporation\nwww.ephox.com",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-618",
        "summary": "Eliminate class HostConfiguration",
        "description": "Remove the target host attribute from the HostConfiguration class. This will allow one HostConfiguration object to be used for different targets.\nThe problem is that currently MultiThreadedHttpConnectionManager uses HostConfiguration objects as cache keys, which needs to be changed.\n\nThis is a followup to HTTPCLIENT-615.\n\ncheers,\n  Roland\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-19",
        "summary": "Response Folded Headers throws HttpException",
        "description": "As of 4/4/02 CVS repository the HttpMethodBase class\ndoesn't handle folded headers in the \nreadResponseHeaders method\n\nHTTP/1.1 and HTTP/1.0 descriptions of folded headers (see \nsection 2.2 Basic Rules)\nhttp://www.ietf.org/rfc/rfc2616.txt\nhttp://www-\nold.ics.uci.edu/pub/ietf/http/rfc1945.html#Basic-Rules\n\nI've prepared a patch and was \nemailed to jakarta-commons@jakarta.apache.org",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-614",
        "summary": "allow different strategies when checking CN of x509 cert",
        "description": "We're now doing a decent job for checking the CN of the x509 cert with https:\n\nhttp://issues.apache.org/jira/browse/HTTPCLIENT-613\n\nI think the patch for HTTPCLIENT-613 should cover 99.9% of the users out there.  But there are some more esoteric possibilities, so I think Oleg is right.  We need to let the user change the strategy, or provide their own strategy if they want to. \n\nSome additional things to think about:\n\n- http://wiki.cacert.org/wiki/VhostTaskForce !!!   CN is depreciated?!?!   (I am not able to find a popular website on HTTPS that isn't using CN!)\n\n- [*.example.com] matches subdomains [a.b.example.com] on Firefox, but not IE6.  The patch for HTTPCLIENT-613 allows subdomains.\n\n- Should we support multiple CN's in the subject?\n\n- Should we support \"subjectAltName=DNS:www.example.com\" ?  Should we support lots of them in a single cert?\n\n- Should we support a mix of CN and subjectAltName?\n\n\nIf we do create some alternate strategies for people to try, I'd probably lean towards something like this:\n\nX509NameCheckingStrategy.SUN_JAVA_6  (default)\nX509NameCheckingStrategy.FIREFOX2\nX509NameCheckingStrategy.IE7\nX509NameCheckingStrategy.FIRST_CN_AND_NO_WILDCARDS   (aka \"STRICT\")\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-504",
        "summary": "max connections per host setting does not work",
        "description": "When using the MultiThreadedHttpConnectionManager the default maximal\nconnections per host/port cannot be exceeded (allowed maximum is 2 by default).\nAttempts to exceed this by manually setting the max connections using\nHttpConnectionManagerParams#setMaxConnectionsPerHost fail. This is caused by a\nbug in the MultiThreadedHttpConnectionManager.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-342",
        "summary": "[API Doc] Improve the description of the preemptive authentication",
        "description": "HttpClient authentication guide does not reflect the fact that preemptive\nauthentication requires default credentials to be set. It should also mention\nthe security implications of preemptive authentication (default credentials sent\nwith EVERY request to ANY target / proxy server)",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1179",
        "summary": "Upgrade commons-codec 1.4 -> 1.6",
        "description": "commons-codec 1.4 is buggy, see for example https://issues.apache.org/jira/browse/CODEC-99",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-73",
        "summary": "No way to get the requestBody out of a PostMethod or use if extending class",
        "description": "Attempting to extend the PostMethod class I discovered that I had no access to \nthe requestBody because the member is declared private and there is no get \nmethod.\n\nI was trying to override the setRequestContentLength() when I discovered the \nproblem.\n\nSo my enhancement request specifically is:\n1. add a get method to be able to get the requestBody (probably a get method to \nthe parameters as well)\n2. (optionally) make the requestBody and parameters members protected instead \nof private so extending the class is easier.\n\nIn case you were wondering, the reason for extending the class was to add the \nability to set a timeout value on the httpconnection and also the ability to \nset the character encoding of the request body.  I don't know if these are \nworthy of an enhancement request but I require them for what I'm doing.  Nice \nwork by the way.\n\nThank you.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-764",
        "summary": "HttpClient javadocs need improving",
        "description": ".. patch coming.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-147",
        "summary": "HttpClient enter 100% for endless time",
        "description": "I was working masively using HttpClient (I was testing it for usage within a \nserver) and it got to 100% CPU for an endless time.\n\nI was querying urls of the type \nhttp://search.barnesandnoble.com/booksearch/results.asp?WRD=<text>&sort=R&SAT=1\n\nTo reproduce it, run 100-200 urls with random words instead of <text> and \nyou'll probably reproduce the problem.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-300",
        "summary": "BasicAuthenticatonExample.java in CVS",
        "description": "From the example in CVS Revision 1.1.2.1 the code below would lead you to \nbelive that setCredentials uses (\"HOST\", \"REALM\", credientials). It actually \nshould be (\"REALM\", \"HOST\", credientials). It looks like it was correct in the \nRevision 1.1 and was changed with Revision 1.1.2.1\n\n// pass our credentials to HttpClient, they will only be used for\n// authenticating to servers with realm \"realm\", to authenticate agains\n// an arbitrary realm change this to null.\nclient.getState().setCredentials(\n            \"www.verisign.com\",\n            \"realm\",\n            new UsernamePasswordCredentials(\"username\", \"password\")\n);",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-697",
        "summary": "Http Client give sme message when proxy/http endpoint is down",
        "description": "Whether Http sever endpoint is down or the proxy server is down we get the same stack trace as:\n\njava.net.ConnectException: Connection refused\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)\n\tat java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)\n\tat java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)\n\tat java.net.Socket.connect(Socket.java:518)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.commons.httpclient.protocol.ReflectionSocketFactory.createSocket(ReflectionSocketFactory.java:139)\n\tat org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:124)\n\tat org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:706)\n\tat org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1321)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:386)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:170)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:396)\n\tat com.approuter.module.http.protocol.HttpTransportSender.perform(HttpTransportSender.java:214)\n\tat \n\n\nIt will be good if we can get information whether the proxy was down or the Http endpoint.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-510",
        "summary": "User-defined ProtocolSocketFactory for secure connection through proxy",
        "description": "I use a custom socket implementation with HttpClient, and am having problems \ngetting secure connections through a proxy working.\n\nHttpClient requires that my SecureProtocolSocketFactory be able to create a \nsecure socket layered over an existing insecure socket, but does not specify \nhow that insecure socket is created. Currently, for secure proxied \nconnections, the insecure connection is always created using a \nDefaultProtocolSocketFactory (HttpConnection.java, line 702). I wish to be \nable to override this behaviour, so that I can create the insecure socket \nusing my own custom implementation.\n\nThe problem with the default behaviour is that my custom socket implementation \nis written in C++ using JNI, and the SSL implementation is handled at the \nnative level. Hence, layering over an existing JDK socket will not work.\n\nMy proposed solution is to add an HTTP connection parameter to specify the \nsocket factory to use, perhaps http.connection.insecuresocketfactory of type \nClass.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-268",
        "summary": "Socket streams are closed in the incorrect order.",
        "description": "HttpConnection should close the streams/socket in the following order:\n\nOutputStream\nInputStream\nSocket\n\n<http://java.sun.com/docs/books/tutorial/networking/sockets/readingWriting.html>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-123",
        "summary": "MultipartPostMethod does not check for error messages",
        "description": "If a MultipartPost request is sent to a server which requires authentication, \nthe server may respond to the request with an unauthorized header and close the \nconnection before all of the data is sent.  HttpClient should monitor the \nincoming stream and cease transmitting the body if an error message is received \n(section 8.2.2 of rfc2616, see below).\n\nAt the very least HttpClient should check for a response when catching the \nHttpRecoverableException and retrying.  This probably should be done in \nHttpMethodBase so that we are in a known state when starting to retry the \nconnection (ie: there isn't an existing response in the socket buffer to cause \nproblems).\n\nIdeally, HttpClient should also implement the 100 (Continue) status as \nspecified in section 8.2.3 of rfc2616.\n\nFinally, PostMethod should be tested to ensure that it does not exhibit this \nbug as well.\n\n-------------\n8.2.2 Monitoring Connections for Error Status Messages\n\n   An HTTP/1.1 (or later) client sending a message-body SHOULD monitor\n   the network connection for an error status while it is transmitting\n   the request. If the client sees an error status, it SHOULD\n   immediately cease transmitting the body. If the body is being sent\n   using a \"chunked\" encoding (section 3.6), a zero length chunk and\n   empty trailer MAY be used to prematurely mark the end of the message.\n   If the body was preceded by a Content-Length header, the client MUST\n   close the connection.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-100",
        "summary": "Add possibility to disable automatic authentication header processing.",
        "description": "In the application I'm working on I need the possibility to manually get the \nWWW-Authenticate header instead of letting the HttpClient process it \nautomatically. Instead of rewriting the execute() method in a subclass I added \na configuration setting, similar to the followRedirects flag. Diffs below for \nanyone interested.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-57",
        "summary": "Define and implement Logging policy",
        "description": "When to use info vs debug vs warning?  \nWhen to log exceptions?\nenter() and exit() messages on a per method basis?\nAlways log debug when swallowing an exception?",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-906",
        "summary": "Minor performance improvement to IdleConnectionHandler",
        "description": "The attached patch does the following changes to IdleConnectionHandler\n - as it iterator over a map of connections, using a LinkedHashMap is a faster\n - rather than using an iterator over the keyset and subsequently getting the values, an iterator over the entry set is used instead for efficiency (at least according to FindBugs)\n\nNote that the patch contains other changes to make variables final where possible. This was done automatically by Eclipse, and can be removed if desired. However I see no harm in them, other than they affect more of the code than intended by the patch.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-358",
        "summary": "Auto method retrial broken",
        "description": "Folks,\nWhile working on the exception handling guide for the 3.0-alpha2 release I\nstumbled upon a problem with HttpTimeoutException and its subclasses. In 3.0a1\nHttpTimeoutException subclasses HttpRecoverableException which causes HTTP\nmethods failed due to a connect or socket timeout to be automatically retried. \n\n[INFO] HttpMethodDirector - -Recoverable exception caught when processing request\n[INFO] HttpMethodDirector - -Recoverable exception caught when processing request\n[INFO] HttpMethodDirector - -Recoverable exception caught when processing request\n[INFO] HttpMethodDirector - -Recoverable exception caught when processing request\n[WARN] HttpMethodDirector - -Recoverable exception caught but\nMethodRetryHandler.retryMethod() returned false, rethrowing exception\norg.apache.commons.httpclient.IOTimeoutException: Read timed out\n\tat\norg.apache.commons.httpclient.HttpConnection$WrappedInputStream.handleException(HttpConnection.java:1350)\n\tat\norg.apache.commons.httpclient.HttpConnection$WrappedInputStream.read(HttpConnection.java:1360)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:66)\n\tat java.io.PushbackInputStream.read(PushbackInputStream.java:120)\n\tat org.apache.commons.httpclient.HttpParser.readRawLine(HttpParser.java:76)\n\tat org.apache.commons.httpclient.HttpParser.readLine(HttpParser.java:104)\n\tat org.apache.commons.httpclient.HttpConnection.readLine(HttpConnection.java:1054)\n\tat\norg.apache.commons.httpclient.HttpMethodBase.readStatusLine(HttpMethodBase.java:1785)\n\tat\norg.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1546)\n\tat org.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:977)\n\tat\norg.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:383)\n\tat\norg.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:164)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:437)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:324)\n\tat Test.main(Test.java:13)\nCaused by: java.net.SocketTimeoutException: Read timed out\n\tat java.net.SocketInputStream.socketRead0(Native Method)\n\tat java.net.SocketInputStream.read(SocketInputStream.java:129)\n\tat java.net.SocketInputStream.read(SocketInputStream.java:182)\n\tat\norg.apache.commons.httpclient.HttpConnection$WrappedInputStream.read(HttpConnection.java:1358)\n\t... 13 more\nException in thread \"main\" \n\nThis probably is not what we want. Besides, for non-idempotent methods this may\nsimply be fatal and result in all sorts of unpleasant side-effects.\n\nOne possibilty that I personally favour is to make HttpTimeoutException class\nextend IOException instead of HttpRecoverableException. There are others. The\nquestion is whether timeout exceptions should be considered recoverable from the\nconseptual standpoint. What do you think?\n\nOleg",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-919",
        "summary": "NTLM implementation lacks support for NTLMv1, NTLMv2, and NTLM2 Session forms of NTLM",
        "description": "The current HttpClient implementation lacks support for all enhancements to NTLM after Windows 95.  That includes NTLMv1, NTLMv2, and NTLM2 Session Response varieties of the protocol.\n\nThis seriously impacts the usability of HttpClient in enterprise situations, which has required the Lucene Connector Framework team to extend HttpClient to address the issue.\n\nI've attached a patch which contains the implementation used by LCF.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-723",
        "summary": "HttpRoutePlanner based on ProxySelector",
        "description": "Since we now require Java 5, we should have a route planner that uses the standard Java ProxySelector. That would allow us to automatically pick up proxy settings from system properties or the browser running an applet.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "HTTPCLIENT-344",
        "summary": "HttpConnection.isOpen() logging is not accurate",
        "description": "isOpen() does not differentiate between stale and closed.  If the connection is closed isStale() will return \ntrue.  The logs will then indicate that the connection was stale, even though it was really just closed.  \nclose() is also called a second time unnecessarily.\n\nThis should be fixed for 3.0, and perhaps even 2.0.1.\n\n<http://nagoya.apache.org/eyebrowse/ReadMsg?listName=commons-httpclient-\ndev@jakarta.apache.org&msgNo=7205>",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1036",
        "summary": "StringBody has incorrect default for characterset",
        "description": "StringBody defaults to Charset.defaultCharset() if the charset is not provided.\n\nThis means that the default depends on the current host.\n\nThe default should be US-ASCII (as was the case with StringPart in Commons HttpClient 3.1).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1168",
        "summary": "HTTPClient doesn't send authentication header in threaded environment",
        "description": "Using HTTPClient with multiple threads and basic authentication seems to create a race condition. The request headers sometimes don't contain the authorization entry, which results in a 401 (although the username and password credentials are correctly set). ",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1107",
        "summary": "HttpClient does not retry authentication when multiple challenges are present if the primary one fails",
        "description": "I'm trying to request a page from IIS (6 and 7.5).  If the IIS is configured with providers for \"negotiate\" and \"ntlm\" then the Negotiate authentication is tried and fails, but it does not then try to use the NTLM authentication which is what I require.  If I removed \"negotiate\" as a provider from IIS and just use NTLM then all works well - but this is not a solution as I don't have control of the web servers. \n\nOutput below...\n\n\n[DEBUG] SingleClientConnManager - Get connection for route HttpRoute[{}->http://WIN-HNB91NNAB2G]\n[DEBUG] DefaultClientConnectionOperator - Connecting to WIN-HNB91NNAB2G/147.183.80.134:80\n[DEBUG] RequestAddCookies - CookieSpec selected: best-match\n[DEBUG] DefaultHttpClient - Attempt 1 to execute request\n[DEBUG] DefaultClientConnection - Sending request: GET / HTTP/1.1\n[DEBUG] wire - >> \"GET / HTTP/1.1[\\r][\\n]\"\n[DEBUG] wire - >> \"Host: WIN-HNB91NNAB2G[\\r][\\n]\"\n[DEBUG] wire - >> \"Connection: Keep-Alive[\\r][\\n]\"\n[DEBUG] wire - >> \"User-Agent: Apache-HttpClient/4.1 (java 1.5)[\\r][\\n]\"\n[DEBUG] wire - >> \"[\\r][\\n]\"\n[DEBUG] headers - >> GET / HTTP/1.1\n[DEBUG] headers - >> Host: WIN-HNB91NNAB2G\n[DEBUG] headers - >> Connection: Keep-Alive\n[DEBUG] headers - >> User-Agent: Apache-HttpClient/4.1 (java 1.5)\n[DEBUG] wire - << \"HTTP/1.1 401 Unauthorized[\\r][\\n]\"\n[DEBUG] wire - << \"Content-Type: text/html[\\r][\\n]\"\n[DEBUG] wire - << \"Server: Microsoft-IIS/7.5[\\r][\\n]\"\n[DEBUG] wire - << \"WWW-Authenticate: Negotiate[\\r][\\n]\"\n[DEBUG] wire - << \"WWW-Authenticate: NTLM[\\r][\\n]\"\n[DEBUG] wire - << \"Date: Fri, 15 Jul 2011 12:15:11 GMT[\\r][\\n]\"\n[DEBUG] wire - << \"Content-Length: 58[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] DefaultClientConnection - Receiving response: HTTP/1.1 401 Unauthorized\n[DEBUG] headers - << HTTP/1.1 401 Unauthorized\n[DEBUG] headers - << Content-Type: text/html\n[DEBUG] headers - << Server: Microsoft-IIS/7.5\n[DEBUG] headers - << WWW-Authenticate: Negotiate\n[DEBUG] headers - << WWW-Authenticate: NTLM\n[DEBUG] headers - << Date: Fri, 15 Jul 2011 12:15:11 GMT\n[DEBUG] headers - << Content-Length: 58\n[DEBUG] DefaultHttpClient - Connection can be kept alive indefinitely\n[DEBUG] DefaultHttpClient - Target requested authentication\n[DEBUG] DefaultTargetAuthenticationHandler - Authentication schemes in the order of preference: [negotiate, NTLM, Digest, Basic]\n[DEBUG] DefaultTargetAuthenticationHandler - negotiate authentication scheme selected\n[DEBUG] NegotiateScheme - Received challenge '' from the auth server\n[DEBUG] DefaultHttpClient - Authorization challenge processed\n[DEBUG] DefaultHttpClient - Authentication scope: NEGOTIATE <any realm>@win-hnb91nnab2g:80\n[DEBUG] DefaultHttpClient - Found credentials\n[DEBUG] wire - << \"You do not have permission to view this directory or page.\"\n[DEBUG] RequestAddCookies - CookieSpec selected: best-match\n[DEBUG] NegotiateScheme - init WIN-HNB91NNAB2G\n[ERROR] RequestTargetAuthentication - Authentication error: Invalid name provided (Mechanism level: Could not load configuration file C:\\WINDOWS\\krb5.ini (The system cannot find the file specified))\n[DEBUG] DefaultHttpClient - Attempt 2 to execute request\n[DEBUG] DefaultClientConnection - Sending request: GET / HTTP/1.1\n[DEBUG] wire - >> \"GET / HTTP/1.1[\\r][\\n]\"\n[DEBUG] wire - >> \"Host: WIN-HNB91NNAB2G[\\r][\\n]\"\n[DEBUG] wire - >> \"Connection: Keep-Alive[\\r][\\n]\"\n[DEBUG] wire - >> \"User-Agent: Apache-HttpClient/4.1 (java 1.5)[\\r][\\n]\"\n[DEBUG] wire - >> \"[\\r][\\n]\"\n[DEBUG] headers - >> GET / HTTP/1.1\n[DEBUG] headers - >> Host: WIN-HNB91NNAB2G\n[DEBUG] headers - >> Connection: Keep-Alive\n[DEBUG] headers - >> User-Agent: Apache-HttpClient/4.1 (java 1.5)\n[DEBUG] wire - << \"HTTP/1.1 401 Unauthorized[\\r][\\n]\"\n[DEBUG] wire - << \"Content-Type: text/html[\\r][\\n]\"\n[DEBUG] wire - << \"Server: Microsoft-IIS/7.5[\\r][\\n]\"\n[DEBUG] wire - << \"WWW-Authenticate: Negotiate[\\r][\\n]\"\n[DEBUG] wire - << \"WWW-Authenticate: NTLM[\\r][\\n]\"\n[DEBUG] wire - << \"Date: Fri, 15 Jul 2011 12:15:11 GMT[\\r][\\n]\"\n[DEBUG] wire - << \"Content-Length: 58[\\r][\\n]\"\n[DEBUG] wire - << \"[\\r][\\n]\"\n[DEBUG] DefaultClientConnection - Receiving response: HTTP/1.1 401 Unauthorized\n[DEBUG] headers - << HTTP/1.1 401 Unauthorized\n[DEBUG] headers - << Content-Type: text/html\n[DEBUG] headers - << Server: Microsoft-IIS/7.5\n[DEBUG] headers - << WWW-Authenticate: Negotiate\n[DEBUG] headers - << WWW-Authenticate: NTLM\n[DEBUG] headers - << Date: Fri, 15 Jul 2011 12:15:11 GMT\n[DEBUG] headers - << Content-Length: 58\n[DEBUG] DefaultHttpClient - Connection can be kept alive indefinitely\n[DEBUG] DefaultHttpClient - Target requested authentication\n[DEBUG] NegotiateScheme - Received challenge '' from the auth server\n[DEBUG] NegotiateScheme - Authentication already attempted\n[DEBUG] DefaultHttpClient - Authorization challenge processed\n[DEBUG] DefaultHttpClient - Authentication scope: NEGOTIATE <any realm>@win-hnb91nnab2g:80\n[DEBUG] DefaultHttpClient - Authentication failed\n[DEBUG] wire - << \"You do not have permission to view this directory or page.\"\ncontent:You do not have permission to view this directory or page.\n[DEBUG] SingleClientConnManager - Releasing connection org.apache.http.impl.conn.SingleClientConnManager$ConnAdapter@17fa65e\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-517",
        "summary": "Cookie Documentation clarifications",
        "description": "The JavaDoc for CookieSpec mentions that the default policy is RFC2109 - it\nwould be nice if this was mentioned on\nhttp://jakarta.apache.org/commons/httpclient/cookies.html as well\n(likewise for 2.0)\n\nThe Javadoc for getDefaultPolicy() says to use getCookieSpec(String); it would\nbe better to say to use getCookieSpec(DEFAULT), and it would be helpful to\nmention getDefaultSpec().\n\nCookiePolicy Javadoc does not mention the IGNORE_COOKIES policy in the header\ndocumentation.\n\nThe cookies.html page mentions automatic and manual handling of cookies, but\ndoes not provide any links as to how to control these. For example, how does one\nturn off automatic cookie handling?",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-903",
        "summary": "Use ConcurrentHashMap instead of HashMap wherever thread-safe access is needed",
        "description": "Consider using ConcurrentHashMap instead of HashMap for any Maps that are used by multiple threads.\n\nFor example SchemeRegistry and AuthSchemeRegistry.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-665",
        "summary": "Change access to internal maps of HttpState to protected.",
        "description": "To be able to serialize the conversational state of a http session access to the internal maps of HttpState is required. Currently they are all \"private\", so subclasses cannot access them. Changing the access to \"protected\" will allow any subclass to access those maps.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1162",
        "summary": "Header adding in org.apache.http.client.protocol.RequestAcceptEncoding should be conditional",
        "description": "org.apache.http.client.protocol.RequestAcceptEncoding adds a header in any case. Any chance to do it conditional (like in RequestClientConnControl)? The code would be something like\nif (!request.containsHeader(\"Accept-Encoding\")) {\n    request.addHeader(\"Accept-Encoding\", \"gzip,deflate\");\n}\n\nIn our app this header may be added before request intercepting, so would be great if this fact is checked.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1045",
        "summary": "HttpGet request not being created when parameter \"url\" is present",
        "description": "\n/*\n* @formatter:off\n* \n* The following redirect Location results in a Bad Request (404) being made.\n* \n* http://www.qpassport.co.uk/passport/register.php?do=signup&who=adult&url=http%3A%2F%2Fwww.qpassport.co.uk%2Fpassport%2F&month=2&year=1947&day=26\n* \n* The GET request is made with these headers (Notice the \"Host\" value):\n* \n* DEBUG org.apache.http.wire  - >> \"GET http://www.qpassport.co.uk/passport/register.php?do=signup&who=adult&url=http%3A%2F%2Fwww.qpassport.co.uk%2Fpassport%2F&month=2&year=1947&day=26 HTTP/1.1[\\r][\\n]\"\n* DEBUG org.apache.http.wire  - >> \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*//*;q=0.8[\\r][\\n]\"\n* DEBUG org.apache.http.wire  - >> \"Accept-Language: en-us,en;q=0.5[\\r][\\n]\"\n* DEBUG org.apache.http.wire  - >> \"Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7[\\r][\\n]\"\n* DEBUG org.apache.http.wire  - >> \"Proxy-Connection: Keep-Alive[\\r][\\n]\"\n* DEBUG org.apache.http.wire  - >> \"Referer: http://www.qpassport.co.uk/passport/register.php?s=b9761dfa820bb55722e3feb6438fa11f&[\\r][\\n]\"\n* DEBUG org.apache.http.wire  - >> \"Host: www.qpassport.co.uk/passport/register.php?do=signup&who=adult&url=http[\\r][\\n]\"\n* DEBUG org.apache.http.wire  - >> \"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)[\\r][\\n]\"\n*  \n* They should be: (Notice the \"Host\" value)\n* DEBUG org.apache.http.wire  - >> \"GET http://www.qpassport.co.uk/passport/register.php?do=signup&who=adult&month=2&year=1947&day=26 HTTP/1.1[\\r][\\n]\"\n* DEBUG org.apache.http.headers  - >> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*//*;q=0.8\n* DEBUG org.apache.http.headers  - >> Accept-Language: en-us,en;q=0.5\n* DEBUG org.apache.http.headers  - >> Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\n* DEBUG org.apache.http.headers  - >> Proxy-Connection: Keep-Alive\n* DEBUG org.apache.http.headers  - >> Referer: http://www.qpassport.co.uk/passport/register.php?s=005ef80064a0fb2f5aa6f4677a194928&\n* DEBUG org.apache.http.headers  - >> Content-Length: 134\n* DEBUG org.apache.http.headers  - >> Content-Type: application/x-www-form-urlencoded; charset=UTF-8\n* DEBUG org.apache.http.headers  - >> Host: www.qpassport.co.uk\n* DEBUG org.apache.http.headers  - >> User-Agent: Opera/9.20 (Windows NT 6.0; U; en)\n* \n* The problem appears to be related to the URL parameter in the request\n* when it is removed, the request succeeds.\n* \n* @formatter:on\n*/\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-71",
        "summary": "Add support for Digest authentication to the Authenticator class",
        "description": "Here's some code initially whipped up by Geza for Apache Axis, now adapted to\nHTTPClient that adds support for Digest authentication to the Authenticator\nclass. I have tested this code against tomcat 4.0.4 with a sample code that\ncalls an Apache Axis Web Service. One caveat according to Geza, the code \"Right\nnow does not support qop-int\".",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-637",
        "summary": "Unit tests for HttpConn",
        "description": "HttpConn needs more test coverage.\nStarting at 0%.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "TEST"
    },
    {
        "key": "HTTPCLIENT-24",
        "summary": "Exception shouldn't be thrown for unsupported authentication method",
        "description": "Currently, Authenticator will throw an UnsupportedOperationException for \nunsupported authentication method (like NTLM). This is correct. However,  \nHttpMethodBase.execute only catches HttpException, so this \nUnsupportedOperationException is leaked to the user. This is undesirable, \nbecause user may want a chance to handle such such authentication themself. The \ncorrect way is to pass the http status code to the user, just like how it \ntreats redirect to a different host.\n\nThe simple fix is to catch all exceptions in HttpMethodBase.execute when \ncalling Authenticator.authenticate.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-13",
        "summary": "empty path not handled correctly",
        "description": "When requesting for a URL which has an empty path, e.g. http://abcnews.go.com ,\nthe code sends the following line:\n\nGET  HTTP/1.1\n\nwhich should be\n\nGET / HTTP/1.1\n\ninstead",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1129",
        "summary": "Redirect and Kerberos authentication in conflict",
        "description": "We are using the HttpClient to connect to a Website that uses Kerberos-Authentication.\n\nBeware this trigger word: Kerberos! I think this is *not* the problem, but please read on.\n\nHere is the sequence of events:\n\nClient: GET /\nServer: Unauthorized.\nClient: GET / and includes authentication.\nServer: 302 to /something on the same host (this shows that in principle authentication works)\nClient: GET /something,  does not include authentication\nServer: Unauthorized\n\nClient quits with 401-Unauthorized.\n\nI would have expected one of the following instead:\n\n1) Client immediately sends authorization information with the redirected GET /something\n2) Client re-requests the /something with authorization after 401-Unauthorized.\n\nWe could get around the problem by setting the ConnectionReuseStrategy to a constant false.\n\nIt would be great if someone could tell me if HttpClient works as expected or whether there is a bug or misconfiguration lurking.\n\nThanks,\nHarald.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": ""
    },
    {
        "key": "HTTPCLIENT-56",
        "summary": "Move to commons-logging",
        "description": "Commons-logging was derived from httpclient.log, still using the old logging\nwhich should be removed.  Some complaints on mailing list about setting up\ncommons-logging: should be simple and well documented.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-301",
        "summary": "Cookie rejected",
        "description": "Hello,\n\nI'm using HttpClient 1.0 rc2 to login in the SourceForge website and perform\nsome operations, but i'm getting the following error:\n\nPage 1 from https://sourceforge.net/account/login.php\n6 d\u00c3\u00a9c. 2003 23:45:27 org.apache.commons.httpclient.HttpMethodBase\nprocessResponseHeaders\nATTENTION: Cookie rejected: \"username=l6qpwtK5hpE%3D\". Illegal domain attribute\n\".sourceforge.net\". Domain of origin: \"sourceforge.net\"\n6 d\u00c3\u00a9c. 2003 23:45:27 org.apache.commons.httpclient.HttpMethodBase readResponseBody\n\nThe cookie returned by Sourceforge is rejected because the domain for the\nrequest was sourceforge.net and the domain for the cookie was .sourceforge.net\nI have tried to change the cookie policy to all available options, but none work. \nCookiePolicy.setDefaultPolicy(CookiePolicy.COMPATIBILITY);\n\nWhat can i do?\n\nThanks,\nLudovic",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1066",
        "summary": "HTTPClient 4.1 auto slash removal",
        "description": "I've put the same comment as in the following issue.\n\nhttps://issues.apache.org/jira/browse/HTTPCLIENT-929?focusedCommentId=13001748#comment-13001748\n\nI am using httpclient 4.1. I had a problem with this fix. In DefaultRequestDirector.rewriteRequestURI method, for non-proxied URI and when it is a absolute URI, it will call the URIUtils.rewriteURI, which then take the \"RawPath\" from an uri and normalize it. So when I pass an uri, for example, http://www.whatever.com/1//3, it will automatically remove the extra slash and become http://www.whatever.com/1/3. I've got a REStful service to accept the uri (/{param1}/{param2}/{param3}) and it takes when there is an empty value past in. Now because of the auto slash removal, the \"3\" value shift left for a position and match to the {param2}. I wouldn't say the above solution is wrong, but I guess it should not change what value that user pass in.",
        "label": "NUG",
        "classified": "BACKPORT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-429",
        "summary": "Problem getting the HTTPClient to use HTTP 1.0 with a proxy server",
        "description": "I am using HTTPClient 3.0-rc1.\nI am connecting to an HTTPS site through a proxy.\n\nI used HTTPLook to see the HTTP messages between the Proxy and the HTTPClient.\nI noticed that it always used HTTP/1.1 and setVersion() on either the \nhttpclient and the method do not help. I could not find how to get \nthe HTTPClient to use HTTP/1.0 with the proxy.\n\nLooking at the ConnectMethod class, the HTTP1.1 was indeed hardcoded.\n\nThanks\nriad",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-286",
        "summary": "Manually set 'Cookie' & 'Authorization' headers get discarded",
        "description": "HttpClient discards all the 'Cookie' & 'Authorization' headers including those\nmanually set when populating request header collection with automatically\ngenerated headers.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1063",
        "summary": "ResponseContentEncoding should also handle x-gzip, compress and x-compress",
        "description": "ResponseContentEncoding should also handle x-gzip, compress and x-compress encodings according to specs (http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html, 3.5 Content Codings).\n\nAlso RequestAcceptEncoding should set Accept-Encoding to \"gzip,deflate,identity\". I am not sure about x-gzip, compress and x-compress here though.\n\nThanks",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-622",
        "summary": "leak in MultiThreadedHttpConnectionManager.ConnectionPool.mapHosts",
        "description": "Once entries are added to MultiThreadedHttpConnectionManager.ConnectionPool.mapHosts, they are never cleaned up unless MultiThreadedHttpConnectionManager is shutdown.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-107",
        "summary": "HttpMethodBase: Port mismatch in URL for redirect to absolute location",
        "description": "The CVS version of latka was failing a test ( $ ant test, not maven ), when\nusing the CVS version of httpclient. The message was\n\n [java] WARN  [main] org.apache.commons.httpclient.HttpMethod\n      - Redirect from port 80 to -1 is not supported: 21 Sep 2002 00:54:32,098\n\nThe request preceding this was:\n\n [java] DEBUG [main] httpclient.wire - >> \"GET /commons HTTP/1.1\n     [java] \" [\\r\\n]: 21 Sep 2002 00:54:31,262\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter\n[java] DEBUG [main] httpclient.wire - >> \"Host: jakarta.apache.org\n     [java] \" [\\r\\n]: 21 Sep 2002 00:54:31,441\n     [java] DEBUG [main] httpclient.wire - >> \"User-Agent: Jakarta\nCommons-HttpClient/2.0M1\n [java] \" [\\r\\n]: 21 Sep 2002 00:54:31,442\n\nAnd the response was:\n\n [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter\nHttpMethodBase.readStatusLine(HttpState, HttpConnection): 21 Sep 2002 00:54:31,444\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter\nHttpConnection.readLine(): 21 Sep 2002 00:54:31,444\n[java] DEBUG [main] httpclient.wire - << \"HTTP/1.1 301 Moved Permanently\"\n[\\r\\n]: 21 Sep 2002 00:54:32,080\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter\nHttpMethodBase.readResponseHeaders(HttpState,HttpConnection): 21 Sep 2002\n00:54:32,086\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter\nHttpConnection.readLine(): 21 Sep 2002 00:54:32,087\n[java] DEBUG [main] httpclient.wire - << \"Date: Fri, 20 Sep 2002 23:54:30 GMT\"\n[\\r\\n]: 21 Sep 2002 00:54:32,088\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter\nHttpConnection.readLine(): 21 Sep 2002 00:54:32,089\n[java] DEBUG [main] httpclient.wire - << \"Server: Apache/2.0.42 (Unix)\" [\\r\\n]:\n21 Sep 2002 00:54:32,090\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter\nHttpConnection.readLine(): 21 Sep 2002 00:54:32,090\n[java] DEBUG [main] httpclient.wire - << \"Location:\nhttp://jakarta.apache.org/commons/\" [\\r\\n]: 21 Sep 2002 00:54:32,091\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter\nHttpConnection.readLine(): 21 Sep 2002 00:54:32,091\n[java] DEBUG [main] httpclient.wire - << \"Content-Length: 319\" [\\r\\n]: 21 Sep\n2002 00:54:32,091\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter\nHttpConnection.readLine(): 21 Sep 2002 00:54:32,092\n[java] DEBUG [main] httpclient.wire - << \"Content-Type: text/html;\ncharset=iso-8859-1\" [\\r\\n]: 21 Sep 2002 00:54:32,092\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter\nHttpConnection.readLine(): 21 Sep 2002 00:54:32,092\n[java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter\nHttpMethodBase.processResponseHeaders(HttpState, HttpConnection): 21 Sep 2002\n00:54:32,093\n     [java] DEBUG [main] org.apache.commons.httpclient.methods.GetMethod - enter\nGetMethod.readResponseBody(HttpState, HttpConnection): 21 Sep 2002 00:54:32,093\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter\nHttpMethodBase.readResponseBody(HttpState, HttpConnection): 21 Sep 2002 00:54:32,093\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter\nHttpMethodBase.readResponseBody(HttpState, HttpConnection): 21 Sep 2002 00:54:32,094\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter\nHttpConnection.getRequestOutputStream(HttpMethod): 21 Sep 2002 00:54:32,094\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter\nwriteRemainingRequestBody(HttpState, HttpConnection): 21 Sep 2002 00:54:32,096\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - Redirect\nrequired: 21 Sep 2002 00:54:32,097\n     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - Redirect\nrequested to location 'http://jakarta.apache.org/commons/': 21 Sep 2002 00:54:32,097\n     [java] WARN  [main] org.apache.commons.httpclient.HttpMethod - Redirect\nfrom port 80 to -1 is not supported: 21 Sep 2002 00:54:32,098\n\n\nThe problem appears to be in this section of code from HttpMethodBase\n\nif (url == null) {\n    //try to construct the new url based on the current url\n    try {\n        URL currentUrl = new URL(conn.getProtocol(),\n                                 conn.getHost(),\n                                 conn.getPort(), getPath());\n        url = new URL(currentUrl, location);   <--- is this inheriting the port?\n    } catch (Exception ex) {\n        log.error(\"Redirected location '\"\n                  + locationHeader.getValue()\n                  + \"' is malformed\");\n        return statusCode;\n    }\n}",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-699",
        "summary": "Performance tuning",
        "description": "",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-369",
        "summary": "Missing skip()-Method in ContentLengthInputStream",
        "description": "ContentLengthInputStream is missing the skip()-Method.\n\nThis causes the internal pos variable to get out of sync with the content \nlength. \nWe oberseved that closing the stream caused a wait time of about 15 sec in \nroutines which use the skip()-method of InputStream.\n\nHere's a possible implementation which should solve the problem:\n\n    public long skip(long len) throws IOException {\n        long count = super.skip(len);\n        pos += count;\n        return count;\n    }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-209",
        "summary": "Add set/getLocalAddress methods to HostConfiguration",
        "description": "On clustered or multi-homed systems, there's a need to specify the local bind\naddress of sockets, to ensure that they're created on the right interface.  To\ndo this, the local address needs to be passed to the 4-argument version of\nProtcolSocketFactory.createSocket.\n\nAfter discussion on the mailing list, the best approach for this seems to be\nadding the local address as a property on HostConfiguration and HttpConnection.  \n\nI've attached a patch which does the following:\n- Add public set/getLocalAddress methods to HostConfiguration and HttpConnection.\n- HttpConnection uses the local address when opening connections.\n- Modify HostConfiguration.equals and hostEquals to compare the local address too.\n- SimpleHttpConnectionManager uses the local address from the provided config. \nI also cleaned up its getConnection method a bit.\n- HttpClient.executeMethod uses the local address from its default\nHostConfiguration if the method's config doesn't specify one.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-61",
        "summary": "configurable User-Agent string",
        "description": "User configurable item to set the user agent without haveing to set it on a per\nHttpMethod basis.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-680",
        "summary": "web site for download of 3.1 fails",
        "description": "Down loading version 3 is not possible.\nDocumentation for 4. does not match 3.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-1156",
        "summary": "Kerberos Authentication Scheme",
        "description": "HttpClient 4.1.2 has a SPNEGO authentication that uses the Negotiate keyword.  But the MS IIS that I must connect to does not send back an WWW-Authenticate: Negotiate, but, instead, does send an WWW-Authenticate: Kerberos\n\nSo I used the NegotiateScheme.java and NegotiateSchemeFactory.java as a base to create a \"new\" scheme, called, KerberosScheme.java and KerberosSchemeFactory.java to make it work.\n\nEssentially I replaced every \"Negotiate\" scheme by \"Kerberos\", in the KerberosScheme.java, and removed the part of the code that tried, first, SPNEGO_OID, using KERBEROS_OID directly, instead.\n\nIt works fine for me, but took me a while to figure this out.\n\nThat why I think it could come on the new versions.\n\nI'll attach my version but it has no package - it was made only for a test project.  It's trivial to put it in the right place/package.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-141",
        "summary": "Using deprecated class javax.servlet.http.HttpUtils",
        "description": "[javac]\ntest-webapp/src/org/apache/commons/httpclient/RedirectServlet.java:74: warning:\njavax.servlet.http.HttpUtils in javax.servlet.http has been deprecated\n    [javac]             to =\nHttpUtils.getRequestURL(request).append(\"?\").append(request.getQueryString()).toString();\n\nThe javax.servlet.http.HttpUtils class is deprecated in Tomcat 4.1.18 and should\nnot be used.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-145",
        "summary": "Align the code base with checkstyle",
        "description": "The style use in HttpClient is still quite inconsistant.  checkstyle should be\nused to align the code base to a similar style.\n\nThe checkstyle report can be found at:\nhttp://jakarta.apache.org/commons/httpclient/checkstyle-report.html\n\nAnd can be generated with:\nmaven checkstyle:generate-report",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-852",
        "summary": "CircularRedirectException encountered when using a proxy, but not when reaching the target directly",
        "description": "A CircularRedirectException is encountered when using a proxy (tinyproxy on a remote machine), whereas everything is fine when using no proxy. The target is a URL such as http://www.seoconsultants.com/w3c/status-codes/301.asp which has a 301 redirection.\n\nThe issue can be fixed by using ALLOW_CIRCULAR_REDIRECTS set to true (client params), but I can't consider this a \"real\" fix.\n\nHere is a snippet of code that exemplifies the problem (use your own proxy):\n\n---\nString proxyHost = \"xyz.webfactional.com\";\nint proxyPort = 7295;\n\nDefaultHttpClient httpclient = new DefaultHttpClient();\n// without a proxy it's OK!\nhttpclient.getParams().setParameter(ConnRoutePNames.DEFAULT_PROXY,\n        new HttpHost(proxyHost, proxyPort, \"http\"));\n\nHttpParams params = httpclient.getParams();\nHttpClientParams.setRedirecting(params, true);\nHttpProtocolParams.setUserAgent(params,\n        \"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.5; en-US; rv:1.9.0.10) Gecko/2009042315 Firefox/3.0.10\");\n\n// OK, this fixes the problem, but at what cost / other problems ?\n//httpclient.getParams().setParameter(ClientPNames.ALLOW_CIRCULAR_REDIRECTS, true);\n\nString url = \"http://www.seoconsultants.com/w3c/status-codes/301.asp\";\n\nHttpUriRequest request;\nHttpResponse response;\n\nrequest = new HttpGet(url);\nSystem.out.println(\"request = \" + request.getRequestLine());\nresponse = httpclient.execute(request);\nSystem.out.println(\"status = \" + response.getStatusLine());\nSystem.out.println(\"headers = \" + Arrays.asList(response.getAllHeaders()));\n---",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-587",
        "summary": "derelativizing of relative URIs with a scheme is incorrect",
        "description": "URI constructor \"public URI(URI base, URI relative) throws URIException\" assumes that if given 'relative' URI has a scheme, it should provide an authority and complete path to the constructed URI. However, a URI can have a scheme but still be relative, requiring the authority and base path of the 'base' URI. \n\nDemonstration code:\n\nURI base = new URI(\"http://www.example.com/some/page\");\nURI rel = new URI(\"http:boo\");\nURI derel = new URI(base,rel);\nderel.toString();\n(java.lang.String) http:boo\n\nIn fact, derel should be \"http://www.example.com/some/boo\". \n\nRFC2396 is a little confused about this; section 3.1 states \"\"Relative URI references are distinguished from absolute URI in that they do not begin with a scheme name.\" But, in section 5, there are several sentences talking about relative URIs that begin with schemes (and how this prevents using relative URIs that have leading path segments that look like scheme identifiers). \n\nRFC3896, which supercedes RFC2396, removes the implication a relative URI cannot begin with a scheme, leaving the other text explcitly discussing relative URIs with schemes. \n\nBoth Firefox (1.5) and IE (6.0) treat \"http:boo\" the same as \"boo\" for purposes of derelativization against an HTTP base URI, which would give the final URI \"http://www.example.com/some/boo\" in the example above. \n\nEven relative URIs like \"http:../../boo\" are explicitly legal. \n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-923",
        "summary": "NetscapeDraftSpec is too strict about cookie expires date format",
        "description": "The Netscape Draft specification (http://curl.haxx.se/rfc/cookie_spec.html) specifies clearly that the date format for Set-Cookie expires is \"Wdy, DD-Mon-YYYY HH:MM:SS GMT\". But on the other hand, in the examples section of the same document, the only example header that contains \"Expires\" is the following:\n\nSet-Cookie: CUSTOMER=WILE_E_COYOTE; path=/; expires=Wednesday, 09-Nov-99 23:12:40 GMT\n\nNote that the weekday is fully spelled out and that the year is written as two digits only. I would say that the specification therefore makes the 2 or 4 digit year optional. I think NetscapeDraftSpec should reflect this. An example of a product that uses the 2 digit version is jetty 6 and 7. When using httpclient 4 talking to a jetty server, any Set-Cookie headers for persistent cookies will be interpreted as a 4 digit year in the date and the cookie will immediately be disregarded as expired by some 2,000 years or so. Httpclient 3 on the other hand had no problem understanding the persistent cookies from jetty. I filed a bug report https://bugs.eclipse.org/bugs/show_bug.cgi?id=304698 on jetty to change their date format, but on the other hand I also think httpclient 4 is too strict about the date format when even the original specification uses two alternatives.\n\nWorkaround is easy by setting CookieSpecPNames.DATE_PATTERNS, but I really think that projects like jetty and httpclient should be compatible by default. Also, since the date format used by jetty is parsable but misinterpreted and disregarded by httpclient makes it especially hard to detect the first time on encounters the problem.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "HTTPCLIENT-337",
        "summary": "Move Content-Type to the RequestEntity",
        "description": "The content type is really a property of the RequestEntity.  It should be moved there.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-1065",
        "summary": "Documentation on SingleClientConnManager(SchemeRegistry schreg) constructor is wrong",
        "description": "Seems that the documentation for single-arg constructor SingleClientConnManager(SchemeRegistry schreg) is wrong.\n\nDocumentation says that incoming SchemeRegistry parameter can be null:\n    schreg - the scheme registry, or null for the default registry\n\nHowever, the constructor throws an exception in incoming schreg param is null:\n\n    /**\n     * Creates a new simple connection manager.\n     *\n     * @param params    the parameters for this manager\n     * @param schreg    the scheme registry, or\n     *                  <code>null</code> for the default registry\n     */\n    public SingleClientConnManager(HttpParams params,\n                                   SchemeRegistry schreg) {\n        if (schreg == null) {\n            throw new IllegalArgumentException\n                (\"Scheme registry must not be null.\");\n        }\n\n\nSo this is likely a documentation bug...",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "TASK"
    },
    {
        "key": "HTTPCLIENT-967",
        "summary": "allow cache to be configured as a non-shared (private) cache",
        "description": "Currently the CachingHttpClient only behaves as a shared cache, which is a safe and conservative assumption. However, in some settings, it would be appropriate to be able to configure the CachingHttpClient as a non-shared cache, which would make more responses cacheable, including:\n* responses to requests with Authorization headers\n* responses with 'Cache-Control: private'\n* ability to serve stale responses when invalidation fails for 'Cache-Control: proxy-revalidate'\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-420",
        "summary": "Provide a non-pooling connection manager",
        "description": "The current implementations of the connection managers all have a connection\npool. For applications requiring only single requests very rarely this is\noverkill. We should provide a very simple connection manager that uses a\nconnection only one time and then closes it right away.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "HTTPCLIENT-958",
        "summary": "client cache currently allows incomplete responses to be passed on to the client",
        "description": "Per the HTTP/1.1 spec:\n\n\"A cache that receives an incomplete response (for example, with fewer bytes of data than specified in a Content-Length header) MAY store the response. However, the cache MUST treat this as a partial response. Partial responses MAY be combined as described in section 13.5.4; the result might be a full response or might still be partial. A cache MUST NOT return a partial response to a client without explicitly marking it as such, using the 206 (Partial Content) status code. A cache MUST NOT return a partial response using a status code of 200 (OK).\"\n\n(http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.8)\n\nFor example, if a 200 response shows up with 128 bytes in the body but a Content-Length header of 256, the cache MUST NOT pass this through unchanged.\n",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    }
]