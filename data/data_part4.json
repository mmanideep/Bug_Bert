[
    {
        "key": "JCR-2147",
        "summary": "Remove deprecated classes in jackrabbit-core",
        "description": "similar to JCR-2109 i think i would be favorable to get rid of stuff that has been marked deprecated for 1.x releases.\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3272",
        "summary": "EventConsumer.canRead() should rely on AccessManager.isGranted()",
        "description": "The current implementation of EventConsumer.canRead() uses\nAccessManager.canRead(), which might cause issues if the item\ndoes not exist anymore. AccessManager.isGranted() explicitly\nmentions and supports checks on paths for items that do not\nyet exist or not exist anymore.\n\nSee also JCR-3271.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1937",
        "summary": "Automatic license header checking using the Apache Rat Plugin",
        "description": "To avoid problems with incorrect license headers, we should include some automated header check in the Maven build and have Hudson run the check whenever changes are committed.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-708",
        "summary": "SearchManager might throw when handling cluster event",
        "description": "When handling events that are generated from another node in the cluster, the SearchManager might try to index an index that does no longer exist. This results in an error message or even a NPE. The scenario looks as follows (A and B are nodes in a repository cluster)\n\n1: A adds node N\n2: A saves changes\n3: A removes node N\n4: A saves changes\n\nUpon receiving the event of a newly created node, B starts indexing node N. If this process hasn't been concluded before step 3 above, it will throw.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2783",
        "summary": "ItemManager.toString() causes StackOverflowError",
        "description": "",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1866",
        "summary": "Query may throw ArrayIndexOutOfBoundsException",
        "description": "There's a bug in DescendantSelfAxisQuery.DescendantSelfAxisScorer.skipTo() that causes the exception.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1503",
        "summary": "Typo in repository.xml",
        "description": "There's another typo in repository.xml. This is basically the same as JCR-1460, but for the SearchIndex element at the bottom of the repository.xml.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "JCR-835",
        "summary": "Java 1.4 compile error in Eclipse",
        "description": "As reported by Ate Douma in JCR-804, the revision 520841 introduced code that causes the Eclipse compiler to fail in Java 1.4 compliance mode. However, the same code compiles with the Sun JDK 1.4.\n\nThe problem is a enclosing class reference that an anonymous innner class instantiated in the constructor of a named inner class contains. Apparently (and understandably), in Eclipse 1.4 complier the instance references are not yet available when evaluating the super() arguments in the constructor.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "JCR-3165",
        "summary": "Consolidate compare behaviour for Value(s) and Comparable(s)",
        "description": "There are 2 different implementations of Value comparison (ValueComparator and Util). With the introduction of JCR-2906 which introduces arrays into the mix, I'd like to refactor all of them into one place, namely o.a.j.core.query.lucene.Util.\n\nThis will also allow for a wider scope of comparison for Value[], marked as TODO in the ValueComparator class.\n\nWill attach patch shortly",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-611",
        "summary": "Setup nightly builds for Jackrabbit",
        "description": "Once the Jackrabbit zone is created (see INFRA-1008), setup nightly Jackrabbit builds as discussed in http://thread.gmane.org/gmane.comp.apache.jackrabbit.devel/9190/.\n",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "JCR-232",
        "summary": "jcr:baseVersion is not updated when the base version is removed from the version history",
        "description": "\n        Session s1 = repo.login(new SimpleCredentials(\"user1\", \"pwd1\".toCharArray()));\n        Node root1 = s1.getRootNode() ;\n        Node test1 = root1.addNode(\"test\") ;\n        test1.addMixin(\"mix:versionable\");\n        s1.save() ;\n        System.out.println(test1.getProperty(\"jcr:baseVersion\").getValue().getString()) ;\n        test1.checkin() ;\n        System.out.println(test1.getProperty(\"jcr:baseVersion\").getValue().getString()) ;\n        test1.getVersionHistory().removeVersion(\"1.0\") ;\n        // the base version wasn't updated :(\n        System.out.println(test1.getProperty(\"jcr:baseVersion\").getValue().getString()) ;\n        // the next line throws ItemNotFoundException :(\n        test1.getBaseVersion() ;\n\njavax.jcr.ItemNotFoundException: c33bf049-c7e1-4b34-968a-63ff1b1113b0\n\tat org.apache.jackrabbit.core.ItemManager.createItemInstance(ItemManager.java:498)\n\tat org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:349)\n\tat org.apache.jackrabbit.core.PropertyImpl.getNode(PropertyImpl.java:642)\n\tat org.apache.jackrabbit.core.NodeImpl.getBaseVersion(NodeImpl.java:2960)\n\tat org.apache.jackrabbit.core.RemoveVersionTest.main(RemoveVersionTest.java:56)\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-98",
        "summary": "extensibility patch for simple WebDAV servlet",
        "description": "attaching a patch that makes the simple WebDAV servlet more extensible - subclasses can now provide their own support objects such as DavResourceFactory and DavLocatorFactory. also patches DavResourceImpl to make importXml and importFile methods protected, for subclass use.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-362",
        "summary": "restore sometime throws error about missing tmp files",
        "description": "Caused by: javax.jcr.RepositoryException: file backing binary value not\nfound: /server/apache-tomcat-5.5.15/temp/bin4435.tmp (No such file or\ndirectory): /server/apache-tomcat-5.5.15/temp/bin4435.tmp (No such file\nor directory)\n   at\norg.apache.jackrabbit.core.value.BLOBFileValue.getStream(BLOBFileValue.java:454)\n   at\norg.apache.jackrabbit.core.state.util.Serializer.serialize(Serializer.java:197)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1825",
        "summary": "DBDataStore doesn't support concurrent reads",
        "description": "My understanding is that setting parameter copyWhenReading to true should allow concurrent reads by spooling binary property to temporary file and free database resources (connection) immediately to make it available for other threads.\n\nAfter applying patch for JCR-1388, DBDataStore doesn't support concurrent reads anymore, resultSet is kept open and db connection is blocked until the stream is read and closed. When copyWhenReading is set to true db connection should be released immediately, this is the reason i guess why temporary file is used.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1804",
        "summary": "Added the functionality to Map and Manage Type Enum",
        "description": "OCM API does not come with a mapper that can map Type Enum.  I have added this functionality.  Attached patch has test cases that tests the feature for Simple fields and Collection fields (For both anotations and digester based implementations)",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-134",
        "summary": "Unreferenced VersionHistory should be deleted automatically.",
        "description": "since the creation of a VersionHistory is triggered by the creation of a mix:versionable node, the removal should happen automatically, as soon as no references to that version histroy exist anymore. this is the case, when all mix:versionable nodes (in all workspaces) belonging to that VH are deleted, and all the versions in the VH are removed i.e. only the jcr:rootVersion is left. At this point, the VH should be deleted aswell.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1245",
        "summary": "JCR2SPI: Use namespace decl. present in imported xml to resolve Name/Path values",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-2150",
        "summary": "Deprecate BLOBStore (use the DataStore instead)",
        "description": "I believe the blob store should be deprecated in favor of the data store (in the source code, and in the documentation). The blob store should still be supported in version 2.x of course.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2510",
        "summary": "AbstractResource: Use jcr:createdBy to expose DAV:creator-displayname",
        "description": "as of jcr 2.0 the DeltaV property DAV:creator-displayname could be extracted from the jcr:createdBy property.\nthe comment in abstract resource: \"// creator-displayname, comment: not value available from jcr\" therefore is outdated. and so is the subsequent line.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-372",
        "summary": "Consistently refer to \"Apache Jackrabbit\" in docs and site",
        "description": "We need to consistently refer to our project (and product) as Apache Jackrabbit\non our site and docs, except where the context is obvious.\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "TASK"
    },
    {
        "key": "JCR-955",
        "summary": "[PATCH] jackrabbit-webapp pom.xml patch to create an additional jar artifact",
        "description": "Modifies the jackrabbit-webapp pom.xml to create a jar artifact in addition to the existing war artifact, to allow the jackrabbit-webapp utility servlets to be reused in other modules.\n\nThe right way would be to create a separate jar module for the servlets (or move them to jackrabbit-jcr-commons?), and reuse that jar as a dependency in the jackrabbit-webapp. So I'm not sure if this patch deserves to be applied to the trunk, but it can be useful as a workaround before a cleaner solution is implemented.\n\nSee also http://mail-archives.apache.org/mod_mbox/jackrabbit-dev/200705.mbox/%3C510143ac0705151453t7a0eb4cam859a40fb106e81f5@mail.gmail.com%3E which discusses possible improvements to these jackrabbit-webapp utility servlets.\n\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3280",
        "summary": "SQL2 joins on empty sets are not efficient",
        "description": "It seems that in the cases where the LEFT side of the join doesn't contain any hits, the QueryEngine in unable to generate an efficient query for the RIGHT side, so it basically select all the possible nodes.\nSee this discussion as context [0].\n\nExample:\nLEFT side has hits, RIGHT side select is fast given some conditions: \n> SQL2 JOIN LEFT SIDE took 18 ms. fetched 145 rows.\n> SQL2 JOIN RIGHT SIDE took 67 ms. fetched 0 rows.\n\nLEFT side has no hits, RIGHT select everything\n> SQL2 JOIN LEFT SIDE took 8 ms. fetched 0 rows.\n> SQL2 JOIN RIGHT SIDE took 845 ms. fetched 13055 rows.\n...so it fetches 130k nodes and doesn't keep any of them.\n\n\n[0] http://jackrabbit.510166.n4.nabble.com/Strange-Search-Performance-problem-with-OR-td4507121.html\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-214",
        "summary": "NullPointerException in LuceneQueryBuilder",
        "description": "after setting up the following query:\n\n//mycoreclass[@ID= 'ArchNachl_class_003']//label[@* = 'A']\n\nI get a NullPointerException:\n\n\njava.lang.NullPointerException\n        at org.apache.jackrabbit.core.query.lucene.LuceneQueryBuilder.visit(LuceneQueryBuilder.java:553)\n        at org.apache.jackrabbit.core.query.RelationQueryNode.accept(RelationQueryNode.java:157)\n        at org.apache.jackrabbit.core.query.NAryQueryNode.acceptOperands(NAryQueryNode.java:131)\n        at org.apache.jackrabbit.core.query.lucene.LuceneQueryBuilder.visit(LuceneQueryBuilder.java:421)\n        at org.apache.jackrabbit.core.query.LocationStepQueryNode.accept(LocationStepQueryNode.java:156)\n        at org.apache.jackrabbit.core.query.lucene.LuceneQueryBuilder.visit(LuceneQueryBuilder.java:400)\n        at org.apache.jackrabbit.core.query.PathQueryNode.accept(PathQueryNode.java:47)\n        at org.apache.jackrabbit.core.query.lucene.LuceneQueryBuilder.visit(LuceneQueryBuilder.java:200)\n        at org.apache.jackrabbit.core.query.QueryRootNode.accept(QueryRootNode.java:112)\n        at org.apache.jackrabbit.core.query.lucene.LuceneQueryBuilder.createLuceneQuery(LuceneQueryBuilder.java:190)\n        at org.apache.jackrabbit.core.query.lucene.LuceneQueryBuilder.createQuery(LuceneQueryBuilder.java:172)\n        at org.apache.jackrabbit.core.query.lucene.QueryImpl.execute(QueryImpl.java:152)\n        at org.apache.jackrabbit.core.query.QueryImpl.execute(QueryImpl.java:132)\n\nI don't really know if it's a valid query. I should search for every label that has a property value (what ever name the property may have) that is  somewhere under a specific \"mycoreclass\" node. Either way Jackrabbit should of cause not exit with a NullPointerExeption here.\n\nI'm using the very current svn snapshot of jackrabbit. For the records line 550-557 of LuceneQueryBuilder.java look like this now:\n\n        String field = \"\";\n        try {\n            field = node.getProperty().toJCRName(nsMappings);\n        } catch (NoPrefixDeclaredException e) {\n            // should never happen\n            exceptions.add(e);\n        }\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1523",
        "summary": "[PATCH] png, apng, mng text extractor",
        "description": "Text extractor for tEXt chunk for png, apng and mng formats",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1566",
        "summary": "Data Store: DB2 fails to create the table",
        "description": "DB2 throws an exception(1) when creating the table. The correct SQL sentence to create it is:\ncreateTable=CREATE TABLE ${tablePrefix}${table}(ID VARCHAR(255) PRIMARY KEY NOT NULL, LENGTH BIGINT, LAST_MODIFIED BIGINT, DATA BLOB(1000M))\n(1): Sorry but I don't have the exception information since I made this change a few weeks ago.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-483",
        "summary": "Lock tokens reains in session after unlock",
        "description": "I do the followin steps:\n\n* node.lock()\n* session.getLockTokens() -> This show the lock token generated by the\nprevious lock.\n* node.unlock()\n* session.getLockTokens() -> Still show me the generated token \u00bf?\u00bf?\n\nIf I unlock a node, the token should'n be delete from the session?",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2793",
        "summary": "Typo in NodeTypeRegistry",
        "description": "It seems a little typo has been introduced in the NodeTypeRegistry, as illustrated in this stack trace : \n\nCaused by: javax.jcr.RepositoryException: internal error: invalid resource: nodetypes/custom_nodetypes.xml\n\tat org.apache.jackrabbit.core.nodetype.NodeTypeRegistry.<init>(NodeTypeRegistry.java:703) ~[jackrabbit-core-2.2-SNAPSHOT.jar:2.2-SNAPSHOT]\n\tat org.apache.jackrabbit.core.RepositoryImpl.createNodeTypeRegistry(RepositoryImpl.java:422) ~[jackrabbit-core-2.2-SNAPSHOT.jar:na]\n\tat org.apache.jackrabbit.core.RepositoryImpl.<init>(RepositoryImpl.java:294) ~[jackrabbit-core-2.2-SNAPSHOT.jar:na]\n\nThis happens when using a DbFileSystem for the root filesystem. This didn't cause a problem in 2.1.1\n\nThe patch attached to this ticket correct the issue.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "JCR-801",
        "summary": "Support for single-workspace repositories",
        "description": "There should be a way to configure the test cases in a way such that NodeTest.java can pass although the repository implementation does not support multiple workspaces.\n\nThe cleanest approach probably would be to allow javax.jcr.tck.workspacename to stay undefined, and to skip the tests in that case. Alternatives would be a special name indicating lack of support for other workspaces, or an additional config variable.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2470",
        "summary": "Include to jackrabbit-jcr-rmi and jackrabbit-jcr-servlet in main trunk",
        "description": "Jackrabbit 2.0 should include the 2.0 version of the RMI component and the related jcr-servlet updates.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-354",
        "summary": "Use a pre-generated version of XPath.jjt",
        "description": "The workaround described in JCR-46 is still causing extra steps for Java 5 users. I'd like to solve this issue by including a pre-generated version of the XPath.jjt file as a normal source file. This will avoid the need for XSL transformations during normal builds and thus remove the need for the extra steps.\n\nI'll create a patch for this and unless anyone objects, I'm planning to include it in the 1.0 branch as well as the svn trunk.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1024",
        "summary": "Only load root node definition when required",
        "description": "The root node definition is currently loaded whenever a session logs in.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3152",
        "summary": "AccessControlImporter does not import repo level ac content",
        "description": "the implementation of the ProtectedNodeImporter responsible for dealing with access control content should be\nadjusted such that it can properly cope with repository level access control that may be stored together with\nthe root node (by using access control API with null path).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1055",
        "summary": "Incorrect node position after import",
        "description": "I have found a behavior that does not seem to be consistent with the\nspec:\n\nAfter replacing a node with importXML using IMPORT_UUID_COLLISION_REPLACE_EXISTING the new node is not at the position of the replaced node (talking about the position among the siblings).\n\nThe origininal node is removed, but the new node is created as the last child of the parent node, and not spec-compliant at the position of the replaced node.\n\nHere how I use it:\n\n// assume Session s, Node n, String text (holding XML data)\n\ns.importXML(\n\tn.getPath(), \n\tnew ByteArrayInputStream (text.getBytes(\"UTF-8\")),\n\tImportUUIDBehavior.IMPORT_UUID_COLLISION_REPLACE_EXISTING\n);\ns.save();\n \n\nAnd here a quote from the spec section 7.3.6\n\nImportUUIDBehavior.IMPORT_UUID_COLLISION_REPLACE_EXISTING: \nIf an incoming referenceable node has the same UUID as a node already existing in the workspace then the already existing node is replaced by the incoming node in the same position as the existing node.\n[note \"same position\"]\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1828",
        "summary": "Improvement in comment of QValue.getLength() ",
        "description": "The comment of QValue.getLength() should document -1 return values.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1654",
        "summary": "Incorrect slf4j-log4j12 dependency scope in spi-commons",
        "description": "The slf4j-log4j12 dependency scope in jackrabbit-spi-commons is \"runtime\", when it should be \"test\". We don't want to impose a specific logging solution to downstream projects.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2422",
        "summary": "Add the new DataSource element to the repository DTD",
        "description": "The connection pooling feature from JCR-1456 introduced a new DataSource configuration element to Jackrabbit. It should be added to the repository config DTD.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3231",
        "summary": "Replace BundleFsPersistenceManager with DerbyPersistenceManager in the JR Core indexing tests",
        "description": "Running the JR Core tests yields a deprecation warning on account of workspace config being outdated for some indexing tests:\n\n  INFO  o.a.j.core.config.BeanConfig - org.apache.jackrabbit.core.persistence.pool.BundleFsPersistenceManager is deprecated. Please use org.apache.jackrabbit.core.persistence.bundle.BundleFsPersistenceManager instead\n\nThis shows up 3 times in the logs because there are 3 indexing related workspaces that need this config update.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1902",
        "summary": "Warning while building DAV:parent-set for root-node resource",
        "description": "the following warning is generated when calculating DAV:parent-set for the resource representing the root-node:\n\n05.12.2008 11:49:50 *WARN * DavResourceImpl: unable to calculate parent set (DavResourceImpl.java, line 955)\njavax.jcr.ItemNotFoundException: root node doesn't have a parent\n        at org.apache.jackrabbit.core.NodeImpl.getParent(NodeImpl.java:2078)\n        at org.apache.jackrabbit.webdav.simple.DavResourceImpl.getParentElements(DavResourceImpl.java:949)\n        at org.apache.jackrabbit.webdav.simple.DavResourceImpl.initProperties(DavResourceImpl.java:393)\n\nthis could simply be avoided by slightly modifying the method getParentElements (starting at line 937) and adding a test asserting that node.getParent() is not called for the root node.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1536",
        "summary": "\"Index already present\" exception when opening a restored repository",
        "description": "I have created a new repository, added one node, then copied all files while Jackrabbit is running.\nThen closed the repository, restored the backup, and tried to open the repository.\nUnfortunately, this resulted in the following exception:\n\njavax.jcr.RepositoryException: Index already present: Index already present: Index already present\n\tat org.apache.jackrabbit.core.SearchManager.initializeQueryHandler(SearchManager.java:575)\n\tat org.apache.jackrabbit.core.SearchManager.<init>(SearchManager.java:255)\n\tat org.apache.jackrabbit.core.RepositoryImpl$WorkspaceInfo.getSearchManager(RepositoryImpl.java:1613)\n\tat org.apache.jackrabbit.core.RepositoryImpl.initWorkspace(RepositoryImpl.java:606)\n\nThe backup contains the following index file:\nworkspaces/default/index/redo.log\nThere are no other files or directories or files in that directory (also no _n directories). The content of redo.log is:\n\n-1 STR\n-1 ADD cafebabe-cafe-babe-cafe-babecafebabe\n-1 COM\n0 STR\n0 DEL cafebabe-cafe-babe-cafe-babecafebabe\n0 ADD fa87759b-f9fe-4ba8-986c-d1914ffce3de\n0 ADD eda04b36-9c21-4712-bedf-206c36f0e3d2\n0 ADD ae917cca-a0bb-4ac0-a16d-805aac6c7b10\n0 ADD cafebabe-cafe-babe-cafe-babecafebabe\n0 COM\n1 STR\n1 ADD 0121f271-bbe7-4f71-a793-5f4380f3c487\n1 COM\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-6",
        "summary": "VersionIteratorImpl problem?",
        "description": "I meet with problem in VersionIterator:\nClassic nextVersion()/hasNext() loop  for VersionIterator become endless. \n\nI think problem with peek/pop misprint:\n\n    public Version nextVersion() {\n.......\n        InternalVersion ret = (InternalVersion) successors.<b>peek</b>();\n......\n    }\n\nI change to\nInternalVersion ret = (InternalVersion) successors.<b>pop</b>();\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1516",
        "summary": "Add Compact Namespace and Node Type Definition support to spi-commons",
        "description": "Add support for reading and writing of Compact Namespace and Node Type Definitions (cnd-files) to spi-commons. ",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1430",
        "summary": "mvn eclipse:eclipse inconsistent",
        "description": "mvn eclipse:eclipse result is inconsistent, due to deprecated avacc-maven-plugin usage.\nshould use piped \"jjtree-javacc\" goal.\ncore :\n          <execution>\n            <id>fulltext-jjtree</id>\n            <configuration>\n              <sourceDirectory>${basedir}/src/main/javacc/fulltext</sourceDirectory>\n              <outputDirectory>${project.build.directory}/generated-src/main/java</outputDirectory>\n              <timestampDirectory>${project.build.directory}/generated-src/javacc-timestamp</timestampDirectory>\n              <packageName>org.apache.jackrabbit.core.query.lucene.fulltext</packageName>\n            </configuration>\n            <goals>\n              <goal>jjtree-javacc</goal>\n            </goals>\n          </execution>\n\nspi-commons:\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>sql-jjtree-javacc</id>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<sourceDirectory>${basedir}/src/main/javacc/sql</sourceDirectory>\n\t\t\t\t\t\t\t<outputDirectory>${project.build.directory}/generated-src/main/java</outputDirectory>\n\t\t\t\t\t\t\t<timestampDirectory>${project.build.directory}/generated-src/javacc-timestamp</timestampDirectory>\n\t\t\t\t\t\t\t<packageName>org.apache.jackrabbit.spi.commons.query.sql</packageName>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>jjtree-javacc</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t</execution>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>xpath-jjtree-javacc</id>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<sourceDirectory>${basedir}/src/main/javacc/xpath</sourceDirectory>\n\t\t\t\t\t\t\t<outputDirectory>${project.build.directory}/generated-src/main/java</outputDirectory>\n\t\t\t\t\t\t\t<timestampDirectory>${project.build.directory}/generated-src/javacc-timestamp</timestampDirectory>\n\t\t\t\t\t\t\t<packageName>org.apache.jackrabbit.spi.commons.query.xpath</packageName>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>jjtree-javacc</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t</execution>",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1360",
        "summary": "Parsing built-in CND and XML nodetypes does not result in equal nt-definitions",
        "description": "i created a test in order to make sure builtin-nodetypes.xml and builtin-nodetypes.cnd provide the same definitions (actually i only wanted to test my own changes).\n\nit reveals that the existing built-in NodeTypeDefinitions are not equal due to the following reason:\n\n- in the xml-format nt:base is always specified if no other super type extends from nt:base\n- in the cnd notation the nt:base is omitted (see below for quote from appendix of jsr 283) even if other super type(s) are\n  defined and none of them extends from nt:base.\n\nthis affects the following nodetypes (all extending from mix:referenceable only):\n\nnt:versionHistory\nnt:version\nnt:frozenNode\nnt:resource\n\n\nquote from public-review of jsr 283:\n\n\"7.2.2.4 Supertypes [...]\nAfter the node type name comes the optional list of supertypes. If this element is not present and the node type is not a mixin (see 7.2.2.5 Options), then a supertype of nt:base is assumed.\"\n\n\nI'm not totally sure, if according to the quote above the built-in cnd-definitions are valid at all. since it states, that the nt:base is assumed if no other super type is defined. In the case of the node types above, mix:referenceable is defined to be the only super type, which is not totally true... the non-mixin types are always sub types of nt:base.\n\nIn either case: From my understanding the node types resulting from parsing the xml and the cnd file should be equal.\nIf the definitions are valid, we may need to adjust the CompactNodeTypeDefReader.\n\n\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1698",
        "summary": "Remove unnecessary TestAll classes in jcr-commons",
        "description": "The module jackrabbit-jcr-commons uses the default test configuration, which means the TestAll test suites are not necessary. They actually cause all tests to be executed twice.",
        "label": "NUG",
        "classified": "TEST",
        "type": "TEST"
    },
    {
        "key": "JCR-2309",
        "summary": "Remove excessive dependencies from jcr-client module",
        "description": "",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2627",
        "summary": "System-view export/import of multi-value property does not respect JCR 2.0",
        "description": "JCR 2.0 has a defined specification about system-view export of multi-value properties when these property have only one value.\nThe attribute sv:multiple attribute of sv:property tag is not written in output stream result.\n\nAnyway if I add that one manually and try to import the modified system-view, multi-value properties with an only value are not recognized, and these properties are simply stored like a single-value ones.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-455",
        "summary": "InternalXAResource.rollback() can be called twice and without prepare",
        "description": "during the prepare phase in the transaction context, each resource is 'prepared'. if one of them fails to prepare, the rest is rolledback, and later all of them are rolledback again. this can cause that:\n- a resource that is never prepared is rolled back (which is ok, since is may need to cleanup stuff)\n- a resource's rollback() may be called twice (which i don't know, if it's ok)\n\nhowever, some of the resources are buggy and can't handle neither case correctly.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-383",
        "summary": "Default namespaces in JackrabbitNodeTypeManager.registerNodetypes",
        "description": "It would be nice if it wasn't necessary to always specify all the namespaces in node type definition files passed to JackrabbitNodeTypeManager.registerNodeTypes(). The node type parsers should by default use the persistent namespace mappings, but allow custom mappigns to be specified in the parsed node type definition files.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1667",
        "summary": "JCARepositoryManager does not close InputStream used to obtain repository config from classpath",
        "description": "",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-712",
        "summary": "NPE Exception Thrown By FileJournal During Commit Operation",
        "description": "The following exception stack traces appearing repeatedly during a performance test of a JCR cluster at a customer site. \n\nERROR - Unexpected error while preparing log entry.\njava.lang.NullPointerException\n\tat org.apache.jackrabbit.core.cluster.FileRevision.unlock(FileRevision.java:117)\n\tat org.apache.jackrabbit.core.cluster.FileRevision.get(FileRevision.java:146)\n\tat org.apache.jackrabbit.core.cluster.FileJournal.sync(FileJournal.java:296)\n\tat org.apache.jackrabbit.core.cluster.FileJournal.begin(FileJournal.java:435)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.updatePrepared(ClusterNode.java:399)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.access$000(ClusterNode.java:40)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode$WorkspaceUpdateChannel.updatePrepared(ClusterNode.java:559)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager$Update.begin(SharedItemStateManager.java:647)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.beginUpdate(SharedItemStateManager.java:778)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:808)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:326)\n\tat org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:313)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:302)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:295)\n\tat org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1204)\n\tat org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:821)\n\t\nERROR - Unexpected error while committing log entry.\njava.lang.NullPointerException\n\tat org.apache.jackrabbit.core.cluster.FileJournal.commit(FileJournal.java:660)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.updateCommitted(ClusterNode.java:425)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode$WorkspaceUpdateChannel.updateCommitted(ClusterNode.java:566)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager$Update.end(SharedItemStateManager.java:712)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:808)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:326)\n\tat org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:313)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:302)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:295)\n\tat org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1204)\n\tat org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:821)\n\t",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3066",
        "summary": "Use only one scheduler for repository tasks",
        "description": "There are still a few Timer instances being used by Jackrabbit. It would be better if all tasks were scheduled by the central ScheduledExecutorService thread pool of the repository.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-130",
        "summary": "extensibility changes to SimpleWebdavServlet",
        "description": "the new SimpleWebdavServlet class lost some of the extensibility of the old WebdavServlet that allowed subclasses to ignore the dependency on RepositoryAccessServlet and provide their own support objects. attached is a patch that adds back these qualities.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1596",
        "summary": "search.jsp doesn't handle utf-8 parameters correctly",
        "description": "\n1.  I  cannot use WebDav client to uploaded a file whose name is in Chinese.  The file name I had is ''\u90ed\u53ef\u4e3a.txt'  and the uploaded command by the WebDav client did something like:\n\n  ========= Outbound Message =========\nPUT /op/%ED%EF%3A.txt HTTP/1.1\nHost: localhost:8080\n-----\n\n The server didn't decode it correctly -- the result is the file name got screwed and the file content was not uploaded.\n\n2. In the default web.war module,  there is search.jsp for rendering the search page. If I type Chinese text in the search box,  search.jsp does not decode the input parameter from ISO-8859-1 to utf-8 and in turn the search engine searches wrong string.\n\n3. The search engine does do search correctly if I hardcode the query  variable in search.jsp or do decoding the query parameter from ISO-885901 to utf-8.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2674",
        "summary": "FileDataStore ignores return code from setLastModified",
        "description": "Garbage collection depends on the file modification date being successfully updated when records are \"touched\" during the mark phase. The result of a silent failure is the catastrophic loss of the file in the sweep phase.\n\nFileDataStore.getRecordIfStored does not, however, check the return code from setLastModified.\n\nI believe I was bitten by this when my dev deployment ran out of disk space. A substantial portion of my datastore was deleted, and the best explanation I can come up with is that the setLastModified calls started (silently) failing, leading to massive overkill in the sweep.\n\nThere is also a call to setLastModified in FileDataStore.addRecord which is not strictly correct in the face of GC (i.e. it needs the resolution offset, and also must succeed if the file is writable or risk incorrect collection).\n\nPatch to follow.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1989",
        "summary": "AppendRecord writes single bytes to disk",
        "description": "The AppendRecord initially buffers writes in memory and starts\nto write it to a temp file as soon as it occupies more than\n64k heap. After switching to the temp file, data is written\nunbuffered.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-191",
        "summary": "Query throws UnsupportedOperationException",
        "description": "When executing an absolute XPath statement where the first location step is not jcr:root the Query may throw an UnsupportedOperationException:\n\nQuery: /foo//element(*, nt:unstructured)[@prop = 'bar']\n\nStacktrace:\njava.lang.UnsupportedOperationException\n        at org.apache.jackrabbit.core.query.lucene.CachingMultiReader$MultiTermDocs.skipTo(CachingMultiReader.java:281)\n        at org.apache.lucene.search.TermScorer.skipTo(TermScorer.java:88)\n        at org.apache.lucene.search.ConjunctionScorer.doNext(ConjunctionScorer.java:53)\n        at org.apache.lucene.search.ConjunctionScorer.next(ConjunctionScorer.java:48)\n        at org.apache.lucene.search.Scorer.score(Scorer.java:37)\n        at org.apache.jackrabbit.core.query.lucene.ChildAxisQuery$ChildAxisScorer.calculateChildren(ChildAxisQuery.java:291)\n        at org.apache.jackrabbit.core.query.lucene.ChildAxisQuery$ChildAxisScorer.next(ChildAxisQuery.java:251)\n        at org.apache.lucene.search.Scorer.score(Scorer.java:37)\n        at org.apache.jackrabbit.core.query.lucene.DescendantSelfAxisQuery$DescendantSelfAxisScorer.calculateSubHits(DescendantSelfAxisQuery.java:302)\n        at org.apache.jackrabbit.core.query.lucene.DescendantSelfAxisQuery$DescendantSelfAxisScorer.next(DescendantSelfAxisQuery.java:237)\n        at org.apache.lucene.search.Scorer.score(Scorer.java:37)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:92)\n        at org.apache.lucene.search.Hits.getMoreDocs(Hits.java:64)\n        at org.apache.lucene.search.Hits.<init>(Hits.java:43)\n        at org.apache.lucene.search.Searcher.search(Searcher.java:33)\n        at org.apache.lucene.search.Searcher.search(Searcher.java:27)\n        at org.apache.jackrabbit.core.query.lucene.SearchIndex.executeQuery(SearchIndex.java:287)\n        at org.apache.jackrabbit.core.query.lucene.QueryImpl.execute(QueryImpl.java:179)\n        at org.apache.jackrabbit.core.query.QueryImpl.execute(QueryImpl.java:132)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-513",
        "summary": "TCK: SetPropertyAssumeTypeTest doesn't allow ValueFormatException upon type conversion failure",
        "description": "SetPropertyAssumeTypeTest# testValuesConstraintVioloationExceptionBecauseOfInvalidTypeParameter\n\nThis test should allow an implementation to throw ValueFormatException.  In Section 7.1.5, the Javadoc for setProperty(String, Value[] int) states: \"If the property type of the supplied Value objects is different from that specified, then a best-effort conversion is attempted. If the conversion fails, a ValueFormatException is thrown.\"\n\nProposal: catch and consume ValueFormatException.\n\n--- SetPropertyAssumeTypeTest.java      (revision 422074)\n+++ SetPropertyAssumeTypeTest.java      (working copy)\n@@ -28,6 +28,7 @@\n import javax.jcr.PropertyType;\n import javax.jcr.RepositoryException;\n import javax.jcr.Property;\n+import javax.jcr.ValueFormatException;\n import java.util.Calendar;\n import java.util.Date;\n  \n@@ -525,6 +526,9 @@\n         catch (ConstraintViolationException e) {\n             // success\n         }\n+        catch (ValueFormatException e) {\n+            // success\n+        }\n     }\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-681",
        "summary": "NullPointerException in ServerRow",
        "description": "A NullPointerException occurs in ServerRow.getValues() when the underlying Value array contains a null reference. See http://www.nabble.com/exception-after-calling-webdav-search-command-tf2826750.html for the details.\n\njava.lang.NullPointerException\n     at org.apache.jackrabbit.rmi.value.StatefulValueAdapter.getType(StatefulValueAdapter.java:98)\n     at org.apache.jackrabbit.rmi.value.SerialValue.<init>(SerialValue.java:65)\n     at org.apache.jackrabbit.rmi.value.SerialValueFactory.makeSerialValue(SerialValueFactory.java:100)\n     at org.apache.jackrabbit.rmi.value.SerialValueFactory.makeSerialValueArray(SerialValueFactory.java:77)\n     at org.apache.jackrabbit.rmi.server.ServerRow.getValues(ServerRow.java:58)\n\nThe best solution would be to explicitly handle nulls in SerialValueFactory.makeSerialValue().",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1882",
        "summary": "Avoid ${project.version} in dependencies",
        "description": "Another one for Jackrabbit 1.5, we should avoid using ${project.version} for our dependencies and override the versions of any transitive dependencies that use ${project.version} (notably the Jetty dependencies in jackrabbit-standalone) to avoid problems with Maven < 2.0.9 caused by MNG-2339 [1].\n\n[1] http://jira.codehaus.org/browse/MNG-2339\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2231",
        "summary": "Avoid item state reads during Session.logout()",
        "description": "Local item states are discarded during Session.logout(). Currently the CachingHierarchyManager is still registered as a item state listener at that time and will cause numerous ItemStateManager.hasItemState() calls. This is unnecessary and just adds overhead to the logout call. In addition it will also contribute to a potential lock contention on the SharedItemStateManager.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2901",
        "summary": "JCR-2523 break the transaction handling in container managed environment",
        "description": "during the cleanup (returning to the pool) of an jca managed connection,  an new internal session is created in the object JCAManagedConnection in the method cleanup, this is supposed to fix JCR-2523, The sideeffect is, that the XA-Resource (variable-xaResource) in JCAManagedConnection is not anymore the same XASessionImpl Object like the session Object. Subsequent calls on this connection, lead that the internal session variable is not anymore informed about the current transaction context. (XAItemStateManager, variables tx and txLog are null), because only the xaResource is informed about the new transaction context. Result is that the complete transaction handling does not work anymore.\nI attached a sample project which shows this behaviour.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-989",
        "summary": "Modify LazyQueryResultImpl to allow resultFetchSize to be set programmatically",
        "description": "In our application we have a search which only shows part of a query result. We always know which part of the result needs to be shown. This means we know in advance how many results need to be fetched. I would like to be able to programmatically set resultFetchSize to minimize the number of loaded lucene docs and therefore improve the performance.\nI know it is already possible to the set the resultFetchSize via the index configuration, but this number is fixed and doesn't work well in environments where you use paging for your results because if you set this number too low the query will be executed multiple times and if you set it too high too many lucene docs are loaded.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2394",
        "summary": "Add timing information to event delivery",
        "description": "There should be debug messages that contain information on how long event listeners spend iterating over the delivered events.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-472",
        "summary": "Wrap IllegalArgumentException from UUID when bad ID passed to Session.getNodeByUUID",
        "description": "Hi,\n\nOn 6/30/06, David Kennedy <davek@us.ibm.com> wrote:\n> When invoking session.getNodeByUUID and passing an invalid ID, an\n> IllegalArgumentException is thrown.  Should this be wrapped in an\n> ItemNotFoundException or RepositoryException by SessionImpl?\n\nGood point, an ItemNotFoundException would probably be best. Could you\nplease file a Jira issue for this?\n\nBR,\n\nJukka Zitting",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1714",
        "summary": "QueryImpl result offSet must be considered after security class grant the item.",
        "description": "ackrabbit version is 1.4 (jackrabbit-core - 1.4.5).\nI use searches with result limit and offset but it is working some wrong for my case.\nLets suppose the total of nodes that will return with the search:\n\nNAME      - GRANTACCESS -   OFFSET\nnode1     -     true                    - 0\nnode2     -     false                  -  1\nnode3     -     true                    - 2\nnode4     -     true                    - 3\nnode5     -     false                  -  4\n\nMy page must have 2 records, so first I do a count for the search and get size of 3 records (after filtered by my security class invoked automatically by jackrabbit), so I have 2 pages to show to the user. The first page must return 2 records, of course, and the second must return 1 record.\n\nIn the first search I do set:\nQueryImp.setOffset(0);\nQueryImpl.setLimit(2);\n\nSo, I get the nodes 1 and 3, thats correct.\n\nIn the second same search (for second page), I do set:\nQueryImp.setOffset(2);\nQueryImpl.setLimit(2);\n\nThis way I pretend to get two records, starting from the record nro 3, which would be only the node4.\nBut, the result I got is node3 (again) and node4, because the offset worked not according to the grantacess (provided by the security class), but according to the sequence of the raw result.\n\nThis offset have to start in the correct position, counting only the granted nodes returned by the security class.\nHope this make sense for you.\n\nThanks.\nHelio.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1754",
        "summary": " The jackrabbit-ocm DTD 1.5 is missing and has to be publish",
        "description": "\nThe jackrabbit-ocm DTD 1.5 is missing and it should be made available for reference on the Jackrabbit web site.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2062",
        "summary": "JSR 283: Repository Compliance",
        "description": "JSR 283 defines a huge set of new (or changed) repository descriptors as well as a couple of new methods on the\nRepository interface that allows the API consumer to determine the feature set exposed by an implementation.\n\nThe new methods are\n\n- Repository.isStandardDescriptor(String key)\n- Repository.isSingleValueDescriptor(String key)\n- Repository.getDescriptorValue(String key) Value\n- Repository.getDescriptorValues(String key) Value[]",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-655",
        "summary": "PropertyReadMethodsTest should also work on NAME property",
        "description": "Some test cases in PropertyReadMethodsTest require a String property even though a NAME property like jcr:primaryType would be sufficient.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-3205",
        "summary": "Missing support for lock timeout and ownerHint in jcr-server",
        "description": "trying to set the lock timeout when creating a lock seems not to work over the davex transport. the timeout is always 2147483.\n\nthis was my test code:\n\nimport javax.jcr.*;\nimport javax.jcr.lock.*;\n\nimport org.apache.jackrabbit.jcr2spi.RepositoryImpl;\nimport org.apache.jackrabbit.jcr2spi.config.RepositoryConfig;\n\n\nString url = \"http://localhost:8080/server/\";\nString workspace = \"tests\";\n\nRepositoryConfig config = new RepositoryConfigImplTest(repoUrl);\nRepository repo = RepositoryImpl.create(config);\n\nCredentials sc = new SimpleCredentials(\"admin\",\"admin\".toCharArray());\nSession s = repo.login(sc,workspace);\n\nNode t;\nif (s.getRootNode().hasNode(\"test\")) {\n    t = s.getRootNode().getNode(\"test\");\n} else {\n    t = s.getRootNode().addNode(\"test\", \"nt:unstructured\");\n}\nt.addMixin(\"mix:lockable\");\ns.save();\nLockManager m = s.getWorkspace().getLockManager();\nLock l = m.lock(t.getPath(), false, true, 10, \"me\");\nSystem.out.println(l.getSecondsRemaining());\n\nand the output is 2147483\n\n\nthe relevant communication fragment is below, i attach the full trace in case i miss something.\n\nLOCK /server/tests/jcr%3aroot/test HTTP/1.1\nTimeout: Second-10\nDepth: 0\nLink: <urn:uuid0c740bb9-042a-4ef2-b019-1a6c52784c29>; rel=\"http://www.day.com/jcr/webdav/1.0/session-id\"\nAuthorization: Basic YWRtaW46YWRtaW4=\nUser-Agent: Jakarta Commons-HttpClient/3.0\nHost: localhost:8080\nContent-Length: 254\nContent-Type: text/xml; charset=UTF-8\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?><D:lockinfo xmlns:D=\"DAV:\"><D:lockscope><dcr:exclusive-session-scoped xmlns:dcr=\"http://www.day.com/jcr/webdav/1.0\"/></D:lockscope><D:locktype><D:write/></D:locktype><D:owner>me</D:owner></D:lockinfo>\n\nHTTP/1.1 200 OK\nContent-Type: text/xml; charset=utf-8\nContent-Length: 450\nLock-Token: <aa724c28-3c24-41e8-a3b4-9fc129adf732>\nServer: Jetty(6.1.x)\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?><D:prop xmlns:D=\"DAV:\"><D:lockdiscovery><D:activelock><D:lockscope><dcr:exclusive-session-scoped xmlns:dcr=\"http://www.day.com/jcr/webdav/1.0\"/></D:lockscope><D:locktype><D:write/></D:locktype><D:depth>0</D:depth><D:timeout>Second-2147483</D:timeout><D:owner>admin</D:owner><D:locktoken><D:href>aa724c28-3c24-41e8-a3b4-9fc129adf732</D:href></D:locktoken></D:activelock></D:lockdiscovery></D:prop>\n\n\n\nby the way: if i do not explicitly logout before the program exits, the lock is also not released even though it is session based. should the session not trigger a logout on destruction?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2275",
        "summary": "some legal jcr names cause unneccessary server-roundtrips ",
        "description": "assume the following legal qualified jcr names:\n\n\"{foo}\"\n\"{foo} bar\"\n\nwhen items with such names are read from the spi layer, they are first interpreted as expanded form names.\na prefix lookup for namespace 'foo' fails and the name is treated as qualified jcr name.\n\n=> depending on the spi implementation, a server-roundtrip is required in order to determine that 'foo' is not a\nregistered namespace. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1545",
        "summary": "webapp: troubleshooting.jsp fails",
        "description": "",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2404",
        "summary": "Return null for optional configuration elements",
        "description": "Two recently introduced configuration elements are optional but the configuration parser still returns an instance when the elements are missing in the configuration. The parser should return null when an element is not there in order to distinguish it from the case where an empty element is present. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1661",
        "summary": "Extend mimetype list of text extractors",
        "description": "Do you think it would be possible to extend the mimetype list of the\nMsPowerpoint and MsExcel textextractors with \"application/powerpoint\" and\n\"application/excel\"? \n\nIt just took me half an hour to figure out why my\ndocuments didn't turn up in a jackrabbit fulltext-search and maybe other\nusers might run into the same problem...\n\nI'm not sure if there is some kind of standard which lists the possible\ndefault mimetypes but after a quick google search it seems to me that they\nare not that uncommon.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1874",
        "summary": "Move generic locking tests from jcr2spi to jackrabbit-jcr-tests",
        "description": "once we touch the jackrabbit-jcr-tests for the JSR 283 implementation, we should also move the generic tests from jackrabbit-jcr2spi to the overall test suite.\n\nopening this issue as a reminder and as a marker issue.\nangela",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-280",
        "summary": "JCR-Server: IllegalArgumentException when retrieving DateHeader",
        "description": "issue reported by martin perez:\n\nHere is one exception. If I access to any repository through WebDAV using a\nweb browser (http://localhost:8080/webapp/repository/default the first time\ngoes well, but if I refresh the page then I get the following exception:\n\nGRAVE: Servlet.service() para servlet Webdav lanz\u00f3 excepci\u00f3n\njava.lang.IllegalArgumentException: mar, 29 nov 2005 22:45:48 CET\n    at org.apache.catalina.connector.Request.getDateHeader(Request.java\n:1791)\n    at org.apache.catalina.connector.RequestFacade.getDateHeader(\nRequestFacade.java:630)\n    at org.apache.jackrabbit.webdav.WebdavRequestImpl.getDateHeader(\nWebdavRequestImpl.java:724)\n    at org.apache.jackrabbit.server.AbstractWebdavServlet.spoolResource(\nAbstractWebdavServlet.java:363)\n    at org.apache.jackrabbit.server.AbstractWebdavServlet.doGet(\nAbstractWebdavServlet.java:344)\n    at org.apache.jackrabbit.j2ee.SimpleWebdavServlet.execute(\nSimpleWebdavServlet.java:191)\n    at org.apache.jackrabbit.server.AbstractWebdavServlet.service(\nAbstractWebdavServlet.java:170)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(\nApplicationFilterChain.java:252)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(\nApplicationFilterChain.java:173)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(\nStandardWrapperValve.java:213)\n    at org.apache.catalina.core.StandardContextValve.invoke(\nStandardContextValve.java:178)\n    at org.apache.catalina.core.StandardHostValve.invoke(\nStandardHostValve.java:126)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(\nErrorReportValve.java:105)\n    at org.apache.catalina.core.StandardEngineValve.invoke(\nStandardEngineValve.java:107)\n    at org.apache.catalina.connector.CoyoteAdapter.service(\nCoyoteAdapter.java:148)\n    at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java\n:868)\n    at\norg.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection\n(Http11BaseProtocol.java:663)\n    at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(\nPoolTcpEndpoint.java:527)\n    at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(\nLeaderFollowerWorkerThread.java:80)\n    at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(\nThreadPool.java:684)\n    at java.lang.Thread.run(Thread.java:595)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2821",
        "summary": "Consistency check/fix doesn't work with PSQL persistence manager",
        "description": "PSQL doesn't save blobs directly into table row, instead saves a link there and puts the binary stream somewhere else. The general consistency check method in BundleDBPersistenceManager doesn't take this into account.\nI've fixed this by changing getBytes(Blob) method in BundleDbPersistenceManager to getBytes(ResultSet) and overriding it for PSQL.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1014",
        "summary": "Convert Batch implementation in spi-rmi from remote object into a local one",
        "description": "The current implementation of the Batch interface in spi-rmi is very simple and just uses remotes to the server side batch. This should be changed to a local object on the client and only transmit the changes in a single call to the server on save.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-510",
        "summary": "TCK: AddNodeTest requires implementation to support one-parameter addNode method on test node",
        "description": "This test requires a repository to support addNode(String) [one argument] on the test node.  However, JSR-170 does not require an implementation to have at least one child node definition with a default primary type.  For such repositories, this test will fail, regardless of configuration.\n\nProposal: introduce a configuration property which, if set, causes calls to addNode(String) to be replaced with addNode(String, String).",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-145",
        "summary": "Document order of result nodes should be configurable",
        "description": "Queries without an order by clause are performed with document order for the result nodes. This is a quite expensive operation, because the document order is available in the search index itself. The document order is calculated with the help of the ItemStateManager and requires loading of all result node states including their ancestors.\n\nQueries with a lot of result nodes become quite expensive, even though the actual query execution is fast. Because most use cases will not care for the document order, this feature should be made configurable. Some parameter for the QueryHandler that disables the document order on result nodes.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3117",
        "summary": "Stats for the PersistenceManager",
        "description": "Statistics for the PersistenceManager impl that cover: \n - bundle cache access count, \n - bundle cache miss count, \n - bundle cache miss avg duration (this avg includes the penalty of having to load from the underlying storage / can be interpreted as avg read latency as there is no cache involved) \n - bundle writes per second\n\nWhat it doesn't cover is :\n - number of bundles\n - size of workspace\nas these are values that are expensive to compute on demand, and caching them would imply being able to store the values (which is not possible currently).",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-703",
        "summary": "Add signature and major/minor version to the journal files used for clustering",
        "description": "Journal files used for clustering should contain a signature, and a major/minor version that helps identifying them.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1084",
        "summary": "Maintan a stable ordering of properties in xml export",
        "description": "When exporting to xml (system view, not tested with document view) the order of properties is not consistent.\nThis is not an issue with the jcr specification, since the order of properties is undefined, but keeping the same (whatever) order in xml export could be useful.\n\nAt this moment if you try running a few import->export->import->export roundtrips you will notice that the exported xml often changes. This is an example of the differences you can see:\n\n  <sv:property sv:name=\"jcr:uuid\" sv:type=\"String\">\n    <sv:value>59357999-b4fb-45cd-8111-59277caf14b7</sv:value>\n  </sv:property>\n+  <sv:property sv:name=\"title\" sv:type=\"String\">\n+    <sv:value>test</sv:value>\n+  </sv:property>\n  <sv:property sv:name=\"visible\" sv:type=\"String\">\n    <sv:value>true</sv:value>\n  </sv:property>\n-  <sv:property sv:name=\"title\" sv:type=\"String\">\n-    <sv:value>test</sv:value>\n-  </sv:property>\n\nIf you may need to diff between two exported files that could be pretty annoying, you have no clear way to understand if something has really changed or not.\nI would propose to keep ordering consistent between export: an easy way could be sorting properties alphabetically during export.\n\nThis behavior has been tested on a recent jackrabbit build from trunk (1.4-SNAPSHOT)\n\n\n\n",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-838",
        "summary": "bad assumptions/error handling in SetValueVersionExceptionTest:",
        "description": "SetValueVersionExceptionTest makes several assumptions that may not be true in all repositories:\n\n- nodes can be created without specifying a node type\n- nodes are not referenceable by default (thus addMixin fails)\n\nAlso, if a repository does not allow creating a reference property, the associated test should be aborted with NotExecutableException.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1684",
        "summary": "SPI sandbox: use tests-jars introduced with JCR-1629 and JCR-1683",
        "description": "... and remove the duplicated tests.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2230",
        "summary": "JSR 283 Evaluate Capabilities",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-1116",
        "summary": "Database persistence managers: log database and driver name and version",
        "description": "Database related problems can be solved more easily when we know what database and driver version is used. Sometimes multiple database drivers are installed in an app server environment, and the user may not even know it. \n\nCurrently the driver class name is logged. I suggest to log the driver and database name and version as well.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2110",
        "summary": "o.a.j.spi.commons.query.sql2.ParserTest uses platform encoding with non-ASCII characters",
        "description": "The ParserTest class loads a series of test SQL statements from test.sql2.txt, which contains a few non-ASCII characters (good to test those!). Unfortunately the file is read using the default platform encoding, which breaks the Linux-based test builds.\n\nI'll recode the file to UTF-8 and explicitly specify the encoding when the file is read.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1782",
        "summary": "Destination header not containing URI scheme causes NPE",
        "description": "In WebDAVRequestImpl. getDestinationLocator assumes that URI.getAuthority is always non-null.\n\nIn RFC2518, a full URI is indeed required, but the NPE causes a status of 500, instead of 400 as expected.\n\nIn RFC4918, an absolute path is allowed.\n\nProposal: delegate to gethrefLocator, which already does the right thing.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2334",
        "summary": "Tika-based type detection in jcr-server",
        "description": "As discussed on dev@, I'd like to make the jackrabbit-jcr-server component use Apache Tika for automatic media type detection.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3102",
        "summary": "InternalVersion.getFrozenNode confused about root version?",
        "description": "It seems the javadoc for InternalVersion.getFrozenNode  is confused:\n\n     * Returns the frozen node of this version or <code>null</code> if this is\n     * the root version.\n\nAFAIU, the frozen node of the root version is always present to capture the node type of the versionable node.\n\nDoes anybody recall how this got here? (SVN says it has been there forever)",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1355",
        "summary": "XML import should not access external entities",
        "description": "With current Jackrabbit the following XML document can not be imported:\n\n    <!DOCTYPE foo SYSTEM \"http://invalid.address/\"><foo/>\n\nEven if the DTD address (or some other external resource referenced in the XML document) is correct, I don't think importXML() should even try resolving those references.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1693",
        "summary": "JNDIDatabaseJournal doesn't work with \"oracle\" schema (or: unable to use OracleDatabaseJournal with a jndi datasource)",
        "description": "Database journal works fine on oracle when using the OracleDatabaseJournal implementation; but when you need to use a jndi datasource you actually need to use org.apache.jackrabbit.core.journal.JNDIDatabaseJournal which doesn't work fine with the \"oracle\" schema.\n\nWith the following configuration:\n<Cluster id=\"node1\" syncDelay=\"10\">\n    <Journal class=\"org.apache.jackrabbit.core.journal.JNDIDatabaseJournal\">\n      <param name=\"schema\" value=\"oracle\" />\n\njackrabbit crashes at startup with a not well defined sql error. Investigating on the problem I see that the \"oracle.ddl\" file contains a \"tablespace\" variable that is replaced only by the OracleDatabaseJournal implementation.\n\nAs a workaround users can create a different ddl without a tablespace variable, but this should probably work better out of the box.\n\nWDYT about one of the following solutions?\n- make the base DatabaseJournal implementation support jndi datasource just like PersistenceManagers do (without a specific configuration property but specifying a jndi location in the url property)\n- move the replacement of the tablespace variable (and maybe: add a generic replacement of *any* parameter found in the databaseJournal configuration) to the main DatabaseJournal implementation. This could be handy and it will make the OracleDatabaseJournal extension useless, but I see that at the moment there can be a problem with the MsSql implementation, since it adds \"on \" to the tablespace name only when it's not set to an empty string.\n\n\n\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-595",
        "summary": "Refactoring of the Persistence Managers",
        "description": "currently the persistence managers reside in:\n org.apache.jackrabbit.core.state\n org.apache.jackrabbit.core.state.db\n org.apache.jackrabbit.core.state.mem\n org.apache.jackrabbit.core.state.obj\n org.apache.jackrabbit.core.state.xml\n (org.apache.jackrabbit.core.state.util)\n\nthere are also a lot of other classes that deal with states (eg:\nSharedItemStateManager) in the state package that do not relate to\npms.\n\ni would like to move all persistencemanagers and pm related stuff to:\n\n org.apache.jackrabbit.core.persistence\n\nI'd keep the current classes as deprecated subclasses within\njackrabbit-core.jar until Jackrabbit 2.0. There may (?) be people who\nare extending the existing classes, so I'd avoid breaking binary\ncompatibility there even though we've never promised to actually honor\ncompatiblity within o.a.j.core.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1877",
        "summary": "the spi2dav sandbox project should be put into a common release cycle",
        "description": "Remoting JSR170 calls requires obviously both server and client sides.  The server is available for download, as JCR WebDAV Server in both http://www.apache.org/dyn/closer.cgi/jackrabbit/binaries/jackrabbit-jcr-server-1.4.1.jar and http://www.apache.org/dyn/closer.cgi/jackrabbit/binaries/jackrabbit-webapp-1.4.war.  However, the client is just casually mentioned as \"can be found in the Jackrabbit sandbox.\"  This issue is to request that the SPI2DAV client code (especially a ResponseFactory that returns a JCR2SPI Repository implementation) be available for download as well.\n\nFurthermore, please make the RepositoryFactory implements javax.naming.spi.ObjectFactory so that only configuration (vs. Java coding) is needed in order to use it.  This is how org.apache.jackrabbit.rmi.client.ClientRepositoryFactory works.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "RFE"
    },
    {
        "key": "JCR-421",
        "summary": "PROPPATCH does not send multistatus after revision 397835",
        "description": "After changes to use alterProperties for PROPPATCH in revision 397835, it returns a status code 200 and doesn't return a multistatus body. Patch below...\n\nIndex: C:/jprojects/eclipse/jackrabbit/jcr-server/server/src/java/org/apache/jackrabbit/server/AbstractWebdavServlet.java\n===================================================================\n--- C:/jprojects/eclipse/jackrabbit/jcr-server/server/src/java/org/apache/jackrabbit/server/AbstractWebdavServlet.java\t(revision 398580)\n+++ C:/jprojects/eclipse/jackrabbit/jcr-server/server/src/java/org/apache/jackrabbit/server/AbstractWebdavServlet.java\t(working copy)\n@@ -448,6 +448,7 @@\n         MultiStatus ms = new MultiStatus();\n         MultiStatusResponse msr = resource.alterProperties(changeList);\n         ms.addResponse(msr);\n+        response.sendMultiStatus(ms);\n     }\n \n     /**\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1889",
        "summary": "Incorrect support for java interfaces in typed collection fields",
        "description": "If a typed collection field is defined with an Interface as the type, the following exception is thrown when the main object is inserted : \n\norg.apache.jackrabbit.ocm.exception.JcrMappingException: Cannot load class interface [name of the interface];\n\nHere is a example : \n\n@Node\npublic class EntityA {\n       @Field(path=true) String path;\n       @Collection List<MyInterface> entityB;\n       ....\n}\n\nWhen inserting a new instance of EntityA with a not null entityB, the exception is thrown. \nA workaround is to add the elementClassName on the annotation @Collection. ex. : \n\n@Collection (elementClassName=MyInterface.class) List<MyInterface> entityB;\n\nelementClassName is used only for untyped collections but if you specify it for a typed collection, the ObjectContentManager will not use reflexion to check the collection class name. \n \nThis should be nice to avoid the usage of elementClassName for typed collections. \n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-3154",
        "summary": "Stats for Queries continued",
        "description": "This is to track the last missing item on the Query Stats list: Top Queries.\nAlso some needed refactoring.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-3020",
        "summary": "AbstractRepositoryService should be able to handle GuestCredentials",
        "description": "AbstractRepositoryService.createSessionInfo should handle GuestCredentials. Currently it only handle SimpleCredentials",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1995",
        "summary": "Move *.log files to target/",
        "description": "The jackrabbit-core component already puts the derby.log file in target/ along with other build  and test artifacts, but many other components don't do that yet. Having all generated files in target/ is good as it makes it very easy to clean things up. Also things like the RAT checks (JCR-1937) are easier when there's no need to worry about such extra files.\n",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3127",
        "summary": "Upgrade to Tika 0.10",
        "description": "Apache Tika 0.10 was released some while ago. It contains lots of improvements and fixes for full text extraction.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-704",
        "summary": "Enable maven-source-plugin",
        "description": "Currently the maven-source-plugin is enabled by default in jackrabbit-jcr-rmi, but it would be good to enable it globally for all Jackrabbit components.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-103",
        "summary": "Add plugable mechanism for import/export of webdav-server",
        "description": "add plugable mechanism to improve flexible configuration of the jcr-server",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-519",
        "summary": "Missing support for some \"general\" relations in QueryTreeDump and xpath.QueryFormat",
        "description": "The two classes lack support for some of the \"general\" relations in XPath.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-2903",
        "summary": "Session.importXml should close the input stream (as to JSR 283/JCR 2.0)",
        "description": "http://markmail.org/thread/crwx27dkt2cnjjy7\n\nThis is available for all that follow:\n  Node.setProperty(String, InputStream)\n  Property.setValue(InputStream)\n  ValueFactory.createValue(InputStream)\n  ValueFactory.createBinary(InputStream)\n  Session.importXML(String, InputStream, int)\n  Workspace.importXML(String, InputStream, int)\n",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "JCR-304",
        "summary": "Set up a release goal in Maven",
        "description": "Create a single Maven goal for building the Jackrabbit release packages. The goal should be based on the standard Maven dist goal, but include also the jackrabbit-commons and other modules we want to include in the release.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "TASK"
    },
    {
        "key": "JCR-1254",
        "summary": "DatabaseJournal commits twice inside a transaction, causing an error with MySQL",
        "description": "When committing a transaction in a clustered setup, multiple records may be appended to the DatabaseJournal. After having appended a record, commit() is called on the connection and auto-commit mode is again enabled. Apart from not being semantically correct, committing a connection that is already in auto-commit mode throws an error when using MySQL as backend.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1987",
        "summary": "Jackrabbit's lucene based query implementation does not check property constraints on the root node.",
        "description": "XPath queries of the kind \"/jcr:root[<any property constraint>]\" apparently always match.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2093",
        "summary": "Implement QueryObjectModelFactory.fullTextSearch() in QueryManagerImpl",
        "description": "While doing the JCR-1104 upgrade to JCR 2.0, we ran into an issue on how to best handle the QueryObjectModelFactory.fullTextSearch() method that seems to have changed a bit since the spi-commons version was written.\n\nMarcel, can you take a look at this when you have time. The dummy implementation I added now is at line 97 of QueryManagerImpl.java in jackrabbit-core.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-494",
        "summary": "Typo in message logged upon startup when repository is already in use",
        "description": "As per subject",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-2735",
        "summary": "Make SessionProvider pluggable in JCRWebdavServerServlet",
        "description": "Although there's a SessionProvider interface in o.a.j.server, the SessionProviderImpl implementation class is hard-coded into JCRWebdavServerServlet.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2264",
        "summary": "Enhance Ingres persistence bundle to handle unicode",
        "description": "Tiny change to ingres.ddl for persistent bundles to handle unicode strings.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1742",
        "summary": "CacheManager resizeAll is slow",
        "description": "CacheManager.resizeAll calls log.debug with a complex constructed log message.\nThe message is immediately discarded except when using the debug log level.\n\nTo improve performance, log.isDebugEnabled() should be used.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-515",
        "summary": "Enhance test data",
        "description": "Running the test cases currently results in a number of test cases that cannot be run. Mostly because not enough test data is in the repository to execute the test.\n\nYou can find out the affected test cases by setting the log level for 'org.apache.jackrabbit.test' to DEBUG and grep for 'executable' in the jcr.log file.\n\nThis returns the following list:\n\ntestGetDeclaringNodeType(org.apache.jackrabbit.test.api.nodetype.PropertyDefTest) not executable\ntestIsMandatory(org.apache.jackrabbit.test.api.nodetype.NodeDefTest) not executable\ntestValueConstraintNotSatisfied(org.apache.jackrabbit.test.api.nodetype.CanSetPropertyBinaryTest) not executable\ntestValueConstraintNotSatisfied(org.apache.jackrabbit.test.api.nodetype.CanSetPropertyBooleanTest) not executable\ntestValueConstraintNotSatisfied(org.apache.jackrabbit.test.api.nodetype.CanSetPropertyDoubleTest) not executable\ntestGetSize(org.apache.jackrabbit.test.api.observation.EventIteratorTest) not executable\ntestGetAttribute(org.apache.jackrabbit.test.api.SessionReadMethodsTest) not executable\ntestReferenceableRootNode(org.apache.jackrabbit.test.api.ReferenceableRootNodesTest) not executable\ntestBinaryProperty(org.apache.jackrabbit.test.api.SetValueConstraintViolationExceptionTest) not executable\ntestBooleanProperty(org.apache.jackrabbit.test.api.SetValueConstraintViolationExceptionTest) not executable\ntestDoubleProperty(org.apache.jackrabbit.test.api.SetValueConstraintViolationExceptionTest) not executable\ntestReferenceProperty(org.apache.jackrabbit.test.api.SetValueConstraintViolationExceptionTest) not executable\ntestMultipleReferenceProperty(org.apache.jackrabbit.test.api.SetValueConstraintViolationExceptionTest) not executable\ntestBinaryProperty(org.apache.jackrabbit.test.api.SetPropertyConstraintViolationExceptionTest) not executable\ntestBooleanProperty(org.apache.jackrabbit.test.api.SetPropertyConstraintViolationExceptionTest) not executable\ntestDoubleProperty(org.apache.jackrabbit.test.api.SetPropertyConstraintViolationExceptionTest) not executable\ntestReferenceProperty(org.apache.jackrabbit.test.api.SetPropertyConstraintViolationExceptionTest) not executable\n\nTest data in Jackrabbit should be enhanced in order to run those test cases successfully.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-308",
        "summary": "Nodes having OPV=Ignore are removed on restore",
        "description": "JCR1.0 Specification mentions:\n\n8.2.11.5 IGNORE\n  Child Node\n    On checkin of N, no state information about C will be stored in VN.\n    On restore of VN, the child node C of the current N will remain and not be removed.\n  Property\n    On checkin of N, no state information about P will be stored in VN.\n    On restore of VN, the property P of the current N will remain and not be removed.\n\nbut the current implementation removed the ignore child.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3163",
        "summary": "NPE in RepositoryServiceImpl.getPropertyInfo()",
        "description": "under unknown conditions, i get a NPE in get property info, such as the 'getValue()' of the getstring dav property is null:\n\n            } else if (props.contains(JCR_GET_STRING)) {\n                // single valued non-binary property\n                String str = props.get(JCR_GET_STRING).getValue().toString();\n                QValue qValue = ValueFormat.getQValue(str, propertyType, getNamePathResolver(sessionInfo), getQValueFactory(sessionInfo));\n                return new PropertyInfoImpl(propertyId, p, propertyType, qValue);\n            } else {\n\nthe other properties in the propset are:\n - getstring: null\n - type: String\n - length: 0\n\nthe property in question is the last property of a node and it's an empty string. the error only occurs on certain usage patterns, but consistently. maybe depending on the fetch-depth or internal cache.\n\nextending the check to:\n            } else if (props.contains(JCR_GET_STRING) && props.get(JCR_GET_STRING).getValue() != null) {\n\nsolves the problem.\n \n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2525",
        "summary": "NodeState and NodeStateListener deadlock",
        "description": "\n\nJava stack information for the threads listed above:\n===================================================\n\"jmssecondaryApplnJobExecutor-8\":\n\tat org.apache.jackrabbit.core.state.NodeState.getChildNodeEntry(NodeState.java:300)\n\t- waiting to lock <0x9e6c6d08> (a org.apache.jackrabbit.core.state.NodeState)\n\tat org.apache.jackrabbit.core.CachingHierarchyManager.nodeModified(CachingHierarchyManager.java:316)\n\t- locked <0xa09882a8> (a java.lang.Object)\n\tat org.apache.jackrabbit.core.CachingHierarchyManager.stateModified(CachingHierarchyManager.java:293)\n\tat org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyStateModified(StateChangeDispatcher.java:111)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.stateModified(SessionItemStateManager.java:889)\n\tat org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyStateModified(StateChangeDispatcher.java:111)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.stateModified(LocalItemStateManager.java:452)\n\tat org.apache.jackrabbit.core.state.XAItemStateManager.stateModified(XAItemStateManager.java:602)\n\tat org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyStateModified(StateChangeDispatcher.java:111)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.stateModified(SharedItemStateManager.java:400)\n\tat org.apache.jackrabbit.core.state.ItemState.notifyStateUpdated(ItemState.java:244)\n\tat org.apache.jackrabbit.core.state.ChangeLog.persisted(ChangeLog.java:297)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager$Update.end(SharedItemStateManager.java:749)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:1115)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:351)\n\tat org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:354)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:326)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:325)\n\tat org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1111)\n\t- locked <0x9b1b0be0> (a org.apache.jackrabbit.core.XASessionImpl)\n\tat org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:915)\n\tat org.apache.jackrabbit.jca.JCASessionHandle.save(JCASessionHandle.java:180)\n        ...\n\tat sun.reflect.GeneratedMethodAccessor1067.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat sun.reflect.misc.Trampoline.invoke(MethodUtil.java:36)\n\tat sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:243)\n\tat javax.management.modelmbean.RequiredModelMBean.invokeMethod(RequiredModelMBean.java:1074)\n\tat javax.management.modelmbean.RequiredModelMBean.invoke(RequiredModelMBean.java:955)\n\tat org.springframework.jmx.export.SpringModelMBean.invoke(SpringModelMBean.java:88)\n\tat org.jboss.mx.server.RawDynamicInvoker.invoke(RawDynamicInvoker.java:164)\n\tat org.jboss.mx.modelmbean.RequiredModelMBeanInvoker.invoke(RequiredModelMBeanInvoker.java:127)\n\tat org.jboss.mx.server.MBeanServerImpl.invoke(MBeanServerImpl.java:659)\n\tat org.jboss.system.server.jmx.LazyMBeanServer.invoke(LazyMBeanServer.java:291)\n\tat javax.management.MBeanServerInvocationHandler.invoke(MBeanServerInvocationHandler.java:288)\n\tat $Proxy692.doDiscoveryNow(Unknown Source)\n        ...\n\tat org.springframework.jms.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:531)\n\tat org.springframework.jms.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:466)\n\tat org.springframework.jms.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:435)\n\tat org.springframework.jms.listener.AbstractPollingMessageListenerContainer.doReceiveAndExecute(AbstractPollingMessageListenerContainer.java:322)\n\tat org.springframework.jms.listener.AbstractPollingMessageListenerContainer.receiveAndExecute(AbstractPollingMessageListenerContainer.java:260)\n\tat org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.invokeListener(DefaultMessageListenerContainer.java:944)\n\tat org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.run(DefaultMessageListenerContainer.java:868)\n\tat java.lang.Thread.run(Thread.java:619)\n\"jmssecondaryApplnJobExecutor-7\":\n\tat org.apache.jackrabbit.core.CachingHierarchyManager.nodeAdded(CachingHierarchyManager.java:362)\n\t- waiting to lock <0xa09882a8> (a java.lang.Object)\n\tat org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyNodeAdded(StateChangeDispatcher.java:159)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.nodeAdded(SessionItemStateManager.java:947)\n\tat org.apache.jackrabbit.core.state.NodeState.notifyNodeAdded(NodeState.java:882)\n\tat org.apache.jackrabbit.core.state.NodeState.addChildNodeEntry(NodeState.java:351)\n\t- locked <0x9e6c6d08> (a org.apache.jackrabbit.core.state.NodeState)\n\tat org.apache.jackrabbit.core.NodeImpl.createChildNode(NodeImpl.java:541)\n\t- locked <0xa00619a8> (a org.apache.jackrabbit.core.NodeImpl)\n\tat org.apache.jackrabbit.core.NodeImpl.internalAddChildNode(NodeImpl.java:802)\n\tat org.apache.jackrabbit.core.NodeImpl.internalAddNode(NodeImpl.java:735)\n\tat org.apache.jackrabbit.core.NodeImpl.addNodeWithUuid(NodeImpl.java:2200)\n\t- locked <0xa00619f8> (a org.apache.jackrabbit.core.NodeImpl)\n\tat org.apache.jackrabbit.core.NodeImpl.addNode(NodeImpl.java:2133)\n\t- locked <0xa00619f8> (a org.apache.jackrabbit.core.NodeImpl)\n        ...\n\tat sun.reflect.GeneratedMethodAccessor1067.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat sun.reflect.misc.Trampoline.invoke(MethodUtil.java:36)\n\tat sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:243)\n\tat javax.management.modelmbean.RequiredModelMBean.invokeMethod(RequiredModelMBean.java:1074)\n\tat javax.management.modelmbean.RequiredModelMBean.invoke(RequiredModelMBean.java:955)\n\tat org.springframework.jmx.export.SpringModelMBean.invoke(SpringModelMBean.java:88)\n\tat org.jboss.mx.server.RawDynamicInvoker.invoke(RawDynamicInvoker.java:164)\n\tat org.jboss.mx.modelmbean.RequiredModelMBeanInvoker.invoke(RequiredModelMBeanInvoker.java:127)\n\tat org.jboss.mx.server.MBeanServerImpl.invoke(MBeanServerImpl.java:659)\n\tat org.jboss.system.server.jmx.LazyMBeanServer.invoke(LazyMBeanServer.java:291)\n\tat javax.management.MBeanServerInvocationHandler.invoke(MBeanServerInvocationHandler.java:288)\n\tat $Proxy692.doDiscoveryNow(Unknown Source)\n        ...\n\tat org.springframework.jms.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:531)\n\tat org.springframework.jms.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:466)\n\tat org.springframework.jms.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:435)\n\tat org.springframework.jms.listener.AbstractPollingMessageListenerContainer.doReceiveAndExecute(AbstractPollingMessageListenerContainer.java:322)\n\tat org.springframework.jms.listener.AbstractPollingMessageListenerContainer.receiveAndExecute(AbstractPollingMessageListenerContainer.java:260)\n\tat org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.invokeListener(DefaultMessageListenerContainer.java:944)\n\tat org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.run(DefaultMessageListenerContainer.java:868)\n\tat java.lang.Thread.run(Thread.java:619)\n\nFound 1 deadlock.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-669",
        "summary": "Move NamespaceMappings/Index from lucene to namespace registry.",
        "description": "The NamespaceMappings class in the indexer is used for generating small prefixes for namespace uris that are stored in the index. This mechanism of stable prefixes could be used in other places as well, for example in the persistence managers.\n\nSuggest to introduce general methods in the namespace registry:\n\nint getURIIndex(String uri)\nString getURI(int index)\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1769",
        "summary": "RFC4918 feature: PROPFIND/include",
        "description": "RFC4918, Section 14.8 (<http://greenbytes.de/tech/webdav/rfc4918.html#rfc.section.14.8>) defines an extension to PROPFIND that allows clients to retrieve all RFC2518 properties, the dead properties, plus a set of additional live properties. This can help avoiding a second roundtrip to retrieve really all properties.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1258",
        "summary": "Add path encoding to ISO9075",
        "description": "The utility class ISO9075 only allows you to encode and decode names. It should also have methods that allow you to pass a path. This is useful when a XPath query is created with a path constraint based on e.g. a Node.getPath().",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-436",
        "summary": "InvalidQueryException thrown for a SQL query using WHERE CONTAINS(., 'someword')",
        "description": "The following SQL query:\nSELECT * FROM es:document WHERE CONTAINS(., 'software')\nthrows an InvalidQueryException exception.\n\njavax.jcr.query.InvalidQueryException: Encountered \".\" at line 1, column 42.\nWas expecting one of:\n    \"BY\" ...\n    \"IN\" ...\n    \"OR\" ...\n    \"IS\" ...\n    \"AND\" ...\n    \"LIKE\" ...\n    \"NULL\" ...\n    \"FROM\" ...\n    \"ORDER\" ...\n    \"WHERE\" ...\n    \"SELECT\" ...\n    \"BETWEEN\" ...\n    \"*\" ...\n    <REGULAR_IDENTIFIER> ...\n    <DELIMITED_IDENTIFIER> ...\n    \nThis syntax seems correct according to the latest jcr spec (1.0.1).\nUsing an asterisk (*) instead of a dot (.) as the first parameter of CONTAINS() works fine.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1408",
        "summary": "Invalid query results when using jcr:like with a case transform function and a pattern not starting with a wildcard",
        "description": "If the repository contains nodes with the following value for the property name :\njohn\nJOhn\njoe\nJoey\n\nand we run the following query :\n//element(*, document)/*[jcr:like(fn:lower-case(@name), 'joh%')]\")\nthen all the previous nodes will match especially the last 2 nodes.\n\nThe reason is the use of two range scans from the lucene term index:\n..._name_jOH\n..................\n..._name_joh_\n\nand\n\n..._name_JOH\n..................\n..._name_Joh_\n\nThe first range will contains ..._name_joe property and the second will contains ..._name_Joey.\nBut the pattern 'joh%' and so the regexp '.*' because of the range scan will match\nthe substring values of the properties ('' in the first range and 'y' in the second range).\n\nThe solution is to use the full pattern (ie 'joh.*') for matching each properties.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2790",
        "summary": "jcr:like on node name",
        "description": "Until now it is only possible to do an exact match on the node name. It would be useful to also use jcr:like on the node name.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1444",
        "summary": "The getOutputStream of the MemoryFileSystem class can replace a folder with a newly created file",
        "description": "It seems that if the filePath parameter passed to the getOutputStream method of the MemoryFileSystem class points to an  existing folder and not to a file - the folder will be replaced with a newly created file.\nThe function should probably check whether the passed path points to a file and throw an exception if it points to a folder.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2767",
        "summary": "Database connection leak with DBCP, MySQL, and Observers",
        "description": "When using DBCP and MySQL with an observer that modifies the content repository, we are seeing abandoned connections in our connection pool.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2929",
        "summary": "Various places do map lookups in loop instead of using entrySet iterator",
        "description": "Various places loop over a keyset iterator and do a map look up each time thru the loop, I plan to convert these places to use an entryset iterator to avoid this.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3090",
        "summary": "setFetchSize() fails in getAllNodeIds()",
        "description": "I get the following exception from the PersistenceManagerIteratorTest on Windows:\n\norg.apache.jackrabbit.core.state.ItemStateException: getAllNodeIds failed.\n        at org.apache.jackrabbit.core.persistence.pool.BundleDbPersistenceManager.getAllNodeIds(BundleDbPersistenceManager.java:1043)\n        at org.apache.jackrabbit.core.data.PersistenceManagerIteratorTest.testGetAllNodeIds(PersistenceManagerIteratorTest.java:106)\nCaused by: java.sql.SQLException: Invalid parameter value '10'000' for Statement.setFetchSize(int rows).\n        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)\n        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)\n        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)\n        at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)\n        at org.apache.derby.impl.jdbc.EmbedConnection.newSQLException(Unknown Source)\n        at org.apache.derby.impl.jdbc.ConnectionChild.newSQLException(Unknown Source)\n        at org.apache.derby.impl.jdbc.EmbedStatement.setFetchSize(Unknown Source)\n        at org.apache.commons.dbcp.DelegatingStatement.setFetchSize(DelegatingStatement.java:279)\n        at org.apache.commons.dbcp.DelegatingStatement.setFetchSize(DelegatingStatement.java:279)\n        at org.apache.jackrabbit.core.util.db.ConnectionHelper.reallyExec(ConnectionHelper.java:372)\n        at org.apache.jackrabbit.core.util.db.ConnectionHelper$3.call(ConnectionHelper.java:353)\n        at org.apache.jackrabbit.core.util.db.ConnectionHelper$3.call(ConnectionHelper.java:349)\n        at org.apache.jackrabbit.core.util.db.ConnectionHelper$RetryManager.doTry(ConnectionHelper.java:472)\n        at org.apache.jackrabbit.core.util.db.ConnectionHelper.exec(ConnectionHelper.java:349)\n        at org.apache.jackrabbit.core.persistence.pool.BundleDbPersistenceManager.getAllNodeIds(BundleDbPersistenceManager.java:1020)\n\nIt's caused by the following code in ConnectionHelper when 0 < maxRows < 10000:\n\n            stmt.setMaxRows(maxRows);\n            stmt.setFetchSize(10000);\n\nA simple fix would be:\n\n\n            stmt.setMaxRows(maxRows);\n            stmt.setFetchSize(Math.min(10000, maxRows));\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-53",
        "summary": "Refactoring config handling",
        "description": "As discussed on the mailing list:\n\n   * Move all XML handling to a separate ConfigurationParser class\n   * Clean up and document the *Config classes\n   * Get rid of the messy AbstractConfig class",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2434",
        "summary": "Occasional IndexingQueueTest failure",
        "description": "Usually the following assertion fails:\n\njunit.framework.AssertionFailedError\n\tat junit.framework.Assert.fail(Assert.java:47)\n\tat junit.framework.Assert.assertTrue(Assert.java:20)\n\tat junit.framework.Assert.assertTrue(Assert.java:27)\n\tat org.apache.jackrabbit.core.query.lucene.IndexingQueueTest.testQueue(IndexingQueueTest.java:77)",
        "label": "NUG",
        "classified": "TEST",
        "type": "TEST"
    },
    {
        "key": "JCR-342",
        "summary": "Jcr-Server: DavResource#getDavSession() missing",
        "description": "Instead of having DavResource#getDavSession() this method is defined individually by most of the\nderived interfaces.",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-858",
        "summary": "NotQuery does not implement extractTerms()",
        "description": "If the not() function is used in query together with the rep:excerpt() function an UnsupportedOperationException is thrown.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2188",
        "summary": "Parallelize tests",
        "description": "As mentioned on the mailing list I'd like to parallelize test execution.\n\nThere will be a pool of RepositoryHelper instances, each represents a distinct repository. This ensures that test cases that run in parallel do not interfere with each other. I suggest we start with a pool of two repositories, but we can later extend this setup.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1054",
        "summary": "Duplicate attribute in BeanDescriptor and CollectionDescriptor",
        "description": "2 different attributes are used in BeanDescriptor and CollectionDescriptor to store the jcr type (jcrType and jcrNodeType). JcrNodeType can be removed. \nThis imply modifications in  the DTD, the pm implementation and the different mapping xml files used for the unit tests. \n\nFurthermore, it should be nice to use the same name (jcrType)  in all descriptors.  There is a lot of confusion across the different descriptors. sometime jcrType is used, sometime jcrNodeType is used. I propose to use only jcrType with the following purpose : \n\n* In the ClassDescriptor, it  is used to store the primary node type of the class. \n* In the FieldDescriptor, it  is used to store the property type. \n* In the BeanDescriptor  it is used to defined the child node type. \n* In the CollectionDescriptor , it is used to defined the child node type. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1738",
        "summary": "BeanConfig may incorrectly throw ConfigurationException",
        "description": "With the changes from JCR-1462 the BeanConfig.newInstance() may throw a ConfigurationException if the bean does not support a configuration parameter that is configured.\n\nThere may be cases where the check in newInstance() yields an unsupported property even though there is a bean property present with the given key. Because the implementation uses 'map.get(key) == null'  as a check for a property name the method will throw if the key exists but the value is null.\n\nThe implementation should rather use 'map.containsKey(key)'.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1093",
        "summary": "Separate initial index creation from MultiIndex construction",
        "description": "If there is no index present the MultiIndex constructor will create an initial index by traversing the workspace item states. This makes it difficult for an outside class to detect the situation where no index is present.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-485",
        "summary": "TCK does not clean 2nd workspace during AbstractJCRTest.setUp()",
        "description": "the XATest.testXAVersionsThoroughly fails if run 2 times, since the 2nd workspace is not cleaned on startup. will provide provisonairy fix.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-2014",
        "summary": "Jcr2Spi: Warning upon reloading property values",
        "description": "tobi reported the following log-warning being written upon reloading property values:\n\n[WARN ] Property data has been discarded\n\nIt seems to me that this has been introduced with JCR-1963. Taking a closer look at it, i get the impression that\nthe 'discarded' flag should only be set if any values are notified accordingly. In addition it seems to me that the MergeResult should have a dispose() method (or something similar) in order to have the replaced (old) property values properly released...",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1199",
        "summary": "Remove dependency to log4j",
        "description": "Currently two classes in the test cases contain unused references to log4j.\nThe attached patch removes the unused logger and makes the package independent from lo4j",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-882",
        "summary": "Add more unit on collection fields",
        "description": "collection fields based on List are  supported not yet tested correctly.\nCheck if other kind collection are well tested",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3",
        "summary": "jcr:mixinTypes property inconsitent, if addMixin() throws exception",
        "description": "If Node.addMixin() throws an exception, that was not due to validation checks but rather internal, the jcr:mixinTypes still contains the newly added nodetype. a subsequent call to Item.save() will store that property. The effective nodetype is not affected though.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-682",
        "summary": "AccessManager + CachingHierarchyManager problem",
        "description": "The problem we have is the implementation of the CachingHierarchyManager,\nto which the SimpleAccessManager holds a reference.\n\nLet's consider following example:\ni add 3 subnodes (a,b,c) to a node and after that i reorder b and c ..\nso i have a,c,b. in the process of reordering (using the function\norderBefore of javax.jcr.Node) our AccessManager is called several times to check the permissions of the nodes. In this AccessManager we use some\nfunctions of the CachingHierarchyManager, f.ex.\n\nPath itemPath = hierMgr.getPath(id);\nreturn itemPath.denotesRoot();\n\nor\n\nPath itemPath = hierMgr.getPath(itemId);\nPath parentPath = itemPath.getAncestor(1);\nreturn hierMgr.resolvePath(parentPath);\n\nthe problem is, that when calling the methods of the\nCachingHierarchyManager the nodes i ask for will be cached in the idCache in a wrong state (i. e.: before actually reordering the elements).\nso if i want f.ex. delete the node b after reordering, the node will\nbe looked up in the idCache. in the cache the index of node b is still 2\n(actually it should be 3) and so the wrong node will be deleted! ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2053",
        "summary": "JSR 283: Shareable nodes support in query",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-1134",
        "summary": "bad assumptions in VersionHistoryTest.testInitallyGetAllVersionsContainsTheRootVersion()",
        "description": "There are two incorrect assumptions in testInitallyGetAllVersionsContainsTheRootVersion:\n\n- getAllVersions() returns versions in a particular order (test assumes root version comes first), and\n\n- Node.equals() is suitable for node comparison\n\nAnd finally, there's a typo in the test case name.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-811",
        "summary": "SetPropertyAssumeTypeTest check for non-protected string array property",
        "description": "SetPropertyAssumeTypeTest.testValuesConstraintViolationExceptionBecauseOfInvalidTypeParameter tries to find a property definition for a writable, multivalued string property. It consults NodeTypeUtil.locatePropertyDef() for that purpose.\n\nIn my setup, the property definition being returned is for jcr:valueConstraints, defined on nt:propertyDefinition. Nodes of that type in turn can not be created on the test node, thus the test fails already when trying to create the node.\n\nIt seems the test suite tries to be too smart here. Can we change this so that the node type and the property name are configuration parameters?",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-947",
        "summary": "XMLReader logs fatal error to system out",
        "description": "Some test cases check if an appropriate exception is thrown when invalid XML is supplied, in that case the build in XMLReader in Java 1.5 logs a fatal error to system out.\n\nThis seems to be caused by a missing error handler on the XMLReader.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1224",
        "summary": "Release references to JCR items in tearDown",
        "description": "On my 64-Bit environment OS/JVM I tried a \"mvn clean install\" and got an OutOfMemory Exception.\nOn my 32-Bit environment Mac OSX 10.5 Java 1.5 the tests were all  fine and the IndexMerger was significant faster.\n\nRunning org.apache.jackrabbit.test.TestAll\n21.11.2007 10:29:51 *INFO * [IndexMerger] IndexMerger: merged 549 documents in 289 ms into _a. (IndexMerger.java, line 304)\n21.11.2007 10:29:55 *ERROR* [main] ImportHandler: fatal error encountered at line: 1, column: 10 while parsing XML stream: org.xml.sax.SAXParseException: Attribute name \"is\" associated with an element type \"this\" must be followed by the ' = ' character. (ImportHandler.java, line 116)\n21.11.2007 10:29:55 *ERROR* [main] ImportHandler: fatal error encountered at line: 1, column: 10 while parsing XML stream: org.xml.sax.SAXParseException: Attribute name \"is\" associated with an element type \"this\" must be followed by the ' = ' character. (ImportHandler.java, line 104)\n21.11.2007 10:29:59 *ERROR* [main] ImportHandler: fatal error encountered at line: -1, column: -1 while parsing XML stream: org.xml.sax.SAXParseException: Premature end of file. (ImportHandler.java, line 104)\n21.11.2007 10:29:59 *ERROR* [main] ImportHandler: fatal error encountered at line: -1, column: -1 while parsing XML stream: org.xml.sax.SAXParseException: Premature end of file. (ImportHandler.java, line 116)\n21.11.2007 10:30:45 *INFO * [IndexMerger] IndexMerger: merged 555 documents in 2015 ms into _l. (IndexMerger.java, line 304)\n21.11.2007 10:33:13 *INFO * [IndexMerger] IndexMerger: merged 412 documents in 25587 ms into _w. (IndexMerger.java, line 304)\nException in thread \"Timer-1\" java.lang.OutOfMemoryError: Java heap space\n        at org.apache.lucene.store.BufferedIndexOutput.<init>(BufferedIndexOutput.java:26)\n        at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:592)\n        at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:435)\n        at org.apache.lucene.util.BitVector.write(BitVector.java:122)\n        at org.apache.lucene.index.SegmentReader.doCommit(SegmentReader.java:236)\n        at org.apache.lucene.index.IndexReader.commit(IndexReader.java:794)\n        at org.apache.lucene.index.FilterIndexReader.doCommit(FilterIndexReader.java:190)\n        at org.apache.lucene.index.IndexReader.commit(IndexReader.java:825)\n        at org.apache.lucene.index.IndexReader.close(IndexReader.java:841)\n        at org.apache.jackrabbit.core.query.lucene.AbstractIndex.close(AbstractIndex.java:327)\n        at org.apache.jackrabbit.core.query.lucene.MultiIndex$DeleteIndex.execute(MultiIndex.java:1715)\n        at org.apache.jackrabbit.core.query.lucene.MultiIndex.executeAndLog(MultiIndex.java:936)\n        at org.apache.jackrabbit.core.query.lucene.MultiIndex.flush(MultiIndex.java:880)\n        at org.apache.jackrabbit.core.query.lucene.MultiIndex.checkFlush(MultiIndex.java:1110)\n        at org.apache.jackrabbit.core.query.lucene.MultiIndex.access$100(MultiIndex.java:75)\n        at org.apache.jackrabbit.core.query.lucene.MultiIndex$1.run(MultiIndex.java:324)\n        at java.util.TimerThread.mainLoop(Timer.java:512)\n        at java.util.TimerThread.run(Timer.java:462)\n21.11.2007 10:34:37 *ERROR* [main] DatabasePersistenceManager: failed to write node state: cfbffd6d-114d-4738-9383-48da2b5dbc1d (DatabasePersistenceManager.java, line 441)\njava.lang.OutOfMemoryError: Java heap space\n        at java.util.Properties$LineReader.<init>(Properties.java:346)\n        at java.util.Properties.load(Properties.java:284)\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1445",
        "summary": "[PATCH] Use entrySet iterators to avoid map look ups in loops",
        "description": "Code uses a keySet iterator in a loop, then does a map look up using the key retrieved from the iterator. \n\nMight as well use an entrySet iterator to avoid n map lookups.\n\nPatch does this.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2753",
        "summary": "Deadlock in DefaultISMLocking",
        "description": "There seems to be a bug in DefaultISMLocking which was detected as part of JCR-2746.\n\n1) The main thread gets a read lock.\n\n2) The ObservationManager thread tries to lock for writing, which is blocked because there is still a read lock.\n\n3) Then the main thread tries to get a second read lock, which is blocked because there is a waiting write lock.\n\nThe bug was introduced as part of JCR-2089 (Use java.util.concurrent), revisions 995411 and 995412. I think the safe solution is to revert those to commits, and add a test case. If the DefaultISMLocking is changed later on, more test cases are required. An efficient solution is relatively complicated.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1401",
        "summary": "Removing-nodes with unexpected nodetype",
        "description": "tobias adds a logic with JCR-973 that the DefaultHandler checks the nodetype of the jcr:content node\nand if it does not match it will be deleted and created with the new one.\ni think its dangerous to automacially change a node type.\nif the node was added programatically and then saved through webdav it could happen that the nodetype will be changed\nfrom nt:resource to the nt:unstructured.\nif some logic depends on the nodetype the failure search will be hard ;-)",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1918",
        "summary": "DbDataStore keeps ResultSets open",
        "description": "The DbDataStore does not always close the ResultSet which can lead to memory leaks and/or large memory usage. It seems that  this already has been fixed in trunk and 1.5.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3183",
        "summary": "Add memory based bundle store",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2511",
        "summary": "Value#getBinary() and #getStream() return internal representation for type PATH and NAME",
        "description": "just found a path-related spi2dav test failing that passed some time before jackrabbit 2.0 (BatchTest#testSetPathValue).\n\ni had a quick look at it and it seems to me that the reasons is the internal (Path, Name) value representation \nbeing exposed when calling Value#getBinary(), Value#getStream() and the corresponding shortcuts on Property.\n\nfrom my understanding of the specification these methods should always return the standard JCR path (or name) representation as it\nis exposed by Value#getString() and Property#getString() as it used to be in previous versions.\n\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2352",
        "summary": "Search results not ordered",
        "description": "The query statements in search.jsp do not have an order by.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-502",
        "summary": "TCK: SetPropertyCalendarTest compares Calendar objects",
        "description": "SetPropertyCalendarTest# testNewCalendarPropertySession\nSetPropertyCalendarTest# testModifyCalendarPropertySession\nSetPropertyCalendarTest# testNewCalendarPropertyParent\nSetPropertyCalendarTest# testModifyCalendarPropertyParent\n\nTests compare Calendar objects.  Calendar.equals(Object) is a stronger test than JSR-170 specifies for Value.equals(Object), leading to false failures.  For the purpose of these tests, even Value.equals(Object) is too strong an equality test, since some repositories may normalize date/time values across a save/read roundtrip (for example, converting \"Z\" to \"+00:00\", or adding/removing trailing zeros in fractional seconds).\n\nProposal: compare the getTimeInMillis() values.\n\n--- SetPropertyCalendarTest.java        (revision 422074)\n+++ SetPropertyCalendarTest.java        (working copy)\n@@ -52,8 +52,8 @@\n         testNode.setProperty(propertyName1, c1);\n         superuser.save();\n         assertEquals(\"Setting property with Node.setProperty(String, Calendar) and Session.save() not working\",\n-                c1,\n-                testNode.getProperty(propertyName1).getDate());\n+                c1.getTimeInMillis(),\n+                testNode.getProperty(propertyName1).getDate().getTimeInMillis());\n     }\n  \n     /**\n@@ -66,8 +66,8 @@\n         testNode.setProperty(propertyName1, c2);\n         superuser.save();\n         assertEquals(\"Modifying property with Node.setProperty(String, Calendar) and Session.save() not working\",\n-                c2,\n-                testNode.getProperty(propertyName1).getDate());\n+                c2.getTimeInMillis(),\n+                testNode.getProperty(propertyName1).getDate().getTimeInMillis());\n     }\n  \n     /**\n@@ -78,8 +78,8 @@\n         testNode.setProperty(propertyName1, c1);\n         testRootNode.save();\n         assertEquals(\"Setting property with Node.setProperty(String, Calendar) and parentNode.save() not working\",\n-                c1,\n-                testNode.getProperty(propertyName1).getDate());\n+                c1.getTimeInMillis(),\n+                testNode.getProperty(propertyName1).getDate().getTimeInMillis());\n     }\n  \n     /**\n@@ -92,8 +92,8 @@\n         testNode.setProperty(propertyName1, c2);\n         testRootNode.save();\n         assertEquals(\"Modifying property with Node.setProperty(String, Calendar) and parentNode.save() not working\",\n-                c2,\n-                testNode.getProperty(propertyName1).getDate());\n+                c2.getTimeInMillis(),\n+                testNode.getProperty(propertyName1).getDate().getTimeInMillis());\n     }\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-899",
        "summary": "Rename package names",
        "description": "Rename package names  *graffito* into *jackrabbit*",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "TASK"
    },
    {
        "key": "JCR-71",
        "summary": "WorkspaceConfig.init() throws NullPointerException if Search configuration is missing",
        "description": "When the search configuration is missing from the repository.xml configuration, the WorkspaceConfig.sc field is null and consequently the WorkspaceConfig.init() method throws a NullPointerException.\n\nThis is by itself a bug, especially since missing search configuration is perfectly ok resulting in Jackrabbit not building the search index (which is - believe it or - what really want).\n\nOn that matter, since the configuration file structure seems to be implied by the configuration framework but the DTD is inlined into the configuration file, the configuration framework should act very gracefully to missing or wrong or unexpected configuration elements. Thus, for example, if the file system configuration (WorkspaceConfig.fsc) would be missing, the WorkspaceConfig should probably hint at this point and not throw a NullPointerException without further explanations (of course throwing anything at all is still better than going wild).",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-275",
        "summary": "NodeTypeRegistry.unregisterNodeTypes(Collection) missing",
        "description": "when having nodetypes depending on each other, or even have cyclic dependencies, they must be unregistered in the correct sequence. \n\ni suggest a NodeTypeRegistry.unregisterNodeTypes(Collection) for that case.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1887",
        "summary": "msoffice text extractor for office 2007 files",
        "description": "i created a patch that provides a mstextextractor for jackrabbit. this patch will entirely replace all existing ms extractors.\nthis patch can be applied as soon as poi-3.5 is available. the ms text extractor supports: doc, docx, ppt, pptx,\nxls, xlsx. the patch is not fully tested and uses poi code which is not yet available on the maven repo (needs to be \nbuild locally)",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1238",
        "summary": "Change default value for maxMergeDocs",
        "description": "This is actually a left over from the time before JCR-197 was implemented. Back then index merges were performed with the client thread and would hold up execution for a long time if a large number of nodes were merged. The default value for maxMergeDocs limited this to 100'000 nodes, resulting in a couple of seconds for the merge operation.\n\nThis default value does not make sense anymore because index merges are performed in a background thread and may take a long time without an effect on regular workspace operations. If a workspace grows large it may cause performance degradation because the number of index segments increases linearly when there are more than 100'000 nodes.\n\nI propose to set the new default to Integer.MAX_VALUE",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1949",
        "summary": "NullPointerException on DelegatingObservationDispatcher cause by parameter null on call : createEventStateCollection(null)",
        "description": "There is a NullPointerException when jackrabbit try to synchronise its indexes :\n22 janv. 2009 09:53:56 INFO  [ClusterNode] - Processing revision: 4485\n22 janv. 2009 09:53:56 ERROR [ClusterNode] - Unexpected error while syncing of journal: null\njava.lang.NullPointerException\n        at org.apache.jackrabbit.core.observation.DelegatingObservationDispatcher.createEventStateCollection(DelegatingObservationDispatcher.java:80)\n        at org.apache.jackrabbit.core.version.VersionManagerImpl$DynamicESCFactory.createEventStateCollection(VersionManagerImpl.java:556)\n        at org.apache.jackrabbit.core.version.VersionManagerImpl.externalUpdate(VersionManagerImpl.java:500)\n        at org.apache.jackrabbit.core.cluster.ClusterNode.process(ClusterNode.java:853)\n        at org.apache.jackrabbit.core.cluster.ChangeLogRecord.process(ChangeLogRecord.java:457)\n        at org.apache.jackrabbit.core.cluster.ClusterNode.consume(ClusterNode.java:799)\n        at org.apache.jackrabbit.core.journal.AbstractJournal.doSync(AbstractJournal.java:213)\n        at org.apache.jackrabbit.core.journal.AbstractJournal.sync(AbstractJournal.java:188)\n        at org.apache.jackrabbit.core.cluster.ClusterNode.sync(ClusterNode.java:315)\n        at org.apache.jackrabbit.core.cluster.ClusterNode.run(ClusterNode.java:286)\n        at java.lang.Thread.run(Thread.java:595)\n\nIn fact the method createEventStateCollection() of DelegatingObservationDispatcher is called by the VersionManagerImpl with session parameter as null...\n\nDelegatingObservationDispatcher:\n\n public EventStateCollection createEventStateCollection(SessionImpl session,\n                                                           Path pathPrefix) {\n        String userData = null;\n        try {\n            userData = ((ObservationManagerImpl) session.getWorkspace().getObservationManager()).getUserData();\n        } catch (RepositoryException e) {\n            // should never happen because this\n            // implementation supports observation\n        }\n        return new EventStateCollection(this, session, pathPrefix, userData);\n    }\n\nVersionManagerImpl$DynamicESCFactory :\n public EventStateCollection createEventStateCollection(SessionImpl source) {\n            return obsMgr.createEventStateCollection(source, VERSION_STORAGE_PATH);\n        }\n\nVersionManagerImpl :\npublic void externalUpdate(ChangeLog changes, List events,\n                               long timestamp, String userData)\n            throws RepositoryException {\n        EventStateCollection esc = getEscFactory().createEventStateCollection(null);\n        esc.addAll(events);\n        esc.setTimestamp(timestamp);\n        esc.setUserData(userData);\n\n        sharedStateMgr.externalUpdate(changes, esc);\n    }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3046",
        "summary": "Improve exception handling in observation (ChangePolling)",
        "description": "Currently when an (internal) event listener throws an exception, all further event listeners are skipped. This happens for move events where the HierarchyListener throws an UnsupportedOperationException. I suggest to move the exception handler up the call chain such that exceptions are caught and logged per listener instead of for all listeners. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1821",
        "summary": "jcr2spi: Item.isSame may return wrong result if any ancestor is invalidated",
        "description": "julian detected an issue with jcr2spi that was previously shadowed due to heavy reloading of items upon save.\nwith the most recent changes however reloading of items is postponed until the next access. this will cause the following test to fail:\n\n        Node n = testRootNode.addNode(\"aFile\", \"nt:file\");\n        n = n.addNode(\"jcr:content\", \"nt:resource\");\n        n.setProperty(\"jcr:lastModified\", Calendar.getInstance());\n        n.setProperty(\"jcr:mimeType\", \"text/plain\");\n        Property jcrData = n.setProperty(\"jcr:data\", \"abc\", PropertyType.BINARY);\n        testRootNode.save();\n\n        // access same property through different session\n        Session otherSession = helper.getReadOnlySession();\n        try {\n            Property otherProperty = (Property) otherSession.getItem(jcrData.getPath());\n            assertTrue(jcrData.isSame(otherProperty));\n        } finally {\n            otherSession.logout();\n        }\n\nwhile \n     \n       assertTrue(n.isSame(otherSession.getItem(n.getPath()));\n\nwould be successful.\n\nthe reason: the jcrData property is not reloaded and it's parent is still _invalidated_. consequently the property isn't aware of it's id having changed due to the fact that nt:resource is a node type extending from mix:referenceable.\n\npossible fixes:\n\n1) mark all items _invalid_ after save \n    instead of setting status non-protected/autocreated properties to EXISTING.\n    -> forcing jcrData to be reloaded before isSame can be called.\n    -> drawback: much more round trip(s) to the server just to make sure the id is up to date.\n\n2) change Item#isSame to make sure the workspaceId is up to date (walking up the\n     hierarchy and force reloading of the first invalidated ancestor).\n     -> drawback: if referenceable nodes are rare or missing at all, this causes some\n          extra round trips.\n \n3) change Item.isSame to compare the 'workspacePath' instead of the 'workspaceId'.\n     -> drawback: upon persisted move of a referenceable node Item#isSame will return false\n\n\nafter taking a closer look at the code and at some additional tests i would opt for 2).\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-683",
        "summary": "Bad transitive dependencies in commons-httpclient",
        "description": "As reported in HTTPCLIENT-605, the commons-httpclient 3.0 dependency introduces junit as a transitive \"compile\" scope dependency. The library also uses commons-logging, which sidesteps Jackrabbit's use of slf4j for logging.\n\nTo avoid these issues we should locally override the junit dependency in commons-httpclient and replace the commons-logging dependency with jcl104-over-slf4j.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-780",
        "summary": "Simultaneous updates by multiple sessions might not appear in the journal",
        "description": "In a clustering environment, simultaneous updates by multiple sessions in the same cluster node might not appear in the journal, because only record at a time can be handled by the cluster's workspace-specific callback method. When such a situtation arises, the following warnings can be found in the log:\n\n*WARN * ClusterNode: No record created.\n*WARN * ClusterNode: No record prepared.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1414",
        "summary": "Data store garbage collection: inUse not correctly synchronized",
        "description": "Access to the fields DbDataStore.inUse and FileDataStore.inUse is not synchronized.\nThis is a problem when concurrently calling GarbageCollector.deleteUnused() \nand accessing the data store (ConcurrentModificationException is thrown).",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-265",
        "summary": "Bug with textfilters and classloaders",
        "description": "I'm having problems with text filter service. I built the contrib/textfilters package and I included the resulting jackrabbit-textfilters-1.0-SNAPSHOT.jar in my application classpath. The problem is that TextFilterService class is unable to find any filters, even though that a services/org...TextFilterService file is wihin the META-INF jar's directory.\n\nI think that this must to be with Eclipse RCP classloader mechanism, but the fact is that it does not work. I find a little bit strange this way to load services, and as you can see, it seems problematic in some scenarios.\n\n----\n\nMarcel Reutegger \t\n<marcel.reutegger@gmx.net> to jackrabbit-dev\n\t More options\t  11:01 am (55 minutes ago)\nHi Martin,\n\nwe had a similar problem with the query languages, but I solved that one\nby telling the registry to use a specific classloader. this seemed to work.\nI'm not sure this will also work for the text filters, because the jar\nfile might be in another classloader.\n\ncould you please post a jira bug? I'll then change the discovery\nmechanism to use good old xml config ;)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-247",
        "summary": "Child axis support for XPath predicates",
        "description": "It seems that Jackrabbit currently only supports the attribute axis in XPath predicates. Support for the child axis would be a nice addition.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-815",
        "summary": "SQLException with OracleBundle PM in name index",
        "description": "The oracle bundle pm shows errors like:\n\njava.lang.IllegalStateException: Unable to insert index: java.sql.SQLException:  \n  ORA-01400: cannot insert NULL into  (\"MARTIJNH\".\"WM9_VERSIONING_PM_NAMES\".\"ID\")\n\nthis is due to the fact that oracle treats empty strings as NULL values which does the schema not allow.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1687",
        "summary": "NamespaceRegistryImpl.getNameResolver/getPathResolver always return null",
        "description": "This seems to be a left over from restructuring commons classes: JCR-1169. Those methods should be removed.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2807",
        "summary": "ConcurrentModificationException in SessionItemStateManager.getIdOfRootTransientNodeState()",
        "description": "SessionItemStateManager.getIdOfRootTransientNodeState() is throwing a ConcurrentModificationException on line 607:\n\nHere's a snippet of the code:\n{code}\n                    for (NodeId id : candidateIds) {\n                        if (nodeId.equals(id) || hierMgr.isAncestor(id, nodeId)) {\n                            // already a candidate or a descendant thereof\n                            // => skip\n                            skip = true;\n                            break;\n                        }\n                        if (hierMgr.isAncestor(nodeId, id)) {\n                            // candidate is a descendant => remove\n                            candidateIds.remove(id);\n                        }\n                    }\n{code}\n\nCan't use Collection.remove(Object) in the middle of iterating. It should probably be changed to use Iterator.remove():\n{code}\n                    Iterator<NodeId> nodeIdItor = candidateIds.iterator();\n                    while (nodeIdItor.hasNext()) {\n                        NodeId id = nodeIdItor.next();\n                        if (nodeId.equals(id) || hierMgr.isAncestor(id, nodeId)) {\n                            // already a candidate or a descendant thereof\n                            // => skip\n                            skip = true;\n                            break;\n                        }\n                        if (hierMgr.isAncestor(nodeId, id)) {\n                            // candidate is a descendant => remove\n                            nodeIdItor.remove();\n                        }\n                    }\n{code}\n\nAny idea what I could do differently to workaround the issue?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3095",
        "summary": "Move operation may turn AC caches stale",
        "description": "the EntryCollector instance associated with a given workspace is listening to any modifications made to the access control content\n(add, modification and removal of access control lists). however, due to the structure of the ac content (the ac node being attached to the affected nodes) \ncaches may become stale if a node is moved that contains ac information somewhere in the subtree.\n\nin order to circumvent that problem the EntryCollector should in addition collect any kind of move operations\nand make sure that the caches are updated accordingly.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2395",
        "summary": "Text Extractor: Image parser throws exception (jpeg)",
        "description": "the below exception is thrown over an over while uploading jpeg images:\n16.11.2009 17:20:42 *WARN * LazyTextExtractorField: Failed to extract text from a binary property (LazyTextExtractorField.java, line 165)\norg.apache.tika.exception.TikaException: TIKA-198: Illegal IOException from org.apache.tika.parser.image.ImageParser@c7bc3\n\tat org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:125)\n\tat org.apache.tika.parser.AutoDetectParser.parse(AutoDetectParser.java:105)\n\tat org.apache.jackrabbit.core.query.lucene.LazyTextExtractorField$ParsingTask.run(LazyTextExtractorField.java:160)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:417)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:123)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:65)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:168)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)\n\tat java.lang.Thread.run(Thread.java:613)\nCaused by: javax.imageio.IIOException: Not a JPEG file: starts with 0x00 0x05\n\tat com.sun.imageio.plugins.jpeg.JPEGImageReader.readImageHeader(Native Method)\n\tat com.sun.imageio.plugins.jpeg.JPEGImageReader.readNativeHeader(JPEGImageReader.java:554)\n\tat com.sun.imageio.plugins.jpeg.JPEGImageReader.checkTablesOnly(JPEGImageReader.java:309)\n\tat com.sun.imageio.plugins.jpeg.JPEGImageReader.gotoImage(JPEGImageReader.java:431)\n\tat com.sun.imageio.plugins.jpeg.JPEGImageReader.readHeader(JPEGImageReader.java:547)\n\tat com.sun.imageio.plugins.jpeg.JPEGImageReader.getHeight(JPEGImageReader.java:609)\n\tat org.apache.tika.parser.image.ImageParser.parse(ImageParser.java:47)\n\tat org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:119)\n\t... 10 more",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-452",
        "summary": "Workspace.clone throws ItemNotFoundException on a referenceable node with children",
        "description": "An ItemNotFoundException is thrown when a referenceable node with children is cloned, this happens after the first time the node is cloned.\n            \nExample:\n\n            Node root = session.getRootNode();   \n            Node parent = root.addNode(\"parent\");\n            parent.addMixin(\"mix:referenceable\");\n            session.save();\n            \n// clone parent\n            WS2.clone(\"default\", \"/parent\", \"/parent\", true);\n            \n            Node child = parent.addNode(\"child\");\n// add child\n            child.addMixin(\"mix:referenceable\");\n            session.save();\n\n// clone parent with child            \n            WS2.clone(\"default\", \"/parent\", \"/parent\", true); \n\n// clone parent again,   ItemNotFoundException - from now on can't clone parent node.\n            WS2.clone(\"default\", \"/parent\", \"/parent\", true);\n\n\nStacktrace:\njavax.jcr.ItemNotFoundException: failed to build path of 229083e5-5f24-4102-b007-785f43be983a: cafebabe-cafe-babe-cafe-babecafebabe has no child entry for 229083e5-5f24-4102-b007-785f43be983a\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.buildPath(HierarchyManagerImpl.java:308)\n\tat org.apache.jackrabbit.core.CachingHierarchyManager.buildPath(CachingHierarchyManager.java:159)\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getPath(HierarchyManagerImpl.java:357)\n\tat org.apache.jackrabbit.core.CachingHierarchyManager.getPath(CachingHierarchyManager.java:221)\n\tat org.apache.jackrabbit.core.BatchedItemOperations.checkRemoveNode(BatchedItemOperations.java:700)\n\tat org.apache.jackrabbit.core.BatchedItemOperations.recursiveRemoveNodeState(BatchedItemOperations.java:1514)\n\tat org.apache.jackrabbit.core.BatchedItemOperations.removeNodeState(BatchedItemOperations.java:1216)\n\tat org.apache.jackrabbit.core.BatchedItemOperations.copyNodeState(BatchedItemOperations.java:1642)\n\tat org.apache.jackrabbit.core.BatchedItemOperations.copy(BatchedItemOperations.java:311)\n\tat org.apache.jackrabbit.core.WorkspaceImpl.internalCopy(WorkspaceImpl.java:294)\n\tat org.apache.jackrabbit.core.WorkspaceImpl.clone(WorkspaceImpl.java:401)\n\tat test.CloneTest.main(CloneTest.java:64)\n\n            ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2721",
        "summary": "Add toString() methods to QOM tree classes",
        "description": "Having the QOM tree classes render themselves to SQL2 in their toString() methods would make debugging the QOM code quite a bit easier.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1665",
        "summary": "In JCAConnectionRequestInfo, equals() and hashCode() implementations are inconsistent",
        "description": "JCAConnectionRequestInfo behaves differently in its equals() and hashCode() methods. The former is aware about SimpleCredentials structure, so two instances of JCAConnectionRequestInfo were supplied SimpleCredentials instances with same userID, password and attributes, they are considered equal.\nBut JCAConnectionRequestInfo.hashCode() just delegates to SimpleCredentials.hashCode() which is same as Object's method. This breaks session pooling.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2954",
        "summary": "SQL-2 query returns more than the requested column",
        "description": "If I do :\n\nSELECT alias.[jcr:title] FROM [jnt:mainContent] as alias\n\nand then iterate through the returned columns of the rows, I get the same result as for :\n\nSELECT * FROM [jnt:mainContent] \n\nwhich is ALL the properties defined for jnt:mainContent.\n\nOnly if I use\n\nSELECT alias.[jcr:title] as title FROM [jnt:mainContent] as alias\n\nthe result is limited to the title column.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2731",
        "summary": "LockMethod.getResponseAsLockDiscovery() fails when status==201 ",
        "description": "RFC 4918 Section 9.10.6 specifies that 201 is a valid response code for LOCK: \"201 (Created) - The LOCK request was to an unmapped URL, the request succeeded and resulted in the creation of a new resource, and the value of the DAV:lockdiscovery property is included in the response body.\"\n\nHowever, LockMethod.getResponseAsLockDiscovery() would fail in that scenario. \n    org.apache.jackrabbit.webdav.DavException: Created\n\t at org.apache.jackrabbit.webdav.client.methods.DavMethodBase.getResponseException(DavMethodBase.java:164)\n\t at org.apache.jackrabbit.webdav.client.methods.LockMethod.getResponseAsLockDiscovery(LockMethod.java:119)\n\n\nThe reason is in LockMethod:175 \n      return statusCode == DavServletResponse.SC_OK;\n\nShould be: \n      return statusCode == DavServletResponse.SC_OK\n             || statusCode ==DavServletResponse.SC_CREATED;",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2066",
        "summary": "NodeTypeRegistry could auto-subtype from nt:base",
        "description": "this is basically a copy of JCR-433, which was fixed but somehow sneaked in again:\n\nwhen tying to register a (primary) nodetype that does not extend from nt:base the following error is\nthrown:\n\n\"all primary node types except nt:base itself must be (directly or indirectly) derived from nt:base\"\n\nsince the registry is able to detect this error, it would be easy to auto-subtype all nodetypes from nt:base. \nimo it's pointless to explicitly add the nt:base to every superclass set. as an analogy, you don't need to \n'extend from java.lang.Object' explicitly - the compiler does that automatically for your.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-536",
        "summary": "Session leak in API test cases",
        "description": "In setUp(). AbstractPropertyTest checks whether it can execute the test and potentially throws an NotExecutableException. In this case, the helper Session is lost (without logging out), and the parent's tearDown() code isn't executed. \n\nThe same problem may be present in more test classes (will check).\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1641",
        "summary": "DefaultLoginModule/SimpleLoginModule don't support custom PrincipalProvider",
        "description": "When configuring a custom PrincipalProvider for the SimpleLoginModule or DefaultLoginModule, inside of a repository.xml file with configuration such as the following:\n\n    <Security appName=\"Jackrabbit\">\n        <AccessManager\n            class=\"org.apache.jackrabbit.core.security.DefaultAccessManager\">\n        </AccessManager>\n        <LoginModule\n            class=\"org.apache.jackrabbit.core.security.authentication.DefaultLoginModule\">\n            <param name=\"principalprovider\" value=\"com.foo.jcr.BasicPrincipalProvider\"/>\n        </LoginModule>\n      <SecurityManager class=\"org.apache.jackrabbit.core.DefaultSecurityManager\">         \n      </SecurityManager>    \n    </Security>\n\nAnd that yields the following stacktrace:\n\njavax.jcr.LoginException: org.apache.jackrabbit.core.security.authentication.DefaultLoginModule does not support 'principalprovider: org.apache.jackrabbit.core.security.authentication.DefaultLoginModule does not support 'principalprovider: org.apache.jackrabbit.core.security.authentication.DefaultLoginModule does not support 'principalprovider\n\tat org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1353)\n\tat org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:53)\n\tat com.foo.jcr.PrincipalProviderTest.testPrincipalProvider(PrincipalProviderTest.java:24)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat org.junit.internal.runners.TestMethod.invoke(TestMethod.java:59)\n\tat org.junit.internal.runners.MethodRoadie.runTestMethod(MethodRoadie.java:98)\n\tat org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:79)\n\tat org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:87)\n\tat org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:77)\n\tat org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:42)\n\tat org.junit.internal.runners.JUnit4ClassRunner.invokeTestMethod(JUnit4ClassRunner.java:88)\n\tat org.junit.internal.runners.JUnit4ClassRunner.runMethods(JUnit4ClassRunner.java:51)\n\tat org.junit.internal.runners.JUnit4ClassRunner$1.run(JUnit4ClassRunner.java:44)\n\tat org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:27)\n\tat org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:37)\n\tat org.junit.internal.runners.JUnit4ClassRunner.run(JUnit4ClassRunner.java:42)\n\tat org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:45)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)\nCaused by: javax.security.auth.login.LoginException: org.apache.jackrabbit.core.security.authentication.DefaultLoginModule does not support 'principalprovider\n\tat org.apache.jackrabbit.core.security.authentication.LocalAuthContext.login(LocalAuthContext.java:68)\n\tat org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1346)\n\t... 24 more\njavax.security.auth.login.LoginException: org.apache.jackrabbit.core.security.authentication.DefaultLoginModule does not support 'principalprovider\n\tat org.apache.jackrabbit.core.security.authentication.LocalAuthContext.login(LocalAuthContext.java:68)\n\tat org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1346)\n\tat org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:53)\n\tat com.foo.jcr.PrincipalProviderTest.testPrincipalProvider(PrincipalProviderTest.java:24)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat org.junit.internal.runners.TestMethod.invoke(TestMethod.java:59)\n\tat org.junit.internal.runners.MethodRoadie.runTestMethod(MethodRoadie.java:98)\n\tat org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:79)\n\tat org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:87)\n\tat org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:77)\n\tat org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:42)\n\tat org.junit.internal.runners.JUnit4ClassRunner.invokeTestMethod(JUnit4ClassRunner.java:88)\n\tat org.junit.internal.runners.JUnit4ClassRunner.runMethods(JUnit4ClassRunner.java:51)\n\tat org.junit.internal.runners.JUnit4ClassRunner$1.run(JUnit4ClassRunner.java:44)\n\tat org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:27)\n\tat org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:37)\n\tat org.junit.internal.runners.JUnit4ClassRunner.run(JUnit4ClassRunner.java:42)\n\tat org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:45)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1267",
        "summary": "Unreachable catch block for NameException in ValueConstraint.java",
        "description": "Unreachable catch block for NameException. Only more specific exceptions are thrown and handled by previous catch block(s). ValueConstraint.java\tline 855\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1478",
        "summary": "Perform random operation tests",
        "description": "As discussed on the mailing list and in other jira issues it makes sense to execute tests that perform random operations on the repository. This helps us detect concurrency issues in jackrabbit and increase code coverage.",
        "label": "NUG",
        "classified": "TEST",
        "type": "TEST"
    },
    {
        "key": "JCR-3194",
        "summary": "ConcurrentModificationException in CacheManager.",
        "description": "Using the test code below, I was able to produce this stack:\n\njava.util.ConcurrentModificationException\n\tat java.util.WeakHashMap$HashIterator.nextEntry(WeakHashMap.java:762)\n\tat java.util.WeakHashMap$KeyIterator.next(WeakHashMap.java:795)\n\tat org.apache.jackrabbit.core.cache.CacheManager.logCacheStats(CacheManager.java:164)\n\tat org.apache.jackrabbit.core.cache.CacheManager.cacheAccessed(CacheManager.java:137)\n\tat org.apache.jackrabbit.core.cache.AbstractCache.recordCacheAccess(AbstractCache.java:122)\n\tat org.apache.jackrabbit.core.cache.ConcurrentCache.get(ConcurrentCache.java:122)\n\tat org.apache.jackrabbit.core.state.MLRUItemStateCache.retrieve(MLRUItemStateCache.java:71)\n\tat org.apache.jackrabbit.core.state.ItemStateReferenceCache.retrieve(ItemStateReferenceCache.java:139)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.getNonVirtualItemState(SharedItemStateManager.java:1716)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.getItemState(SharedItemStateManager.java:268)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.getNodeState(LocalItemStateManager.java:110)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.getItemState(LocalItemStateManager.java:175)\n\tat org.apache.jackrabbit.core.state.XAItemStateManager.getItemState(XAItemStateManager.java:260)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:161)\n\tat org.apache.jackrabbit.core.ItemManager.getItemData(ItemManager.java:382)\n\tat org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:328)\n\tat org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:622)\n\tat org.apache.jackrabbit.core.ItemManager.getRootNode(ItemManager.java:531)\n\tat org.apache.jackrabbit.core.SessionImpl.getRootNode(SessionImpl.java:760)\n\tat test.JackrabbitTest$1.run(JackrabbitTest.java:37)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\n\n-------------------------\n\npackage test;\n\nimport java.io.File;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicBoolean;\nimport java.util.concurrent.atomic.AtomicInteger;\n\nimport javax.jcr.Repository;\nimport javax.jcr.RepositoryException;\nimport javax.jcr.Session;\nimport javax.jcr.SimpleCredentials;\n\nimport org.apache.jackrabbit.core.TransientRepository;\n\npublic class JackrabbitTest {\n\n public static void main(final String[] args) throws Exception {\n   File dir = File.createTempFile(\"jackrabbit-test\", \"\");\n   dir.delete();\n   dir.mkdir();\n   System.out.println(\"created temporary directory: \" +\n       dir.getAbsolutePath());\n   dir.deleteOnExit();\n\n   final Repository jcrRepo = new TransientRepository(dir);\n   final AtomicBoolean passed = new AtomicBoolean(true);\n   final AtomicInteger counter = new AtomicInteger(0);\n   ExecutorService executor = Executors.newFixedThreadPool(50);\n   Runnable runnable = new Runnable() {\n\n     @Override\n     public void run() {\n       try {\n         Session session = jcrRepo.login(\n             new SimpleCredentials(\"admin\",\n                 \"admin\".toCharArray()));\n         session.getRootNode().addNode(\"n\" +\n                 counter.getAndIncrement()); //unique name\n         session.save();\n         session.logout();\n       } catch (RepositoryException e) {\n         e.printStackTrace();\n         passed.set(false);\n       }\n     }\n\n   };\n   System.out.println(\"Running threads\");\n   for (int i = 0; i<  500; i++) {\n     executor.execute(runnable);\n   }\n   executor.shutdown(); //Disable new tasks from being submitted\n   if (!executor.awaitTermination(120, TimeUnit.SECONDS)) {\n     System.err.println(\"timeout\");\n     System.exit(1);\n   }\n   if (!passed.get()) {\n     System.err.println(\"one or more threads got an exception\");\n     System.exit(1);\n   } else {\n     System.out.println(\"all threads ran with no exceptions\");\n     System.exit(0);\n   }\n\n }\n\n}\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1696",
        "summary": "Add PlainTextExtractor to default configuration of TransientRepository",
        "description": "The current default configuration of TransientRepository does not include the PlainTextExtractor, which means resources of type text/plain are not fulltext indexed. The PlainTextExtractor should be added to the configuration.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2515",
        "summary": "ISO8601 uses default DecimalFormat constructor using locale specific digits",
        "description": "ISO8601.java uses the default DecimalFormat constructor which uses locale specific DecimalFormatSymbols. Runnning Jackrabbit in an Indian locale the format() produces a date using DEVANAGARI numeric digits. The saved version (UTF-8) encoded is much longer than usual and is not transportable. On parsing, DecimalFormat works, but TimeZone.getTimeZone(\"GMT+09:30\") (with Indian numeric digits) fails and null is returned from ISO8601. Later this traceback occurs.\n\n2010-02-22 15:14:04,059[http-0.0.0.0-8080-16] ERROR org.apache.jackrabbit.core.persistence.bundle.BundleFsPersistenceManager - failed to write bundle: ff629488-ebb9-4300-a63b-341553cc1140\njava.lang.IllegalArgumentException: argument can not be null\n\tat org.apache.jackrabbit.util.ISO8601.format(ISO8601.java:217)\n\tat org.apache.jackrabbit.core.value.InternalValue.toString(InternalValue.java:531)\n\tat org.apache.jackrabbit.core.persistence.bundle.util.BundleBinding.writeState(BundleBinding.java:689)\n\tat org.apache.jackrabbit.core.persistence.bundle.util.BundleBinding.writeBundle(BundleBinding.java:273)\n\tat org.apache.jackrabbit.core.persistence.bundle.BundleFsPersistenceManager.storeBundle(BundleFsPersistenceManager.java:664)\n\tat org.apache.jackrabbit.core.persistence.bundle.AbstractBundlePersistenceManager.putBundle(AbstractBundlePersistenceManager.java:703)\n\tat org.apache.jackrabbit.core.persistence.bundle.AbstractBundlePersistenceManager.store(AbstractBundlePersistenceManager.java:643)\n\n\nISO8601 probably meant the chars to be ASCII, and so the constructor with a fixed locale is more appropriate (and this doesn't encounter the TimeZone issue either).\n\n    private static final DecimalFormat XX_FORMAT = new DecimalFormat(\"00\", new DecimalFormatSymbols(Locale.US));\n    private static final DecimalFormat XXX_FORMAT = new DecimalFormat(\"000\", new DecimalFormatSymbols(Locale.US));\n    private static final DecimalFormat XXXX_FORMAT = new DecimalFormat(\"0000\", new DecimalFormatSymbols(Locale.US));\n ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2518",
        "summary": "Make ItemIds more stable",
        "description": "The ItemIds returned by spi2dav are currently not stable in the sense that they are sometimes uuid based and sometimes not: If a node is referenceable some of its properties will receive fully path based ids while others will receive ids based on the uuid of its parent node. \n\nThe efficiency of caching introduced with JCR-2498 depends on stable ids. I therefore suggest to improve spi2dav such that property ids are always uuid based if the parent's node has a uuid. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1647",
        "summary": "UserManager throws javax.jcr.query.InvalidQueryException on createUser",
        "description": "The UserManager method createUser(String userID, String password) throws an exception (javax.jcr.query.InvalidQueryException) if the user name contains a '@' character.\n\nStack trace:\nException in thread \"main\" javax.jcr.query.InvalidQueryException: Lexical error at line 1, column 76.  Encountered: \"@\" (64), after : \"\" for statement: for $v in /jcr:root/rep:security/rep:authorizables/rep:groups//element(test@example.com,rep:Group) return $v: Lexical error at line 1, column 76.  Encountered: \"@\" (64), after : \"\": Lexical error at line 1, column 76.  Encountered: \"@\" (64), after : \"\"\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPathQueryBuilder.<init>(XPathQueryBuilder.java:302)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPathQueryBuilder.createQuery(XPathQueryBuilder.java:331)\n        at org.apache.jackrabbit.spi.commons.query.xpath.QueryBuilder.createQueryTree(QueryBuilder.java:39)\n        at org.apache.jackrabbit.spi.commons.query.QueryParser.parse(QueryParser.java:57)\n        at org.apache.jackrabbit.core.query.lucene.QueryImpl.<init>(QueryImpl.java:91)\n        at org.apache.jackrabbit.core.query.lucene.SearchIndex.createExecutableQuery(SearchIndex.java:615)\n        at org.apache.jackrabbit.core.query.QueryImpl.init(QueryImpl.java:128)\n        at org.apache.jackrabbit.core.SearchManager.createQuery(SearchManager.java:282)\n        at org.apache.jackrabbit.core.query.QueryManagerImpl.createQuery(QueryManagerImpl.java:102)\n        at org.apache.jackrabbit.core.security.user.IndexNodeResolver.buildQuery(IndexNodeResolver.java:105)\n        at org.apache.jackrabbit.core.security.user.IndexNodeResolver.findNode(IndexNodeResolver.java:50)\n        at org.apache.jackrabbit.core.security.user.UserManagerImpl.getAuthorizable(UserManagerImpl.java:93)\n        at org.apache.jackrabbit.core.security.user.UserManagerImpl.createUser(UserManagerImpl.java:177)\n        at org.apache.jackrabbit.core.security.user.UserManagerImpl.createUser(UserManagerImpl.java:158)\n        at FirstHop.main(FirstHop.java:20)\nCaused by: org.apache.jackrabbit.spi.commons.query.xpath.TokenMgrError: Lexical error at line 1, column 76.  Encountered: \"@\" (64), after : \"\"\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPathTokenManager.getNextToken(XPathTokenManager.java:13263)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.jj_ntk(XPath.java:9187)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ElementTest(XPath.java:8745)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.KindTest(XPath.java:8120)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.NodeTest(XPath.java:5041)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.AbbrevForwardStep(XPath.java:4891)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ForwardStep(XPath.java:4747)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.AxisStep(XPath.java:4692)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.StepExpr(XPath.java:4597)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.RelativePathExpr(XPath.java:4547)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.PathExpr(XPath.java:4396)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ValueExpr(XPath.java:4125)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.UnaryExpr(XPath.java:4032)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.CastExpr(XPath.java:3935)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.CastableExpr(XPath.java:3898)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.TreatExpr(XPath.java:3861)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.InstanceofExpr(XPath.java:3824)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.IntersectExceptExpr(XPath.java:3748)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.UnionExpr(XPath.java:3672)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.MultiplicativeExpr(XPath.java:3586)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.AdditiveExpr(XPath.java:3510)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.RangeExpr(XPath.java:3451)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ComparisonExpr(XPath.java:3353)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.AndExpr(XPath.java:3290)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.OrExpr(XPath.java:3227)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ExprSingle(XPath.java:2214)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ForClause(XPath.java:2337)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.FLWORExpr(XPath.java:2233)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ExprSingle(XPath.java:2133)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.Expr(XPath.java:2094)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.QueryBody(XPath.java:2066)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.MainModule(XPath.java:512)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.Module(XPath.java:387)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.QueryList(XPath.java:151)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.XPath2(XPath.java:118)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPathQueryBuilder.<init>(XPathQueryBuilder.java:295)\n        ... 14 more\norg.apache.jackrabbit.spi.commons.query.xpath.TokenMgrError: Lexical error at line 1, column 76.  Encountered: \"@\" (64), after : \"\"\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPathTokenManager.getNextToken(XPathTokenManager.java:13263)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.jj_ntk(XPath.java:9187)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ElementTest(XPath.java:8745)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.KindTest(XPath.java:8120)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.NodeTest(XPath.java:5041)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.AbbrevForwardStep(XPath.java:4891)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ForwardStep(XPath.java:4747)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.AxisStep(XPath.java:4692)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.StepExpr(XPath.java:4597)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.RelativePathExpr(XPath.java:4547)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.PathExpr(XPath.java:4396)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ValueExpr(XPath.java:4125)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.UnaryExpr(XPath.java:4032)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.CastExpr(XPath.java:3935)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.CastableExpr(XPath.java:3898)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.TreatExpr(XPath.java:3861)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.InstanceofExpr(XPath.java:3824)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.IntersectExceptExpr(XPath.java:3748)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.UnionExpr(XPath.java:3672)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.MultiplicativeExpr(XPath.java:3586)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.AdditiveExpr(XPath.java:3510)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.RangeExpr(XPath.java:3451)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ComparisonExpr(XPath.java:3353)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.AndExpr(XPath.java:3290)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.OrExpr(XPath.java:3227)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ExprSingle(XPath.java:2214)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ForClause(XPath.java:2337)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.FLWORExpr(XPath.java:2233)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.ExprSingle(XPath.java:2133)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.Expr(XPath.java:2094)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.QueryBody(XPath.java:2066)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.MainModule(XPath.java:512)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.Module(XPath.java:387)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.QueryList(XPath.java:151)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPath.XPath2(XPath.java:118)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPathQueryBuilder.<init>(XPathQueryBuilder.java:295)\n        at org.apache.jackrabbit.spi.commons.query.xpath.XPathQueryBuilder.createQuery(XPathQueryBuilder.java:331)\n        at org.apache.jackrabbit.spi.commons.query.xpath.QueryBuilder.createQueryTree(QueryBuilder.java:39)\n        at org.apache.jackrabbit.spi.commons.query.QueryParser.parse(QueryParser.java:57)\n        at org.apache.jackrabbit.core.query.lucene.QueryImpl.<init>(QueryImpl.java:91)\n        at org.apache.jackrabbit.core.query.lucene.SearchIndex.createExecutableQuery(SearchIndex.java:615)\n        at org.apache.jackrabbit.core.query.QueryImpl.init(QueryImpl.java:128)\n        at org.apache.jackrabbit.core.SearchManager.createQuery(SearchManager.java:282)\n        at org.apache.jackrabbit.core.query.QueryManagerImpl.createQuery(QueryManagerImpl.java:102)\n        at org.apache.jackrabbit.core.security.user.IndexNodeResolver.buildQuery(IndexNodeResolver.java:105)\n        at org.apache.jackrabbit.core.security.user.IndexNodeResolver.findNode(IndexNodeResolver.java:50)\n        at org.apache.jackrabbit.core.security.user.UserManagerImpl.getAuthorizable(UserManagerImpl.java:93)\n        at org.apache.jackrabbit.core.security.user.UserManagerImpl.createUser(UserManagerImpl.java:177)\n        at org.apache.jackrabbit.core.security.user.UserManagerImpl.createUser(UserManagerImpl.java:158)\n        at FirstHop.main(FirstHop.java:20)\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1111",
        "summary": "Access to version history results in reading all versions of versionable node",
        "description": "InternalVersionHistoryImpl loads all versions at once during initialization. Because of that all versioning operations (incl. checkin, label, restore) are significantly slower when node has many versions.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3027",
        "summary": "JCR Server has concurrency issues on JcrWebdavServer.SessionCache internal HashMap caches",
        "description": "After doing the davex remoting performance work outlined in JCR-3026, the increased concurrency on my jcr server exposed a lot of errors related to getting and putting from the JcrWebdavServer.SessionCache's internal HashMap's.  This problem with HashMap's is a well known concurrency error and was easily fixed by upgrading these maps to ConcurrentHashMaps.  Performance seems dramatically better.  \n\nThe fix includes exposure of a tuning parameter that allows the user to set the expected concurrency level.  This is the number of concurrent requests you expect the server to be handling.  In the typical davex remoting scenario, this means you should tune this server side value to match the total max connections of all clients pointed at the server.  See JCR-3026. \n\nUSAGE:  Set the 'concurrency-level' init param for the JcrRemotingServlet, via the web.xml of the jackabbit-webapp component.  Default value is 50.  Or you can intervene in a lower level api if appropriate.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2370",
        "summary": "Index recovery may fail when redo log contains nodes that are part of an index aggregate",
        "description": "SearchIndex.mergeAggregatedNodeIndexes() will throw a NullPointerException because index is not yet set. The call is made from the recovery code that is triggered in the MultiIndex constructor.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2017",
        "summary": "System view export truncates carriage return",
        "description": "If a string contains a carriage return (\\r), this character was truncated on some platforms. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1230",
        "summary": "Jcr-Server: useful output upon GET to root- and workspace-resources",
        "description": "in contrast to the resources representing JCR Node or Properties, the 'root' resource and the resources representing the\nworkspaces present in the repository don't provide any output when accessed in a browser.\n\n-> add some very simple listing for those 2 resource types.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1844",
        "summary": "Convenience method to Or multiple values with a single filter",
        "description": "Added a convenience method to add Or Filter for the same property with multiple values. This is to simulate an IN Clause in JackRabbit. ",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2198",
        "summary": "Text.escapeIllegalJCRChars should be adjusted to match the 2.0 set of illegal chars",
        "description": "Text.escapeIllegalJCRChars still contains chars that were illegal in JCR 1.0 but were removed from the set for JCR 2.0",
        "label": "NUG",
        "classified": "TEST",
        "type": ""
    },
    {
        "key": "JCR-376",
        "summary": "JCR-RMI depends on commons-logging",
        "description": "The commons-logging dependency in JCR-RMI should be removed.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "JCR-1731",
        "summary": "Session.checkPermission(\"/\", \"add_node\") throws PathNotFoundException instead of AccessControlException",
        "description": "When invoking Session.checkPermission(\"/\", \"add_node\"), a PathNotFoundException is thrown:\n\nException in thread \"main\" javax.jcr.PathNotFoundException: no such ancestor path of degree 1\n\tat org.apache.jackrabbit.spi.commons.name.PathFactoryImpl$PathImpl.getAncestor(PathFactoryImpl.java:443)\n\tat org.apache.jackrabbit.core.SessionImpl.checkPermission(SessionImpl.java:710)\n\tat Test.main(Test.java:35)\n\ni assume that getAncestor(1) used to return null in an earlier version.\n\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-75",
        "summary": "JCR taglib",
        "description": "JCR Taglib. Maven generated site at http://cablemodem.fibertel.com.ar/edgarpoce/index.html",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2152",
        "summary": "ValueFormat should provide method getJCRString",
        "description": "In order to retrieve the JCR String representation of a QValue currently the following calls are required:\n\nValueFormat.getJCRValue(QValue, NamePathResolver, ValueFactory)\nValue.getString()\n\nThis could be simplified if the ValueFormat would provide\n\nValueFormat.getJCRString(QValue, NamePathResolver)\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-621",
        "summary": "create jcr-browser contrib project",
        "description": "If noone oposes I'll start a contrib project called jcr-browser. A live demo of the initial code is available at http://edgarpoce.dyndns.org:8080/jcr-browser/",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1622",
        "summary": "Session.getUserID returns first principal in the set obtained from Subject.getPrincipals()",
        "description": "this may lead to a wrong value for the UserID (e.g. the name of a Group principal).\n\njsr 170 defines the getUserID() to return \" the user ID associated with this Session.\" and implies (javadoc) that the method has a relation to the login.\n\nThis issues has already been partially addressed while working on jsr 283 access control (trunk).",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-523",
        "summary": "QueryManagerImpl hardwires supported query languages",
        "description": "QueryManagerImpl hardwires supported query languages. This seems to be sub-optimal, given the fact that Jackrabbit has a pluggable architecture for additional query languages.\n",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1234",
        "summary": "CachingMultiReader has inconsistent name",
        "description": "All other classes that extend IndexReader are also named that way, except CachingMultiReader. It should be renamed to CachingMultiIndexReader.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-511",
        "summary": "TCK: Node types selected by SetValueValueFormatExceptionTest may lead to incorrect test failure",
        "description": "During setup, the test selects two node types, one with a BOOLEAN property and one with a DATE property, and creates nodes of these types as children of the target node.  Having the TCK select these node types creates two problems:  First, JSR-170 does not require an implementation to provide deterministic, stable ordering of node types returned by NodeTypeManager.  Consequently, the node types selected during test setup may vary from run to run, making test configuration difficult or impossible.  Second, if a repository imposes implementation-specific type constraints not discoverable through JSR-170, the TCK may select a node type inappropriate as a child of the test node.\n\nProposal: introduce configuration properties which, if set, override the property definition and node type selected by NodeTypeUtil.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-3158",
        "summary": "Deadlock in DBCP when accessing node",
        "description": "I found a deadlock situation using JR 2.2.10, the problem is with DBCP 1.2.2 and is fixed in DBCP 1.3, JR trunk also uses DBCP 1.2.2 and should also be updated\n\nThe ticket in dbcp is #DBCP-270, related tickets are #DBCP-65 #DBCP-281 #DBCP-271\n\nStack trace of where my call is stalled:\n{code}\nmain@1, prio=5, in group 'main', status: 'MONITOR'\n\t blocks Timer-1@2545\n\t waiting for Timer-1@2545 to release lock on {1}\n\t  at org.apache.commons.pool.impl.GenericObjectPool.addObjectToPool(GenericObjectPool.java:1137)\n\t  at org.apache.commons.pool.impl.GenericObjectPool.returnObject(GenericObjectPool.java:1076)\n\t  at org.apache.commons.dbcp.PoolableConnection.close(PoolableConnection.java:87)\n\t  at org.apache.commons.dbcp.PoolingDataSource$PoolGuardConnectionWrapper.close(PoolingDataSource.java:181)\n\t  at org.apache.jackrabbit.core.util.db.DbUtility.close(DbUtility.java:75)\n\t  at org.apache.jackrabbit.core.util.db.ResultSetWrapper.invoke(ResultSetWrapper.java:63)\n\t  at $Proxy12.close(Unknown Source:-1)\n\t  at org.apache.jackrabbit.core.persistence.pool.BundleDbPersistenceManager.loadBundle(BundleDbPersistenceManager.java:1042)\n\t  at org.apache.jackrabbit.core.persistence.bundle.AbstractBundlePersistenceManager.getBundle(AbstractBundlePersistenceManager.java:669)\n\t  at org.apache.jackrabbit.core.persistence.bundle.AbstractBundlePersistenceManager.load(AbstractBundlePersistenceManager.java:415)\n\t  at org.apache.jackrabbit.core.state.SharedItemStateManager.loadItemState(SharedItemStateManager.java:1830)\n\t  at org.apache.jackrabbit.core.state.SharedItemStateManager.getNonVirtualItemState(SharedItemStateManager.java:1750)\n\t  at org.apache.jackrabbit.core.state.SharedItemStateManager.getItemState(SharedItemStateManager.java:265)\n\t  at org.apache.jackrabbit.core.state.LocalItemStateManager.getNodeState(LocalItemStateManager.java:109)\n\t  at org.apache.jackrabbit.core.state.LocalItemStateManager.getItemState(LocalItemStateManager.java:174)\n\t  at org.apache.jackrabbit.core.state.XAItemStateManager.getItemState(XAItemStateManager.java:260)\n\t  at org.apache.jackrabbit.core.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:161)\n\t  at org.apache.jackrabbit.core.ItemManager.getItemData(ItemManager.java:382)\n\t  at org.apache.jackrabbit.core.ItemManager.getNode(ItemManager.java:669)\n\t  at org.apache.jackrabbit.core.ItemManager.getNode(ItemManager.java:647)\n\t  at org.apache.jackrabbit.core.LazyItemIterator.prefetchNext(LazyItemIterator.java:120)\n\t  at org.apache.jackrabbit.core.LazyItemIterator.next(LazyItemIterator.java:257)\n\t  at info.magnolia.jcr.iterator.DelegatingNodeIterator.next(DelegatingNodeIterator.java:79)\n{code}\n\nThis is the offending thread:\n{code}\nTimer-1@2545 daemon, prio=5, in group 'main', status: 'MONITOR'\n\t blocks main@1\n\t waiting for main@1 to release lock on {1}\n\t  at org.apache.commons.dbcp.AbandonedTrace.addTrace(AbandonedTrace.java:176)\n\t  at org.apache.commons.dbcp.AbandonedTrace.init(AbandonedTrace.java:92)\n\t  at org.apache.commons.dbcp.AbandonedTrace.<init>(AbandonedTrace.java:82)\n\t  at org.apache.commons.dbcp.DelegatingStatement.<init>(DelegatingStatement.java:61)\n\t  at org.apache.commons.dbcp.DelegatingConnection.createStatement(DelegatingConnection.java:224)\n\t  at org.apache.commons.dbcp.PoolableConnectionFactory.validateConnection(PoolableConnectionFactory.java:331)\n\t  at org.apache.commons.dbcp.PoolableConnectionFactory.validateObject(PoolableConnectionFactory.java:312)\n\t  at org.apache.commons.pool.impl.GenericObjectPool.evict(GenericObjectPool.java:1217)\n\t  at org.apache.commons.pool.impl.GenericObjectPool$Evictor.run(GenericObjectPool.java:1341)\n\t  at java.util.TimerThread.mainLoop(Timer.java:512)\n\t  at java.util.TimerThread.run(Timer.java:462)\n{code}",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2060",
        "summary": "JSR 283: Access Nodes and Properties by Array of \"NameGlob\"",
        "description": "The proposed final draft contains new variants of Node.getNodes and Node.getProperties:\n\n- Node.getNodes(String[] nameGlobs)\n- Node.getProperties(String[] nameGlobs)\n\nsee section 5.2.2 Iterating Over Child Items and 5.2.2.2 Name Globs",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-2439",
        "summary": "More utility methods in JcrUtils",
        "description": "I'd like to add at least the following utility methods to JcrUtils:\n\nFor logging:\n\n    // Utility method to simplify log messages and debug prints:\n    // Node -> \"name [type]\"\n    // Property -> \"@name = value(s)\"\n    String toString(Item item)\n\nFor making sure that a node exists:\n\n    // Returns the identified child node. If the child does not already exist,\n    // it is added using the default node type from the parent.\n    Node setNode(Node parent, String name)\n\n    // Same as above, but ensures that isNodeType(type) is true for the\n    // returned node, using addNode(name, type) or setPrimaryType(type)\n    // if needed.\n    Node setNode(Node parent, String name, String type)\n\nFor adding (or setting, see above) nt:folder nodes:\n\n    // Adds a new nt:folder node with the given name\n    Node addFolder(Node parent, String name)\n\n    // Ensures that an nt:folder node with the given name exists\n    Node setFolder(Node parent, String name)\n\nFor adding (or setting) nt:file nodes:\n\n    // Adds a new nt:file/nt:resource structure\n    // If the mime type contains a charset parameter, then the jcr:encoding property is also set\n    Node addFile(Node parent, String name, String mime, InputStream data)\n    Node addFile(Node parent, String name, String mime, Calendar date, InputStream data)\n\n    // Ensures that an nt:file/nt:resource structure exists with the given data.\n    // Note that the type of a potential existing jcr:content node is not modified\n    Node setFile(Node parent, String name, String mime, InputStream data)\n    Node setFile(Node parent, String name, String mime, Calendar date, InputStream data)\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2672",
        "summary": "Cache also failed principal lookups",
        "description": "The principal cache in Jackrabbit normally does a good job in ensuring good performance in critical areas like ACL evaulation. However, the cache only includes successful principal lookups, so an ACE that references a missing (or mistyped) principal can cause notable performance issues as a new principal lookup is needed whenever the node covered by such an ACL is accessed.\n\nTo solve that problem I propose that we extend the principal cache to also cover negative principal lookups.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2488",
        "summary": "Add the ability to disable inheriting ancestor ACLs",
        "description": "The current ACL implementation will walk the tree from the item being accessed, up to the root, collecting ACL entries for all the ancestors. With this system, there is no easy way to restrict access to subnodes except by adding DENY entries to negate the entries inherited from the parent nodes.\n\nI'd like to request a way to turn this behavior off either at a node level or global level.\n\nThe place where recursion is happening is in org.apache.jackrabbit.core.security.authorization.acl.ACLProvider$Entries.collectEntries(NodeImpl node). Inside this method, it could perhaps check a global parameter or the existence of property of the ACL policy node to determine whether to recurse up the tree.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2747",
        "summary": "ConcurrentModificationException in IndexMerger",
        "description": "The IndexMerger.start() method can cause the following ConcurrentModificationException to be thrown since it doesn't protect against concurrent access to the busyMergers list. The workers started by the start() method will remove themselves from the busyMergers list, which makes it possible for a quick worker to concurrently modify the list before the start() method is finished iterating through it.\n\njava.util.ConcurrentModificationException\n\tat java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)\n\tat java.util.AbstractList$Itr.next(AbstractList.java:343)\n\tat org.apache.jackrabbit.core.query.lucene.IndexMerger.start(IndexMerger.java:122)\n\tat org.apache.jackrabbit.core.query.lucene.MultiIndex.<init>(MultiIndex.java:325)\n\tat org.apache.jackrabbit.core.query.lucene.SearchIndex.doInit(SearchIndex.java:507)\n\tat org.apache.jackrabbit.core.query.AbstractQueryHandler.init(AbstractQueryHandler.java:78)\n\tat org.apache.jackrabbit.core.config.RepositoryConfigurationParser$1.getQueryHandler(RepositoryConfigurationParser.java:630)\n\tat org.apache.jackrabbit.core.config.WorkspaceConfig.getQueryHandler(WorkspaceConfig.java:215)\n\tat org.apache.jackrabbit.core.config.WorkspaceConfig.getQueryHandler(WorkspaceConfig.java:215)\n\tat org.apache.jackrabbit.core.SearchManager.<init>(SearchManager.java:173)\n\tat org.apache.jackrabbit.core.RepositoryImpl$WorkspaceInfo.getSearchManager(RepositoryImpl.java:1868)\n\tat org.apache.jackrabbit.core.RepositoryImpl$WorkspaceInfo.doPostInitialize(RepositoryImpl.java:2077)\n\tat org.apache.jackrabbit.core.RepositoryImpl$WorkspaceInfo.initialize(RepositoryImpl.java:1996)\n\tat org.apache.jackrabbit.core.RepositoryImpl.initStartupWorkspaces(RepositoryImpl.java:535)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1198",
        "summary": "Issue while loading list of classes at that path itself.",
        "description": "Hi,\n\nI cannot retrieve list of objects that are directly under the path that they were saved in. I did not know where to simulate this issue and hence I have used DigesterSimpleQueryTest. I have attached the path for the newly added test case testObjectListRetrievalAtBasePath. In case the patch is not up to the mark I have attached the modified file too.\n\nInstead of creating Page in /test if I create it in /sample/test and search in /sample/test it returns nothing but if I search in /sample it would return the object.\n\nAnother important point here is that it is causing issues while retrieving Page class, the other test cases that are retrieving Paragraph class (embedded inside Page class) are still working fine!\n\nRegards,\n\nKaizer",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-710",
        "summary": "NullPointerException in DatabasePersistenceManager and DatabaseFileSystem after a failed reconnection attempt",
        "description": "As reported on the dev mailing-list, this is what happens:\n\nThe reconnection/retry mechanism in DatabasePersistenceManager/DatabaseFileSystem seems to behave fine when the connection times out or is killed for some reason, and the DB server is in fact still running.\nHowever there is a problem if the connection cannot be re-established directly, for example if a transient network outage lasts longer than the few reconnection attempts.\nInside DatabasePersistenceManager.reestablishConnection(), initConnection() will fail, and the preparedStatements map will stay empty.\nThis in turn will trigger a nasty NullPointerException (never caught) next time executeStmt() is called, because the map is still empty, and there is no check for that.\n\n\nThe following proposed fix from Stefan Guggisberg has been tested to work when applied on 1.2-rc2:\n\n> the simplest fix would be to remove line 783 in\n> DatabasePersistenceManager.java and line 1010 in\n> DatabaseFileSystem.java,\n> i.e. the following stmt:\n> \n >      preparedStatements.clear();\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-303",
        "summary": "Add JCR-RMI documentation to the Jackrabbit web site",
        "description": "Use the org.apache.jackrabbit.rmi.{client,server} package javadocs as a base for a JCR-RMI document page on the Jackrabbit web site.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "RFE"
    },
    {
        "key": "JCR-685",
        "summary": "Remove some synchronization on CachingNamespaceResolver",
        "description": "The methods getQName() and getJCRName() are unnecessarily synchronized and cause monitor contention with concurrent calls to the methods of the NameCache interface (those are also synchronized).\n\nI propose the following change:\n\nIndex: CachingNamespaceResolver.java\n===================================================================\n--- CachingNamespaceResolver.java\t(revision 488245)\n+++ CachingNamespaceResolver.java\t(working copy)\n@@ -84,7 +84,7 @@\n     /**\n      * @deprecated use {@link NameFormat#parse(String, NamespaceResolver)}\n      */\n-    public synchronized QName getQName(String name)\n+    public QName getQName(String name)\n             throws IllegalNameException, UnknownPrefixException {\n         return NameFormat.parse(name, this);\n     }\n@@ -92,7 +92,7 @@\n     /**\n      * @deprecated use {@link NameFormat#format(QName, NamespaceResolver)}\n      */\n-    public synchronized String getJCRName(QName name)\n+    public String getJCRName(QName name)\n             throws NoPrefixDeclaredException {\n         return NameFormat.format(name, this);\n     }\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2740",
        "summary": "On missing child node, automatically remove the entry (when a session attribute is set)",
        "description": "If a node points to a non-existing child node (which is a repository inconsistency), currently this child node is silently ignored for read operations (as far as I can tell). However, when trying to add another child node with the same name, an exception is thrown with a message saying a child node with this name already exists. Also, the parent node can't be removed.\n\nOne solution is to remove the bad child node entry, but only if the session attribute \"org.apache.jackrabbit.autoFixCorruptions\" is set (so by default the repository is not changed 'secretly'):\n\n    SimpleCredentials cred = new SimpleCredentials(...);\n    cred.setAttribute(\"org.apache.jackrabbit.autoFixCorruptions\", \"true\");\n    rep.login(cred);\n\nIt's not a perfect solution, but it might be better than throwing an exception and basically preventing changes.\n\nAnother solution (not implemented) would be to rename the missing child node entry when trying to add a child node with the same name (for example add the current date/time, or a random digit until there is no conflict), and then continue with adding the new child node.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-367",
        "summary": "Remove dependency on Xerces",
        "description": "Classloaders in certain J2EE servers do not play well with the Xerces requirement",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1967",
        "summary": "Impossible comparison in NodeTypeImpl",
        "description": "org.apache.jackrabbit.jcr2spi.nodetype.NodeTypeImpl does\n\n    public boolean isNodeType(Name nodeTypeName) {\n        return getName().equals(nodeTypeName) ||  ent.includesNodeType(nodeTypeName);\n    }\n\n\nas getName() is a string and nodeTypeName is a Name this will always be false. Perhaps you meant\n\n    public boolean isNodeType(Name nodeTypeName) {\n        return getName().equals(nodeTypeName.getLocalName()) ||  ent.includesNodeType(nodeTypeName);\n    }\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2249",
        "summary": "Remove duplicate code in InternalValueFactory",
        "description": "After JCR-2245 has been applied some of the duplicate code in InternaValueFactory can be removed.\n\nNamely:\n- create(String, int)\n- all other create methods that are non-binary ?",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1346",
        "summary": "InternalValue.createCopy for binary properties (jcr:data) causes problems",
        "description": "Running 1.4 with no data store configured, and option org.jackrabbit.useDataStore not set (i.e true), the following code gives 0 for the property length.\n\nNode n = root.getNode(relPath);\nsession.getWorkspace().copy(n.getPath(), destPath);\nNode contentNode = n.getNode(JcrConstants.JCR_CONTENT);\nProperty p = contentNode.getProperty(JcrConstants.JCR_DATA);\nSystem.out.println(\"length = \"+p.getLength());\n\nInternalValue.createCopy checks USE_DATA_STORE and returns the same value for the source node's state. BundleBinding.writeState() calls BLOBInMemory.discard() when persisting the new node. This has now changed the value of the existing nodes property. Setting the option org.jackrabbit.useDataStore to false works fine. Possibly the check for binary property type in InternalValue.createCopy should be done first?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-157",
        "summary": "Reorganize Jackrabbit into 'core' 'api' and 'commons'",
        "description": "",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3011",
        "summary": "Fix incorrect IndexingQueueTest logic",
        "description": "The IndexingQueueTest class assumes that a Session.save() call will push all pending text extraction tasks to the indexing queue, when in fact those can still be kept waiting in the VolatileIndex.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-823",
        "summary": "NamespaceRegistryTest makes assumptions about legal names",
        "description": "org.apache.jackrabbit.test.api.NamespaceRegistryTest.testRegisterNamespace() makes the assumption that once a namespace is registered, it can be used in a node name. In practice, many repositories have their own restrictions on node naming, in particular may not support namespace prefixes in node names at all.\n\nProposal: change the test case so that it's independant of the repository's ability to create new nodes in that namespace.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1285",
        "summary": "ObjectContentManagerImpl.getObject(Query) throws NoSuchElementException when query does not match an object",
        "description": "When a query returns no objects, ObjectContentManagerImpl.getObject(Query) throws the following exception:\n\njava.util.NoSuchElementException\n        at java.util.AbstractList$Itr.next(AbstractList.java:427)\n        at org.apache.jackrabbit.ocm.manager.impl.ObjectContentManagerImpl.getObject(ObjectContentManagerImpl.java:538)\n\nJavadocs for ObjectContentManager interface suggest that a ObjectContentManagerException should be thrown in this case.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2124",
        "summary": "Do not increment revison while target workspace is not initialized",
        "description": "It can happen that a workspace is not initialized at all during a syncronize should be performed.\nThis can happen when a cluster member performs a re-index of a workspace. The changelog should not be ignored it\nshould be processed after the workspace is initailized.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2951",
        "summary": "Item.remove fails if a child-item is not visible to the editing session",
        "description": "the following test setup fails:\n\n- a given session is allowed to remove a node\n- the node has a policy child node which is not visible to the editing session (missing ac-read permission)\n  OR the node has another invisible child item which could - based on the permissions above - be removed by that session.\n\ncalling Node.remove however fails with accessdeniedexception because the internal remove\nmechanism accesses all child items to mark them removed. however, the access is executed\nusing the regular itemmgr calls that are used to retrieve the items using the JCR API which\nresults in accessdenied exception as those child items are not visible to the session.\nsince the items can be removed i would argue that this is a bug in the internal remove process.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2957",
        "summary": "Improve password hashing",
        "description": "",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1369",
        "summary": "indexing-rules should allow wildcards for (global) property names",
        "description": "eg:\n\n<indexing-rule nodeType=\"*\">\n  <property>text</property>\n  <property>*Text</property>\n</indexing-rule>\n\ndefines that all properties named 'text' and all that end with 'Text' should be fulltext indexed.\nif the property name includes namespace prefixes, wildcards are only allowed for 'any' namespace. eg:\n\n*:title\n\nbut not: j*:title\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1954",
        "summary": "DataStore: gc.stopScan() should be optional",
        "description": "Data Store garbage collection currently works like this:\n\ngc.scan();\ngc.stopScan();\ngc.deleteUnused();\n\nCurrently, if stopScan() is not called, an exception is thrown. This is not user friendly. Instead, stopScan() should be optional, and should be allowed any time. It may be used to indicate garbage collection has finished:\n\ntry {\n  gc.scan();\n  ...\n  gc.deleteUnused();\n} finally {\n  gc.stopScan();\n}\n\nOr when sharing the repository:\n\ngc1.scan();\ngc2.scan();\ngc1.deleteUnused();\ngc2.stopScan();\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1497",
        "summary": "Incorrect decodedAttributeValue in AbstractImportXmlTest",
        "description": "The string literal is not correctly escaped.\n\nLater on the decoded attribute value should be used to check the imported value. There is currently an odd test that checks the encoded attribute value twice.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-50",
        "summary": "Persistence data of versioning not cleaned up correctly",
        "description": "when deleting a version or removing its label, the respective persistence data is not always properly removed.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-755",
        "summary": "Add Bundle Persistence Managers",
        "description": "we (day software) offer our set of bundle persistence managers to the jackrabbit project. those pms combine the node and property states into a single bundle and store them together. this improves performance and reduces storage-memory overhead (no exact numbers available). The bundle pms also have a \"bundle-cache\" that does a memory sensitive caching of the bundles and a negative cache for non-existent bundles. small binary properties are inlined into the bundle rather than stored in the blobstore.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2529",
        "summary": "jcr2spi:  Remove sanityCheck() from ItemImpl.getSession()",
        "description": "same as JCR-911 for jcr2spi.\n\nthe check was responsible for the failure of ActivitiesTest#testActivitiesRelation",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1439",
        "summary": "MOVE method returns error 412 Precondition Failed",
        "description": "Hi, I was trying MacOS X 10.5 Finder's WebDAV client to do testing on Jackrabbit 1.4 which is hosted on Tomcat 5.5.25 on a Windows XP SP2 computer on a LAN. I encounter an error while doing remote editing, I was able to open the text document, but the problem is I couldn't save it.\n\nI tried to find some log on Tomcat but sadly Jackrabbit didn't produces any log files regarding of my problem. So I used Ethereal 0.99.0 to check the packets from the Windows XP computer. The below trace is a summary from the exported text file of the packet analyzer where the problem occur:-\n\nline 11818:-\nNo.     Time        Source                Destination           Protocol Info\n4352 27.629257   10.60.1.90            10.60.1.187           HTTP     MOVE /jackrabbit-webapp-1.4/repository/default/.TemporaryItems/folders.501/TemporaryItems/(A%20Document%20Being%20Saved%20By%20TextEdit)/Copy%20of%20Request_for_GAMS_User_Account.rtf HTTP/1.1\n\nFrame 4352 (592 bytes on wire, 592 bytes captured)\nEthernet II, Src: AppleCom_72:c3:5e (00:0d:93:72:c3:5e), Dst: 00:19:d1:a0:34:f7 (00:19:d1:a0:34:f7)\nInternet Protocol, Src: 10.60.1.90 (10.60.1.90), Dst: 10.60.1.187 (10.60.1.187)\nTransmission Control Protocol, Src Port: 64970 (64970), Dst Port: 8080 (8080), Seq: 69060, Ack: 90475, Len: 526\n    Source port: 64970 (64970)\n    Destination port: 8080 (8080)\n    Sequence number: 69060    (relative sequence number)\n    Next sequence number: 69586    (relative sequence number)\n    Acknowledgement number: 90475    (relative ack number)\n    Header length: 32 bytes\n    Flags: 0x0018 (PSH, ACK)\n    Window size: 524280 (scaled)\n    Checksum: 0xd4f9 [correct]\n    Options: (12 bytes)\nHypertext Transfer Protocol\n    MOVE /jackrabbit-webapp-1.4/repository/default/.TemporaryItems/folders.501/TemporaryItems/(A%20Document%20Being%20Saved%20By%20TextEdit)/Copy%20of%20Request_for_GAMS_User_Account.rtf HTTP/1.1\\r\\n\n        Request Method: MOVE\n        Request URI: /jackrabbit-webapp-1.4/repository/default/.TemporaryItems/folders.501/TemporaryItems/(A%20Document%20Being%20Saved%20By%20TextEdit)/Copy%20of%20Request_for_GAMS_User_Account.rtf\n        Request Version: HTTP/1.1\n    User-Agent: WebDAVFS/1.5 (01508000) Darwin/9.1.0 (Power Macintosh)\\r\\n\n    Accept: */*\\r\\n\n    Destination: http://10.60.1.187:8080/jackrabbit-webapp-1.4/repository/default/au/gov/arc/www/rtf/Copy%20of%20Request_for_GAMS_User_Account.rtf\\r\\n\n    Authorization: Basic YWRtaW46YWRtaW4=\\r\\n\n        Credentials: admin:admin\n    Content-Length: 0\\r\\n\n    Connection: keep-alive\\r\\n\n    Host: 10.60.1.187:8080\\r\\n\n    \\r\\n\n\nline 11850 -\nNo.     Time        Source                Destination           Protocol Info\n4353 27.630345   10.60.1.187           10.60.1.90            HTTP     HTTP/1.1 412 Precondition Failed (text/html)\n\nFrame 4353 (1191 bytes on wire, 1191 bytes captured)\nEthernet II, Src: 00:19:d1:a0:34:f7 (00:19:d1:a0:34:f7), Dst: AppleCom_72:c3:5e (00:0d:93:72:c3:5e)\nInternet Protocol, Src: 10.60.1.187 (10.60.1.187), Dst: 10.60.1.90 (10.60.1.90)\nTransmission Control Protocol, Src Port: 8080 (8080), Dst Port: 64970 (64970), Seq: 90475, Ack: 69586, Len: 1125\n    Source port: 8080 (8080)\n    Destination port: 64970 (64970)\n    Sequence number: 90475    (relative sequence number)\n    Next sequence number: 91600    (relative sequence number)\n    Acknowledgement number: 69586    (relative ack number)\n    Header length: 32 bytes\n    Flags: 0x0018 (PSH, ACK)\n    Window size: 65535\n    Checksum: 0x1c18 [incorrect, should be 0xa2f0]\n    Options: (12 bytes)\nHypertext Transfer Protocol\n    HTTP/1.1 412 Precondition Failed\\r\\n\n        Request Version: HTTP/1.1\n        Response Code: 412\n    Server: Apache-Coyote/1.1\\r\\n\n    Content-Type: text/html;charset=utf-8\\r\\n\n    Content-Length: 965\\r\\n\n    Date: Fri, 29 Feb 2008 02:31:01 GMT\\r\\n\n    \\r\\n\nLine-based text data: text/html\n    <html><head><title>Apache Tomcat/5.5.25 - Error report</title><style><!--H1 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:22px;} H2 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#52\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1746",
        "summary": "The cluster syncDelay attribute is milliseconds",
        "description": "The repository DTDs document the cluster syncDelay attribute as being the sync interval in seconds, when it really is the interval in milliseconds.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-1262",
        "summary": "Deprecated AbstractWebdavServlet should be empty and extend new AbstractWebdavServlet",
        "description": "The AbstractWebdavServlet has been copied from the jcr-server to the webdav project. The class at the old location has been marked deprecated. I suggest that in addition to marking it deprecated we should have this class extend the new AbstractWebdavServlet class from the webdav project but not contain any fields and methods. This way, users of the old class will always get the newest and best version but can still use the old class.\n\nWill provide a patch for this proposal",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2158",
        "summary": "Consolidate CND related classes from SPI and Core",
        "description": "currently SPI Commons and Core, both have a CND Reader/Writer. they should be consolidated; i.e. core should use the SPI one.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1424",
        "summary": "[PATCH] simplify conversion of strings to primitives by using parseXXX, not valueOf(xxx).xxxValue()",
        "description": "Code converts strings to primitives using a two step process, eg\n\nBoolean.valueOf(myString).booleanValue();\n\ncan be simplified to \n\nBoolean.parseBoolean(myString);\n\ntrue of Float, Double, Int etc. \n\nIn some cases, this avoids allocating temporary boxed objects\n\npatch fixes this.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-925",
        "summary": "Incorrect transitive snapshot dependencies",
        "description": "Using ${version} in dependency declarations causes troubles since for snapshot dependencies the version variable apparently gets replaced by the exact timestamp of a deployed snapshot instead of the \"x.y-SNAPSHOT\" string. Typically the timestamps of different artifacts are not the same, causing broken dependencies.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-1197",
        "summary": "Node.restore() may throw InvalidItemStateException",
        "description": "It seems that ItemManager cache is not maintained correctly. I'm getting InvalidItemStateException: 'propertyId' has been modified externally tryin restore/checkout versionable nodes in single thread.\n\nItemState should be evicted from ItemStateManager cache when modified, it seems that status of ItemState is changed to MODIFIED, but itemState remains in the cache.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1963",
        "summary": "Determination of property state difference should skip binary values",
        "description": "o.a.j.jcr2spi.state.PropertyState.diffPropertyData, PropertyData) should alway consider two binary values to be different. The current implementation compares two binary values with equals(). An implementation will in general have to do a byte by byte comparison of both values. This is most likely always more expensive than considering the values different right from the start. \n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2240",
        "summary": "Binary value may leave temp file behind",
        "description": "The following call leaves a temp file behind that is never deleted:\n\nInputStream in = ...\nValueFactory vf = ....\nvf.createBinary(in).dispose();\n\nOnly happens when the datastore is disabled.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-2524",
        "summary": "Reduce memory usage of DocIds",
        "description": "Implementations of DocIds are used to cache parent child relations of nodes in the index. Usually there are a lot of duplicate objects because a DocId instance is used to identify the parent of a node in the index. That is, sibling nodes will all have DocIds with the same value. Currently a new DocId instance is created for each node. Caching the most recently used DocIds and reuse them might help to reduce the memory usage. Furthermore there are DocIds that could be represented with a short instead of an int when possible.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-504",
        "summary": "TCK: DocumentViewImportTest does not call refresh after direct-to-workspace import",
        "description": "After performing a direct-to-workspace import, the test does not call refresh to ensure the transient layer doesn't contain stale data.\n\nProposal: call refresh(false) after performing direct-to-workspace imports.\n\n--- DocumentViewImportTest.java (revision 422074)\n+++ DocumentViewImportTest.java (working copy)\n@@ -106,6 +106,12 @@\n             SAXException, NotExecutableException {\n  \n         importXML(target, createSimpleDocument(), uuidBehaviour, withWorkspace);\n+\n+        if (withWorkspace)\n+        {\n+          session.refresh(false);\n+        }\n+\n         performTests();\n     }\n  \n@@ -127,6 +133,12 @@\n             SAXException, IOException, NotExecutableException {\n  \n         importWithHandler(target, createSimpleDocument(), uuidBehaviour, withWorkspace);\n+\n+        if (withWorkspace)\n+        {\n+          session.refresh(false);\n+        }\n+\n         performTests();\n     }\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1601",
        "summary": "Occasional NullPointerException in ItemManager",
        "description": "From time to time I see a NullPointerException in ItemManager when running ConcurrentReadWriteTest. The exception is probably caused by another session that removes the property, which has the effect that the ItemState in ItemData is set to null.\n\nException in thread \"Thread-11\" java.lang.NullPointerException\n\tat org.apache.jackrabbit.core.ItemManager.canRead(ItemManager.java:313)\n\tat org.apache.jackrabbit.core.ItemManager.getItemData(ItemManager.java:293)\n\tat org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:226)\n\tat org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:486)\n\tat org.apache.jackrabbit.core.LazyItemIterator.prefetchNext(LazyItemIterator.java:111)\n\tat org.apache.jackrabbit.core.LazyItemIterator.<init>(LazyItemIterator.java:93)\n\tat org.apache.jackrabbit.core.LazyItemIterator.<init>(LazyItemIterator.java:75)\n\tat org.apache.jackrabbit.core.ItemManager.getChildProperties(ItemManager.java:658)\n\tat org.apache.jackrabbit.core.NodeImpl.getProperties(NodeImpl.java:2663)\n\tat org.apache.jackrabbit.core.ConcurrentReadWriteTest$1$1.execute(ConcurrentReadWriteTest.java:65)\n\tat org.apache.jackrabbit.core.AbstractConcurrencyTest$Executor.run(AbstractConcurrencyTest.java:206)\n\tat java.lang.Thread.run(Thread.java:595)\n\nThis issue does not occur in a release but only in trunk.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-782",
        "summary": "TCK: LockTest.testGetLock compares Nodes with equals",
        "description": "i think comparison by 'isSame' would be better.\n\n-> line 545\n\n-        assertTrue(\"lock holding node must be parent\", lock.getNode().equals(n1));\n+        assertTrue(\"lock holding node must be parent\", lock.getNode().isSame(n1));",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1399",
        "summary": "Backport JCR-1197: Node.restore() may throw InvalidItemStateException",
        "description": "Backport issue JCR-1197 (Node.restore() may throw InvalidItemStateException) to 1.3 branch for 1.3.4 (separate issue to avoid re-opening JCR-1197 which was already released with 1.4).",
        "label": "NUG",
        "classified": "BACKPORT",
        "type": "BUG"
    },
    {
        "key": "JCR-3243",
        "summary": "RepositoryStatistics should be more flexible",
        "description": "Right now, Jackrabbit reports TimeSeries for things like BUNDLE_READ_COUNTER, BUNDLE_WRITE_COUNTER, etc. but there is no way to extend Jackrabbit and report TimeSeries for additional properties. That's because the type of TimeSeries are defined in RepositoryStatistics class as Type enum. Enums in Java cannot be extended which limits to TimeSeries to the Types defined in RepositoryStatistics. \n\nI suggest that RepositoryStatistics is improved to allow additional TimeSeries. One approach is to define an additional RepositoryStatistics#getType(String) method. ",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1996",
        "summary": "Handle date values in the far future or prevent these from being persisted",
        "description": "Setting a date property with a value in the far future (e.g., the year 20009) and saving the session causes the index component to throw an exception (see the DateField#timeToString method). Furthermore, when the repository is restarted, the properties' value cannot be retrieved anymore because of a ValueFormatException caused by an empty value. Restarting the repository with an empty search index does not work because indexing fails. I haven't looked into the effect on queries.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-1816",
        "summary": "Provide more options for OCM CRUD API Writers to enhance the functionality",
        "description": "I am working on an Extension to Object Content Manager and from that angle require a few methods and variable from the base classes to be exposed with protected access.  I have modifier only the getters and these should not cause any issues to the current functionality.  Request a review and addition to the trunk.  \n\n1. added a clone implementation to FilterImpl\n2.  Exposed : \npublic CollectionConverter getCollectionConverter(Session session, CollectionDescriptor collectionDescriptor) from ObjectConverter",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-825",
        "summary": "WebDAV: LocatorFactoryImplEx doesn't properly evaluate resource path...",
        "description": "... if the item path happens to start with the workspace name.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-454",
        "summary": "Query with document order fails when result set size > caching hierarchy manager size",
        "description": "When a query returns a lot of nodes in the query result and document order is enabled (which is the default) then the query will fail with error messages in the log:\n\n*ERROR* [main] DocOrderNodeIteratorImpl: Internal error: unable to determine document order of nodes: (DocOrderNodeIteratorImpl.java, line 241)\n*ERROR* [main] DocOrderNodeIteratorImpl:    Node1: /stuff/node[2]/node[13]/node9 (DocOrderNodeIteratorImpl.java, line 242)\n*ERROR* [main] DocOrderNodeIteratorImpl:    Node2: /stuff/node[2]/node[13]/node5 (DocOrderNodeIteratorImpl.java, line 243)\n\nThe critical size seems to be equivalent to the cache size of the caching hierarchy manager. Attached are two test cases. The first one simply creates test nodes and the second one executes a query for those nodes. Using the cache size of 10'000 in the CachingHierarchyManager#DEFAULT_UPPER_LIMIT everything works fine, but when this value is set to 1000 (you need to re-compile the class CachingHierarchyManager) the test fails with the mentioned errors.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1488",
        "summary": "Node deleted while query is executed should not affect result size",
        "description": "Currently the QueryResultImpl counts result nodes as invalid when the access check throws a ItemNotFoundException (line 311). This leads to inconsistent total size. IMO it is sufficient to count them as invalid when the client iterates over the nodes (line 555).",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2804",
        "summary": "Add isDeclaredMember() method to Group",
        "description": "I suggest to add a method for checking whether an authorizable is a declared member of a group. Currently there is only a method for checking membership (which includes indirect memberships). \n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1971",
        "summary": "Use the new Jackrabbit parent POM",
        "description": "Now that we have an official release of the new org.apache.jackrabbit:parent:2 POM, we should start using that as the parent of all Jackrabbit builds.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1117",
        "summary": "Bundle cache is not rolled back when the storage of a ChangeLog fails",
        "description": "The bundle cache in the bundle persistence managers is not restored to its old state when the AbstractBundlePersistenceManager.store(ChangeLog changeLog) method throws an exception. If, for instance, the storage of references fails then the AbstractBundlePersistenceManager.putBundle(NodePropBundle bundle) method has already been called for all modified bundles. Because of the connection rollback, the bundle cache will be out-of-sync with the persistent state. As a result, the SharedItemStateManager will have an incorrect view of the persistent state.\nFurthermore, if the blockOnConnectionLoss property is set to true, then the BundleDbPersistenceManager can be caught in an infinite loop because of invalid SQL inserts because of an incorrect bundle cache; see attached stacktrace.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1237",
        "summary": "Change default value for respectDocumentOrder",
        "description": "The current default value for the search index configuration parameter respectDocumentOrder is true. Almost all applications are not interested in document order, while this default adds significant overhead to query execution because document order information is present in the index but has to be calculated over the complete result set.\n\nI propose to change the default value to false and document this change in the 1.4 release notes. If an application relies on document order one can still explicitly set the parameter in the configuration to true.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1546",
        "summary": "H2PersistenceManager: no need to call shutdown; javadoc bugs",
        "description": "The H2PersistenceManager implementation calls \"shutdown\" to force closing the database when using file based databases. There is no need to do that when using the H2 database engine: the database is closed automatically when the last connection is closed.\n\nAlso, the javadocs of the H2PersistenceManager need to be fixed.\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "JCR-1998",
        "summary": "Initialize hierarchy cache on startup",
        "description": "In some cases it may be desirable to initialize the hierarchy cache in the search index on startup. Currently this initialization is done in the background. For larger workspaces, this puts considerable load on the repository and may slow down access and queries. There should be a configuration parameter that forces the repository to initialize the hierarchy cache on startup and only return the repository instance when the initialization is completed.  The default value would be the current behaviour (using background thread).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2906",
        "summary": "Multivalued property sorted by last/random value",
        "description": "Sorting on multivalued property may produce incorrect result because sorting is performed only by last value of multivalued property.\nSteps to reproduce:\n1. Create multivalued field in repository. Example from nodetypes file:\n<propertyDefinition name=\"MyProperty\" requiredType=\"String\" autoCreated=\"false\" mandatory=\"false\"\n   onParentVersion=\"COPY\" protected=\"false\" multiple=\"false\">\n2. Create few records so that all records except one would contain single value for MyProperty and one record would contain \nfirst value which is greater then of any other record and the second value is somewhere in the middle. Here is an example:\n1st record: \"aaaa\"\n2nd record: \"cccc\"\n3rd record: \"dddd\", \"bbbb\"\n3. Run some query which sorts Example of XPath query:\n//*[...here are some criteria...] order by @MyProperty ascending\nThe query would return documents in such order:\n\"aaaa\"\n\"dddd\", \"bbbb\"\n\"cccc\"\nwhich is not expected order (expected same order as they were entered - as \"aaaa\" < \"cccc\", \"cccc\" < \"dddd\")\n\nAfter some digging I found out that it happens because method \norg.apache.jackrabbit.core.query.lucene.SharedFieldCache.getValueIndex\n(called from org.apache.jackrabbit.core.query.lucene.SharedFieldSortComparator.SimpleScoreDocComparator constructor)\nreturns only last Comparable of the document. Here is overwrites previous value:\nretArray[termDocs.doc()] = getValue(value, type);\n\nI tried to concatenate comparables (just to check if it would work for my case):\n\tif(retArray[termDocs.doc()] == null) {\n\t\tretArray[termDocs.doc()] = getValue(value, type);\n\t} else {\n\t\tretArray[termDocs.doc()] =\n\t\t\t\tretArray[termDocs.doc()] + \" \" + getValue(value, type);\n\t}\nBut it didn't worked well either - TermEnum returns terms not in the same order as JackRabbit returns values of multivalued field\n(as an example [\"qwer\", \"asdf\"] may become [\"asdf\", \"qwer\"] ). So, simple concatenation doesn't help.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1493",
        "summary": "Root exception not logged in ClusterNode for ClusterException",
        "description": "When our MySQL server is down or failed queries we have the following log :\nERROR (ClusterNode-node1) [org.apache.jackrabbit.core.cluster.ClusterNode] Periodic sync of journal failed: Unable to return record iterater.\n\nSo the root exception (SQLException in my case) is missing from the log and this prevent me from quickly finding the reason.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2324",
        "summary": "Remove dependency on  EDU.oswego.cs.dl.util.concurrent",
        "description": "EDU.oswego.cs.dl.util.concurrent is in maintenance mode, and http://g.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/package-summary.html advises to migrate to the JDK5 java.util.concurrent package.\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "TASK"
    },
    {
        "key": "JCR-2288",
        "summary": "o.a.jackrabbit.spi.commons.conversion.NameParser should not assume that namespace URI's are registered",
        "description": "according to JCR 2.0, \"3.4.3.4 Parsing Lexical Paths\":\n\n<quote>\nAn otherwise valid path containing an expanded name with an unregistered \nnamespace URI will always resolve into a valid internal representation of a path \n</quote>\n\nthe current implementation assumes that namespace URIs encountered in \nexpanded form names are registered, otherwise the name is treated as\nqualified name. ",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "JCR-2237",
        "summary": "ItemManager registers itself as listener too early",
        "description": "This is similar to JCR-2168 but for ItemManager and SessionItemStateManager.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-658",
        "summary": "CanAddChildNodeCallWithNodeTypeTest.testDefinedAndLegalType() may fail if protected child node definition is picked",
        "description": "If the utility NodeTypeUtil.locateChildNodeDef() picks a protected child node definition the test case will fail because it is not allowed add a protected child node.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-47",
        "summary": "Node.setProperty(String, String) does not convert values",
        "description": "when setting the value of a defined property via the Node.setProperty(String, String) method, a ConstraintViolationException is thrown. but the string value should be converted, or a ValueFormatException must be thrown.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-688",
        "summary": "Improve name resolution",
        "description": "As discussed in JCR-685, the current CachingNamespaceResolver class contains excessive synchronization causing monitor contention that reduces performance.\n\nIn JCR-685 there's a proposed patch that replaces synchronization with a read-write lock that would allow concurrent read access to the name cache.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3286",
        "summary": "InternalVersionManagerBase.calculateCheckinVersionName will fail with NPE upon empty predecessors property",
        "description": "(Note: this can only happen on inconsistent version storage)\n\nWe should add a check here, and throw a more descriptive exception.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-286",
        "summary": "Jcr-Server: Invalid value for HTTP auth header",
        "description": "At present, DAV Explorer won't log in to the JCR WebDav servlet - it doesn't even ask for a username & password.  (Neither the Microsoft WinXP WebDAV & Novell's NetDrive were as fussy and were happy to log in)\nUsing Ethereal, I compared the traffic for a valid Slide WebDav login compared to a JCR WebDav login.\n\nI've now found and fixed the problem on my local build, and I've now got DAV Explorer to work with JCR Webdav.  Here's a description of the bugfix:\n\nIn jackrabbit/contrib/jcr-server/server/src/java/org/apache/jackrabbit/server/AbstractWebdavServlet.java, there is a public static final String DEFAULT_AUTHENTICATE_HEADER.\nThis is currently set to \"Basic Realm=Jackrabbit Webdav Server\".\n\nThis is not a valid string for use in this context as it is in breach of RFC2617 for 2 reasons:\n1) \"Realm\" should be \"realm\"\n2) \"Jackrabbit Webdav Server\" should be in quotes, i.e. \"\\\"Jackrabbit Webdav Server\\\"\"\n\nAccording to http://www.ietf.org/rfc/rfc2617.txt, a valid challenge would be:\n   WWW-Authenticate: Basic realm=\"WallyWorld\"\nNote that \"realm\" is not capitalised and \"WallyWorld\" has been enclosed in quotes (the \"WWW-Authenticate: \" string is held elsewhere in the Java code and is correct)\n\n\nIn other words, AbstractWebdavServlet.java line 82, which currently reads:\n    public static final String DEFAULT_AUTHENTICATE_HEADER = \"Basic Realm=Jackrabbit Webdav Server\";\nshould be changed to read\n    public static final String DEFAULT_AUTHENTICATE_HEADER = \"Basic realm=\\\"Jackrabbit Webdav Server\\\"\";\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2202",
        "summary": "UserManagement: IndexNodeResolver.findNodes(..... , nonExact) fails to find values containing backslash",
        "description": "",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1457",
        "summary": "Restart of RMI-component fails (because it's not released while shutdown)",
        "description": "I just moved setup model for the Jackrabbit repository from a Tomcat-global JNDI-datasouce to a autonomous server connected via RMI to get rid off the problem of a total restart of the tomcat, if e.g. something is changed in the jackrabbit setup.\n\nBut the restart of the RMI component of the jackrabbit server package will fail, because on shutdown the rmi binding isn't released. From that, at restart, the socket is still in use and the (just) RMI component fails to start. In the other hand, it isn't possible to connect to the server through the remaining rmi component; you'll get a EOF-exception in RMI communication. Of course, a complete restart of the Tomcat will help, but isn't appropriate. \n\nIt looks to me like just some release on shutdown is missing. May somebody provide a patch?\n\n(log exception at restart)\n20080306-093849.086 INFO  [ajp-8009-2] [] [RepositoryStartupServlet] Cannot create Registry\njava.rmi.server.ExportException: Port already in use: 1099; nested exception is: \n        java.net.BindException: Address already in use\n        at sun.rmi.transport.tcp.TCPTransport.listen(TCPTransport.java:249)\n        at sun.rmi.transport.tcp.TCPTransport.exportObject(TCPTransport.java:184)\n        at sun.rmi.transport.tcp.TCPEndpoint.exportObject(TCPEndpoint.java:382)\n        at sun.rmi.transport.LiveRef.exportObject(LiveRef.java:116)\n        at sun.rmi.server.UnicastServerRef.exportObject(UnicastServerRef.java:180)\n        at sun.rmi.registry.RegistryImpl.setup(RegistryImpl.java:92)\n        at sun.rmi.registry.RegistryImpl.<init>(RegistryImpl.java:68)\n        at java.rmi.registry.LocateRegistry.createRegistry(LocateRegistry.java:222)\n        at org.apache.jackrabbit.j2ee.RepositoryStartupServlet.registerRMI(RepositoryStartupServlet.\n        at org.apache.jackrabbit.j2ee.RepositoryStartupServlet.startup(RepositoryStartupServlet.java\n        at org.apache.jackrabbit.j2ee.RepositoryStartupServlet.init(RepositoryStartupServlet.java:21\n        at javax.servlet.GenericServlet.init(GenericServlet.java:212)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2016",
        "summary": "ChildNodeEntriesImpl.update logs incorrect errors",
        "description": "The ChildNodeEntriesImpl logs errors on a correct update.\n\n\"ChildInfo iterator contains multiple entries with the same name|index or uniqueID -> ignore ChildNodeInfo.\"  (line 186)",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1150",
        "summary": "JCR2SPI: several performance improvements pointed out by Findbugs",
        "description": "FindBug report:\n\nM P Bx: Method org.apache.jackrabbit.jcr2spi.nodetype.BitsetENTCacheImpl.getBitNumber(QName) invokes inefficient Integer(int) constructor; use Integer.valueOf(int) instead\tsrc/main/java/org/apache/jackrabbit/jcr2spi/nodetype\tBitsetENTCacheImpl.java\tline 177\t1190981544656\t1666284\nM P Bx: Method org.apache.jackrabbit.jcr2spi.query.RowIteratorImpl$RowImpl.getValue(String) invokes inefficient Integer(int) constructor; use Integer.valueOf(int) instead\tsrc/main/java/org/apache/jackrabbit/jcr2spi/query\tRowIteratorImpl.java\tline 247\t1190981544671\t1666292\nM P Bx: Method org.apache.jackrabbit.jcr2spi.WorkspaceManager.onEventReceived(EventBundle[], InternalEventListener[]) invokes inefficient Integer(int) constructor; use Integer.valueOf(int) instead\tsrc/main/java/org/apache/jackrabbit/jcr2spi\tWorkspaceManager.java\tline 616\t1190981544640\t1666279\nM P WMI: Method org.apache.jackrabbit.jcr2spi.name.NamespaceCache.syncNamespaces(Map) makes inefficient use of keySet iterator instead of entrySet iterator\tsrc/main/java/org/apache/jackrabbit/jcr2spi/name\tNamespaceCache.java\tline 193\t1190981544656\t1666283\nM P WMI: Method org.apache.jackrabbit.jcr2spi.nodetype.NodeTypeRegistryImpl.internalRegister(Map) makes inefficient use of keySet iterator instead of entrySet iterator\tsrc/main/java/org/apache/jackrabbit/jcr2spi/nodetype\tNodeTypeRegistryImpl.java\tline 524\t1190981544656\t1666285\nM P WMI: Method org.apache.jackrabbit.jcr2spi.observation.ObservationManagerImpl.onEvent(EventBundle) makes inefficient use of keySet iterator instead of entrySet iterator\tsrc/main/java/org/apache/jackrabbit/jcr2spi/observation\tObservationManagerImpl.java\tline 189\t1190981544656\t1666286\nM P WMI: Method org.apache.jackrabbit.jcr2spi.state.NodeState.persisted(ChangeLog) makes inefficient use of keySet iterator instead of entrySet iterator\tsrc/main/java/org/apache/jackrabbit/jcr2spi/state\tNodeState.java\tline 275\t1190981544671\t1666297\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2522",
        "summary": "unable to workspace import XML.",
        "description": "tika detects xml as \"application/xml\" thus breaking the org.apache.jackrabbit.server.io.XmlHandler\nwhich just checks for \"text/xml\".",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-25",
        "summary": "default value with autocreated fields like null",
        "description": "I have a custom nodetype which has two properties, both autocreated (but not mandatory).\nIf I create the node and want to read the first property (not filling in any value), I get a:\n\njavax.jcr.RepositoryException: Unable to get value of /pages/mjo:page/jcr:content/mjo:title:java.lang.ArrayIndexOutOfBoundsException: 0\n at org.apache.jackrabbit.core.PropertyImpl.getValue(PropertyImpl.java:378)\n at de.freaquac.test.JCRTest.propIterator(JCRTest.java:207)\n\nAfter setting the property the exception is no longer thrown. Not sure if this really an error but is a little bit anyoing. Are there any default values (null) in jsr170?",
        "label": "BUG",
        "classified": "BUG",
        "type": ""
    },
    {
        "key": "JCR-95",
        "summary": "Build instructions for contributions",
        "description": "Add READMEs in order to instruct how the contribution projects can ne built",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2613",
        "summary": "NoSuchItemStateException on checkin after removeVersion in XA Environment",
        "description": "After removing a version, a checkin on the same node in a different transaction (with a different session) fails.\nThe NoSuchItemStateException refer to the uuid of the previously removed version. \nI'll attach a test demonstrating the problem. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1104",
        "summary": "JSR 283 support",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2926",
        "summary": "DefaultProtectedPropertyImporter masks several fields from parent, causing potential derived classes to not perform correctly",
        "description": "The fields session, resolver, and referenceTracker are duplicated in DefaultProtectedPropertyImporter from DefaultProtectedItemImporter, and thus future derived classes will not function correctly if they attempt to use those fields, as they will be null.\n\nI Plan to remove them from DefaultProtectedPropertyImporter",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-694",
        "summary": "Remove query handler idleTime",
        "description": "The changes included in JCR-415 revealed a synchronization issue with the query handler idle timer task.\n\nSee thread on dev-list: http://thread.gmane.org/gmane.comp.apache.jackrabbit.devel/10199\n\nWe could either fix the synchronization issue in the SearchManager class or remove the functionality all together.\n\nBecause the repository also supports a idle time parameter for the whole workspace (maxIdleTime in Workspaces element) the query handler idle time should be removed.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-17",
        "summary": "Creating and saving a mix:versionable node creates two VersionHistory nodes",
        "description": "Steps:\n   - Create a new mix:versionable node\n      [ This creates a new VersionHistory node below jcr:persistentVersionStore\n        and sets the new node's versionHistory property to the UUID of this\n        VersionHistory node. ]\n   - Save the session (or alternatively save the parent of the new node)\n      [ This creates a new VersionHistory node below jcr:persistentVersionStore\n        and sets the node's versionHistory property to the UUID of this\n        VersionHistory node. ]\n\nAs you can see, you end up with two VersionHistory nodes for the same node, of which the first VersionHistory node is never used again, because the second VersionHistory node is used from now on.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2482",
        "summary": "Reduce number of compiler warning by adding @Override and generics where appropriate ",
        "description": "Add @Override and generics where possible to reduce the number of warnings issued by the compiler.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1570",
        "summary": "[PATCH] better exception messages when generating schema",
        "description": "When a statement fails to execute generating the schema, patch outputs the statement that failed.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-876",
        "summary": "ManageableCollectionUtil should not throw \"unsupported\" JcrMapping exception",
        "description": "Many times, the object model'd code cannot be altered for ocm.\n\nTo avoid the \"unsupported\" exception in almost all such cases, use a delegating wrapper class to encapsulate a Collection.    The wrapper class implements MaangeableCollection.\n\nSince delegation is a performance hit, make the test below the last resort for *object*  conversion in the method:\npublic static ManageableCollection getManageableCollection(Object object) \n\nProposed \"catchall\" test and program action:\n\n            if (object instanceof Collection) {\n                return new ManageableCollectionImpl((Collection)object);\n            }\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1962",
        "summary": "web.xml refers to 2.2 dtd",
        "description": "the web.xml present in the jackrabbit-webapp project contains the following doctype:\n\n<!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/j2ee/dtds/web-app_2_2.dtd\">\n\nwhat is probably meant is\n\n<!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\">\n\nsince the dependency also points to version 2.3 of the servlet-api\n\nif nobody objects, i will adjust it accordingly.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "JCR-1672",
        "summary": "Adding Event interface and isLocal()",
        "description": "when a repository cluster is used, it seems that a common problem many people have is to detect if an observation event is send because of changes on the local instance or a remote instance of the cluster.\n\nThis is especially important if you want to do post processing of data\nbased on observation (the post processing should only be done by one instance in the cluster).\n\nA current solution is to cast the jcr event object to the EventImpl of jackrabbit core which is obviously not a nice solution :)\n\nSo what about adding an event interface to jackrabbit api which extends the jcr event interface and adds the isLocal() method? ",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-106",
        "summary": "Minimize use of fields in lucene index",
        "description": "Currently every property name creates a field in the lucene index, bloating the size of the index because of the norm files created for each field.\n\nWhen values are indexed as is (not tokenized for fulltext indexing), then the property name may be part of the term text. That way lucene must only maintain one field for all property names. With this approach the search terms are always a combination of property name and literal value. e.g. instead of using TermQuery(new Term(\"prop\", \"foo\")) the query must be TermQuery(new TermQuery(\"common-field\", \"prop:foo\")). this works for general comparison / value comparison operators and also for the like function. the contains function uses the fulltext index which uses a different field anyway.\n\nUsing the property name as part of the indexed term text, requires a custom SortComparator which is aware of the property name.\n\nThis change will not be backward compatible with earlier indexes created by jackrabbit.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2967",
        "summary": "SessionItemStateManager.getIdOfRootTransientNodeState() may cause NPE",
        "description": "regression of JCR-2425\n\nin certain scenarios, calling SessionItemStateManager.getIdOfRootTransientNodeState() may cause a NPE.\n\nTest case: \n\n        Repository repository = new TransientRepository(); \n        Session session = repository.login( \n                new SimpleCredentials(\"admin\", \"admin\".toCharArray())); \n        Session session2 = repository.login( \n                new SimpleCredentials(\"admin\", \"admin\".toCharArray())); \n\n        try { \n            while (session.getRootNode().hasNode(\"test\")) { \n                session.getRootNode().getNode(\"test\").remove(); \n            } \n            Node test = session.getRootNode().addNode(\"test\"); \n            session.save(); \n            Node x = test.addNode(\"x\"); \n            session.save(); \n\n            Node x2 = session2.getRootNode().getNode(\"test\").getNode(\"x\"); \n            x2.remove(); \n            x.addNode(\"b\"); \n            session2.save(); \n            session.save(); // throws NPE \n        } finally { \n            session.logout(); \n            session2.logout(); \n        }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-674",
        "summary": "String properties with invalid XML characters export as invalid XML",
        "description": "As noted in the current JCR 1.0.1 maintenance draft, sections 6.4.1,\n6.4.2.6, XML export of string properties that contain invalid XML\ncharacters isn't well-defined currently, since those characters are\nnot permissible in XML.  The proposed fix is to use base64\nencoding for such values in System View.\n\nMost characters below #x20 are examples of this.  Currently, these\nare escaped numerically in output (such as (amp)#0; )  but\nsuch escape sequences can't be parsed by the XML\nimport methods.\n\nThe current behavior is particularly problematic, because the user\ndoesn't know the output is corrupt until later, when they try to import it\nand get InvalidSerializedDataException.\n\nIf for some reason the base64 option is delayed, it might\nmake sense, as an interim solution, to fail on export\nor to somehow patch import to relax its parsing and allow\nthese escape codes.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-760",
        "summary": "Default blob size for mysql ddl too small",
        "description": "the default datatype for:\nNODE.NODE_DATA\nPROP.PROP_DATA\nREFS.REFS_DATA \nin the mysql ddl is \"BLOB\" which is pretty small to the default size in other dbs.\n\nWhen playing with a (not very large) jackrabbit repo using mysql for persistence I easily got data truncation errors on both NODE.NODE_DATA and PROP.PROP_DATA columns. The same issue has been reported in the past by other users.\nAlthough anyone could easily create a custom ddl with larger fields it should be nice to increase the blob size in the mysql ddl embedded in jackrabbit, in order to avoid this kind of problems for new users (you usually learn this the hard way, when the number of nodes in your repository starts to grow and jackrabbit start throwing errors :/).\nChanging BLOB to MEDIUMBLOB will make the default size for mysql more similar to the one in other dbs, without critically increasing the used space...\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1357",
        "summary": "Create \"quick start\" developer bundles for model 1,2,3 deployment",
        "description": "Please create \"quick start\" developer bundles for deployment models 1,2,3 with all dependance libs and application startup code. Some kind of \"Hello, world\" app on models 1,2,3.\nTomcat and jetty bundles would be nice.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2178",
        "summary": "Test must not fail if mixin cannot be added",
        "description": "Nearly all mixin types are optional and a test must not fail if a mixin cannot be added. It should rather throw a NotExecutableException. Some tests still try to add a mixin without checking whether an implementation supports it.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1531",
        "summary": "[PATCH] Add Column and line numbers to repository.xml parse exception messages",
        "description": "Code caught SAXExceptions when the an xml parsing exception occurred parsing the repository.xml. But catching SAXParseException (a subclass) allows access to column and line numbers of the problem. So also catch this exception and add this to the exception message to make it easier to fix errors.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-80",
        "summary": "AbstractQueryTest.evaluateResultOrder() should fail if workspace does not contain enough content",
        "description": "The method AbstractQueryTest.evaluateResultOrder() currently throws a NotExecutableException if the workspace contains less than two nodes that can be used for ordering. It should rather fail with an error message telling that the workspace does not contain sufficient content to run the test.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-851",
        "summary": "Handling of binary properties (streams) in QValue interface",
        "description": "The current SPI requires QValue to return new streams upon each call to getStream(). As far as I can tell, this essentially requires a QValue implementation to preserve the whole content of a stream, be it in memory or on disk.\n\nIn particular (and unless I'm missing something), when importing large content into a repository, this causes the whole data stream to be written twice. We really should try to avoid that.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-178",
        "summary": "Allow concurrent index updates and queries",
        "description": "Currently the query handler either allows one modification or multiple queries at a time. That is, write operations are separated from read operations. With this synchronization scheme multiple queries may run concurrently, but only in the absence of a write operation.\n\nThere is one major drawback with this synchronization: a single long running query is able to block the whole workspace from committing changes. Because the query handler is coupled to the Workspace via a synchronous event listener, further processing is blocked until the query handler has finished its event processing (reflecting the changes in the index).\n\nInstead, each index modification should be non-blocking, in the sense that an index modification should not have to wait for any queries to complete.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2214",
        "summary": "Avoid string concatenation in AbstractBundlePersistenceManager",
        "description": "The following line:\n\n        log.debug(\"stored bundle \" + bundle.getId());\n\nshould be changed to:\n\n        log.debug(\"stored bundle {}\", bundle.getId());\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1728",
        "summary": "Observation logs error when a node is moved in place",
        "description": "An error message is written to the log when the following sequence of operations is executed:\n\n- create node 'parent'\n- create node 'child' as a child of 'parent'\n- save\n- create node 'tmp'\n- move 'child' under 'tmp'\n- remove 'parent'\n- move 'tmp' to former path of 'parent'\n\nThe log will say: EventStateCollection: Unable to calculate old path of moved node\n\nThis is because the zombie path of 'child' is equal to the new path after the move. The EventStateCollection detects a new parentId assigned to 'child' and expects a new path that is different from the zombie path. The above case however shows that there is a use case where the paths are equal and events should be generated.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1032",
        "summary": "Clean caches in node type registry on session logout",
        "description": "When running the JCR tests the memory consumption increases steadily. At the end of the test run it consumes about 300 Mb on my machine. There's not really a memory leak in jcr2spi, because the JUnit tests keep references to Session and Node instances until the end of the test run, but  it would be nice if those instances were a bit more lightweight.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1034",
        "summary": "Unable to save session after saving a renamed node",
        "description": "\t\tTransientRepository repo = new TransientRepository(\n\t\t\t\t\"applications/test/repository.xml\", \"applications/test\");\n\t\tSession s = repo.login(new SimpleCredentials(\"test\", \"\".toCharArray()));\n\n\t\tif (s.getRootNode().hasNode(\"parent\")) {\n\t\t\ts.getRootNode().getNode(\"parent\").remove();\n\t\t\ts.save();\n\t\t}\n\n\t\t// create parent node\n\t\tNode parent = s.getRootNode().addNode(\"parent\");\n\t\t\n\t\t// create node to rename\n\t\tparent.addNode(\"newnode\");\n\t\ts.save();\n\n\t\t// rename node\n\t\ts.move(\"/parent/newnode\", \"/parent/renamedNewNode\");\n\n\t\t// save renamed node\n\t\ts.getRootNode().getNode(\"parent/renamedNewNode\").save();\n\n\t\t// try to save session --> FAILS\n\t\ts.save();\n\n\t\ts.logout();",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3178",
        "summary": "Improve error messages for index aggregates",
        "description": "In the case where an index aggregate fails because of a node that doesn't exist the logged warn messages contain a full stack-trace.\nBesides the fact that this can be misleading (you may think that there's something wrong that you need to fix right away) it is also borderline useless.\n\nThe desired behavior would be to just log an \"info\" message mentioning that a certain node was skipped, similar to what the SeachManager does.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2143",
        "summary": "Registering a Nodetype based on an existing NodeType fail",
        "description": "If I create a new NodeTypeTemplate using the code show below,\n\n           NodeTypeManagerImpl ntm = (NodeTypeManagerImpl) session.getWorkspace().getNodeTypeManager();\n           NodeTypeDefinition nt = (NodeTypeDefinition) ntm.getNodeType(\"wr:entity\");\n           NodeTypeTemplate ntt = ntm.createNodeTypeTemplate(nt);\n\nthe list of declaredSuperType contains the same name of the original nodeType (repeted twice) and not the declaredSuperType of the original nodeType (in this example [nt:base, nt:file])\n\n          ntt.getDeclaredSupertypeNames(); -> [wr:entity, wr:entity]",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1364",
        "summary": "DirListingExportHandler: Should not implement PropertyHandler",
        "description": "issue found by Roland Porath:\n\nif the DirListingExportHandler is used with some other collection nodetype that nt:folder (that may allow other properties) the list of dav properties obtained upon PROPFIND (being delegated to PropertyHandler) results in an imcomplete list.\n\nsince the only benefit of the DirListingExportHandler is to display something nice(?) upon a GET to a folder, i'd suggest to remove the implementation of PropertyHandler from the DirListingExportHandler.\n\nangela",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "BUG"
    },
    {
        "key": "JCR-142",
        "summary": "allow subclassing of NodeTypeReader",
        "description": "in working towards an offline tool to import custom namespaces and node types, i found that i needed to make some small changes to NodeTypeReader and DOMWalker so that i could subclass NodeTypeReader and access the namespaces specified in the node type definition file. see the attached patch.\n",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1061",
        "summary": "Allow extendability of RepositoryImpl.WorkspaceInfo",
        "description": "the workspace info has some package private and some protected methods. in order to be able to extend the workspace info, we need to have all methods protected.",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1151",
        "summary": "avoid converting property values to strings",
        "description": "QValues currently can not expose properties of types LONG and DOUBLE in a parsed format. Thus, setting/retrieving properties of these types requires roundtripping through Strings, which we should avoid.\n\nProposal:\n\n1) Add \"long getLong()\" and \"double getDouble()\" to QValue.\n\n2) Add matching create methods to QValueFactory.\n\n3) Take advantage of the new methods in JCR2SPI, for instance by allowing it's own Value implementation to internally just hold the QValue.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-238",
        "summary": "workspace.copy causes 2 nodes in the same workspace to have the same version history",
        "description": "workspace.copy creates a copy of a versionable node with a new uuid which share the same version. \"In a given workspace, there is at most one versionable node per version history\" (4.11 spec)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-456",
        "summary": "maven 2 poms contain variables in dependency versions that are never resolved, breaking transitive dependency resolution",
        "description": "There are problems with the dependencies declared in jackrabbit-server-1.0 and other poms using variables for dependency versions. These variables are never resolved and break the transitive resolution of these dependencies",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-2280",
        "summary": "Lazy initialize ItemDefinition",
        "description": "The item definition is currently set immediately when an ItemData is instantiated. Accessing nodes usually does not require reading the item definition, thus it is not necessary to load/set it that early.\n\nLazy initialization also has the benefit that content migration in an upgrade scenario becomes easier. Instead of throwing an exception early, jackrabbit could allow access to the item until an item definition is really required for the operation.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-987",
        "summary": "Deploy JCA JAR file to maven repository",
        "description": "Please deploy the JCA JAR file to the maven repository (ibiblio) whenever deploying the RAR artifact.\n\nThe JAR is need for non managed usage of the Jackrabbit JCA, eg. for embedding the resource adapter in your application with Spring JCA in order to use XA for Jackrabbit.\n\nIt would be nice if this could be done starting at the current 1.3 version (and for future versions, too).\n\nThanks!",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1956",
        "summary": "Database Data Store: close result sets",
        "description": "The database data store doesn't close one result sets. This is not a problem for most databases, but anyway should be fixed.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-711",
        "summary": "Select * does not return declared properties of node type in FROM clause",
        "description": "The query only returns the default columns: jcr:primaryType, jcr:score and jcr:path",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1079",
        "summary": "Extend the IndexingConfiguration to allow configuration of reuseable analyzers",
        "description": "To the indexing_configuration.xml a xml block of analyzers should be configurable. In each <index-rule> to a property an analyzer can be assigned. This means, that property will be analyzed with that specific analyzer. In the first place, it enables multilingual indexing. \n\nDocumentation needs to be added explaining the difference in searching in the node scope [jcr:contains(.,'foo')] and in some property [jcr:contains(@myprop,'foo')]. The node scope will always be searched and indexed with the default analyzer, which can be configured in the workspace.xml in  the  <SearchIndex> element.\n\nBelow a possible indexing_configuration.xml snippet is shown. Also node the possible enhancement (not sure wether this implementation will have it, because it requires a lot of filter Factories and is probably out of scope). Adding custom filters which do not need a factory might be easier.\n\n<analyzers>\n\t<analyzer name=\"fr\" class=\"org.apache.lucene.analysis.fr.FrenchAnalyzer\"/>\n\t<analyzer name=\"de\" class=\"org.apache.lucene.analysis.de.GermanAnalyzer\"/>\n        <analyzer name=\"compound\" class=\"org.apache.lucene.analysis.SimpleAnalyzer\">\n             <filter class=\"jr.StopFilterFactory\" words=\"stopwords.txt\"/>\n             <filter class=\"jr.EdgeNGramTokenizerFactory\" side=\"front\" minGram=\"1\" maxGram=\"2\"/>\n        </analyzer>\n</analyzers>\n\n<index-rule nodeType=\"nt:unstructured\">\n       <property analyzer=\"fr\">bode_fr</property>\n       <property analyzer=\"de\">bode_de</property>\n</index-rule>",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2971",
        "summary": "Revert subsequent token-node updates (tentatively introduced)",
        "description": "i would like to revert this improvement has been tentatively introduced based on the following\nthread on the dev list: http://www.mail-archive.com/dev@jackrabbit.apache.org/msg24437.html\nas i am still concerned about undesired effects. in addition i still feel that this somehow\nviolates the basic contract.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-193",
        "summary": "MultiStatus response for PROPPATCH (copied from JCR-175)",
        "description": "Rob Owen commented on JCR-175:\n--------------------------------------------------\n\ndoPropPatch in AbstractWebdavServlet still needs to send back a multistatus (207) response even in the successful case.\n\nI didn't see a way to collect the success/failure status for each property, but instead created a multistatus response and added a propstat (SC_OK) for each of the properties in the setProperties and removeProperties. This allowed a WebDAV client, which expected a multistatus response from PROPPATCH, to work correctly with jcr-server. In the more general case the actual property status code will need to be used .",
        "label": "NUG",
        "classified": "SPEC",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2180",
        "summary": "Use the assembly plugin for packaging -tests jars",
        "description": "The spi and jcr2spi components have test code that currently packaged using the jar:test-jar goal and used as a test dependency by other components.\n\nThe extra jar plugin invocation creates extra Maven build numbers and causes problems for snapshot dependencies from the repository.apache.org repository that we recently started using. Using the assembly plugin to create the test jars should avoid this problem.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1114",
        "summary": "Remove QueryResultImpl and rename LazyQueryResultImpl to QueryResultImpl",
        "description": "QueryResultImpl isn't used in Jackrabbit anymore. Instead LazyQueryResultImpl is now used. See the discussion in JCR-1073.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2750",
        "summary": "MultiStatusResponse should not call resource.getProperties",
        "description": "current constructor MultiStatusResponse() calls resource.getProperties() even if propFindType == PROPFIND_BY_PROPERTY.\n\nThis is inconvenient, because some properties are expensive to generate if they are not requested. MultiStatusResponse() constructor with parameter PROPFIND_BY_PROPERTY should do:\n\n===\nif (propFindType == PROPFIND_BY_PROPERTY) {\n  for (propName : propNameSet) {\n    prop = resource.getProperty(propName);\n    if (prop != null)\n      status200.addContent(prop);\n    else\n      status404.addContent(propName);\n  }\n} else {\n  ...\n}\n===",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-573",
        "summary": "Add missing license headers",
        "description": "There are a few source files and a number of other files with missing or incorrect license headers within the Jackrabbit source tree. See the  discusssion at http://thread.gmane.org/gmane.comp.apache.jackrabbit.devel/8698 for details. The missing license headers need to be added. \n\nThere are also W3C licensed files. This needs to be mentioned in the NOTICE file.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "TASK"
    },
    {
        "key": "JCR-2435",
        "summary": "[patch] Fix overly specific casting in core",
        "description": "several places in core, casts are made to overly concrete classes when, interfaces are only needed. Doing so ties the algorithms to specific implementations, unnecessarily. patch fixes these.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-461",
        "summary": "ManagedConnection#cleanup doesn't refresh the session",
        "description": "the ManagedConnection is not cleaned up correctly. I think that the underlying jcr Session should be refreshed by calling\nSession#refresh(false) at JCAManagedConnection#cleanup. In the current implementation a new Session see the changes stored in the transient level of a closed session",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1612",
        "summary": "Reintroduce NamespaceStorage",
        "description": "hi jukka\n\ni open this issue as a reminder of our recent discussion in basel:\n\nwe decided that you will \n- reintroduce the NamespaceStorage you recently removed from jcr2spi\n- reintroduce a namespace cache in jcr2spi (but using a simple map instead of NamespaceCache object)\n\nin addition we agreed that we want to share the NamespaceRegistryImpl between jcr2spi and jackrabbit-core\nand you volenteered to provide a patch for that.\n\nthanks in advance\nangela",
        "label": "NUG",
        "classified": "BACKPORT",
        "type": "BUG"
    },
    {
        "key": "JCR-3255",
        "summary": "Access cluster node id",
        "description": "I need to know the cluster node id in my application. I didn't find any other way than to cast to org.apache.jackrabbit.core.RepositoryImpl : ((RepositoryImpl) session.getRepository()).getConfig().getClusterConfig().getId()\n\nI would appreciate it if I could get to this using the system property ClusterNode.SYSTEM_PROPERTY_NODE_ID.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2006",
        "summary": "References to old repository-1.x.dtd",
        "description": "Some components still reference old version of the repository-1.x.dtd.\nAll components should be upgraded to repository-1.6.dtd",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1910",
        "summary": "RMIRemoteBindingServlet fails to initialize if the RMI registry is not available",
        "description": "If the RMI registry is not available, the RMIRemoteBindingServlet in jcr-rmi will throw an exception in the init() method and prevent the servlet from being loaded.\n\nThe same servlet can however also be mapped to the normal HTTP URL space as an alternative mechanism of making the RMI endpoint available to clients. Thus it would be better if the init() method just logged a warning instead of failing completely.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2598",
        "summary": "Saving concurrent sessions executing random operations causes a corrupt JCR",
        "description": "Run the attached unit test. Several concurrent sessions add, move, and remove nodes. Then the index is removed and the repository is again started. The repository is in an inconsistent state and the index cannot be rebuild. Also a lot of exceptions occur. See (see Output before patch.txt). Note that the unit test also suffers from the deadlock of issue http://issues.apache.org/jira/browse/JCR-2525 about half the time.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2587",
        "summary": "Coarser granularity of node type unregistration notifications",
        "description": "When unregistering multiple node types at a time, the internal notification methods are called separately for each type. This causes some problems as the first notifications triggers the regeneration of the full virtual node type tree, and later notification calls will fail (logging an error) in VirtualNodeTypeStateManager because the removed type is no longer there. A better approach would be to send the names of all the unregistered node types as a collection.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1557",
        "summary": "Avoid exceptions during shutting repository down if several PMs/FSs use same DB",
        "description": "According to docs and forum discussions, it's legal to use same DB for different FileSystems/Persistence Managers. Such configurations seem to work fine, but when repository is stopped, exceptions are produced like following:\n\nSEVERE: Error while closing Version Manager.\njava.sql.SQLNonTransientConnectionException: No current connection.\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.getMetaData(Unknown Source)\n\tat org.apache.jackrabbit.core.persistence.db.DerbyPersistenceManager.closeConnection(DerbyPersistenceManager.java:109)\n\tat org.apache.jackrabbit.core.persistence.db.DatabasePersistenceManager.close(DatabasePersistenceManager.java:261)\n\tat org.apache.jackrabbit.core.version.VersionManagerImpl.close(VersionManagerImpl.java:201)\n\tat org.apache.jackrabbit.core.RepositoryImpl.doShutdown(RepositoryImpl.java:1000)\n\tat org.apache.jackrabbit.core.RepositoryImpl.shutdown(RepositoryImpl.java:948)\n\tat org.apache.jackrabbit.core.TransientRepository.stopRepository(TransientRepository.java:275)\n\tat org.apache.jackrabbit.core.TransientRepository.loggedOut(TransientRepository.java:427)\n\tat org.apache.jackrabbit.core.SessionImpl.notifyLoggedOut(SessionImpl.java:574)\n\tat org.apache.jackrabbit.core.SessionImpl.logout(SessionImpl.java:1247)\n\tat org.apache.jackrabbit.core.XASessionImpl.logout(XASessionImpl.java:403)\n\tat com.blandware.tooling.jcrplugin.ExportMojo.execute(ExportMojo.java:81)\n\tat org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:447)\n\tat org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:539)\n\tat org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeStandaloneGoal(DefaultLifecycleExecutor.java:493)\n\tat org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:463)\n\tat org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:311)\n\tat org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:278)\n\tat org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:143)\n\tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:333)\n\tat org.apache.maven.DefaultMaven.execute(DefaultMaven.java:126)\n\tat org.apache.maven.cli.MavenCli.main(MavenCli.java:282)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315)\n\tat org.codehaus.classworlds.Launcher.launch(Launcher.java:255)\n\tat org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430)\n\tat org.codehaus.classworlds.Launcher.main(Launcher.java:375)\nCaused by: java.sql.SQLException: No current connection.\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)\n\t... 35 more\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3234",
        "summary": "QueryStat getPopularQueries doesn't set the proper position",
        "description": "Embarrassing copy/paste error. I was updating the wrong array and the position info was never returned. \n\nThis made any jmx client to fail with: \nat javax.management.openmbean.TabularDataSupport.checkValueAndIndex(TabularDataSupport.java:871) \nat javax.management.openmbean.TabularDataSupport.internalPut(TabularDataSupport.java:331) \nat javax.management.openmbean.TabularDataSupport.put(TabularDataSupport.java:323) \nat org.apache.jackrabbit.core.jmx.QueryStatManager.asTabularData(QueryStatManager.java:103)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1362",
        "summary": "DatabaseJournal improperly finds tables in external schemas when used on Oracle",
        "description": "The DatabaseJournal currently calls database metadata to determine if the journal table has already been created.  It uses the following code to do so:\n\nResultSet rs = metaData.getTables(null, null, tableName, null);\n\nThe Oracle driver sometimes will return the table if it is in another schema on the same database.  Other DBMS code within JackRabbit has a specific Oracle version that handles this case.  In order for the journal table to be properly created, Oracle databases will need the schema name included in the getTables() call.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1298",
        "summary": "Wrong schemaObjectPrefix parameter in default repository.xml",
        "description": "The object schema prefix is hard-coded in the default configuration file (I think this taken from the jackrabbit-core.jar):\n\n        <PersistenceManager class=\"org.apache.jackrabbit.core.persistence.bundle.DerbyPersistenceManager\">\n          <param name=\"url\" value=\"jdbc:derby:${wsp.home}/db;create=true\"/>\n          <param name=\"schemaObjectPrefix\" value=\"Jackrabbit Core_\"/>\n        </PersistenceManager>\n\nThis is probably caused by JCR-945, though I've no idea why ${wsp.name} is replaced with the name of the module...\n\nI have marked this issue as minor because it still works with the DerbyPersistenceManager. There are separate database instances for each workspace, but it will become a problem if a data base persistence manager on a dedicated server is used.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "JCR-2808",
        "summary": "Hop 0 sample app doesn't exit because of on-daemon thread pool-1-thread-1",
        "description": "When starting the sample app Hop 0 (or any other Hop sample app) if there is no \"repository\" directory, then the application doesn't exit because there is a non-daemon thread named \"pool-1-thread-1\".",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1138",
        "summary": "Data store garbage collection",
        "description": "Currently the data store garbage collection needs to be run manually. It should be simpler to use (maybe tool based), or automatic.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1793",
        "summary": "Namespace handling in AbstractSession should be synchronized",
        "description": "The AbstractSession base class in o.a.j.commons implicitly assume that the session is never accessed concurrently from more than one thread and thus doesn't synchronize access to the namespace map. This causes problems when the session *is* accessed concurrently. Instead of relying on client code we should enforce thread-safety by explicitly synchronizing potentially unsafe operations on the session instance.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3261",
        "summary": "Problems with BundleDbPersistenceManager getAllNodeIds",
        "description": "When using MySQL:\nThe problem arises when the method parameter maxcount is less than the total amount of records in the bundle table.\n\nFirst of all I found out that mysql orders the nodeid objects different than jackrabbit does. The following test describes this idea:\n\n    public void testMySQLOrderByNodeId() throws Exception {\n        NodeId nodeId1 = new NodeId(\"7ff9e87c-f87f-4d35-9d61-2e298e56ac37\");\n        NodeId nodeId2 = new NodeId(\"9fd0d452-b5d0-426b-8a0f-bef830ba0495\");\n\n        PreparedStatement stmt = connection.prepareStatement(\"SELECT NODE_ID FROM DEFAULT_BUNDLE WHERE NODE_ID = ? OR NODE_ID = ? ORDER BY NODE_ID\");\n\n        Object[] params = new Object[] { nodeId1.getRawBytes(), nodeId2.getRawBytes() };\n        stmt.setObject(1, params[0]);\n        stmt.setObject(2, params[1]);\n\n        ArrayList<NodeId> nodeIds = new ArrayList<NodeId>();\n        ResultSet resultSet = stmt.executeQuery();\n        while(resultSet.next()) {\n            NodeId nodeId = new NodeId(resultSet.getBytes(1));\n            System.out.println(nodeId);\n            nodeIds.add(nodeId);\n        }\n        Collections.sort(nodeIds);\n        for (NodeId nodeId : nodeIds) {\n            System.out.println(nodeId);\n        }\n    }\n\nWhich results in the following output:\n\n7ff9e87c-f87f-4d35-9d61-2e298e56ac37\n9fd0d452-b5d0-426b-8a0f-bef830ba0495\n9fd0d452-b5d0-426b-8a0f-bef830ba0495\n7ff9e87c-f87f-4d35-9d61-2e298e56ac37\n\n\nNow the problem with the getAllNodeIds method is that it fetches an extra 10 records on top of maxcount (to avoid a problem where the first key is not the one you that is wanted). Afterwards it skips a number of records again, this time using nodeid.compareto. This compareto statement returns true unexpectedly for mysql because the code doesn't expect the mysql ordering.\n\nI had the situation where I had about 17000 records in the bundle table but consecutively getting the ids a thousand records at a time returned only about 8000 records in all.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1204",
        "summary": "Redesign SPI observation",
        "description": "With the current SPI observation design it may happen that events are lost while the filter for an event listener is changed.\n\nSee:\n- http://www.nabble.com/SPI-observation%3A-EventFilter-lifecycle-tf4732281.html\n- http://people.apache.org/~mreutegg/spi-event/problem.png\n\nMy proposal is to introduce a Subscription interface. See attached patch and:\nhttp://people.apache.org/~mreutegg/spi-event/proposal.png",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2772",
        "summary": "replacing an extended mixin with it's supertype is problematic",
        "description": "node.addMixin() / node.removeMixin() have some checks to avoid redundant mixin settings on a node and not only when the node is saved.\n\neg: have 2 mixins: mix:A and mix:AA where mix:AA > mix:A and a node (N with mix:AA) on it.\n\nthen, N.addMixin(mix:A)  has no effect, since it's regarded as redundant.  so you have to remove mix:AA first and then add mix:A.\nthere is the first problem when applying mixin types programmatically, just be sure to remove them first before adding new ones.\n\nthe 2nd problem occurs when mix:A has a mandatory property. then somehow when downgrading from mix:AA to mix:A, some information is lost, and a save call results in\n\nUnable to save node 'N': javax.jcr.nodetype.ConstraintViolationException: /test/A: mandatory property {}prop does not exist.\nyou need to \"touch\" the property, otherwise it will not work.\n\nso only this works:\n\nN.removeMixin(\"mix:AA\");\nN.addMixin(\"mix:A\");\nN.setProperty(\"prop\", N.getProperty(\"prop\").getValue());\nsession.save();\n\n\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-20",
        "summary": "Logging into a repository with a big version history takes a long time",
        "description": "Wenn a SessionImpl instance is created, the VersionManager.getVirtualItemStateProvider method is called. This method - amongst other things - loads the complete (!) version history into memory and walks through it to do some mapping.\n\nBesides taking a long time (near 1 minute just to get the version history through PersistentVersionManager.getVersionHistories()) mapping the version histories ultimately results in an \"OutOfMemoryError\".\n\nCurrently there are 768 version histories and this is only a very small fraction of the expected final number of version histories in my application",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-3253",
        "summary": "Set omit term freq positions flag on parent field in the index",
        "description": "The flag to omit term frequencies is set to true by default and it is not changed by any of the constructors on the Field class.\nWe don't use this info in the index anyway, so it is safe to remove it.\n\nThe index size gain for 130K nodes (3 leves, ~50 nodes per level) is around 150kb for a 30mb index.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1958",
        "summary": "Enhanced JCR remoting (extending webdav SPI impl, basic remoting servlet)",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-305",
        "summary": "provide option to automatically dispose idle workspaces",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1347",
        "summary": "Move Jackrabbit Query Parser from core to spi-commons",
        "description": "The query parser can be used outside jackrabbit-core, for instances in other repository implementations based on JCR2SPI.\n\nProposal:\n\n- move source and build infrastructure from o.a.j.core.query to o.a.j.spi.commons.query\n\n- switch over jackrabbit.core to use spi-commons for query\n\n- optimally, add specific test cases for the query tree generation. ",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2291",
        "summary": "Issues with compiled permissions of ACL provider",
        "description": "- should not use search for infrastructure checks\n- event listener never discarded.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2855",
        "summary": "Writers blocked forever when waiting on update operations  ",
        "description": "Thread 1 calls Session.save() and has a write lock.\n\nThread 2 is in XA prepare() and is waiting on thread 1 in FineGrainedISMLocking.acquireWriteLock().\n\nThread 1's save calls SharedItemStateManager.Update#end() and performs a write-lock downgrade to a read-lock, then (at the end of Update#end()) it calls readLock.release(). FineGrainedISMLocking.ReadLockImpl#release thinks activeWriterId is of the current transation and does not notify any writers (activeWriterId is not being reset on downgrade in what seems to be a related to JCR-2753).\nThread 1 waits forever.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1829",
        "summary": "PlainTextExtractor returns an empty reader when encoding is unsupported",
        "description": "PlainTextExtractor is failing to index text files.  Searching for content in text files is not coming back with results.\n\nOn the extractText(InputStream stream, String type, String encoding) method, the encoding is coming in as an empty string, and it throws the java.io.UnsupportedEncodingException at line 40 ( return new InputStreamReader(stream, encoding); ).\n\nmodifying the following statement fixes the problem:\nbefore:  if (encoding != null) {\nafter:  if (encoding != null && !encoding.equals(\"\")) {",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-585",
        "summary": "Create jackrabbit-api(.jar) and the respective jackrabbit-rmi extensions",
        "description": "currently some of the management functions not covered in jcr, like notetype management and workspace creation, are not exposed via any specific api and therfor not accessible via rmi.\n\ncreate a jackrabbit api and the respective rmi extension.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2734",
        "summary": "Inconsistencies in BitSetKey comparison",
        "description": "Hi,\n\nI encountered a problem with the BitsetENTCacheImpl and the BitsetKey comparisons. I have 3 bitsets A, B and C , defined as :\n\nA : bits 0,4,17,38,60,63 \nB : bits 4,17,38,52,59,60\nC : bits 0,17,38,60,61,63\n\nIf call BitsetKey.compareTo  method on each pair , i get : \n\nA < B\nB < C\nC < A\n\nwhich is not correct and leads to inconsistencies in the TreeSet.\n\nAll 2 bitsets are contained in one single word (max bit is 63). So, the method is comparing first the 32 MSB - which are enough in that case to compare the bits. But the problem is, that the difference between the 32 MSB of B and C is too big to fit in an integer : for B, we have 403701824 - for C , 2952790080 . The difference between both is 2549088256 (positive) , which is bigger than Integer.MAX_VALUE , and makes a  -1745879040 (negative) after casting to an int .\n\nIn order to fix that, the shift should either be bigger in order to fit a signed integer ( 33 instead of 32 ), or a simple -1 / 0 / +1 could be returned\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2055",
        "summary": "RepositoryStub implementation in jackrabbit-core",
        "description": "Currently setting up a Jackrabbit repository for use with the TCK is a relatively complex operation with a large repositoryStubImpl.properties file and lots of specially crafted test content and settings to worry about. This makes it hard to set up new TCK test instances with the various JCR and SPI layers we now have.\n\nTo simplify things I'd like to introduce a RepositoryStubImpl class and related configuration files inside src/main/java in jackrabbit-core.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1997",
        "summary": "Performance fix, when deserializing large jcr:binary in ValueHelper.deserialize()",
        "description": "While profiling import of large PDF files into Magnolia 3.6.3 (which uses Jackrabbit 1.4 as JCR repository) we had found that there is large CPU time spent on:\n\n\"http-8080-4\" daemon prio=6 tid=0x5569fc00 nid=0x6ec runnable [0x5712d000..0x5712fb14]\n   java.lang.Thread.State: RUNNABLE\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:260)\n\tat org.apache.jackrabbit.util.Base64.decode(Base64.java:269)\n\tat org.apache.jackrabbit.util.Base64.decode(Base64.java:184)\n\tat org.apache.jackrabbit.value.ValueHelper.deserialize(ValueHelper.java:759)\n\tat org.apache.jackrabbit.core.xml.BufferedStringValue.getValue(BufferedStringValue.java:258)\n\tat org.apache.jackrabbit.core.xml.PropInfo.apply(PropInfo.java:132)\n\nLooking into source code of Base64.decode it became obvious, that it writes each 1to3byte chunk into unbuffered FileOutputStream (thus calling OS kernel many times to write just few bytes) which causes lot of CPU usage without disk usage.\n\n\nProvided fix is quite trivial - just wrap FileOutputStream into BufferedOutputStream.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-2385",
        "summary": "webdav: nullpointer exception while getting the tikka detector ",
        "description": "seems to be introduced by https://issues.apache.org/jira/browse/JCR-2334\n\n05.11.2009 14:28:27 *MARK * servletengine: Servlet threw exception: \njava.lang.NullPointerException\n\tat org.apache.jackrabbit.server.io.DefaultHandler.detect(DefaultHandler.java:668)\n\tat org.apache.jackrabbit.server.io.XmlHandler.canExport(XmlHandler.java:152)\n\tat org.apache.jackrabbit.server.io.DefaultHandler.canExport(DefaultHandler.java:557)\n\tat org.apache.jackrabbit.server.io.PropertyManagerImpl.exportProperties(PropertyManagerImpl.java:58)\n\tat org.apache.jackrabbit.webdav.simple.DavResourceImpl.initProperties(DavResourceImpl.java:320)\n\tat org.apache.jackrabbit.webdav.simple.DeltaVResourceImpl.initProperties(DeltaVResourceImpl.java:248)\n\tat org.apache.jackrabbit.webdav.simple.VersionControlledResourceImpl.initProperties(VersionControlledResourceImpl.java:320)\n\tat org.apache.jackrabbit.webdav.simple.DavResourceImpl.getProperties(DavResourceImpl.java:300)\n\tat org.apache.jackrabbit.webdav.MultiStatusResponse.<init>(MultiStatusResponse.java:181)\n\tat org.apache.jackrabbit.webdav.MultiStatus.addResourceProperties(MultiStatus.java:62)\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.doPropFind(AbstractWebdavServlet.java:447)\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.execute(AbstractWebdavServlet.java:235)\n\tat com.day.crx.j2ee.CRXDavServlet.service(CRXDavServlet.java:76)\n\tat com.day.crx.j2ee.ResourceServlet.service(ResourceServlet.java:97)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n\tat com.day.j2ee.servletengine.ServletRuntimeEnvironment.service(ServletRuntimeEnvironment.java:228)\n\tat com.day.j2ee.servletengine.RequestDispatcherImpl.doFilter(RequestDispatcherImpl.java:315)\n\tat com.day.j2ee.servletengine.RequestDispatcherImpl.service(RequestDispatcherImpl.java:334)\n\tat com.day.j2ee.servletengine.RequestDispatcherImpl.service(RequestDispatcherImpl.java:378)\n\tat com.day.j2ee.servletengine.ServletHandlerImpl.execute(ServletHandlerImpl.java:313)\n\tat com.day.j2ee.servletengine.DefaultThreadPool$DequeueThread.run(DefaultThreadPool.java:134)\n\tat java.lang.Thread.run(Thread.java:613)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1823",
        "summary": "Repository.login throws IllegalStateException",
        "description": "Calling any login method on Repository instance, which has been shut down throws an IllegalStateException, which is caused by the RepositoryImpl.sanityCheck method.\n\nThis exception is unexpected by callers of the login method, which is specified to throw one of LoginException, NoSuchWorkspaceException and RepositoryException. In particular the spec says, that a RepositoryException is thrown \"if another error occurs\".\n\nSo I suggest to modify the RepositoryImpl.login(Credentials, String) as follows (patch against trunk):\n\nIndex: /usr/src/jackrabbit/trunk/jackrabbit-core/src/main/java/org/apache/jackrabbit/core/RepositoryImpl.java\n===================================================================\n--- /usr/src/jackrabbit/trunk/jackrabbit-core/src/main/java/org/apache/jackrabbit/core/RepositoryImpl.java\t(revision 706543)\n+++ /usr/src/jackrabbit/trunk/jackrabbit-core/src/main/java/org/apache/jackrabbit/core/RepositoryImpl.java\t(working copy)\n@@ -1358,6 +1358,8 @@\n         } catch (AccessDeniedException ade) {\n             // authenticated subject is not authorized for the specified workspace\n             throw new LoginException(\"Workspace access denied\", ade);\n+        } catch (RuntimeException re) {\n+            throw new RepositoryException(re.getMessage(), re);\n         } finally {\n             shutdownLock.readLock().release();\n         }\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2221",
        "summary": "Rename \"Version Managers\"",
        "description": "currently there is a VersionManager interface and VersionManagerImpl class that operate on the version storage.\nnew for JSR283, the is a javax.jcr.version.VersionManager and its implementation JcrVersionManager.\n\nin order to avoid confusion, i would like to rename the following classes:\n\no.a.j.core.version.VersionManager - > o.a.j.core.version.InternalVersionManager\no.a.j.core.version.VersionManagerImpl -> o.a.j.core.version.InternalVersionManagerImpl\no.a.j.core.version.AbstractVersionManager -> o.a.j.core.version.AbstractInternalVersionManager\no.a.j.core.version.XAVersionManager -> o.a.j.core.version.XAInternalVersionManager\n\no.a.j.core.version.JcrVersionManagerImpl -> o.a.j.core.version.VersionManagerImpl",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1664",
        "summary": "JNDI Referencable Issues",
        "description": "I'm questioning the use of Referencable in the BindableResource and BindableResourceFactory classes for the JNDI lookup process. Reason for this is because Referencable needs the Addrs to be in the EXACT order in order for it to be considered the same. (see http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/Reference.html#equals(java.lang.Object) )\n\nIn order for me to get the JNDI reference to be found correctly I had to change the BindableResource.getReference method to swap the order the StringReferences were added to match up what was being passed in by glassfish. This seems EXTREMELY fragile to me as I don't know what order, say JBoss, would pass the StringRefences in in the Reference object for the Factory method.\n\nAlso, another problem is that getReference is binding the class name to BindableRepository class implementation and not javax.jcr.Repository. This again causes them not to match if you follow the example on the wiki on setting up the JNDI reference and use javax.jcr.Repository as the type. This can either be fixed by changing the JNDI reference to use the BindableRepository class or the change the BindableRepository class to set that to the Repository interface. Not sure which would be considered 'better'\n\nI have a patch that fixes the first issue (at least for glassfish), but not the second. Again, this seems like a really 'breakable' setup right now and not sure what would be better to make sure this is avoided.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2800",
        "summary": "Implement search facility for users and groups",
        "description": "Implement a search facility for users and groups supporting:\n- search for users and/or groups with a certain property (value) either directly on the user/group node or on any of its sub nodes\n- full text search on user and/or group nodes and its sub nodes\n- inclusion/exclusion based on group membership: i.e. restricting search to members of a group or to groups with a certain member\n- ordering \n- paging",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1943",
        "summary": "jcr-tests: make property value(s) and property type(s) configurable",
        "description": "test-cases using Node.setProperty or Property.setValue mostly hardcode the value... there should be the possibility to specify type and value in the config.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1835",
        "summary": "Database Data Store: support database type 'mssql'",
        "description": "MS SQL Server is referred to with the schema name 'mssql' in the persistence managers and the cluster journal. For the DbDataStore it is called 'sqlserver'. This is not consistent.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-291",
        "summary": "jcr-server-webapp: RMI Registration unstable",
        "description": "Registration of the repository to a RMI registry in RepositoryStartupServlet.registerRMI uses web application parameters inconsistently and may not always succeed registering the repository.\n\nToday, the registerRMI uses these parameters for registration to RMI:\n\n    rmi-host : The name of the host on which the registry is running\n    rmi-port : The port on which the registry is running\n    rmi-uri : An RMI URI to use for registration\n    repository-name : The name to bind the repository to\n\nThe problem is, that rmi-port is used to try to create the registry to make sure a registry is running on the local host. The rmi-uri is used to register the repository using the static Naming.bind method. If the rmi-uri is not configured, the URI is created from rmi-host, rmi-port and repository-name.\n\nThis may now create a bunch of problems: If the rmi-port and rmi-uri configurations do not match, registration fails, if rmi-host does not resolve to an IP address to which the registry is bound, registration fails.\n\nI encounter this issue, when trying to register the repository to an RMI registry using default rmi-port configuration (rmi-host and rmi-uri not configured) when running the web app in Jetty.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2917",
        "summary": "Indexing configuration ignored when indexing length",
        "description": "The NodeIndexer does not respect the indexing configuration when it adds a field for the property length. NodeIndexer.addValue(Document doc, InternalValue value, Name name) should check it the property actually needs to be indexed.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-707",
        "summary": "Range queries fail on large repositories",
        "description": "As discussed on the user mailing list, queries on large repositories with date constraints like \"field > constant\" treat the constraint as always true, returning results that should not be returned.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-180",
        "summary": "allow ResourceType dav property to have multiple values",
        "description": "attached is a patch that allows the ResourceType dav property to have multiple values (useful for dav protocol extensions such as caldav). \n\nit is not a perfect patch, in that subclasses of ResourceType do not know about each others' resource types, but it is a decent start. one way to address this issue might be to have subclasses register extended resource types and their corresponding xml representations with ResourceType, removing the need for them to override resourceTypeToXml() and isValidResourceType().\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-619",
        "summary": "CacheManager (Memory Management in Jackrabbit)",
        "description": "Jackrabbit can run out of memory because the the combined size of the various caches is not managed. The biggest problem (for me) is the combined size of the o.a.j.core.state.MLRUItemStateCache caches. Each session seems to create a few (?) of those caches, and each one is limited to 4 MB by default.\n\nI have implemented a dynamic (cache-) memory management service that distributes a fixed amount of memory dynamically to all those caches.\n\nHere is the patch",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1398",
        "summary": "[PATCH] ClassDescriptor.hasIdField uses faulty logic",
        "description": "hasIdField tries to compare a FieldDescriptor to an empty string, which doesn't make sense, here:\n\n     public boolean hasIdField() {\n        return (this.idFieldDescriptor != null && ! this.idFieldDescriptor.equals(\"\"));\n     }\n\n\ni'm assuming it should be\n\n       return (this.idFieldDescriptor != null && this.idFieldDescriptor.isId());\n\npatch does this\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1368",
        "summary": "improve documentation of SPI Batch addProperty",
        "description": "Clarify that Batch.addProperty should succeed even though the property already exists.\n\n\n(See mailing list thread starting with: http://mail-archives.apache.org/mod_mbox/jackrabbit-dev/200801.mbox/%3c47A1E1C1.2050107@gmx.de%3e)",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1047",
        "summary": "Update link for javadocs from 1.0 to 1.3",
        "description": "On this page: http://jackrabbit.apache.org/doc/arch/overview/jcrlevels.html\n\nYou see this link:\nBrowse current Jackrabbit API: http://jackrabbit.apache.org/api-1/index.html\n\nThis should point to the latest javadoc version.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-2192",
        "summary": "handling of expanded-form jcr names by node type *Template classes ",
        "description": "ItemDefinitionTemplate treats the name as opque string, instead of a JCR Name.\n\nExample: when setting the name to\n\n  \"{http://example.org/}foo\"\n\nthen getName() needs to return\n\n  \"bar:foo\"\n\nwhich the prefix \"bar\" being mapped to the namesapce \"http://example.org/\".",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2373",
        "summary": "Buffered I/O in IndexInfos",
        "description": "IndexInfos currently uses plain Input/OutputStreams without buffering.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1181",
        "summary": "Use common base classes in jackrabbit-core and jcr2spi",
        "description": "As part of JCR-742 I've implemented a number of generic JCR base classes and adapters in org.apache.jackrabbit.commons. These classes are based on existing code in jackrabbit-core.\n\nTo encourage code reuse across jackrabbit-core and jcr2spi, I'd like to make both components use these generic base classes.\n\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1920",
        "summary": "Custom LoginModule configurations broken in 1.5.0",
        "description": "Upgrading Jackrabbit from 1.4.5 to 1.5 has created an LDAP exception.  The configuration file which has not changed (except for the adding the new SimpleSecurityManager as required) is the default with the following substituted for the LoginModule:\n\n        <LoginModule class=\"com.sun.security.auth.module.LdapLoginModule\">\n            <param name=\"userProvider\" value=\"ldap://localhost/ou=people,dc=example,dc=com\" />\n            <param name=\"userFilter\" value=\"(&amp;(uid={USERNAME})(objectClass=inetOrgPerson))\" />\n            <param name=\"authzIdentity\" value=\"{USERNAME}\" />\n            <param name=\"debug\" value=\"true\" />\n        </LoginModule>\n\nThis configuration worked correctly and I was able to authenticate properly with Jackrabbit 1.4.5\nThe same configuration with 1.5 throws the following exception:\n\njavax.jcr.LoginException: com.sun.security.auth.module.LdapLoginModule does not support 'userProvider: com.sun.security.auth.module.LdapLoginModule does not support 'userProvider: com.sun.security.auth.module.LdapLoginModule does not support 'userProvider\n        at org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1414)\n        at org.apache.jackrabbit.jca.JCAManagedConnectionFactory.openSession(JCAManagedConnectionFactory.java:140)\n        at org.apache.jackrabbit.jca.JCAManagedConnectionFactory.createManagedConnection(JCAManagedConnectionFactory.java:176)\n        at org.apache.jackrabbit.jca.JCAManagedConnectionFactory.createManagedConnection(JCAManagedConnectionFactory.java:168)\n        at com.sun.enterprise.resource.ConnectorAllocator.createResource(ConnectorAllocator.java:136)\n        at com.sun.enterprise.resource.AbstractResourcePool.createSingleResource(AbstractResourcePool.java:891)\n        at com.sun.enterprise.resource.AbstractResourcePool.createResourceAndAddToPool(AbstractResourcePool.java:1752)\n        at com.sun.enterprise.resource.AbstractResourcePool.createResources(AbstractResourcePool.java:917)\n        at com.sun.enterprise.resource.AbstractResourcePool.initPool(AbstractResourcePool.java:225)\n        at com.sun.enterprise.resource.AbstractResourcePool.internalGetResource(AbstractResourcePool.java:516)\n        at com.sun.enterprise.resource.AbstractResourcePool.getResource(AbstractResourcePool.java:443)\n        at com.sun.enterprise.resource.PoolManagerImpl.getResourceFromPool(PoolManagerImpl.java:248)\n        at com.sun.enterprise.resource.PoolManagerImpl.getResource(PoolManagerImpl.java:176)\n        at com.sun.enterprise.connectors.ConnectionManagerImpl.internalGetConnection(ConnectionManagerImpl.java:337)\n        at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:189)\n        at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:165)\n        at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:158)\n        at org.apache.jackrabbit.jca.JCARepositoryHandle.login(JCARepositoryHandle.java:98)\n        at org.apache.jackrabbit.jca.JCARepositoryHandle.login(JCARepositoryHandle.java:89)\n        at org.apache.jackrabbit.jca.JCARepositoryHandle.login(JCARepositoryHandle.java:73)\n        at com.threesl.Sapphire.CradleJCR.login(CradleJCR.java:44)   \n\n try {\n            InitialContext ctx = new InitialContext();\n            repository = (Repository) ctx.lookup(\"jcr/repository\");\n            session = repository.login(credentials);\n        } catch (Exception e) {\n\n        at com.threesl.Sapphire.CradleWS.doLogin(CradleWS.java:68)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at com.sun.jersey.impl.model.method.dispatch.EntityParamDispatchProvider$TypeOutInvoker._dispatch(EntityParamDispatchProvider.java:136)\n        at com.sun.jersey.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:85)\n        at com.sun.jersey.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:123)\n        at com.sun.jersey.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:111)\n        at com.sun.jersey.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:71)\n        at com.sun.jersey.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:111)\n        at com.sun.jersey.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:63)\n        at com.sun.jersey.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:722)\n        at com.sun.jersey.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:692)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:344)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:831)\n        at org.apache.catalina.core.ApplicationFilterChain.servletService(ApplicationFilterChain.java:411)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:290)\n        at org.apache.catalina.core.StandardContextValve.invokeInternal(StandardContextValve.java:271)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:202)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:632)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:577)\n        at com.sun.enterprise.web.WebPipeline.invoke(WebPipeline.java:94)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:206)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:632)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:577)\n        at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:571)\n        at org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:1080)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:150)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:632)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:577)\n        at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:571)\n        at org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:1080)\n        at org.apache.coyote.tomcat5.CoyoteAdapter.service(CoyoteAdapter.java:272)\n        at com.sun.enterprise.web.connector.grizzly.DefaultProcessorTask.invokeAdapter(DefaultProcessorTask.java:637)\n        at com.sun.enterprise.web.connector.grizzly.DefaultProcessorTask.doProcess(DefaultProcessorTask.java:568)\n        at com.sun.enterprise.web.connector.grizzly.DefaultProcessorTask.process(DefaultProcessorTask.java:813)\n        at com.sun.enterprise.web.connector.grizzly.DefaultReadTask.executeProcessorTask(DefaultReadTask.java:341)\n        at com.sun.enterprise.web.connector.grizzly.DefaultReadTask.doTask(DefaultReadTask.java:263)\n        at com.sun.enterprise.web.connector.grizzly.DefaultReadTask.doTask(DefaultReadTask.java:214)\n        at com.sun.enterprise.web.connector.grizzly.TaskBase.run(TaskBase.java:265)\n        at com.sun.enterprise.web.connector.grizzly.ssl.SSLWorkerThread.run(SSLWorkerThread.java:106)\nCaused by: javax.security.auth.login.LoginException: com.sun.security.auth.module.LdapLoginModule does not support 'userProvider\n        at org.apache.jackrabbit.core.security.authentication.LocalAuthContext.login(LocalAuthContext.java:68)\n        at org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1407)\n        ... 62 more\njavax.security.auth.login.LoginException: com.sun.security.auth.module.LdapLoginModule does not support 'userProvider\n        at org.apache.jackrabbit.core.security.authentication.LocalAuthContext.login(LocalAuthContext.java:68)\n        at org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1407)\n        at org.apache.jackrabbit.jca.JCAManagedConnectionFactory.openSession(JCAManagedConnectionFactory.java:140)\n        at org.apache.jackrabbit.jca.JCAManagedConnectionFactory.createManagedConnection(JCAManagedConnectionFactory.java:176)\n        at org.apache.jackrabbit.jca.JCAManagedConnectionFactory.createManagedConnection(JCAManagedConnectionFactory.java:168)\n        at com.sun.enterprise.resource.ConnectorAllocator.createResource(ConnectorAllocator.java:136)\n        at com.sun.enterprise.resource.AbstractResourcePool.createSingleResource(AbstractResourcePool.java:891)\n        at com.sun.enterprise.resource.AbstractResourcePool.createResourceAndAddToPool(AbstractResourcePool.java:1752)\n        at com.sun.enterprise.resource.AbstractResourcePool.createResources(AbstractResourcePool.java:917)\n        at com.sun.enterprise.resource.AbstractResourcePool.initPool(AbstractResourcePool.java:225)\n        at com.sun.enterprise.resource.AbstractResourcePool.internalGetResource(AbstractResourcePool.java:516)\n        at com.sun.enterprise.resource.AbstractResourcePool.getResource(AbstractResourcePool.java:443)\n        at com.sun.enterprise.resource.PoolManagerImpl.getResourceFromPool(PoolManagerImpl.java:248)\n        at com.sun.enterprise.resource.PoolManagerImpl.getResource(PoolManagerImpl.java:176)\n        at com.sun.enterprise.connectors.ConnectionManagerImpl.internalGetConnection(ConnectionManagerImpl.java:337)\n        at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:189)\n        at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:165)\n        at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:158)\n        at org.apache.jackrabbit.jca.JCARepositoryHandle.login(JCARepositoryHandle.java:98)\n        at org.apache.jackrabbit.jca.JCARepositoryHandle.login(JCARepositoryHandle.java:89)\n        at org.apache.jackrabbit.jca.JCARepositoryHandle.login(JCARepositoryHandle.java:73)\n        at com.threesl.Sapphire.CradleJCR.login(CradleJCR.java:44)\n        at com.threesl.Sapphire.CradleWS.doLogin(CradleWS.java:68)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at com.sun.jersey.impl.model.method.dispatch.EntityParamDispatchProvider$TypeOutInvoker._dispatch(EntityParamDispatchProvider.java:136)\n        at com.sun.jersey.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:85)\n        at com.sun.jersey.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:123)\n        at com.sun.jersey.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:111)\n        at com.sun.jersey.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:71)\n        at com.sun.jersey.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:111)\n        at com.sun.jersey.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:63)\n        at com.sun.jersey.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:722)\n        at com.sun.jersey.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:692)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:344)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:831)\n        at org.apache.catalina.core.ApplicationFilterChain.servletService(ApplicationFilterChain.java:411)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:290)\n        at org.apache.catalina.core.StandardContextValve.invokeInternal(StandardContextValve.java:271)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:202)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:632)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:577)\n        at com.sun.enterprise.web.WebPipeline.invoke(WebPipeline.java:94)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:206)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:632)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:577)\n        at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:571)\n        at org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:1080)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:150)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:632)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:577)\n        at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:571)\n        at org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:1080)\n        at org.apache.coyote.tomcat5.CoyoteAdapter.service(CoyoteAdapter.java:272)\n        at com.sun.enterprise.web.connector.grizzly.DefaultProcessorTask.invokeAdapter(DefaultProcessorTask.java:637)\n        at com.sun.enterprise.web.connector.grizzly.DefaultProcessorTask.doProcess(DefaultProcessorTask.java:568)\n        at com.sun.enterprise.web.connector.grizzly.DefaultProcessorTask.process(DefaultProcessorTask.java:813)\n        at com.sun.enterprise.web.connector.grizzly.DefaultReadTask.executeProcessorTask(DefaultReadTask.java:341)\n        at com.sun.enterprise.web.connector.grizzly.DefaultReadTask.doTask(DefaultReadTask.java:263)\n        at com.sun.enterprise.web.connector.grizzly.DefaultReadTask.doTask(DefaultReadTask.java:214)\n        at com.sun.enterprise.web.connector.grizzly.TaskBase.run(TaskBase.java:265)\n        at com.sun.enterprise.web.connector.grizzly.ssl.SSLWorkerThread.run(SSLWorkerThread.java:106)\nRAR5117 : Failed to obtain/create connection from connection pool [ jackrabbit-connection-pool ]. Reason : Failed to create session: com.sun.security.auth.module.LdapLoginModule does not support 'userProvider: com.sun.security.auth.module.LdapLoginModule does not support 'userProvider\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2252",
        "summary": "Update idea plugin version",
        "description": "We are using a quite outdated version (2.0). The most recent idea plugin release is 2.2.\n\nIndex: jackrabbit-parent/pom.xml\n===================================================================\n--- jackrabbit-parent/pom.xml\t(revision 802755)\n+++ jackrabbit-parent/pom.xml\t(working copy)\n@@ -73,7 +73,7 @@\n       <plugin>\n         <!-- http://maven.apache.org/plugins/maven-idea-plugin/ -->\n         <artifactId>maven-idea-plugin</artifactId>\n-        <version>2.0</version>\n+        <version>2.2</version>\n         <configuration>\n           <downloadSources>true</downloadSources>\n           <jdkLevel>1.5</jdkLevel>\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-2356",
        "summary": "Session holds LockToken after removeLockToken in XA Environment",
        "description": "",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2403",
        "summary": "insufficient privileges",
        "description": "HI,\nIn Jackrabbit  DBStore, On the fly its creating some tables in DB .  But, In our Dev environment we do not have permission for creating tables on the fly. So, I manually inserted all the dll (tables & indexes) before the application start. Although I'm getting the following exception while running application. \n\nAttached repository.xml.\n\nBelow the log.\n\n[11/23/09 11:32:04:405 EST] 0000003a SystemOut     O WARN > org.apache.jackrabbit.core.config.ConfigurationErrorHandler[WebContainer : 3]: Warning parsing the configuration at line 4 using system id file:/usr/local/web/fda/WAS/61x/svdw0047v61fda/installedApps/afda21Network001/osa_registry.ear/osa_registry.war/WEB-INF/cfg/repository.xml: org.xml.sax.SAXParseException: Document root element \"Repository\", must match DOCTYPE root \"null\".\n[11/23/09 11:32:04:407 EST] 0000003a SystemOut     O WARN > org.apache.jackrabbit.core.config.ConfigurationErrorHandler[WebContainer : 3]: Warning parsing the configuration at line 4 using system id file:/usr/local/web/fda/WAS/61x/svdw0047v61fda/installedApps/afda21Network001/osa_registry.ear/osa_registry.war/WEB-INF/cfg/repository.xml: org.xml.sax.SAXParseException: Document is invalid: no grammar found.\n[11/23/09 11:32:04:977 EST] 0000003a SystemOut     O INFO > org.apache.jackrabbit.core.RepositoryImpl[WebContainer : 3]: Starting repository...\n[11/23/09 11:32:05:474 EST] 0000003a SystemOut     O ERROR> org.apache.jackrabbit.core.fs.db.DatabaseFileSystem[WebContainer : 3]: failed to initialize file system\njava.sql.SQLException: ORA-01031: insufficient privileges\n\n\tat oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112)\n\tat oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:331)\n\tat oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:288)\n\tat oracle.jdbc.driver.T4C8Oall.receive(T4C8Oall.java:745)\n\tat oracle.jdbc.driver.T4CStatement.doOall8(T4CStatement.java:210)\n\tat oracle.jdbc.driver.T4CStatement.executeForRows(T4CStatement.java:961)\n\tat oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1190)\n\tat oracle.jdbc.driver.OracleStatement.executeUpdateInternal(OracleStatement.java:1657)\n\tat oracle.jdbc.driver.OracleStatement.executeUpdate(OracleStatement.java:1626)\n\tat org.apache.jackrabbit.core.fs.db.OracleFileSystem.checkSchema(OracleFileSystem.java:211)\n\tat org.apache.jackrabbit.core.fs.db.DatabaseFileSystem.init(DatabaseFileSystem.java:190)\n\tat org.apache.jackrabbit.core.fs.db.OracleFileSystem.init(OracleFileSystem.java:137)\n\tat org.apache.jackrabbit.core.config.RepositoryConfigurationParser$2.getFileSystem(RepositoryConfigurationParser.java:762)\n\tat org.apache.jackrabbit.core.config.RepositoryConfig.getFileSystem(RepositoryConfig.java:666)\n\tat org.apache.jackrabbit.core.RepositoryImpl.<init>(RepositoryImpl.java:262)\n\tat org.apache.jackrabbit.core.RepositoryImpl.create(RepositoryImpl.java:621)\n\tat org.apache.jackrabbit.core.jndi.BindableRepository.createRepository(BindableRepository.java:140)\n\tat org.apache.jackrabbit.core.jndi.BindableRepository.init(BindableRepository.java:116)\n\tat org.apache.jackrabbit.core.jndi.BindableRepository.<init>(BindableRepository.java:105)\n\tat org.apache.jackrabbit.core.jndi.BindableRepositoryFactory.getObjectInstance(BindableRepositoryFactory.java:51)\n\tat org.apache.jackrabbit.core.jndi.RegistryHelper.registerRepository(RegistryHelper.java:74)\n\tat com.ssc.soareg.jackrabbit.ContentRepository.<clinit>(ContentRepository.java:71)\n\tat com.ssc.soareg.jaxr.registry.client.infomodel.ServiceImpl.<init>(ServiceImpl.java:177)\n\tat com.ssc.soareg.governance.client.SOALifeCycleManagerImpl.saveBusinessServices(SOALifeCycleManagerImpl.java:259)\n\tat com.ssc.soareg.registry.server.UploadServlet.service(UploadServlet.java:473)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:856)\n\tat com.ibm.ws.webcontainer.servlet.ServletWrapper.service(ServletWrapper.java:1068)\n\tat com.ibm.ws.webcontainer.servlet.ServletWrapper.handleRequest(ServletWrapper.java:543)\n\tat com.ibm.ws.wswebcontainer.servlet.ServletWrapper.handleRequest(ServletWrapper.java:478)\n\tat com.ibm.ws.webcontainer.webapp.WebApp.handleRequest(WebApp.java:3357)\n\tat com.ibm.ws.webcontainer.webapp.WebGroup.handleRequest(WebGroup.java:267)\n\tat com.ibm.ws.webcontainer.WebContainer.handleRequest(WebContainer.java:811)\n\tat com.ibm.ws.wswebcontainer.WebContainer.handleRequest(WebContainer.java:1455)\n\tat com.ibm.ws.webcontainer.channel.WCChannelLink.ready(WCChannelLink.java:115)\n\tat com.ibm.ws.http.channel.inbound.impl.HttpInboundLink.handleDiscrimination(HttpInboundLink.java:454)\n\tat com.ibm.ws.http.channel.inbound.impl.HttpInboundLink.handleNewInformation(HttpInboundLink.java:383)\n\tat com.ibm.ws.http.channel.inbound.impl.HttpICLReadCallback.complete(HttpICLReadCallback.java:102)\n\tat com.ibm.ws.tcp.channel.impl.AioReadCompletionListener.futureCompleted(AioReadCompletionListener.java:165)\n\tat com.ibm.io.async.AbstractAsyncFuture.invokeCallback(AbstractAsyncFuture.java:217)\n\tat com.ibm.io.async.AsyncChannelFuture.fireCompletionActions(AsyncChannelFuture.java:161)\n\tat com.ibm.io.async.AsyncFuture.completed(AsyncFuture.java:136)\n\tat com.ibm.io.async.ResultHandler.complete(ResultHandler.java:195)\n\tat com.ibm.io.async.ResultHandler.runEventProcessingLoop(ResultHandler.java:784)\n\tat com.ibm.io.async.ResultHandler$2.run(ResultHandler.java:873)\n\tat com.ibm.ws.util.ThreadPool$Worker.run(ThreadPool.java:1473)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2603",
        "summary": "DefaultLoginModule performs anonymous login in case of unsupported Credentials implementation",
        "description": "If Repository.login in called with an unsupported Credentials implementation the DefaultLoginModule#getCredentials returns null\nand thus an anonymous login. The expected behavior from my point of view however was, that login with unsupported credentials \nwould not be handled by the LoginModule and - if no other module is able to handle it -  login would consequently fails.",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "JCR-3093",
        "summary": "Inconsistency between Session.getProperty and Node.getProperty for binary values",
        "description": "there an inconsistency in the binary handling between the batch-reading facility and those cases where a property is directly\naccessed without having accessed the parent node before.\n\nthis issue came up with timothee maret running into performance issues when retrieving the length of a binary property:\n\nif the property-entry has been created in the run of a batch-read operation the corresponding property-data object\ncontains internal values that contain the length of the binary (such as transported with the json response) and only\nread the data from the server if the value stream is explicitly requested.\nhowever, if the property is accessed directly (e.g. Session.getProperty or Node.getProperty with a relative path) \na GET request is made to the corresponding dav resource and the stream is read immediately.\n\npossible solution:\n\nif RepositoryService#getItemInfos(SessionInfo, ItemId) is called with a PropertyId the implementation\nshould not result in a GET request to the corresponding resource by calling super.getPropertyInfo(sessionInfo, (PropertyId) itemId).\ninstead it should be consistent with the batch-read and only make a PROPFIND request for the property\nlength. the returned PropertyInfo object would in that case be identical to the one generated by the batch-read functionality.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-8",
        "summary": "Multiple PropertyDefs with same name not possible",
        "description": "when adding property defs with the same name but different settings, for example one singlevalued, one multivalued, only the last is respected when creating a property.\n\nproblem is the 'namedItemDefs' HashMap in the EffectiveNodeType which rather must contain a list of defs rather than the def itself.\n",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "BUG"
    },
    {
        "key": "JCR-640",
        "summary": "rename jcr-browser contrib project",
        "description": "There's a project called jcr-browser at sourceforge, it's a desktop browser mantained by sandro boehme. I'll rename the contrib project to jcr-navigator unless someone proposes a better name :). ",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "JCR-2755",
        "summary": "ConcurrentModificationException in WebDAV UPDATE",
        "description": "After fixing JCR-2750, I started seeing the following exception in the jcr2dav integration tests:\n\njava.util.ConcurrentModificationException: null\n\tat java.util.LinkedHashMap$LinkedHashIterator.nextEntry(LinkedHashMap.java:365) ~[na:1.5.0_22]\n\tat java.util.LinkedHashMap$ValueIterator.next(LinkedHashMap.java:380) ~[na:1.5.0_22]\n\tat java.util.AbstractCollection.toArray(AbstractCollection.java:176) ~[na:1.5.0_22]\n\tat org.apache.jackrabbit.webdav.MultiStatus.getResponses(MultiStatus.java:122) ~[jackrabbit-webdav-2.2-SNAPSHOT.jar:2.2-SNAPSHOT]\n\tat org.apache.jackrabbit.webdav.MultiStatus.toXml(MultiStatus.java:151) ~[jackrabbit-webdav-2.2-SNAPSHOT.jar:2.2-SNAPSHOT]\n\tat org.apache.jackrabbit.webdav.WebdavResponseImpl.sendXmlResponse(WebdavResponseImpl.java:145) ~[jackrabbit-webdav-2.2-SNAPSHOT.jar:2.2-SNAPSHOT]\n\tat org.apache.jackrabbit.webdav.WebdavResponseImpl.sendMultiStatus(WebdavResponseImpl.java:113) ~[jackrabbit-webdav-2.2-SNAPSHOT.jar:2.2-SNAPSHOT]\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.doUpdate(AbstractWebdavServlet.java:1117) ~[jackrabbit-webdav-2.2-SNAPSHOT.jar:2.2-SNAPSHOT]\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.execute(AbstractWebdavServlet.java:327) ~[jackrabbit-webdav-2.2-SNAPSHOT.jar:2.2-SNAPSHOT]\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.service(AbstractWebdavServlet.java:201) ~[jackrabbit-webdav-2.2-SNAPSHOT.jar:2.2-SNAPSHOT]\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820) ~[servlet-api-2.5-20081211.jar:na]\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511) ~[jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:390) ~[jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.Server.handle(Server.java:326) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:938) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:755) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228) [jetty-6.1.22.jar:6.1.22]\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582) [jetty-util-6.1.22.jar:6.1.22]\n\nInstead of something caused by JCR-2750, it looks like a deeper problem that the JCR_2750 fix just uncovered. As far as I can tell, the ConcurrentModificationException is coming from the AbstractResource.EListener class that may end up concurrently modifying the MultiStatus response while it's being serialized.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1339",
        "summary": "ManageableCollectionUtil doesn't support Maps",
        "description": "ManageableCollectionUtil has two getManageableCollection methods, which do not currently return a ManageableCollection which wraps Maps. \n\nManagedHashMap already exists in the codebase which I assume was created for this purpose, so both getManageableCollection methods could be modified so that they do something like:\n\n            if (object instanceof Map){\n                return new ManagedHashMap((Map)object);\n            }\n\n\nAn alternative solution might be to modify the JCR mapping to support explicitly defining the 'ManagedXXX' class.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1898",
        "summary": "Replace customized QueryParser.jjt",
        "description": "We should rather use the Lucene default and implement a  Jackrabbit  version that extends from it. This eases maintenance when moving from one Lucene version to another.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2455",
        "summary": "Automatic staging of the non-Maven release artefacts",
        "description": "Currently the Jackrabbit release process includes the following manual steps in addition to the standard Maven release plugin invocations:\n\n<script>\nVERSION=x.y.z  # Release version number\n\n# Prepare the release directory\nmkdir target/$VERSION\n\n# Copy the main release artifacts created in the release:perform stage\ncp target/checkout/RELEASE-NOTES.txt target/$VERSION\ncp target/checkout/target/jackrabbit-$VERSION-src.zip* target/$VERSION\ncp target/checkout/jackrabbit-webapp/target/jackrabbit-webapp-$VERSION.war* target/$VERSION\ncp target/checkout/jackrabbit-jca/target/jackrabbit-jca-$VERSION.rar* target/$VERSION\ncp target/checkout/jackrabbit-standalone/target/jackrabbit-standalone-$VERSION.jar* target/$VERSION\n\n# Add MD5 and SHA1 checksums\nfor BINARY in target/$VERSION/*.zip target/$VERSION/*ar; do\n  openssl md5 < $BINARY > $BINARY.md5\n  openssl sha1 < $BINARY > $BINARY.sha\ndone\n\n# Upload the release directory to people.apache.org\nscp -r target/$VERSION people.apache.org:public_html/jackrabbit/$VERSION\n</script>\n\nI'd like to automate these steps.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2379",
        "summary": "BindVariable not registered in JCR-SQL2 CONTAINS",
        "description": "The following fails with a \"java.lang.IllegalArgumentException: not a valid variable in this query:\"\n\nQuery query = qm.createQuery(\"SELECT * FROM [my:document] AS document WHERE CONTAINS(document.original, $x)\", Query.JCR_SQL2);\nquery.bindVariable(\"x\", vf.createValue(\"moo\"));\n\nAnd query.getBindVariableNames() returns an empty array.\n\nThe FullTextSearchExpression _is_ however correctly parsed as a BindVariableValueImpl:\n((FullTextSearch) ((QueryObjectModelImpl) query).getConstraint()).getFullTextSearchExpression() instanceof BindVariableValue\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-469",
        "summary": "Problem with child order after restoring of parent",
        "description": "The following sequence leads to swapped child nodes in the mentioned trunk version (this worked in 1.0.1).\nSpecifically:\n\nAdd nodes:\n parent\n   childA\n   childB\n\nRemove childA:\n parent\n   childB\n\nRestore initial version:\n parent\n   childB\n   childA\n\nThe parent node is of type nt:unstructured which carries an\nOrderableChildNodes=true so I would assume that upon restoring the order\nwould be preserved.\n\nCheers,\nTanju\n\n--------------\n\nTESTCASE used with both Derby & InMemPMs (boiled down beyond sense :)\n\n// Add parent & childA, childB\nNode parent = session.getRootNode().addNode(\"parent\", \"nt:unstructured\");\nparent.addMixin(\"mix:versionable\");\nNode c1 = parent.addNode(\"childA\", \"nt:unstructured\");\nc1.addMixin(\"mix:versionable\");\nNode c2 = parent.addNode(\"childB\", \"nt:unstructured\");\nc2.addMixin(\"mix:versionable\");\nsession.save();\nc1.checkin();\nc2.checkin();\nVersion v1 = parent.checkin();\n// OK : parent.getNodes() -> childA, childB\n\n// Remove childA\nparent = session.getRootNode().getNode(\"parent\");\nparent.checkout();\nc1 = parent.getNodes().nextNode();\nc1.checkout();\nc1.remove();\nsession.save();\nVersion v2 = parent.checkin();\n// OK : parent.getNodes() -> childA, childB\n\n// Remove childA\nparent = session.getRootNode().getNode(\"parent\");\nparent.restore(v1, true);\n// Not OK : parent.getNodes() -> childB, childA",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2936",
        "summary": "JMX Bindings for Jackrabbit",
        "description": "There has been a slight interest in the past for adding JMX support.\nThis would be the first stab at it. It is a Top 15 slow query log. (the 15 part is configurable)\n\nIt is not enabled by default, so just being there should not affect the overall performance too much. You can enable it and play a little, tell me what you think.\nI've also added a test case that does a duration comparison with and without the logger.\n\nThe most important part of this issue is that it should open the way for some proper monitoring tools support around queries, caches, anything/everything Jackrabbit.\n\nAs usual, please let me know what you guys think",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-140",
        "summary": "Versioning might no be thread safe",
        "description": "check versioning for thread safeness",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1923",
        "summary": "Startup fails if clustered jackrabbit is upgrade from 1.4.4 to 1.5",
        "description": "This is closely related to JCR-1087\n\nThe call to checkLocalRevisionSchema() is too late because preapreStatements() already uses the LOCAL_REVISIONS table.\n\ncheckLocalRevisionSchema() should be called in checkSchema()",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2725",
        "summary": "PostgreSQL: Failed to guess validation query",
        "description": "When using PostgreSQL, the following warning appears in the log file:\n\n> *WARN  [org.apache.jackrabbit.core.util.db.ConnectionFactory] (main)\n> Failed to guess validation query for URL\n> jdbc:postgresql:...",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2328",
        "summary": "PropertyValue constraint fails with implicit selectorName using JCR-SQL2",
        "description": "Compiling a JCR-SQL2 query involving a PropertyValue constraint using a qualified property name fails if selectorName is not explicitly defined.\n\nThe following query works:\n\nSELECT * FROM [my:thing] AS thing WHERE thing.[my:property] = 'abc'\n\nthe following doesn't:\n\nSELECT * FROM [my:thing] AS thing WHERE [my:property] = 'abc'\n\n(the \"AS thing\" is unecessary here, I can leave it out with the same result).\n\nThe second query results in an:\njavax.jcr.query.InvalidQueryException: Query:\nSELECT * FROM [my:thing] AS thing WHERE [(*)my:property] = 'abc';\nexpected: NOT, (\n\nThe spec final draft however states:\n\nPropertyValue ::= [selectorName'.'] propertyName\n   /* If only one selector exists in this query,\n      explicit specification of the selectorName is\n      optional */",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-624",
        "summary": "OutOfMemoryError When repeat login and the logout many times",
        "description": "When repeat login and the logout many times, I encountered?OutOfMemoryError.\n\njavax.jcr.RepositoryException: Cannot instantiate persistence manager org.apache.jackrabbit.core.state.db.DerbyPersistenceManager: Java exception: 'Java heap space: java.lang.OutOfMemoryError'.: Java exception: 'Java heap space: java.lang.OutOfMemoryError'.\n\tat org.apache.jackrabbit.core.RepositoryImpl.createPersistenceManager(RepositoryImpl.java:1095)\n\tat org.apache.jackrabbit.core.RepositoryImpl.createVersionManager(RepositoryImpl.java:300)\n\tat org.apache.jackrabbit.core.RepositoryImpl.<init>(RepositoryImpl.java:245)\n\tat org.apache.jackrabbit.core.RepositoryImpl.create(RepositoryImpl.java:498)\n\tat org.apache.jackrabbit.core.TransientRepository$2.getRepository(TransientRepository.java:245)\n\tat org.apache.jackrabbit.core.TransientRepository.startRepository(TransientRepository.java:265)\n\tat org.apache.jackrabbit.core.TransientRepository.login(TransientRepository.java:333)\n\tat org.apache.jackrabbit.core.TransientRepository.login(TransientRepository.java:388)\n\tat Test.tryLoginAndLogout(Test.java:19)\n\tat Test.test1(Test.java:13)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat junit.framework.TestCase.runTest(TestCase.java:164)\n\tat junit.framework.TestCase.runBare(TestCase.java:130)\n\tat junit.framework.TestResult$1.protect(TestResult.java:106)\n\tat junit.framework.TestResult.runProtected(TestResult.java:124)\n\tat junit.framework.TestResult.run(TestResult.java:109)\n\tat junit.framework.TestCase.run(TestCase.java:120)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:230)\n\tat junit.framework.TestSuite.run(TestSuite.java:225)\n\tat org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)\nCaused by: SQL Exception: Java exception: 'Java heap space: java.lang.OutOfMemoryError'.\n\tat org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.javaException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedPreparedStatement20.<init>(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedPreparedStatement30.<init>(Unknown Source)\n\tat org.apache.derby.jdbc.Driver30.newEmbedPreparedStatement(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source)\n\tat org.apache.jackrabbit.core.state.db.DatabasePersistenceManager.init(DatabasePersistenceManager.java:224)\n\tat org.apache.jackrabbit.core.RepositoryImpl.createPersistenceManager(RepositoryImpl.java:1091)\n\t... 27 more\njava.lang.OutOfMemoryError: Java heap space\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1510",
        "summary": "[PATCH] more verbose exception messages (BatchedItemOperations)",
        "description": "added context to exception messages in BatchedItemOperations to aid debugging",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1188",
        "summary": "WebDAV: Allow for Extensions of MimeResolver in the Configuration.",
        "description": "Currently mime type detection is done using the content type header or (if missing) using a static MimeResolver instance in \nthe IOUtil class. The MimeResolver itself reads from a properties file, that obviously does not list all possible extensions and\nmimetypes.\n\nThis could be improved by:\n\n- extending the resource configuration.\n- extend the ImportContext and ExportContext interfaces\n- replacing the current usages of IOUti#MIMERESOLVER by the corresponding calls on the Context classes which \n  themselves get a MimeResolver that is retrieved from the resource configuration.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2866",
        "summary": "Cluster: Node type register/unregister deadlock",
        "description": "A deadlock can occur when two cluster nodes concurrently register or unregister node types.\n\nReason: \n\nNodeTypeRegistry.registerNodeTypes is synchronized, and calls eventChannel.registered(ntDefs), which calls AbstractJournal.lockAndSync(), which tries to lock AbstractJournal.rwLock.\n\nOn the other hand, AbstractJournal.sync() locks AbstractJournal.rwLock, then calls NodeTypeRecord.process, which calls NodeTypeRegistry.unregisterNodeTypes, which is also synchronized.\n\nPossible solutions: Either \n\n- NodeTypeRegistry doesn't synchronize on the object when calling a eventChannel method,\n\n- or NodeTypeRegistry locks AbstractJournal.rwLock before synchronizing.\n\nThere might be other solutions.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-660",
        "summary": "SQL Parser fails with SQL 92 timestamp format",
        "description": "The SQL query parser fails with an exception if the SQL 92 timestamp format is used.\n\nE.g:\n... WHERE my:date > TIMESTAMP '1976-01-01 00:00:00.000+01:00'\n\ndoes not work, but the following will succeed using ISO8601:\n\n... WHERE my:date > TIMESTAMP '1976-01-01T00:00:00.000+01:00'",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-210",
        "summary": "jcr-rmi maven \"site\" target fails",
        "description": "the target \"site\" in jcr rmi fails because org.apache.jackrabbit.rmi.remote.SerialValue.java is empty",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-676",
        "summary": "Participation of a workspace in a cluster should be configurable",
        "description": "Currently, when clustering is enabled, every workspace participates automatically. This should be configurable in the workspace, by introducing an attribute such as \"clustered=[true|false]\".",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2168",
        "summary": "Avoid premature publication of XAItemStateManager",
        "description": "The XAItemStateManager constructor calls the super constructor (LocalItemStateManager)  which registers the instance as a listener with the SharedItemStateManager. The construction of the instance has not yet been finished, but it is accessible from the SharedItemStateManager. This can result in strange exceptions like the following:\n\njava.lang.NullPointerException\n        at org.apache.jackrabbit.core.state.XAItemStateManager.stateModified(XAItemStateManager.java:580)\n        at org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyStateModified(StateChangeDispatcher.java:111)\n        at org.apache.jackrabbit.core.state.SharedItemStateManager.stateModified(SharedItemStateManager.java:400)\n        at org.apache.jackrabbit.core.virtual.AbstractVISProvider.stateModified(AbstractVISProvider.java:445)\n        at org.apache.jackrabbit.core.state.ItemState.notifyStateUpdated(ItemState.java:244) \n\nThe NPE is caused by the commitLogs field being null (it has not yet been initialized to its final value).",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2594",
        "summary": "Make cache limits configurable",
        "description": "The cache settings of the CacheManager class (JCR-619) can be adjusted programmatically (JCR-725), but it would be nice if there was also a way to set them with system properties or ideally as a part of the repository configuration.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2774",
        "summary": "Access control for repository level API operations",
        "description": "it is a open issue (i guess since jackrabbit 1.0) that the repository level write operations lack any kind of permission check.\nthis issues has been raised during specification of jsr 283 [1] but didn't made it into the specification (left to implementation).\n\nin jackrabbit 2.0 this affects the following parts of the API\n\n- namespace registration\n- node type registration\n- workspace creation/removal\n\nbased on a issue reported by david (\"currently an anonymous user can write the namespace registry which is probably\nundesirable [...]\"), we could at least add some minimal restrictions. In addition i would like to take up this discussion\nfor jsr 333.\n\n[1] https://jsr-283.dev.java.net/issues/show_bug.cgi?id=486",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-868",
        "summary": "Jackrabbit JCR Nodemanagement API implementation",
        "description": "There needs to be a Jackrabbit implementation of the org.apache.portals.graffito.jcr.nodemanagement.NodeTypeManager interface.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-3212",
        "summary": "add TCK test for Info map of NODE_MOVED event on node reordering",
        "description": "add the TCK test for this problem, and mark this as known test failure for now",
        "label": "NUG",
        "classified": "TEST",
        "type": ""
    },
    {
        "key": "JCR-2424",
        "summary": "Avoid Maven 3 warnings",
        "description": "Jackrabbit trunk builds fine with the Maven 3 alpha releases, but there are some warnings about deprecated ${pom....} variables and unspecified reporting plugin versions that we might want to fix.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2573",
        "summary": "Performance of AC Evaluation",
        "description": "1. Performance in access control evaluation\n=====================================================================\n\n - main focus on\n   > read performance\n   > resource-based access control in .a.j.c/s/authorization/acl/*\n\n - comparison admin vs. anonymous with full permissions\n - comparision between shortcut and ACL-evaluation.\n - comparison JR 1.4 vs JR 2.0 [actually i will compare Day's CRX as it already provided\n   some custom AC stuff with JR 1.4]\n\n\n2. Potential Problems\n=====================================================================\n\n   I would expect the most significant problems to be found in\n\na) ACLProvider#retrieveResultEntries: calculating effective ACEs\n     for each session separately.\n\nb) AclPermission:\n     Each instance registering an event listener in order to\n     keep the result cache up to date\n\nc) AclPermission:\n     Resolution form Path to Item or to nearest existing Item ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-774",
        "summary": "TCK: Test that expect that modifications made by Session1 are automatically visible to Session2",
        "description": "While changes made by session1 are automatically visible to any other session2 with the RI, this is not required by the\nspecification. Therefore i would suggest to modify the following test cases:\n\n- NodeUUIDTest.testSaveMovedRefNode()\n- SessionUUIDTest.testSaveMovedRefNode()\n\n-> no patch. sorry.\n\n- NodeTest.testRemoveInvalidItemStateException()\n\n-> see patch.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1270",
        "summary": "CompactNodeTypeDefReader does not recognise MIXIN ORDERABLE sequence",
        "description": "the code in 'doOptions' misses to set the setOrderableChildNodes flag if the order of the tokens is MIXIN ORDERABLE.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-162",
        "summary": "bad project.xml",
        "description": "project.xml in the \"api\" module actually contains an error (nested comment) and can't be read by maven.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-2257",
        "summary": "Removal of a node with shared subnodes fails",
        "description": "A simple testcase:\n\nSet up (first transaction):\nNode a1 = testRootNode.addNode(\"a1\");\nNode a2 = testRootNode.addNode(\"a2\");\na2.addMixin(\"mix:shareable\");\nsession.save();\n// now we have a shareable node N with path a2\n\nWorkspace workspace = session.getWorkspace();\nString path = a1.getPath() + \"/b1\";\nworkspace.clone(workspace.getName(), a2.getPath(), path, false);\nsession.save();\n// now we have another shareable node N' in the same shared set as N with path a1/b1\n\nTest(second transaction):\ntestRootNode.remove(\"a1\");\nsession.save();\n\nAt least in a transactional repository the node will not be removed, an error will be thrown instead.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-546",
        "summary": "Deadlock during checkin",
        "description": "Under a load of 3 threads performing checkin and restore operations it's possible for all to become deadlocked in AbstractVersionManager.checkin(). This method attempts to upgrade a read lock to a write lock with the following code\n\n    aquireReadLock();\n    ....\n\n    try {\n        aquireWriteLock();\n        releaseReadLock();\n        ...\n\nIf 2 or more threads acquire the read lock then neither can acquire the write lock resulting in the deadlock, and after that any other thread that calls this method will block waiting for the write lock. The release of the read lock needs to be done before acquiring the write lock, this is documented Concurrent library javadoc.\n\nThere is another area where there is an attempt to upgrade a read lock to write lock, RepositoryImpl.WorkspaceInfo.disposeIfIdle() acquires a read lock and calls dispose() which then acquires a write lock, this maybe ok, as I assume there is only 1 thread that will attempt to dispose of idle workspaces.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1774",
        "summary": "Jackrabbit concurrency review and invariants",
        "description": "I've been working on reviewing and verifying the internal concurrency model of Jackrabbit in an attempt to proactively prevent the kinds of deadlock issues we've seen before. Overall things seem pretty good nowadays. I'll be updating the web site with some resulting design and review docs that should help guide future work in this area. I also have created some global invariant checks that I'll be adding to the codebase.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2882",
        "summary": "DatabaseJournal: java.lang.IllegalStateException: already in batch mode",
        "description": "Using the database journal (any database) fails with the following stack trace:\n\njava.lang.IllegalStateException: already in batch mode\n\tat org.apache.jackrabbit.core.util.db.ConnectionHelper.startBatch(ConnectionHelper.java:212)\n\tat org.apache.jackrabbit.core.journal.DatabaseJournal.doSync(DatabaseJournal.java:449)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.lockAndSync(AbstractJournal.java:254)\n\tat org.apache.jackrabbit.core.journal.DefaultRecordProducer.append(DefaultRecordProducer.java:51)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode$WorkspaceUpdateChannel.updateCreated(ClusterNode.java:539)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager$Update.begin(SharedItemStateManager.java:559)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.beginUpdate(SharedItemStateManager.java:1457)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:1487)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:351)\n\tat org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:354)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-156",
        "summary": "Review test cases and cross check with 1.0 specification",
        "description": "This jira task is meant to collect issues with the TCK test cases.",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "JCR-943",
        "summary": "SQL Server support in clustering module",
        "description": "I realize the clustering module doesn't specifically support SQL Server yet (there's no mssql.ddl), but I still tried to run the repository against SQL Server with clustering enabled in the hope that the default schema (default.ddl) would suffice. Apparently, it doesn't (unless I'm doing something very wrong), since I kept getting the following error whenever a write operation was attempted:\n\n2007-05-25 14:48:06,757 WARN  [org.apache.jackrabbit.core.journal.DatabaseJournal] Error while rolling back connection: You cannot rollback with autocommit set!\n2007-05-25 14:48:06,757 ERROR [org.apache.jackrabbit.core.cluster.ClusterNode] Unable to commit log entry.\norg.apache.jackrabbit.core.journal.JournalException: Unable to append revision 1090.\n\tat org.apache.jackrabbit.core.journal.DatabaseJournal.append\n\tat org.apache.jackrabbit.core.journal.AppendRecord.update(AppendRecord.java:242)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode$WorkspaceUpdateChannel.updateCommitted(ClusterNode.java:530)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager$Update.end(SharedItemStateManager.java:725)\n\tat org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:855)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:326)\n\tat org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:313)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:302)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:306)\n\tat org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1214)\n\tat org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:849)\nCaused by: java.sql.DataTruncation: Data truncation\n\tat net.sourceforge.jtds.jdbc.SQLDiagnostic.addDiagnostic(SQLDiagnostic.java:379)\n\tat net.sourceforge.jtds.jdbc.TdsCore.tdsErrorToken(TdsCore.java:2781)\n\tat net.sourceforge.jtds.jdbc.TdsCore.nextToken(TdsCore.java:2224)\n\tat net.sourceforge.jtds.jdbc.TdsCore.getMoreResults(TdsCore.java:628)\n\tat net.sourceforge.jtds.jdbc.JtdsStatement.processResults(JtdsStatement.java:525)\n\tat net.sourceforge.jtds.jdbc.JtdsStatement.executeSQL(JtdsStatement.java:487)\n\tat net.sourceforge.jtds.jdbc.JtdsPreparedStatement.execute(JtdsPreparedStatement.java:475)\n\tat org.jboss.resource.adapter.jdbc.WrappedPreparedStatement.execute(WrappedPreparedStatement.java:183)\n\tat org.apache.jackrabbit.core.journal.DatabaseJournal.append\n\t... 58 more\n\nHowever, I think I got things working by using a modified version of default.ddl, with the only change being the type of the REVISION_DATA field (varbinary -> IMAGE).",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2427",
        "summary": "UUIDDocId.getDocumentNumbers() may return illegal value",
        "description": "Happens when the node with the given UUID is not present in the index. The method then returns -1, which is illegal. Document numbers must be >= 0. The method must returns an empty array when the id is invalid, as documented in DocId.getDocumentNumbers().",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-307",
        "summary": "serious performance degradation of node operations when node has a large number of child nodes (e.g. > 10k child node entries)",
        "description": "",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-284",
        "summary": "Locking two same-name siblings and unlocking first apparently unlocks second instead.",
        "description": "Executing the following test that unlocks the first of two locked same-name siblings:\n\npublic void testLocking() throws RepositoryException {\n       Session jcrSession = ((S1SessionImpl) session).getSession();\n       Node rootNode = jcrSession.getRootNode();\n\n       Node n1 = rootNode.addNode(\"path\");\n       n1.addMixin(\"mix:lockable\");\n       Node n2 = rootNode.addNode(\"path\");\n       n2.addMixin(\"mix:lockable\");\n\n       jcrSession.save();\n\n       n1.lock(true, true);\n       n2.lock(true, true);\n\n       System.out.println(\"n1.isLocked() = \" + n1.isLocked());\n       System.out.println(\"n2.isLocked() = \" + n2.isLocked());\n       assertTrue(n1.isLocked());\n       assertTrue(n2.isLocked());\n\n       n1.save();\n       n1.unlock();\n\n       System.out.println(\"n1.isLocked() = \" + n1.isLocked());\n       System.out.println(\"n2.isLocked() = \" + n2.isLocked());\n       assertFalse(n1.isLocked());\n       assertTrue(n2.isLocked());\n   }\n\nResults in:\n\nn1.isLocked() = true\nn2.isLocked() = true\nn1.isLocked() = true\nn2.isLocked() = false\n\nwhich is wrong.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-181",
        "summary": "jcr-server should honor a webdav request's Content-Type and Content-Language headers",
        "description": "when processing a PUT or a POST, the DavResource should have access to the Content-Type and Content-Language headers presented in the webdav request, if any.\n\nwhen the client explicitly communicates these headers, their values should take priority over server calculations (such as that done in SetContentTypeCommand), or at least be input into server calculations\n\nfurthermore, the dav getcontentlanguage is not at all supported by at least the simple webdav server.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1520",
        "summary": "DatabaseFileSystem's logger references the wrong class",
        "description": "In DatabaseFileSystem, the logger is constructed as\nprivate static Logger log = LoggerFactory.getLogger(DbFileSystem.class);\n\nIt should be constructed as:\nprivate static Logger log = LoggerFactory.getLogger(DatabaseFileSystem.class);",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2088",
        "summary": "Drop Maven 1 compatibility",
        "description": "We migrated from Maven 1 to Maven 2 as the build system in Jackrabbit 1.2, but we kept compatibility with related Maven 1 build with the maven-one-plugin that deployed all builds also to the local Maven 1 repository.\n\nHardly any downstream project uses Maven 1 anymore, so it's safe for us to simplify our build now by dropping the use of the maven-one-plugin.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1049",
        "summary": "DatabaseFileSystem: mysql.ddl works for mysql5 but not mysql 4.1.20",
        "description": "Perhaps a new column ( primary key ) could get added to the table called uid, which is actually an md5checksum of FSENTRY_PATH and FSENTRY_NAME.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-467",
        "summary": "CompactNodeTypeReader fails to explain why valid JCR names cause errors",
        "description": "for example, you cannot use underscores in node type definitions:\n[my:example_breaks2]\n\nIn fact only A-Z, a-z, 0-9, : are allowed, unless you quote the name. The error message you see when you make this mistake doesn't give any hint:\nMissing ']' delimiter for end of node type name (nodetypes.cnd, line 8)\n\nand the documentation on the website and the javadoc for CompactNodeTypeDefReader both just say:\n\n * unquoted_string ::= ...a string...\n\n... not helpful. If you made this mistake, you end up needing to look at the source to figure out what you've done wrong. \n\nA few suggested solutions:\n- change the documentation to say unquoted string is '[A-Za-z0-9:]+'\n- change the error message to mention the token causing the problem, eg:\nif (!currentTokenEquals(Lexer.END_NODE_TYPE_NAME)) {\n            lexer.fail(\"Missing '\" + Lexer.END_NODE_TYPE_NAME + \"' delimiter for end of node type name, found \" + currentToken);\n}\n- add \"st.wordChars('_','_');\" to the lexer, its probably going to be the most common cause, and doesnt conflict with other rules.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1957",
        "summary": "Move common validation checks to a single place",
        "description": "check for effective locks, nodes being checked-in, protection of item definitions etc. are abundant throughout jackrabbit-core. now that in addition retention and holds will be added and need to be checked as well, i suggest to move those checks to a common utility class and pass item and a list of checks to be performed.\n\nbatcheditemoperations already provides a similar pattern for the operations on item states.\ni therefore suggest to move the flags to its base (ItemValidator) and add the utility methods needed.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-982",
        "summary": "Each TransactionContext creates new thread",
        "description": "The rollback threads are not stopped when the transaction commits, but only when the timeout occurs. This has the effect that lots of threads are created and sleeping when many transactions are committed in a short time frame. The rollback thread should be signaled when the transaction is committed or even better a Timer should be used with a single thread for all transaction contexts.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-279",
        "summary": "IllegalStateException thrown when consuming events",
        "description": "i assume, when session is closed, or beeing closed, the observation still tries to deliver some events:\n\n[java] 2005-11-24 22:58:41,764 [ObservationManager] WARN  org.apache.jackrabbit.core.observation.ObservationManagerFactory - EventConsumer threw exception: java.lang.IllegalStateException: not in\nitialized\n[java] 2005-11-24 22:58:41,764 [ObservationManager] DEBUG org.apache.jackrabbit.core.observation.ObservationManagerFactory - Stacktrace:\n[java] java.lang.IllegalStateException: not initialized\n[java]     at org.apache.jackrabbit.core.security.SimpleAccessManager.isGranted(SimpleAccessManager.java:119)\n[java]     at org.apache.jackrabbit.core.observation.EventConsumer.consumeEvents(EventConsumer.java:231)\n[java]     at org.apache.jackrabbit.core.observation.ObservationManagerFactory.run(ObservationManagerFactory.java:161)\n[java]     at java.lang.Thread.run(Thread.java:595)\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2210",
        "summary": "Move tests that require indexing configuration",
        "description": "Tests that require an indexing configuration should be moved to the indexing-test workspace. This allows us to remove the indexing configuration from the default workspace and speed up the JCR API tests.",
        "label": "NUG",
        "classified": "TEST",
        "type": "TEST"
    },
    {
        "key": "JCR-2854",
        "summary": "Add option to make sorting in user/group query case insensitive",
        "description": "Sorting on string properties is currently case sensitive in the user/group search. There should be a way to specify whether sorting shuld be case (in)sensitive.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1291",
        "summary": "Missing class JNDIDatabaseJournal",
        "description": "We're dealing to set up a clustered repository and run into some issues and missing features stated to be fixed in the upcoming v1.4. But while scanning the sources of the v1.4-rc1, i still can't find the class\n\n  JNDIDatabaseJournal (org.apache.jackrabbit.core.journal.JNDIDatabaseJournal)\n\nas a silbing to the classes \n\n  JNDIDatabaseFileSystem (org.apache.jackrabbit.core.fs.db.JNDIDatabaseFileSystem)\n\nand \n\n  JNDIDatabasePersistenceManager (org.apache.jackrabbit.core.persistence.db.JNDIDatabasePersistenceManager)\n\nThe missing one you'll need to configure all parts of a repository handeled in an abstract way by (e.g one common) JNDI database resource. From the shortness and simplicity of the source code of the other ones, i think adding this missing feature takes just about an hour.\n\nThank you for support",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1581",
        "summary": "ClassCastException when registering new node type",
        "description": "java.lang.ClassCastException: org.apache.jackrabbit.core.nodetype.NodeTypeImpl\n\tat org.apache.jackrabbit.core.nodetype.NodeTypeManagerImpl.registerNodeTypes(NodeTypeManagerImpl.java:708)\n\tat org.apache.jackrabbit.core.nodetype.NodeTypeManagerImpl.registerNodeType(NodeTypeManagerImpl.java:637)\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-253",
        "summary": "org.apache.jackrabbit.server.SessionProvider needs 'releaseSession()'",
        "description": "the SessionProvider does not have a 'releaseSession()' method, thus the DavSessionProviderImpl just calls repSession.logout() after is DavSession is released. This should rather be handled over to the given SessionProvider.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1850",
        "summary": "Journal: Use buffered input / output streams",
        "description": "The journal should use buffered input / output streams wherever possible. Currently there are some places where bytes are directly written to the journal file, which degrades performance.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1752",
        "summary": "Allow users to disable validation",
        "description": "DigesterMapperImpl leaves validating set to default true when creating a DigesterDescriptorReader.\n\nBut as the dtd is not available anywhere (published or in the source), it is usually not declared in mapping files, and DigesterDescriptorReader complains about it.\n\nCould it be possible to leave the user a way to configure the validation? The simpliest way would be to add this constructor to DigesterMapperImpl :\n\n    public DigesterMapperImpl(InputStream[] streams, boolean validate) {\n        descriptorReader = new DigesterDescriptorReader(streams);\n        DigesterDescriptorReader.class.cast(descriptorReader).setValidating(validate);\n        this.buildMapper();\n    }\n\nBest regard,\n\nStephane Landelle",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1437",
        "summary": "add framework for performance tests",
        "description": "Add a test suite for running various kinds of performance tests.",
        "label": "NUG",
        "classified": "TEST",
        "type": "RFE"
    },
    {
        "key": "JCR-2495",
        "summary": "Exclude tests instead skipping them",
        "description": "jcr2spi tests run with the spi2jcr module by default so they are configured to be skipped when jcr2spi is built. Manually running a jcr2spi test like this\n\nmvn -Dtest=MyTest -Dmaven.test.skip=false test\n\ndoes not work however. The pom configuration seems to take precedence here. \n\nTo fix this I propose to exclude all test instead of skipping them making it possible to manually execute tests like this\n\nmvn -Dtest=MyTest test\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-63",
        "summary": "/contrib/orm-persistence/ OJBPersistenceManager",
        "description": "OJBPersistenceManager seems to have the following problems\n\n1. OJBPersistenceBroker inherites from AbstractPersistenceBroker. There's no \nneed of using a non transactional implementation as the feature is available in \njdbc. \n\n2. A single broker is used and It's not thread-safe. This is not a problem now \nbecause it inherits from AbstractPersistenceManager, and the store(ChangeLog ) \nmethod is synchronized.\n\n3. The broker is never closed so it leaves an open connection.\n\n4. There's no pooling with only one broker.\n\n5 Each write method (e.g. store(NodeState state)) starts its own transaction \nbut the transaction should start and end in store(ChangeLog log).\n\n6. It never rollbacks, even when an item in the changelog can't be persisted.\n\n7. The mysql example create MyISAM tables which don't support transactions. \nInnodb tables would be more appropriate.\n\n8. jdbc to java type mapping is wrong for \nclass: org.apache.jackrabbit.core.state.orm.ORMBlobValue\nfield: size\nChanged from INTEGER to BIGINT\n\n9. When a Blob value is loaded a ArrayStoreException is thrown because in \nload(PropertyId id) BlobFileValues are added to internalValueList instead of \nInternalValue instances.\n\n10. in store(NodeReferences). When storing a NodeReferences which have some (but not all) the references deleted the OJB persistence Manager doesn't delete any one.\n\nSome of this problems are present in the Hibernate implementation.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-433",
        "summary": "NodeTypeRegistry could auto-subtype from nt:base",
        "description": "when tying to register a (primary) nodetype that does not extend from nt:base the following error is\nthrown:\n\n\"all primary node types except nt:base itself must be (directly or indirectly) derived from nt:base\"\n\nsince the registry is able to detect this error, it would be easy to auto-subtype all nodetypes from nt:base. imo it's pointless to explzitely add the nt:base to every supperclass set. as an analogy, you don't need to 'extend from java.lang.Object' explicitely - the compiler does that automatically for your.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2009",
        "summary": "Large file download over webdav causes exception",
        "description": "Downloading a large file (>2GB) from webdav causes an exception.\n\n(Note: uploading the file works ok, when jackrabbit is configured to use the filesystem DataStore.)\n\nWhen trying to retrieve the file with e.g. \"wget\", we get the following error:\n\nGozer:Desktop greg$ wget --http-user=xxx --http-passwd=xxx http://localhost:8080/jackrabbit/repository/workbench/pkgs/demo/zip/zips/largetest-1.zip\n--08:59:50--  http://localhost:8080/jackrabbit/repository/workbench/pkgs/demo/zip/zips/largetest-1.zip\n           => `largetest-1.zip'\nResolving localhost... done.\nConnecting to localhost[127.0.0.1]:8080... connected.\nHTTP request sent, awaiting response... 500 For input string: \"3156213760\"\n09:04:53 ERROR 500: For input string: \"3156213760\".\n\nIn the server log we see this:\n\n06.03.2009 08:59:50 *INFO * RepositoryImpl: SecurityManager = class org.apache.jackrabbit.core.security.simple.SimpleSecurityManager (RepositoryImpl.java, line 432)\n2009-03-06 09:04:53.822::WARN:  /jackrabbit/repository/workbench/pkgs/demo/zip/zips/largetest-1.zip\njava.lang.NumberFormatException: For input string: \"3156213760\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)\n\tat java.lang.Integer.parseInt(Integer.java:459)\n\tat java.lang.Integer.parseInt(Integer.java:497)\n\tat org.apache.jackrabbit.webdav.io.OutputContextImpl.setContentLength(OutputContextImpl.java:60)\n\tat org.apache.jackrabbit.server.io.ExportContextImpl.informCompleted(ExportContextImpl.java:192)\n\tat org.apache.jackrabbit.server.io.IOManagerImpl.exportContent(IOManagerImpl.java:157)\n\tat org.apache.jackrabbit.webdav.simple.DavResourceImpl.spool(DavResourceImpl.java:332)\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.spoolResource(AbstractWebdavServlet.java:422)\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.doGet(AbstractWebdavServlet.java:388)\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.execute(AbstractWebdavServlet.java:229)\n\tat org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.service(AbstractWebdavServlet.java:196)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:324)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)\n\tat org.mortbay.thread.BoundedThreadPool$PoolThread.run(BoundedThreadPool.java:451)\n\n\nThe problem seems to lie in OutputContextImpl.java it makes the mistake of potentially trying to parse a Long as an Integer, here: http://svn.apache.org/repos/asf/jackrabbit/trunk/jackrabbit-webdav/src/main/java/org/apache/jackrabbit/webdav/io/OutputContextImpl.java\n\nin the method setContentLength(long contentLength):\n\npublic void setContentLength(long contentLength) {\n       int length = Integer.parseInt(contentLength + \"\");\n       if (length >= 0) {\n           response.setContentLength(length);\n       }\n   }\n\nI'm not sure, but a fix might be like this:\n\npublic void setContentLength(long contentLength) {\n       if(contentLength <= Integer.MAX_VALUE && contentLength >= 0) {\n           response.setContentLength((int) contentLength);\n       }else if (contentLength >  Integer.MAX_VALUE) {\n            response.addHeader(\"Content-Length\", Long.toString(contentLength));\n       }\n   }\n\nThis would at least set the Content-Length header, and in some preliminary tests does seem to allow downloading the files.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-614",
        "summary": "Weird locking behaviour in CachingHierarchyManager",
        "description": "in some of our itegration tests the repository sometime locks-up with a stacktrace like this:\n\n\"Thread-38\" daemon prio=5 tid=0x08cb3908 nid=0xdd8 runnable [9fef000..9fefd90]\n        at org.apache.jackrabbit.core.CachingHierarchyManager.removeLRU(CachingHierarchyManager.java:540)\n        - waiting to lock <0x16a9b0e0> (a java.lang.Object)\n        at org.apache.jackrabbit.core.CachingHierarchyManager.cache(CachingHierarchyManager.java:510)\n        - locked <0x16a9b0e0> (a java.lang.Object)\n        at org.apache.jackrabbit.core.CachingHierarchyManager.buildPath(CachingHierarchyManager.java:163)\n        at org.apache.jackrabbit.HierarchyManagerImpl.buildPath(HierarchyManagerImpl.java:296)\n[...]\n\nalthough i think that this sacktrace is valid (a thread holding a monitor waiting to lock it again) this scenario shows up a lot during stress-testing. i assume it's the JIT that messesup synchornization. \n\nthe fix is to remove the double monitor entry in this case.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-980",
        "summary": "Single quote in contains function is not parsed correctly",
        "description": "If there is a single quote in the contains statement the parser will throw an exception.\n\nExample:\n//element(*, nt:resource)[jcr:contains(., 'it''s fun')]\n\nThe LuceneQueryBuilder replaces the single quote with a double quote and hence the lucene fulltext query parser fails because there is a missing closing double quote. Not sure why this is done in the code, maybe this is a left over from an early JSR 170 draft.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1792",
        "summary": "jcr:frozenUuid does not contain jcr:content",
        "description": "When I store versionable files, I get problems retrieving the jcr:data from a custom node type.\n\nI am storing a node type:\n\nxrc:learningContent\n        pd: xrc:Keywords\n        pd: xrc:MimeType\n        pd: jcr:mixinTypes\n        pd: xrc:Description\n        pd: xrc:Language\n        pd: xrc:Creator\n        pd: jcr:created\n        pd: xrc:Title\n        pd: jcr:primaryType\nExtends: nt:resource\n        pd: jcr:uuid\n        pd: jcr:mixinTypes\n        pd: jcr:data\n        pd: jcr:encoding\n        pd: jcr:mimeType\n        pd: jcr:lastModified\n        pd: jcr:primaryType\n\nSo I commit the changes, then later pull up the version and get it's frozenNode.\n\nNode frozenNode = v.getNode(JcrConstants.JCR_FROZENNODE);\n\nAnd then I return all of the properties contained within:\n\nPropertyIterator pi = frozenNode.getProperties();\n                while (pi.hasNext()) {\n                    System.out.println(pi.nextProperty().getName());\n}\n\n\nAll that are returned are:\n\njcr:frozenUuid\njcr:uuid\njcr:frozenPrimaryType\njcr:frozenMixinTypes\njcr:primaryType\n\nHere is the frozen node type:\n\nnt:frozenNode\n        pd: *\n        pd: *\n        pd: jcr:frozenUuid\n        pd: jcr:uuid\n        pd: jcr:mixinTypes\n        pd: jcr:frozenPrimaryType\n        pd: jcr:frozenMixinTypes\n        pd: jcr:primaryType\n\n\n\nSo basically it would seem that the recursive copy inside the InternalFrozenNodeImpl is not working. But it seems that is not the case from the code trace I did. Add this to line 368 of InternalFrozenNodeImpl.java\n\nSystem.out.println(\"New node created. Props: \");\n        try {\n            PropertyState [] ps = node.getProperties();\n            for (PropertyState p : ps) {\n                System.out.println(p.getName());\n                System.out.println(p.toString());\n            }\n            NodeStateEx [] ns = node.getChildNodes();\n            for (NodeStateEx n : ns) {\n                System.out.println(n.getName());\n                System.out.println(n.toString());\n            }\n        } catch (ItemStateException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n\n\nAnd you will get the result:\n\n\nNew node created. Props:\n{http://www.jcp.org/jcr/1.0}uuid\norg.apache.jackrabbit.core.state.PropertyState@10dd791\n{http://www.jcp.org/jcr/1.0}frozenPrimaryType\norg.apache.jackrabbit.core.state.PropertyState@1c38291\n{http://www.jcp.org/jcr/1.0}frozenMixinTypes\norg.apache.jackrabbit.core.state.PropertyState@b12fbb\n{http://www.jcp.org/jcr/1.0}baseVersion\norg.apache.jackrabbit.core.state.PropertyState@b4d4b6\n{http://www.jcp.org/jcr/1.0}primaryType\norg.apache.jackrabbit.core.state.PropertyState@1f9045f\n{http://www.jcp.org/jcr/1.0}isCheckedOut\norg.apache.jackrabbit.core.state.PropertyState@18e16b5\n{http://www.jcp.org/jcr/1.0}frozenUuid\norg.apache.jackrabbit.core.state.PropertyState@174cb00\n{http://www.jcp.org/jcr/1.0}predecessors\norg.apache.jackrabbit.core.state.PropertyState@bb7c1b\n{http://www.jcp.org/jcr/1.0}data\norg.apache.jackrabbit.core.state.PropertyState@d10133\n{http://www.jcp.org/jcr/1.0}versionHistory\norg.apache.jackrabbit.core.state.PropertyState@1a5f001\n{http://www.jcp.org/jcr/1.0}encoding\norg.apache.jackrabbit.core.state.PropertyState@12fe3ef\n{http://www.jcp.org/jcr/1.0}mimeType\norg.apache.jackrabbit.core.state.PropertyState@11d92c8\n{http://www.jcp.org/jcr/1.0}lastModified\norg.apache.jackrabbit.core.state.PropertyState@8fb83a\nNew node created. Props:\n{http://www.xerceo.com/learn/jcr-1.0}Keywords\norg.apache.jackrabbit.core.state.PropertyState@18808f3\n{http://www.jcp.org/jcr/1.0}uuid\norg.apache.jackrabbit.core.state.PropertyState@397a4\n{http://www.jcp.org/jcr/1.0}frozenPrimaryType\norg.apache.jackrabbit.core.state.PropertyState@1d88ffd\n{http://www.xerceo.com/learn/jcr-1.0}Creator\norg.apache.jackrabbit.core.state.PropertyState@d5625b\n{http://www.xerceo.com/learn/jcr-1.0}Language\norg.apache.jackrabbit.core.state.PropertyState@12c70e6\n{http://www.xerceo.com/learn/jcr-1.0}Title\norg.apache.jackrabbit.core.state.PropertyState@a836b3\n{http://www.jcp.org/jcr/1.0}frozenMixinTypes\norg.apache.jackrabbit.core.state.PropertyState@19f273c\n{http://www.jcp.org/jcr/1.0}primaryType\norg.apache.jackrabbit.core.state.PropertyState@1c8e97d\n{http://www.jcp.org/jcr/1.0}frozenUuid\norg.apache.jackrabbit.core.state.PropertyState@15915a3\n{http://www.jcp.org/jcr/1.0}predecessors\norg.apache.jackrabbit.core.state.PropertyState@19ba907\n{http://www.xerceo.com/learn/jcr-1.0}MimeType\norg.apache.jackrabbit.core.state.PropertyState@763ca1\n{http://www.xerceo.com/learn/jcr-1.0}Description\norg.apache.jackrabbit.core.state.PropertyState@8687e8\n{http://www.jcp.org/jcr/1.0}versionHistory\norg.apache.jackrabbit.core.state.PropertyState@44ca0f\n{http://www.jcp.org/jcr/1.0}content\norg.apache.jackrabbit.core.version.NodeStateEx@2da721\n\nSo the new Node definately has these new properties.\n\nDo I have to somehow extend my frozenNode to work with this? Can anyone help me?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-830",
        "summary": "SetValueBinaryTest: some repositories have constraints on where binary properties can be set",
        "description": "For repositories that do only support binary properties in the form of jcr:content/jcr:data, the current configurability is not sufficient. To avoid more config params, I'd suggest to check for propertyName1 == \"jcr:data\" && node.hasNode(\"jcr:content\"), and in that case to automatically navigate down to the \"jcr:content\" child node.\n\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1316",
        "summary": "ID Field Descriptor is not inherited as is the case with UUID Field Descriptor",
        "description": "ID Field descriptor when defined in the base class in jcr-mapping is not inherited. The child class also has to define it again. A patch for the same is attached herewith. Patch is on similar lines of UUID Field Descriptor",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3025",
        "summary": "NPE in ConsolidatingChangeLog",
        "description": "The hasSNS(NodeId) method in ConsolidatingChangeLog throws an NPE when nodeId is null. It should rather return false. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1033",
        "summary": "webapp doesn't compile (use of enum keyword)",
        "description": "AbstractConfig.java and JNDIConfig.java have local variables named 'enum' that aren't allowed when using JDK5 or later compilers.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2584",
        "summary": "Switch from log4j to Logback",
        "description": "Logback (http://logback.qos.ch/) is a native SLF4J implementation and is in many ways superior to log4j (see http://logback.qos.ch/reasonsToSwitch.html). Most notably it includes package version information in logged stack traces (http://logback.qos.ch/reasonsToSwitch.html#packagingData), which can be really useful in many cases.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-945",
        "summary": "Use correct version number in repository descriptor",
        "description": "The repository descriptor 'jcr.repository.version' always shows 1.0-dev.\n\nThe value should reflect the current jackrabbit version.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-486",
        "summary": "Removed version is not invalidated",
        "description": "when a version is removed, it's internal represenation is not evicted from the cache. this can leed to unexpected behaviours. XATest.removeVersion() tests this. this also happens in a non-transactional environment.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1009",
        "summary": "JCR2SPI: add JNDI support",
        "description": "adding jndi support to jcr2spi was one of the improvements that came up during the f2f.\njulian volunteered to take a look at it.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1096",
        "summary": "Problems with custom nodes in journal",
        "description": "I have an application that uses custom node types and I am having problems in a clustered configuration.\n\nIssue 1: the following definition in a nodetype is incorrectly read from the journal:\n  + * (nt:hierarchyNode) version\n\nThe * is stored in the journal as _x002a_ since it should be a QName and it gets escaped.\nWhen read, the code ...core.nodetype.compact.CompactNodeTypeDefReader.doChildNodeDefinition does the following test:\n\n        if (currentTokenEquals('*')) {\n            ndi.setName(ItemDef.ANY_NAME); \n        } else {\n            ndi.setName(toQName(currentToken));\n        }\n\nSince currentToken is _x002a_ and not * toQName(currentToken) is called but it fails.\nI changed the test to:\n        if (currentTokenEquals('*') || currentTokenEquals(\"_x002a_\"))\n            ....\nand that fixes the problem.\n\nIssue 2: when storing a nodeType in the journal the superclass nt:base is not store, but when reading I get an error saying the node should be a subclass of nt:base.\n\nThe code in...core.nodetype.compact.CompactNodeTypeDefWriter.writeSupertypes skips nt:base when writing the node.\n\nWhen reading the nodetype definition from the journal the following exception is thrown:\n\nUnable to deliver node type operation: [{http://namespace/app/repository/1.0}resource] all primary node types except nt:base itself must be (directly or indirectly) derived from nt:base\n\nprobably because nt:base is not re-added to the nodetype definition\n\n ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2251",
        "summary": "WorkspaceManager.dispose() should wait until change feed thread is stopped",
        "description": "The WorkspaceManager currently only interrupts the change feed thread, but does not wait until it stops.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1467",
        "summary": "Hide ugly repository init code for OCM",
        "description": "Hide repository namespace registration and ocm:discriminator node type registration in implementation of OCM",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1563",
        "summary": "Data Store: UTFDataFormatException when using large minRecordLength",
        "description": "If using a value larger than 33000 for minRecordLength, and then trying to store a value with 33000 bytes, the following exception is thrown: UTFDataFormatException. The reason is that values are serialized using DataOutputStream.writeUTF. There is size limitation of 65 K when using this method. Small entries are hex encoded, and there is a prefix, so the limitation for minRecordLength should be 32000.\n\nThis is a problem for both FileDataStore and DbDataStore.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1193",
        "summary": "war missing jcr jar ",
        "description": "dropping the latest war (from latest svn) presents with this error when i point my browser to http://localhost:8080/jackrabbit-webapp-1.4-SNAPSHOT/. Simple solution is to make sure the jcr-1.0.jar is added to the generated war.\n\norg.apache.jasper.JasperException: Unable to compile class for JSP: \n\nAn error occurred at line: 1 in the generated java file\nThe type javax.jcr.Repository cannot be resolved. It is indirectly referenced from required .class files\n\nAn error occurred at line: 9 in the generated java file\nThe import javax.jcr.Repository cannot be resolved\n\nAn error occurred at line: 27 in the jsp file: /index.jsp\nRepository cannot be resolved to a type\n24: </head>\n25: <body style=\"font-family:monospace\">\n26: <%\n27:     Repository rep;\n28:     try {\n29:         rep = RepositoryAccessServlet.getRepository(pageContext.getServletContext());\n30:     } catch (Throwable e) {\n\n\nAn error occurred at line: 84 in the jsp file: /index.jsp\nRepository.REP_VENDOR_URL_DESC cannot be resolved to a type\n81:     </li>\n82: </ol>\n83: <p/>\n84: <hr size=\"1\"><em>Powered by <a href=\"<%= rep.getDescriptor(Repository.REP_VENDOR_URL_DESC) %>\"><%= rep.getDescriptor(Repository.REP_NAME_DESC)%></a> version <%= rep.getDescriptor(Repository.REP_VERSION_DESC) %>.</em>\n85: </body>\n86: </html>\n\n\nAn error occurred at line: 84 in the jsp file: /index.jsp\nRepository.REP_NAME_DESC cannot be resolved to a type\n81:     </li>\n82: </ol>\n83: <p/>\n84: <hr size=\"1\"><em>Powered by <a href=\"<%= rep.getDescriptor(Repository.REP_VENDOR_URL_DESC) %>\"><%= rep.getDescriptor(Repository.REP_NAME_DESC)%></a> version <%= rep.getDescriptor(Repository.REP_VERSION_DESC) %>.</em>\n85: </body>\n86: </html>\n\n\nAn error occurred at line: 84 in the jsp file: /index.jsp\nRepository.REP_VERSION_DESC cannot be resolved to a type\n81:     </li>\n82: </ol>\n83: <p/>\n84: <hr size=\"1\"><em>Powered by <a href=\"<%= rep.getDescriptor(Repository.REP_VENDOR_URL_DESC) %>\"><%= rep.getDescriptor(Repository.REP_NAME_DESC)%></a> version <%= rep.getDescriptor(Repository.REP_VERSION_DESC) %>.</em>\n85: </body>\n86: </html>\n\n\nStacktrace:\n\torg.apache.jasper.compiler.DefaultErrorHandler.javacError(DefaultErrorHandler.java:92)\n\torg.apache.jasper.compiler.ErrorDispatcher.javacError(ErrorDispatcher.java:330)\n\torg.apache.jasper.compiler.JDTCompiler.generateClass(JDTCompiler.java:423)\n\torg.apache.jasper.compiler.Compiler.compile(Compiler.java:308)\n\torg.apache.jasper.compiler.Compiler.compile(Compiler.java:286)\n\torg.apache.jasper.compiler.Compiler.compile(Compiler.java:273)\n\torg.apache.jasper.JspCompilationContext.compile(JspCompilationContext.java:566)\n\torg.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:317)\n\torg.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:320)\n\torg.apache.jasper.servlet.JspServlet.service(JspServlet.java:266)\n\tjavax.servlet.http.HttpServlet.service(HttpServlet.java:803)\n\nnote The full stack trace of the root cause is available in the Apache Tomcat/6.0.14 logs.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-378",
        "summary": "jackrabbit-server.war is missing the slf4j-log4j12 library",
        "description": "Reported by Martin Perez:\n\nBut I found a bug on the .war file. It is missing the slf4j-log4j12-1.0.jar. It's in someway tricky to detect it because if you do not include it a ClassNotFoundException will be thrown but poiting to the JCR class with the log statement. Anyways, if you include the .jar file on the WEB-INF/lib directory, then the exception goes to exception's hell.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2021",
        "summary": "WebDAV: add support for DAV:lockroot",
        "description": "see http://www.webdav.org/specs/rfc4918.html#ELEMENT_lockroot\n\nthis element has been added with RFC 4918.\nadd constant to the DAVConstants and extend ActiveLock interface accordingly.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2023",
        "summary": "WorkspaceInfo.dispose() does not deregister SharedItemStateManager from virtual item state providers",
        "description": "Automatic disposal of idle workspaces frees unused workspaces but corresponding SharedItemStateManager (and releated PersistenceManager) is still kept in memory referenced by virtual item state providers,  this can lead to memory leaks.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-419",
        "summary": "Request for other RMI binding options in RepositoryStartupServlet",
        "description": "The current deployment options for RepositoryStartupServlet bind a local repository to JNDI and/or register a remote ServerRepository via RMI using an RMIServerSocketFactory and LocateRegistry. \n\nThe LocateRegistry mechanism does not appear to work by default in a Weblogic environment.\n\nI would like to request the option of binding a ServerRepository in registerRMI() to JNDI using the servlets current context instead of attempting LocateRegistry.createRegistry() and then LocateRegistry.getRegistry(). This JNDI binding option could use a different name so as to not interfere with the JNDI binding attempted in registerJNDI().\n\nFor example, if requested in the web.xml config, registerRMI() could bind the following using it's reference to a ServerRepository:\n\n      Context ctx = new InitialContext();\n      ctx.bind(repositoryName + \"Remote\", remote);\n\nThis allows for easy remote access using weblogic's native T3 protocol using the following on the client with:\n\n      Context ctx = new InitialContext(); // with say -Djava.naming.provider.url and -Djava.naming.factory.initial set \n      Object ref = ctx.lookup(repositoryName + \"Remote\");\n      LocalAdapterFactory laf = new ClientAdapterFactory();\n      Repository remote = laf.getRepository((RemoteRepository) ref);\n\nFrom the initial tests I have done this appears to work well inside the Weblogic container. \n\n- Paul.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1006",
        "summary": "StackOverflowError if too many versions of a node are created",
        "description": "In org.apache.jackrabbit.core.version.VersionIteratorImpl addVersion() is called recursively which can cause StackOverflowErrors if there are too many versions.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-541",
        "summary": "NPE in PredefinedNodeTypeTest.getPropertyDefSpec",
        "description": "Occurs when PropertyDefinition.getValueConstraints returns null, which is allowed by the spec.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-439",
        "summary": "Workspace.clone() fails the second time, if cloning referenceables",
        "description": "the following testcode fails with the 2nd clone. please note, that if the 'folder' node is not made\nreferenceable, the test passes (copied an adapted from test in WorkspaceCloneTest).\n\n    public void testCloneNodesTwice() throws RepositoryException {\n        // clone referenceable node below non-referenceable node\n        String dstAbsPath = node2W2.getPath() + \"/\" + node1.getName();\n\n        Node folder = node1.addNode(\"folder\");\n        folder.addMixin(\"mix:referenceable\");\n        node1.save();\n        workspaceW2.clone(workspace.getName(), node1.getPath(), dstAbsPath, true);\n        workspaceW2.clone(workspace.getName(), node1.getPath(), dstAbsPath, true);\n\n        // there should not be any pending changes after clone\n        assertFalse(superuserW2.hasPendingChanges());\n    }\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1727",
        "summary": "HTMLTextExtractor modifying UTF-8 encoded String",
        "description": "Trying to extract an HTML that is UTF-8 encoded is modifying the UTF-8 special char (like \u00e1, \u00e9, \u00f3, \u00e3 etc).\n\nThis cause a wrong search, because lucene use this extractor to index content.\n\nSee attachments for an example of the problem.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-114",
        "summary": "Suggestion regarding NodeImpl and PropertyImpl in jackrabbit.core",
        "description": "Both NodeImpl and PropertyImpl contain in their respective setProperty/setValue (respectively) initial validation checks, that is indentical across the various\nvariants of each and could possibly in either case be place in a separate method.\n\nin NodeImpl.setProperty (also: addMixin, removeMixin, orderBefore):\n\n- sanityCheck\n- is-parent-checked-out\n- is-not-protected (missing for setProperty ???)\n- is-parent-not-locked\n\nin PropertyImpl.setValue:\n\n- sanityCheck\n- is-parent-checked-out\n- is-not-protected \n- is-value-compatible-with-multivalue-definition (NOTE: check opposite for setting single\n  or multiple values)\n- is-parent-not-locked\n\n\nSecond, i'm never sure, in which case ChildNode, ChildProperty is prefered \nover Node/Property (as present in the jcr api)...\n\nregards\nangela\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1432",
        "summary": "Saving a node deletion that has been modified externally throws a ConstraintViolationException",
        "description": "Deleting a node \"a\" and saving its parent might result in a ConstraintViolationException if node \"a\" has been modified externally, where an InvalidItemStateException with message \"item x has been modified externally\" would be more intuitive.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-864",
        "summary": "Bug in UtilDateTypeConverterImpl",
        "description": "In this converter following line is used:\nreturn this.getValueFactory().createValue(((java.util.Date) propValue).getTime());\nbut propValue must be converted to java.util.Calendar, not into long! ValueFactory than converts to LongValue not DateValue as expected.\n\nFollowing code works OK:\nfinal long timeInMilis = ((java.util.Date) propValue).getTime();\nfinal Calendar calendar = Calendar.getInstance();\ncalendar.setTimeInMillis(timeInMilis);\nreturn this.getValueFactory().createValue( calendar );\n\nbut I dont know better Date-> Calendar conversion.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1925",
        "summary": "CVE-2009-0026: Cross site scripting issues in webapp",
        "description": "Some of the jackrabbit-webapp forms don't properly escape user input when displaying it in the resulting HTML page. This leads to potential cross site scripting issues. For example:\n\n    search.jsp?q=%25%22%3Cscript%3Ealert(1)%3C/script%3E\n    swr.jsp?q=%25\"<script>alert(1)</script>&swrnum=1\n\nThe CVE id for this issue is CVE-2009-0026. This issue was reported by the Red Hat Security Response Team.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1924",
        "summary": "ms-sql tablespace support for FileSystem and PersistenceManager",
        "description": "Trunk and released version 1.5.0 does not have complete support for ms-sqlserver tablespaces.  This patch was originally submitted via JCR-1295 but was not applied to the 1.4 trunk.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-637",
        "summary": "Multiple namespace definitions in CND prevent definition of node type without child nodes",
        "description": "The BNF in http://jackrabbit.apache.org/api-1/org/apache/jackrabbit/core/nodetype/compact/CompactNodeTypeDefReader.html\ndefines:\n\n[...]\ncnd ::= {ns_mapping | node_type_def}\n[...]\n\nso multiple namespace definitions should not affect the node type definitions.\n\nHowever, the following CND definition will fail:\n\n<namespace= 'http://www.mynamespace.co.uk/namespace'>\n<nt = 'http://www.jcp.org/jcr/nt/1.0'>\n[namespace:document] > nt:file\n   - namespace:name (string) mandatory\n\n<namespace= 'http://www.mynamespace.co.uk/namespace'>\n<nt = 'http://www.jcp.org/jcr/nt/1.0'>\n[namespace:document2] > nt:file\n   - namespace:name (string) mandatory\n\n\nRemove the second set of namespace definitions, and all's well:\n\n<namespace= 'http://www.mynamespace.co.uk/namespace'>\n<nt = 'http://www.jcp.org/jcr/nt/1.0'>\n[namespace:document] > nt:file\n   - namespace:name (string) mandatory\n\n[namespace:document2] > nt:file\n   - namespace:name (string) mandatory",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1976",
        "summary": "Text.unescape() should should preserve 'unicode' characters",
        "description": "When an input to Text.unescape() contains characters > \\u00ff, the most significant byte is lost resulting in garbled output. The unescape() function should preserve such characters in order to be useful to decode Internationalized Resource Identifiers (RFC 3987). ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2367",
        "summary": "RepositoryCopier does not copy open-scoped Locks",
        "description": "If you use the RepositoryCopier to make a backup of your repository and you have open-scoped (not session scoped) locks, these locks will not be copied. If you try to restore your copy of the repository all locks are gone.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-885",
        "summary": "BundlePersistenceManager.externalBLOBs can not be configured",
        "description": "If you try to configure the property externalBLOBs through the workspace.xml it does not work.\nThe BundlePersistenceManager has not Method setExternalBLOBs(boolean externalBLOBs) so it can not be configured\nbecause its not bean conform. See the DatabasePersistenceManager which has such a Method\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-565",
        "summary": "Refactor ObservationManagerFactory",
        "description": "The current o.a.j.core.observation.ObservationManagerFactory class has two main responsibilities:\n\n    1) Create new ObservationManagerImpl instances as an observation manager factory\n    2) Manage event consumers and dispatch events within a workspace\n\nThese two responsibilities are quite unrelated and the factory responsibility essentially boils down to the following method that is only ever invoked within WorkspaceImpl.getObservationManager():\n\n    public ObservationManagerImpl createObservationManager(SessionImpl session, ItemManager itemMgr) {\n        return new ObservationManagerImpl(this, session, itemMgr);\n    }\n\nTo simplify the design I'd inline this method and rename ObservationManagerFactory to ObservationDispatcher to better reflect the one remaining responsibility.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-705",
        "summary": "PdfTextExtractor does not close temp file in case of an error",
        "description": "If PDF parsing fails in PDFParser.parse() a temp file is not closed and results in an open file handle.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1528",
        "summary": "CLONE -ManageableCollectionUtil doesn't support Maps",
        "description": "ManageableCollectionUtil has two getManageableCollection methods, which do not currently return a ManageableCollection which wraps Maps. \n\nManagedHashMap already exists in the codebase which I assume was created for this purpose, so both getManageableCollection methods could be modified so that they do something like:\n\n            if (object instanceof Map){\n                return new ManagedHashMap((Map)object);\n            }\n\n\nAn alternative solution might be to modify the JCR mapping to support explicitly defining the 'ManagedXXX' class.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1560",
        "summary": "Data Store: Oracle fails to create the table",
        "description": "When using an Oracle database, the following exception occurs when trying to create the table: ORA.00902: invalid datatype\nThe problem is that Oracle doesn't support the data type BIGINT. Instead, LONG should be used.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2828",
        "summary": "InternalVersionManager deadlock",
        "description": "The changes in JCR-2753 exposed the InternalVersionManager classes to the following deadlock scenario:\n\n   java.lang.Thread.State: WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\t- waiting on <0x0000000085edb5a0> (a org.apache.jackrabbit.core.state.DefaultISMLocking)\n\tat java.lang.Object.wait(Object.java:485)\n\tat org.apache.jackrabbit.core.state.DefaultISMLocking.acquireReadLock(DefaultISMLocking.java:92)\n\t- locked <0x0000000085edb5a0> (a org.apache.jackrabbit.core.state.DefaultISMLocking)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerBase.acquireReadLock(InternalVersionManagerBase.java:192)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerImpl.getItem(InternalVersionManagerImpl.java:324)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerBase.createInternalVersionItem(InternalVersionManagerBase.java:761)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerImpl.getItem(InternalVersionManagerImpl.java:329)\n\t- locked <0x0000000085edb770> (a org.apache.commons.collections.map.ReferenceMap)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerBase.getVersionHistory(InternalVersionManagerBase.java:130)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerImpl.getVersionHistory(InternalVersionManagerImpl.java:70)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerImpl$4.run(InternalVersionManagerImpl.java:415)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerImpl$DynamicESCFactory.doSourced(InternalVersionManagerImpl.java:720)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerImpl.checkin(InternalVersionManagerImpl.java:407)\n\tat org.apache.jackrabbit.core.version.InternalXAVersionManager.checkin(InternalXAVersionManager.java:251)\n\tat org.apache.jackrabbit.core.version.VersionManagerImplBase.checkoutCheckin(VersionManagerImplBase.java:190)\n\tat org.apache.jackrabbit.core.VersionManagerImpl.access$100(VersionManagerImpl.java:72)\n\tat org.apache.jackrabbit.core.VersionManagerImpl$1.perform(VersionManagerImpl.java:121)\n\tat org.apache.jackrabbit.core.VersionManagerImpl$1.perform(VersionManagerImpl.java:114)\n\tat org.apache.jackrabbit.core.session.SessionState.perform(SessionState.java:200)\n\tat org.apache.jackrabbit.core.VersionManagerImpl.perform(VersionManagerImpl.java:95)\n\tat org.apache.jackrabbit.core.VersionManagerImpl.checkin(VersionManagerImpl.java:114)\n\tat org.apache.jackrabbit.core.VersionManagerImpl.checkin(VersionManagerImpl.java:100)\n\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerImpl.getItem(InternalVersionManagerImpl.java:327)\n\t- waiting to lock <0x0000000085edb770> (a org.apache.commons.collections.map.ReferenceMap)\n\tat org.apache.jackrabbit.core.version.InternalXAVersionManager.getItem(InternalXAVersionManager.java:442)\n\tat org.apache.jackrabbit.core.version.InternalVersionManagerBase.getVersionHistory(InternalVersionManagerBase.java:130)\n\tat org.apache.jackrabbit.core.version.InternalXAVersionManager.getVersionHistory(InternalXAVersionManager.java:58)\n\tat org.apache.jackrabbit.core.version.VersionHistoryImpl.getInternalVersionHistory(VersionHistoryImpl.java:78)\n\tat org.apache.jackrabbit.core.version.VersionHistoryImpl.isSame(VersionHistoryImpl.java:278)\n\tat org.apache.jackrabbit.core.version.VersionHistoryImpl.checkOwnVersion(VersionHistoryImpl.java:326)\n\tat org.apache.jackrabbit.core.version.VersionHistoryImpl.getVersionLabels(VersionHistoryImpl.java:218)\n\nThe problem is the ReferenceMap synchronization (object 0x0000000085edb770) that now interferes with the more general read/write locking mechanism.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1564",
        "summary": "JSR 283 namespace handling",
        "description": "JSR 283 makes namespace handling more flexible and user-friendly (less exceptions, no unexpected mapping changes during a session, etc.). The changes are mostly compliant with JSR 170, so we can implement them already for Jackrabbit 1.x.\n\nTODO: JSR 283 namespace handling + related TCK tests",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-620",
        "summary": "Workspace.getImportHandler() doesn't handle namespace declarations in document view when they are reported as attributes",
        "description": "XMIDocumentViewImportTest is copy of DocumentViewImportTest EXCEPT that createSimpleDocument is overridden.\n\nNew simple document is typical of XMI serializations from Eclipse Modeling Framework (EMF).\n\nFour out of eight tests fail due to bad uri    Trace below:\n\njavax.jcr.NamespaceException: www.apache.org/jackrabbit/test/namespaceImportTest7: is not a registered namespace uri.\n\tat org.apache.jackrabbit.core.NamespaceRegistryImpl.getPrefix(NamespaceRegistryImpl.java:378)\n\tat org.apache.jackrabbit.core.LocalNamespaceMappings.getPrefix(LocalNamespaceMappings.java:193)\n\tat org.apache.jackrabbit.core.SessionImpl.getNamespacePrefix(SessionImpl.java:1307)\n\tat org.apache.jackrabbit.test.api.XMIDocumentViewImportTest.checkImportSimpleXMLTree(XMIDocumentViewImportTest.java:176)\n\tat org.apache.jackrabbit.test.api.XMIDocumentViewImportTest.performTests(XMIDocumentViewImportTest.java:154)\n\tat org.apache.jackrabbit.test.api.XMIDocumentViewImportTest.doTestImportXML(XMIDocumentViewImportTest.java:119)\n\tat org.apache.jackrabbit.test.api.XMIDocumentViewImportTest.testWorkspaceImportXml(XMIDocumentViewImportTest.java:70)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat junit.framework.TestCase.runTest(TestCase.java:154)\n\tat junit.framework.TestCase.runBare(TestCase.java:127)\n\tat junit.framework.TestResult$1.protect(TestResult.java:106)\n\tat junit.framework.TestResult.runProtected(TestResult.java:124)\n\tat junit.framework.TestResult.run(TestResult.java:109)\n\tat junit.framework.TestCase.run(TestCase.java:118)\n\tat org.apache.jackrabbit.test.AbstractJCRTest.run(AbstractJCRTest.java:393)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:208)\n\tat junit.framework.TestSuite.run(TestSuite.java:203)\n\tat org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-979",
        "summary": "Extend apache parent pom for Apache wide configuration",
        "description": "Apache wide config is published in the apache parent pom, please use",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-316",
        "summary": "Fixed README.txt on textfilters project",
        "description": "- Fixed a little mistake: changed org.apache.jackrabbit.core.query..RTFTextFilter to org.apache.jackrabbit.core.query.RTFTextFilter\n\n- Added the OpenOfficeTextFilter to the sample configuration line.",
        "label": "NUG",
        "classified": "TASK",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2149",
        "summary": "Data Store: remove kill switch \"InternalValue.USE_DATA_STORE\"",
        "description": "There is still a \"kill switch\" (public static final boolean USE_DATA_STORE) in the class org.apache.jackrabbit.core.value.InternalValue. In version 2.0 this constant should be removed. Also, the system property \"org.jackrabbit.useDataStore\" will no longer be used. \n\nIt is still possible to disable the DataStore (don't include a DataStore configuration in repository.xml).",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-821",
        "summary": "Document View Import: ISO 9075-encoded element/attribute names may lead to illegal node/property names ",
        "description": "reported by sridhar raman on the users-list:\n\nimporting the following xml document leads to a node of name \"abc [1]\" which is illegal:\n\n<?xml version=\"1.0\"?>\n<abc_x0020__x005B_1_x005D_ foo=\"bar\"/>\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-122",
        "summary": "cannot PUT changes to a resource in the simple webdav server",
        "description": "when using the simple webdav server to PUT a resource, the \"versionable\" mixin node type is assigned to the new node without regard to whether the node type is already assigned to the node. this causes PUT requests that change existing resources to fail with 403 errors.\n\nthe fix is to augment AddMixinCommand to not try to add the mixin node type if the node already has it.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1380",
        "summary": "CachingHierarchyManager synchronization problem",
        "description": "The method CachingHierarchyManager.resolveNodePath(..) does not synchronize on the cacheMonitor object. This can result in an endless loop in cache(), in NullPointerException or in other unexpected behavior in CachingHierarchyManager.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2064",
        "summary": "Add new JSR283 features to CND reader/writer",
        "description": "the current CND parser(s) and writers do not support the new options specified by JSR283",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-3216",
        "summary": "When fetching node ids in checks for the checker all queries should use the same ordering",
        "description": "The \"bundleSelectAllIdsSQL\" query and the \"bundleSelectAllIdsFromSQL\" should use the same ordering.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2045",
        "summary": "Jcr-Server: missing-auth-mapping init parameter should have option for GuestCredential login",
        "description": "the missing-auth-mapping parameter of the servlets contained in jcr-server is defined as follows:\n\n             <param-value>anonymous:anonymous</param-value>\n             <description>\n                 Defines how a missing authorization header should be handled.\n                 1) If this init-param is missing, a 401 response is generated.\n                    This is suiteable for clients (eg. webdav clients) for which\n                    sending a proper authorization header is not possible if the\n                    server never sent a 401.\n                 2) If this init-param is present with an empty value,\n                    null-credentials are returned, thus forcing an null login\n                    on the repository.\n                 3) If this init-param has a 'user:password' value, the respective\n                    simple credentials are generated.\n             </description>\n\nJCR 2.0 introduces GuestCredentials used to obtain a \"anonymous\" session.\n\nTherefore we should probably extend/modify the missing-auth-param in a way that\nallows to distinguish between\n\n- null-login\n- guest login\n\nin case of missing authorization header.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1405",
        "summary": "SPI: Introduce NodeInfo.getChildInfos()",
        "description": "Improvement suggested by Marcel:\n\nChildInfo is basically a stripped down NodeInfo. With little effort it would even be possible to have NodeInfo extends ChildInfo. Not sure how useful that is, but since we don't have that inheritance in code and at the same time nearly a 100% overlap it makes me suspicious.\n\nHere's another idea:\n\nintroduce a method ChildInfo[] NodeInfo.getChildInfos(). The method either returns:\n\n- all child infos, which also gives the correct number of child nodes. this may also mean that an empty array is returned to indicate there are no child nodes.\n- null, to indicate that there are *lots* of child nodes and the method RepositoryService.getChildInfos() with the iterator should be used. \n\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-349",
        "summary": "New node type namespaces should be automatically registered",
        "description": "A user currently needs to explicitly register any new namespaces used in new node types before registering the node types. See for example the problem on the mailing list:\n\n    http://mail-archives.apache.org/mod_mbox/incubator-jackrabbit-dev/200603.mbox/%3c1142091097.13136.0.camel@localhost.localdomain%3e\n\nThe node type registration should be changed so that new namespaces are automatically registered.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2216",
        "summary": "Append-only index updates",
        "description": "Currently index updates modify some existing files. This is troublesome in scenarios like a backup or when an index will be shared in a cluster (though this is not yet the case).\n\nRequirements are:\n\n- index segments need a custom (lucene) IndexDeletionPolicy to keep index commits for a given time.\n- index segments are not only referenced by their name, but also with their generation\n- the segments file must now also record the generation of a segment. the file itself must be generational itself.\n- purging of outdated index segment commits\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1852",
        "summary": "session.exportDocumentView() does not work with jaxb 2.1.x  UnmarshallerHandler",
        "description": "I tried to update my project from Jackrabbit 1.4 to 1.5 and found following error, that is critical for my app.\nProject uses Import/Export features of JCR and JAXB to map XML from JCR to java objects.\n\nexportDocumentView() works with streams when I call it like this:\n\n              Unmarshaller umr = getUnmarshaller();\n        ...\n                fo = new FileOutputStream(\"/tmp/export-node.xml\");\n                jcrs.exportDocumentView(path,fo , false, false);\n                fi = new FileInputStream(\"/tmp/export-node.xml\");\n                umr.unmarshal(new InputSource(fi));    \n\nBut it does not work when I call it using SAX event handler:\n\n            UnmarshallerHandler ctxh = umr.getUnmarshallerHandler();\n             jcrs.exportDocumentView(path, ctxh, false, false);\n\ngiving following exception:\n\njava.lang.NullPointerException\n        at org.xml.sax.helpers.AttributesImpl.getIndex(AttributesImpl.java:203)\n        at com.sun.xml.bind.v2.runtime.unmarshaller.InterningXmlVisitor$AttributesImpl.getIndex(InterningXmlVisitor.java:112)\n        at com.sun.xml.bind.v2.runtime.unmarshaller.XsiNilLoader.selectLoader(XsiNilLoader.java:62)\n        at com.sun.xml.bind.v2.runtime.unmarshaller.ProxyLoader.startElement(ProxyLoader.java:53)\n        at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallingContext._startElement(UnmarshallingContext.java:449)\n        at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallingContext.startElement(UnmarshallingContext.java:427)\n        at com.sun.xml.bind.v2.runtime.unmarshaller.InterningXmlVisitor.startElement(InterningXmlVisitor.java:71)\n        at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:137)\n        at org.apache.jackrabbit.commons.xml.Exporter.startElement(Exporter.java:438)\n        at org.apache.jackrabbit.commons.xml.DocumentViewExporter.exportNode(DocumentViewExporter.java:76)\n        at org.apache.jackrabbit.commons.xml.Exporter.exportNode(Exporter.java:298)\n        at org.apache.jackrabbit.commons.xml.Exporter.exportNodes(Exporter.java:214)\n        at org.apache.jackrabbit.commons.xml.DocumentViewExporter.exportNode(DocumentViewExporter.java:77)\n        at org.apache.jackrabbit.commons.xml.Exporter.exportNode(Exporter.java:298)\n        at org.apache.jackrabbit.commons.xml.Exporter.exportNodes(Exporter.java:214)\n        at org.apache.jackrabbit.commons.xml.DocumentViewExporter.exportNode(DocumentViewExporter.java:77)\n        at org.apache.jackrabbit.commons.xml.Exporter.exportNode(Exporter.java:298)\n        at org.apache.jackrabbit.commons.xml.Exporter.export(Exporter.java:144)\n        at org.apache.jackrabbit.commons.AbstractSession.export(AbstractSession.java:461)\n        at org.apache.jackrabbit.commons.AbstractSession.exportDocumentView(AbstractSession.java:241)\n        at ua.org.dg.semaril.helpers.AbstractTypeResolver.getContent(AbstractTypeResolver.java:31\n\nVersion 1.4. works fine.\n\nJukka, please check your changes to  org.apache.jackrabbit.commons.xml.Exporter.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-747",
        "summary": "TCK: observation tests are too restrictive",
        "description": "The basic sequence in all observation tests is:\n\n1) add listener\n2) modify workspace\n3) remove listener\n4) wait for events on listener\n\nThis sequence forces an implementation to maintain a logical order for listener registrations and content changes. In the light of the asynchronous nature of observation events this seems too restrictive for certain implementations.\n\nThe sequence should be changed to:\n\n1) add listener\n2) modify workspace\n3) wait for events on listener\n4) remove listener\n\nWhich is also more intuitive from a user perspective.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-3129",
        "summary": "It should be possible to create a non-transient Repository inside the JCARepositoryManager",
        "description": "With JCR-2555 jukka changed the code to create a Repository with the RepositoryFactory mechanism.\nIt should be possible to create a non-transient Repository\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3120",
        "summary": "Change log level in UserManagerImpl#getAuthorizable(NodeImpl) and UserImporter#handlePropInfo",
        "description": "This is current implementation:\n\nAuthorizable getAuthorizable(NodeImpl n) throws RepositoryException {\n        Authorizable authorz = null;\n        if (n != null) {\n            String path = n.getPath();\n            if (n.isNodeType(NT_REP_USER) && Text.isDescendant(usersPath, path)) {\n                authorz = createUser(n);\n            } else if (n.isNodeType(NT_REP_GROUP) && Text.isDescendant(groupsPath, path)) {\n                authorz = createGroup(n);\n            } else {\n                /* else some other node type or outside of the valid user/group\n                   hierarchy  -> return null. */\n                log.debug(\"Unexpected user nodetype \" + n.getPrimaryNodeType().getName());\n            }\n        } /* else no matching node -> return null */\n        return authorz;\n    }\n\n\nIt seems that 'else' branch can be improved, at least by increasing log level. But I think, that best way is to throw exception.\nCurrent message can also be misleading, in case when user type is correct but check Text.isDescendant fails.\n\nAbove method is called from within UserImporter#handlePropInfo\n\n...\nAuthorizable a = userManager.getAuthorizable(parent);\nif (a == null) {\n     log.debug(\"Cannot handle protected PropInfo \" + protectedPropInfo + \". Node \" + parent + \" doesn't represent a valid Authorizable.\");\n     return false;\n} \n....\n\nHere again log level is debug. Because at this point we have return statement, property 'principalName' is not set, and if we try to save session following exception will be thrown:\n\njavax.jcr.nodetype.ConstraintViolationException: /home/public/users/b/bb2: mandatory property {internal}password does not exist\n     at org.apache.jackrabbit.core.ItemSaveOperation.validateTransientItems(ItemSaveOperation.java:537)\n     at org.apache.jackrabbit.core.ItemSaveOperation.perform(ItemSaveOperation.java:216)\n     at org.apache.jackrabbit.core.session.SessionState.perform(SessionState.java:200)\n     at org.apache.jackrabbit.core.ItemImpl.perform(ItemImpl.java:91)\n     at org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:329)\n    ...\n \n\nSo if the log level is not set to 'debug' it is not obvious why mentioned property is missing. Use case and root cause is that 'path' (/home/public/users/b/bb2)  is not descendant of 'usersPath' (/home/users).\n\nRegards,\nMiroslav",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2616",
        "summary": "ItemInfoCacheImpl.getNodeInfo() and .getPropertyInfo() might not clear all relevant entries",
        "description": "ItemInfoCacheImpl.getNodeInfo() and .getPropertyInfo() remove the retrieved entry from the cache.\n\nsince entries might be cached by id AND path, entires identified by path are not removed from the cache if they're retrieved by id.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2162",
        "summary": "Data Store: garbage collection continues when the session is closed",
        "description": "Currently, the data store garbage collection continues even if the session is closed.\n\nThis can cause problems.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2121",
        "summary": "Use java.util.UUID",
        "description": "Replace the use of org.apache.jackrabbit.uuid.UUID with the new java.util.UUID class introduced in Java 5.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-290",
        "summary": "NodeTypeRegistry.registerNodeType(NodeTypeDef) does not verify that the referenced namespaces are registered",
        "description": "currently it's possible to register a node type using a defintion that contains references to unregistered namespaces.\n\nusing such a  node type in content would lead to unpredictable results.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2781",
        "summary": "FileDataStore performance improvements",
        "description": "As seen in JCR-2695, the FileDataStore is slow on some file system. \n\nSome file operations such as File.exists() or File.isDirectory() can be replaced with try / catch, or by inspecting the return value of a previous method (File.renameTo).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1929",
        "summary": "The 1.5.0 webapp points to 1.4 javadocs",
        "description": "There's a \"Jackrabbit API\" link on the Jackrabbit webapp 1.5.0 that points to http://jackrabbit.apache.org/api/1.4/. It should be updated to point to http://jackrabbit.apache.org/api/1.5/.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-2505",
        "summary": "High memory usage on node with multi-valued string properties",
        "description": "Multi-valued string properties are tokenized per value, which may consume quite some memory when there are lots of small values in on a property. The memory footprint is 2k per value, because each value is tokenized with a separate tokenizer instance. That tokenizer uses a stream buffer of 2k bytes.\n\nInstead the values should be concatenated (whitespace separated) and then tokenized in one go.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-775",
        "summary": "\"JCR levels\" link on http://jackrabbit.apache.org/doc/index.html broken",
        "description": "The \"JCR levels\" link on the Jackrabbit home page is broken.\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-1627",
        "summary": "pom.xml in sandbox/spi has wrong scm url",
        "description": "the pom in sandbox/spi has the wrong scm url.\nYou can see the pom here:\nhttp://svn.apache.org/repos/asf/jackrabbit/sandbox/spi/pom.xml\n\nIt probably should be:\n<scm>\n    <connection>scm:svn:http://svn.apache.org/repos/asf/jackrabbit/sandbox/spi </connection>\n    <developerConnection>scm:svn:https://svn.apache.org/repos/asf/jackrabbit/sandbox/spi </developerConnection>\n    <url>http://svn.apache.org/viewvc/jackrabbit/sandbox/spi </url>\n</scm>\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-1607",
        "summary": "Add a NamespaceHelper in jcr-commons",
        "description": "We have a number of code snippets in jackrabbit-core and many JCR clients that do something like the following:\n\n* get the prefix/URI for a given namespace URI/prefix without throwing an exception if the namespace is not found (return null instead)\n* get a Map containing all current namespace prefix->URI mappings\n* get the prefixed name for a given URI + local name pair in a given session (without a dependency to the SPI)\n* safely register a given namespace (don't throw if the namespace is already registered, automatically select an unused prefix if needed, etc.)\n\nI'd like to introduce a NamespaceHelper class in jcr-commons to cover such common code.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-751",
        "summary": "Update Jackrabbit API JavaDoc on http://jackrabbit.apache.org",
        "description": "Update the JavaDoc on http://jackrabbit.apache.org to the latest release version of jackrabbit.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "TASK"
    },
    {
        "key": "JCR-2354",
        "summary": "Remove double quote as illegal XPathSearchChar from helper method in Text",
        "description": "Since Lucene 2.4 the double quote character at the end of a search term is no more illegal and must not be escaped",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1862",
        "summary": "jcr2spi: transient removal of mandatory item throws ConstraintViolationException",
        "description": "reported by tobi:\n\nthe transient removal of a mandatory (non-protected) item immediately fails. \ninstead the check should be postponed until the save() call, since it would be perfectly legal to remove the mandatory item and then re-add it.\n\nsuggested fix:\nItemStateValidator#checkRemoveConstraints should only check for protection and ignore mandatory definitions.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-338",
        "summary": "Query Builder and jcr:deref problem. Can't add predicate after jcr:deref",
        "description": "Cannot add a predicate (like [@property = 'value'] after a jcr:deref function.\nThe query builder throws an \"InvalidQueryException: Unsupported location for jcr:deref()\".\n\nSo for example, the query :\n\n//element(*,nt:category)[@member]/jcr:deref(@member, '*')[@property='value'] \n\nis invalid and it should be valid.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1154",
        "summary": "Database Data Store",
        "description": "We want to have a database backed data store implementation.\nAn implementation using files is already available as part of JCR-926.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1556",
        "summary": "PersistenceManager API change breaks backward compatibility",
        "description": "Persistence Manager API change introduced in JCR-1428 breaks backward compatibility. although this is not a public visible API it renders 3rd party PMs invalid that do not extend from AbstractPersistenceManager.\nat least for the 1.4.3 patch release, we should not do this.\n\nsuggest to revert the API change for the next 1.4.4 release, but leave the method on the abstract pm, and introduce it only for 1.5.\n",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "JCR-1345",
        "summary": "ClassCastException when updating properties using WebDAV",
        "description": "When issuing PROPPATCH commands, a ClassCastException is raised.\n\ne.g. \n\nPROPPATCH /jackrabbit-webapp-1.4/repository/default/test/test_file_v.txt HTTP/1.1\nHost: localhost:9000\nConnection: TE\nTE: trailers, deflate, gzip, compress\nUser-Agent: UCI DAV Explorer/0.91 RPT-HTTPClient/0.3-3E\nTranslate: f\nAuthorization: Basic Y3Jvc3NqYTp0ZXN0\nAccept-Encoding: deflate, gzip, x-gzip, compress, x-compress\nContent-type: text/xml\nContent-length: 170\n\n<A:propertyupdate xmlns:A=\"DAV:\">\n<A:set>\n<A:prop>\n<A:auto-version>checkout-checkin</A:auto-version>\n</A:prop>\n</A:set>\n</A:propertyupdate>\n\n\nresults in\n\n\n\n24.01.2008 15:38:34 *ERROR* [Webdav]: Servlet.service() for servlet Webdav threw\n exception (StandardWrapperValve.java, line 257)\njava.lang.ClassCastException: org.apache.jackrabbit.webdav.property.DefaultDavPr\noperty\n        at org.apache.jackrabbit.webdav.simple.DavResourceImpl.alterProperties(D\navResourceImpl.java:456)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.doPropPatch\n(AbstractWebdavServlet.java:457)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.execute(Abs\ntractWebdavServlet.java:234)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.service(Abs\ntractWebdavServlet.java:192)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:803)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(Appl\nicationFilterChain.java:269)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationF\nilterChain.java:188)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperV\nalve.java:210)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextV\nalve.java:174)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.j\nava:127)\n        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.j\nava:117)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineVal\nve.java:108)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.jav\na:151)\n        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java\n:870)\n        at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.p\nrocessConnection(Http11BaseProtocol.java:665)\n        at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpo\nint.java:528)\n        at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFol\nlowerWorkerThread.java:81)\n        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadP\nool.java:685)\n        at java.lang.Thread.run(Thread.java:595)\n24.01.2008 15:38:34 *ERROR* [Webdav]: Servlet.service() for servlet Webdav threw\n exception (SLF4JLocationAwareLog.java, line 174)\njava.lang.ClassCastException: org.apache.jackrabbit.webdav.property.DefaultDavPr\noperty\n        at org.apache.jackrabbit.webdav.simple.DavResourceImpl.alterProperties(D\navResourceImpl.java:456)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.doPropPatch\n(AbstractWebdavServlet.java:457)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.execute(Abs\ntractWebdavServlet.java:234)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.service(Abs\ntractWebdavServlet.java:192)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:803)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(Appl\nicationFilterChain.java:269)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationF\nilterChain.java:188)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperV\nalve.java:210)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextV\nalve.java:174)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.j\nava:127)\n        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.j\nava:117)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineVal\nve.java:108)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.jav\na:151)\n        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java\n:870)\n        at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.p\nrocessConnection(Http11BaseProtocol.java:665)\n        at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpo\nint.java:528)\n        at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFol\nlowerWorkerThread.java:81)\n        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadP\nool.java:685)\n        at java.lang.Thread.run(Thread.java:595)\n24.01.2008 15:53:54 *ERROR* [Webdav]: Servlet.service() for servlet Webdav threw\n exception (StandardWrapperValve.java, line 257)\njava.lang.ClassCastException: org.apache.jackrabbit.webdav.property.DefaultDavPr\noperty\n        at org.apache.jackrabbit.webdav.simple.DavResourceImpl.alterProperties(D\navResourceImpl.java:456)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.doPropPatch\n(AbstractWebdavServlet.java:457)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.execute(Abs\ntractWebdavServlet.java:234)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.service(Abs\ntractWebdavServlet.java:192)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:803)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(Appl\nicationFilterChain.java:269)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationF\nilterChain.java:188)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperV\nalve.java:210)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextV\nalve.java:174)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.j\nava:127)\n        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.j\nava:117)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineVal\nve.java:108)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.jav\na:151)\n        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java\n:870)\n        at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.p\nrocessConnection(Http11BaseProtocol.java:665)\n        at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpo\nint.java:528)\n        at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFol\nlowerWorkerThread.java:81)\n        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadP\nool.java:685)\n        at java.lang.Thread.run(Thread.java:595)\n24.01.2008 15:53:54 *ERROR* [Webdav]: Servlet.service() for servlet Webdav threw\n exception (SLF4JLocationAwareLog.java, line 174)\njava.lang.ClassCastException: org.apache.jackrabbit.webdav.property.DefaultDavPr\noperty\n        at org.apache.jackrabbit.webdav.simple.DavResourceImpl.alterProperties(D\navResourceImpl.java:456)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.doPropPatch\n(AbstractWebdavServlet.java:457)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.execute(Abs\ntractWebdavServlet.java:234)\n        at org.apache.jackrabbit.webdav.server.AbstractWebdavServlet.service(Abs\ntractWebdavServlet.java:192)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:803)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(Appl\nicationFilterChain.java:269)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationF\nilterChain.java:188)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperV\nalve.java:210)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextV\nalve.java:174)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.j\nava:127)\n        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.j\nava:117)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineVal\nve.java:108)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.jav\na:151)\n        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java\n:870)\n        at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.p\nrocessConnection(Http11BaseProtocol.java:665)\n        at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpo\nint.java:528)\n        at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFol\nlowerWorkerThread.java:81)\n        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadP\nool.java:685)\n        at java.lang.Thread.run(Thread.java:595) ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2684",
        "summary": "Setting Query.setOffset() passed the results total returns negative getSize() instead of zero",
        "description": "1. Have a query that returns 3 results\n2. Now set Query.setOffset(10) (passed the total of 3)\n3. Row/NodeIterator.getSize() returns -7 (incorrect)\n\nExpected: getSize() should return 0",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2130",
        "summary": "Node.removeMixin() should not remove valid items",
        "description": "assume you define a mixin like:\n\n[test] mix\n- aprop (string)\n+ anode (nt:base)\n\nand you add this mixin to a nt:unstructured and add 'anode' and set 'aprop'.\nthen a subsequent node.removeMixin(\"test\") will also remove 'anode' and 'aprop' although they are valid by the definition of nt:unstructured.\n\nimo, the items should only be removed if they become invalid by the definition of the resulting effective node type.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1306",
        "summary": "Reduce number of different repository.xml present with jackrabbit-core",
        "description": "while taking a look at the repository configuration and the related test-cases, i saw that there are quite some repository.xml files around... which i think is a bit confusion and probably hard to maintain once we make\nchanges to the config.\n\ni would to suggest to consolidate that and - if possible - get rid of some of them.\nif we can't i would suggest to put some comment in every of the different configuration files indicating\nwhat they are used for.\n\nfrom what i've seen so far (still missing complete overview)\n\n1) http://svn.apache.org/repos/asf/jackrabbit/trunk/jackrabbit-core/src/main/config/repository.xml\n\n    Current comment: <!-- Example Repository Configuration File -->\n    Usage: ??\n\n2) http://svn.apache.org/repos/asf/jackrabbit/trunk/jackrabbit-core/src/main/resources/org/apache/jackrabbit/core/test-repository.xml\n\n   current comment: -  \n   Used as repository configuration in org.apache.jackrabbit.core.TestRepository.java\n   \n\n3) http://svn.apache.org/repos/asf/jackrabbit/trunk/jackrabbit-core/src/main/resources/org/apache/jackrabbit/core/repository.xml\n  \n   current comment: <!-- Example Repository Configuration File -->\n\n   Used by org.apache.jackrabbit.core.config.RepositoryConfigTest.java in order to create another repository.xml \n   under target/test-repository.xml. a bit confusing given the fact, that a test-repository.xml exists as well. I would\n   suggest to rename the REPOSITORY_XML constant in RepositoryConfigTest.\n\n\n4) http://svn.apache.org/repos/asf/jackrabbit/trunk/jackrabbit-core/src/test/repository/repository.xml\n\n   current comment: <!-- Example Repository Configuration File -->\n   Usage: i assume, that is the one referenced in test/resources/repositoryStubImpl.properties\n\n5) http://svn.apache.org/repos/asf/jackrabbit/trunk/jackrabbit-core/src/test/resources/org/apache/jackrabbit/core/config/repository.xml\n\n   current comment: <!-- Example Repository Configuration File -->\n   Usage: ?? \n\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1145",
        "summary": "ObjectConverterImpl.getObject(Session, Class, String) may not resolve mapping correctly for incompletely described mappings",
        "description": "When a node is mapped by calling the ObjectConverter.getObject(Session, Class, String) method and no discriminator property is configured the ObjectConverterImpl class tries to find a \"best\" mapping for the effective node. This is done by walking the class descriptor hierarchy starting at the descriptor for the selected class until a mapping for the node type is found.\n\nIn case the class descriptor hierarchy is incomplete because an improperly defined class descriptor would actually perfectly map the node but is not declared to extend (or implement) its parent classes/interfaces, the hierarchy walk down will not find the mapping and thus in the end, the originally requested class will be instantiated. If the class is abstract or an interface this of course fails.\n\nIf an exact class descriptor for the node type would be looked up directly, the mapping might be found immediately and the class of the descriptor can be verified it actually is assignement compatible with the requested class. If this would fail, we could still walk the hierarchy to see, whether we find another classdescriptor.\n\nTo clarify the issue consider the following example of an abstract base class and a concrete extension class with their node types\n\n   AbstractBaseClass maps abstractly to AbstractBaseType\n   BaseClass (extends AbstractBaseClass) maps to BaseType ( with supertype AbstractBaseType )\n\nNote, that the BaseClass mapping does not declare to extend the AbstractBaseClass.\n\nWhen calling ObjectConverterImpl.getObject(session, AbstractBaseClass.class, aBaseTypeNode), the descriptor fore the AbstractBaseClass is inspected agains the node and then it is decided to check the class descriptor hierarchy. Node mapping can be found by walking the hierarchy and hence the AbstractBaseClass is instantiated, which of course fails.\n\nIf the BaseClass mapping would be declared as extending the AbstractBaseClass mapping, everything would be fine.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2039",
        "summary": "Add log information when node/property type determination fails",
        "description": "getQNodeDefinition() and getQPropertyDefinition() of o.a.j.jcr2spi.nodetype.ItemDefinitionProviderImpl silently ignore errors which might occur on determination of node and property types. Instead these methods use RepositoryService.getNodeDefinition() and RepositoryService.getPropertyDefinition(), respectively to determine the types. This might lead to difficult to track down problems when the RepositoryService call occurs because of an error in the node type definition. I suggest to add logging statements to these methods. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2934",
        "summary": "SQL2 queries are not logged",
        "description": "SQL2 queries are constructed via QueryObjectModel, and ran via QueryObjectModelImpl which does not log the run time.\nI'll attach a run time log similar to the old one.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-373",
        "summary": "all references to incubator need to be replaced with new locations",
        "description": "The following files under 1.0 branch refer to incubator in one way or another.  Some of them may be benign.\n\n./contrib/bdb-persistence/project.properties\n./contrib/bdb-persistence/project.xml\n./contrib/bdb-persistence/README.txt\n./contrib/classloader/project.properties\n./contrib/classloader/project.xml\n./contrib/examples/project.xml\n./contrib/extension-framework/project.properties\n./contrib/extension-framework/project.xml\n./contrib/jcr-commands/jmeter-chain/project.properties\n./contrib/jcr-commands/project.properties\n./contrib/jcr-commands/xdocs/navigation.xml\n./contrib/jcr-ext/project.xml\n./contrib/jcrtaglib/project.properties\n./contrib/orm-persistence/project.properties\n./contrib/orm-persistence/project.xml\n./jackrabbit/applications/test/cnd-reader-test-input.cnd\n./jackrabbit/project.properties\n./jackrabbit/project.xml\n./jackrabbit/README.txt\n./jackrabbit/src/site/fml/faq.fml\n./jackrabbit/src/site/xdoc/doc/arch/overview/jcrlevels.xml\n./jackrabbit/src/site/xdoc/doc/building.xml\n./jackrabbit/src/site/xdoc/doc/config.xml\n./jackrabbit/src/site/xdoc/downloads.xml\n./jackrabbit/src/site/xdoc/index.xml\n./jackrabbit/src/site/xdoc/tasks.xml\n./jackrabbit/src/test/java/org/apache/jackrabbit/core/nodetype/compact/CompactNodeTypeDefTest.java\n./jca/project.properties\n./jca/project.xml\n./textfilters/project.properties\n./textfilters/project.xml\n\nI'd edit them myself, but I need to sleep... maybe tomorrow if nobody beats me to it.\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-2675",
        "summary": "Node.hasProperty() with relative path can throw ClassCastException",
        "description": "Calling Node.hasProperty() with a relative path that traverses higher than the root node will throw a ClassCastException because the ItemId returned by HierarchyManagerImpl.resolvePath() will be the root node id.  The blind cast in the HierarchyManagerImpl.resolvePropertyPath() will then throw the ClassCastException.  This issue is not just with hasProperty/resolvePropertyPath, but any call to resolvePath that goes higher than the root node, will wrongfully get the root node id returned as result.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-227",
        "summary": "move core module to a subdirectory",
        "description": "Actually the jackrabbit svn holds the code for the main module in the top level dir\nhttp://svn.apache.org/repos/asf/incubator/jackrabbit/trunk/\nand all the subprojects in subdirectories\nhttp://svn.apache.org/repos/asf/incubator/jackrabbit/trunk/contrib/\n\ngiven this layout is not possible to checkout from svn only the main module (if you get trunk, you get all), and you can't work to different modules using any IDE which doesn't support nested projects (namely Eclipse).\n\nI would like to request moving the main module (that means moving all the files and directories in trunk except \"contrib\") from \nhttp://svn.apache.org/repos/asf/incubator/jackrabbit/trunk/\nto \nhttp://svn.apache.org/repos/asf/incubator/jackrabbit/trunk/jackrabbit\nfollowing the usual organization of maven-based projects and solving these problems...\n\n\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": ""
    },
    {
        "key": "JCR-1471",
        "summary": "Error when registering nodetype with same propdef as supertype",
        "description": "error in check:\n\n                                if (pd.getRequiredType() == epd.getRequiredType()\n                                        && pd.isMultiple() == epd.isMultiple()) {\n                                    // conflict\n                                    String msg = \"The property definition for '\"\n                                            + name + \"' in node type '\"\n                                            + def.getDeclaringNodeType()\n                                            + \"' conflicts with node type '\"\n                                            + existingDef.getDeclaringNodeType()\n                                            + \"': ambiguous property definition\";\n                                    log.debug(msg);\n                                    throw new NodeTypeConflictException(msg);\n                                }\n\nif needs to be inverted.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2452",
        "summary": "DefaultPrincipalProvider#collectGroupMembership puts wrong principal instance into the cache",
        "description": "DefaultPrincipalProvider#collectGroupMembership adds the passed principal instance to the cache. This may cause\ninconsistencies as the cache should only contain principals obtained from by the provider.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-641",
        "summary": "can't add lock token to session after 3 login/logout",
        "description": "I login and lock a file and logout. Perfoms a new login and add the previous lock token to the current session because I want to unlock this file. This works fine. But if I do a new logout/login I can't unlock the file (the file is locked). It is best understanded looking at the test case.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-261",
        "summary": "iterative removal of same-name sibling nodes might under certain circumstances throw unexpected exceptions",
        "description": "code fragment to reproduce the issue:\n\n            // setup test\n            if (root.hasNode(\"tmp\")) {\n                root.getNode(\"tmp\").remove();\n                session.save();\n            }\n            Node tmp = root.addNode(\"tmp\");\n            for (int i = 0; i < 4; i++) {\n                Node a = tmp.addNode(\"a\");\n                System.out.println(\"added \" + a.getPath());\n            }\n            session.save();\n\n            // iterative removal of same name sibling child nodes\n            NodeIterator ni = tmp.getNodes();\n            while (ni.hasNext()) {\n                Node n = ni.nextNode();\n                System.out.println(\"removing \" + n.getPath());\n                n.remove();\n                tmp.save();\n            }\n\nconsole output:\n\nadded /tmp/a\nadded /tmp/a[2]\nadded /tmp/a[3]\nadded /tmp/a[4]\nremoving /tmp/a\nremoving /tmp/a\nremoving /\njavax.jcr.RepositoryException: /: cannot remove root node\n\tat org.apache.jackrabbit.core.ItemImpl.internalRemove(ItemImpl.java:766)\n\tat org.apache.jackrabbit.core.ItemImpl.remove(ItemImpl.java:997)\n\tat org.apache.jackrabbit.core.Test.main(Test.java:141)\n\n\nnote that the msg of the exception is misleading: the above code did never try to remove\nthe root node. \n\nthe exception is caused by a bug in CachingHierarchyManager which fails to update\nthe cache correctly.\n\nbtw: if you comment the first logging stmt, i.e. \n\n                //System.out.println(\"added \" + a.getPath());\n\nthe problem doesn't occur anymore.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-809",
        "summary": "Misleading method names in SetValueBinaryTest",
        "description": "Some of the method names in SetValueBinaryTest say \"Boolean\" when they should say \"Binary\" (copy&paste error from SetValueBooleanTest?).\n\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1265",
        "summary": "Lower-Case Search-Function works with Upper-Case Searchstring",
        "description": "if you perform a query like this\ntestroot/*[jcr:like(fn:lower-case(@prop1), 'FO%')]\nyou get valid results even though the value in the property has the \"foo\" value\nThe search works with lower and upper-case search strings.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-208",
        "summary": "tck doesn't compile (use of enum keyword)",
        "description": "Use if enum keyword in TestFinder (patch will be attached)",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "JCR-3050",
        "summary": "NullPointerException on removing a node acquired from search result",
        "description": "with a code snipped like the following, i get a NullPointerException in ItemState:\n\nSession s = repo.login(sc,workspace);\nQueryManager qm = s.getWorkspace().getQueryManager();\nQuery q = qm.createQuery(\"SELECT * FROM [nt:unstructured]\", Query.JCR_SQL2);\nQueryResult r = q.execute();\nNodeIterator i = r.getNodes();\n\nNode n = i.nextNode();\nn.remove(); // breaks here with NullPointerException\n\nException in thread \"main\" java.lang.NullPointerException                                                                                                                                                                                   \n        at org.apache.jackrabbit.jcr2spi.state.ItemState.getParent(ItemState.java:210)                                                                                                                                                      \n        at org.apache.jackrabbit.jcr2spi.operation.Remove.create(Remove.java:98)                                                                                                                                                            \n        at org.apache.jackrabbit.jcr2spi.ItemImpl.remove(ItemImpl.java:306) ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2509",
        "summary": " Reduce number of compiler warning by adding @Override and generics where appropriate ",
        "description": "Same as JCR-2482 for the webdav library and the modules using it.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2904",
        "summary": "Uncaught AbstractMethodError exception in in DomUtil.createFactory()",
        "description": "DomUtil.createFactory() throws an uncaught AbstractMethodError exception when xerces is on the classpath and the jackrabbit webdav module is used. \n\nThis can render the class unusable when used in conjunction with the xerces library. \n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1575",
        "summary": "[PATCH] cleanup unwanted stream closing that isn't used",
        "description": "Due to refactoring, a stream is being closed that is never used. Isn't harmful, just is cruft.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1682",
        "summary": "Session returned does not offers transaction support",
        "description": "The javax.jcr.Session instance returned by the repository is an implementation of org.apache.jackrabbit.jca.JCASessionHandle which doesn't implement the interface org.apache.jackrabbit.api.XASession.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-174",
        "summary": "Contrib JCR-Server: improve handing of strong etags",
        "description": "copied from dev-mail:\n\n[..]\n\nso... could we\n- delegate the calculation of the etag to the\n  commands, letting them decide on whether they are able\n  to provide any and whether it would be a strong or a\n  weak one?\n- remove that additional method in NodeResource that is\n  not used? ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2748",
        "summary": "provide a (relatively) simple way to disable anonymous access to the security workspace",
        "description": "As discussed in this thread: http://sling.markmail.org/thread/st52jejjuxykfxtj, the security workspace is, by default, configured with an AccessControlProvider which provides a fixed access control policy (i.e. o.a.j.core.security.user.UserAccessControlProvider). In order to prevent anonymous access to security-related nodes requires the use of an alternate AccessControlProvider.\n\nThe attached patch provides a simpler mechanism. By adding\n\n<param name=\"anonymousAccessToSecurityWorkspace\" value=\"false\" />\n\nto the configuration of the DefaultSecurityManager, anonymous access to the security workspace is forbidden.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1551",
        "summary": "TransientRepository: application doesn't exit quickly",
        "description": "When using the TransientRepository, the repository should be closed when the last session logs out. This works, but in some cases there is a very long (60 seconds) delay between closing the last session and closing the repository.\n\nTest case:\n\n    public static void main(String[] args) throws Exception {\n        Repository repository = new TransientRepository();\n        Session session = repository.login(new SimpleCredentials(\"\", new char[0]));\n        session.getRootNode().setProperty(\"a\", \"0\");\n        session.save(); // very quick logout without this line\n        session.logout();\n        System.out.println(\"Logout...\");\n        final long time = System.currentTimeMillis();\n        Runtime.getRuntime().addShutdownHook(new Thread() {\n            public void run() {\n                System.out.println(\"End after: \" + (System.currentTimeMillis() - time));\n            }\n        });\n    }\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1110",
        "summary": "GetReferencesNodeTest test assumptions",
        "description": "Bad test assumptions in GetReferencesNodeTest:\n\n1) In setUp(): there is a primary node type including mixin:versionable. Proposed fix: just create the node, try to add mixin:versionable, check the node type after save.\n\n2) The repository supports non-protected reference properties. Proposed fix: check with AbstractJCRTest's ensureCanSetProperty method, and let NotExecutableException be thrown.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-199",
        "summary": "uploading large streams through rmi",
        "description": "when I try to upload a file of 35 Meg, I get an out of memory error.\n\nThis is caused because the whole file is read into memory instead of buffering",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-3108",
        "summary": "SQL2 ISDESCENDANTNODE can throw BooleanQuery#TooManyClauses if there are too many matching child nodes",
        "description": "Running a query that has a ISDESCENDANTNODE clause can easily go over the max clause limit from lucene's BooleanQuery when there's a bigger hierarchy involved.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2546",
        "summary": "SISM blocks the item state cache when loading a new item",
        "description": "The SharedItemStateManager.getNonVirtualItemState() method contains a loadItemState() call within a \"synchronized (cache)\" block. This prevents all item state cache access while a new item is being loaded from the persistence manager. I have at least one case where this has caused a serious performance drop, essentially synchronizing repository access for all readers.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1218",
        "summary": "RepositoryUtil moved outside of main source tree",
        "description": "It appears that the RepositoryUtil class was moved from src/main to src/test. This class is used by the ocm-spring project.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "JCR-1703",
        "summary": "Oracle JNDI DataSource support",
        "description": "When org.apache.jackrabbit.core.persistence.bundle.util.ConnectionFactory tries to get a connection from a JNDI Datasource without login and pasword, if no user/password are specified, they re retrieved as empty strings, not null, so it tries to do a ds.getConnection(user, password), which fails. Please complete the test line 66 as :\nif ((user == null || user.length() > 0) && (password == null || password.length() > 0)) {\n\nSincerely,\n\nSt\u00e9phane Landelle",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1745",
        "summary": "Mark pending nodes in IndexingQueue directly in index",
        "description": "The index currently writes an indexing_queue.log file which contains all nodes that timed out while text was extracted. Instead, the index itself should mark an indexed node as pending. This is more robust because no additional file must be written.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-194",
        "summary": "dead lock while locking or unlocking nodes",
        "description": "JackRabbit is still hanging on the Node.lock() or Node.unlock() function.\n\n... everything fine until here...\ns13: 4\ns13: 5\ns13: 6\ns13: 7   -> unlock()\ns14: started.\ns14: 1   -> session.getRootNode()\ns15: started.\ns15: 1\ns16: started.\n\nI just find this failure during the first run (emtpy repository home directory). 2nd and 3th run are fine after killing the vm from first run, but with already initialized repository directory these time.\n\n1. rm -rf repository.home\n2. run -> hang\n3. kill\n4. run -> ok\n5. run -> ok\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-881",
        "summary": "Use jackrabbit 1.2.1",
        "description": "Use Jackarabit 1.2.1",
        "label": "NUG",
        "classified": "TASK",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2850",
        "summary": "RMI problems prevent proper startup of the Jackrabbit webapp",
        "description": "A trouble in binding the repository to a RMI registry will prevent the entire Jackrabbit webapp from starting properly. Since RMI is seldom the primary function of the webapp, it's more appropriate to simply log a warning in such cases.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2708",
        "summary": "Merge jcr-benchmark into the performance test suite",
        "description": "The jackrabbit-jcr-benchmark component currently lives in the JCR Commons area, but there have been no active plans to release the component and AFAIUI it's so far only been used for the performance test suite we set up in JCR-2695. To avoid the extra complexity of spreading the test code over multiple components and trunks, I'd like to merge the jcr-benchmark component back to Jackrabbit trunk into the performance test suite we have in tests/performance.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1633",
        "summary": "When node is created and locked in same transaction, exception is thrown",
        "description": "Following code fails when executed inside an XA transaction:\n\nNode n = session.getRootNode().addNode(\"n\");\nn.addMixin(\"mix:lockable\");\nsession.save();\nLock lock = n.lock(false, false);\n\nStacktrace is\n\nCaused by: javax.transaction.xa.XAException\n\tat org.apache.jackrabbit.core.TransactionContext.prepare(TransactionContext.java:155)\n\tat org.apache.jackrabbit.core.XASessionImpl.commit(XASessionImpl.java:337)\n\tat org.apache.jackrabbit.jca.TransactionBoundXAResource.commit(TransactionBoundXAResource.java:39)\n\tat org.apache.geronimo.transaction.manager.WrapperNamedXAResource.commit(WrapperNamedXAResource.java:47)\n\tat org.apache.geronimo.transaction.manager.TransactionImpl.commit(TransactionImpl.java:301)\n\t... 32 more\nCaused by: org.apache.jackrabbit.core.TransactionException: Unable to update.\n\tat org.apache.jackrabbit.core.lock.XAEnvironment.prepare(XAEnvironment.java:275)\n\tat org.apache.jackrabbit.core.lock.XALockManager.prepare(XALockManager.java:245)\n\tat org.apache.jackrabbit.core.TransactionContext.prepare(TransactionContext.java:138)\n\t... 36 more\nCaused by: javax.jcr.ItemNotFoundException: failed to build path of 48fb59d8-ac77-4b9f-8b53-9f2492dca5e5: 48fb59d8-ac77-4b9f-8b53-9f2492dca5e5: 48fb59d8-ac77-4b9f-8b53-9f2492dca5e5\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getPath(HierarchyManagerImpl.java:407)\n\tat org.apache.jackrabbit.core.CachingHierarchyManager.getPath(CachingHierarchyManager.java:272)\n\tat org.apache.jackrabbit.core.lock.LockManagerImpl.getPath(LockManagerImpl.java:651)\n\tat org.apache.jackrabbit.core.lock.LockManagerImpl.internalLock(LockManagerImpl.java:276)\n\tat org.apache.jackrabbit.core.lock.XAEnvironment$LockInfo.update(XAEnvironment.java:409)\n\tat org.apache.jackrabbit.core.lock.XAEnvironment.prepare(XAEnvironment.java:273)\n\t... 38 more\nCaused by: org.apache.jackrabbit.core.state.NoSuchItemStateException: 48fb59d8-ac77-4b9f-8b53-9f2492dca5e5\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:189)\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getItemState(HierarchyManagerImpl.java:188)\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getPath(HierarchyManagerImpl.java:402)\n\t... 43 more\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1539",
        "summary": "SPI: Get rid of unused method ItemInfo.getParentId()",
        "description": "Looking at the various SPI impls in the trunk and in the sandbox reveals that ItemInfo.getParentId is not used at all.\nI'd like to suggest to get rid of that method.\n\nAny objections/concerns?\nangela\n\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-600",
        "summary": "Repository does not release all resources on shutdown",
        "description": "When Jackrabbit is shutdown some java.util.Timer threads are still running in the background even though no tasks are scheduled. This prevents the GC from collecting the classes when Jackrabbit is redeployed within a web application.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-209",
        "summary": "orm-persistence package doesn't compile against cvs head.",
        "description": "Corrected QName import (which I guess was moved). \nThis patch has no meaning besides making the src/java compile and to update the dependencies in the project.xml.\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "JCR-1721",
        "summary": "make collection element names configurable",
        "description": "- add jcrElementName to CollectionDescriptor and Collection annotation\n- make COLLECTION_ELEMENT_NAME protected instead of private\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2737",
        "summary": "have jackrabbit-core produce a test jar",
        "description": "I'm writing a custom FileSystem implementation and it would be nice to be able to reuse AbstractFileSystemTest.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1921",
        "summary": "EventFilterImpl should implement toString",
        "description": "This would simplify logging and debugging.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2803",
        "summary": "Deprecate non-pooled bundle DB persistence managers",
        "description": "In JCR-1456 and Jackrabbit 2.0 we introduced database connection pooling, but decided to keep the existing database bundle persistence managers intact to avoid potential regressions. We haven't seen such problems even though pooled bundle persistence has been the default since the 2.0 release, so I think it would be safe to deprecate all the non-pooled bundle DB PMs.\n\nAnd in order to remove duplicate code (that has already complicated some changes within o.a.j.persistence), I'd also take the extra step of  making the o.a.j.p.bundle.* classes extend respective the o.a.j.p.pool.* classes. This would automatically allow also old non-pooled configurations to benefit from connection pooling.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2695",
        "summary": "Jackrabbit performance test suite",
        "description": "I'd like to set up a multi-version performance test suite inside jackrabbit-core/src/test/performance, similar to the compatibility test suite we added in JCR-2631. This performance test suite would produce comparable performance numbers for a number of simple benchmark tests across different Jackrabbit versions, including the latest snapshot.\n\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2224",
        "summary": "Change access levels in SearchIndex and NodeIndexer for better inherance",
        "description": "I want to change NodeIndexer#addBinaryValue logic in JR 1.5.6, therefore i needed to:\n* create a custom class extending NodeIndexer for changing binary field indexation\n* create a custom class extending SearchIndex for using this custom NodeIndexer\n\nI was obliged to:\n* override SearchIndex#createTextExtractor in order to store created TextExtractor because of private attribute\n* put both classes into package org.apache.jackrabbit.core.query.lucene because NodeIndexer#createDoc(...) is protected\n\nIn trunk TextExtractor has now a getter but there are still some private attributes.\nAnd NodeIndexer#createDoc(...) is still protected and there are some private methods.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1843",
        "summary": "jcr2spi: wrong status change upon conflicting removal (CacheBehaviour.OBSERVATION)",
        "description": "with CacheBehaviour.OBSERVATION the external removal of a transiently removed item results in wrong status change that brings it back to life.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3254",
        "summary": "make max size of CachingEntryCollector's cache configurable",
        "description": "To assist in analyzing the bottleneck it would be good if it was easy to change the max size, currently hard-wired to 5000. Suggest to be pragmatic and do that through a system property.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-769",
        "summary": "Unable to login with two different Credentials to same workspace in one Transaction",
        "description": "I'm using the Jackrabbit 1.2.1 JCA adapter and trying to access in a SessionBean-Method with Container Transaction a Workspace with 2 different Credentials. \nThe Method takes about 400ms to finish but no commit on TransactionContextr occurs (Debugging ..) only the prepare was called 2 times .\nThe Container hangs on the PostInvoke Method about 5 seconds and then i get a \"javax.transaction.xa.XAException\" \nwith the Warn Message: Transaction rolled back because timeout expired\n\nThe code ..\nContext ctx = new InitialContext(); \nRepository repository = (Repository) ctx.lookup(\"java:comp/env/jackrabbit\"); \nCredentials credentials = new SimpleCredentials(\"user1\", \"password1\".toCharArray()); \nCredentials credentials2 = new SimpleCredentials(\"user2\", \"password2\".toCharArray()); \nSession session1 = repository.login(credentials, \"default\"); \nSession session2 = repository.login(credentials2, \"default\"); \n\nSession1 adds a node to the workspace .. and with the session2 i do nothing except the login !\nIf i make no second login the Method works fine.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-384",
        "summary": "Changes of JCR-313 introduced db-transaction problem",
        "description": "the fix of JCR-313 changed the autocommit from 'true' to 'false', resulting the DatabaseFileSystems not to write back correctly anymore.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2977",
        "summary": "AccessControlManager#getApplicablePolicy should check for colliding rep:policy node",
        "description": "while AccessControlManager#getApplicablePolicy returns an empty iterator if the target node cannot get the accesscontrollable-mixin set, it does not test if there is a colliding child node that would prevent the policy to be applied calling AccessControlManager#setPolicy. consequently, the setPolicy call fails with ItemExistsException. A simple test upfront could prevent this unexpected failure.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-268",
        "summary": "invalid groupid for tm-extractors in textfilters project",
        "description": "groupid for tm-extractors should be \"org.textmining\" and not \"textmining\".\nThe dependency with the correct groupid is available on ibiblio",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1678",
        "summary": "NullPointerException in constructor of JcrDavException",
        "description": "within DavSessionProviderImpl.attachSession() a org.apache.jackrabbit.rmi.client.RemoteRepositoryException is thrown, catched as RepositoryException and passed into the \nctor of JcrDavException\n\nthe lookup for the class in the static HashMap codeMap for the class fails and a NPE is thrown \n\nsuggested fix:\nThe static lookup by the javax.jcr.*Exception classed must be fixed to include derived exception classes.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2635",
        "summary": "Disable Users",
        "description": "add \"disable user\" functionality to prevent an existing user from login into the repository.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-860",
        "summary": "Add relative path parameter to rep:excerpt()",
        "description": "This allows one to create an excerpt not just for the node associated with a result node, but also for a node relative to the result node.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1737",
        "summary": "JSP page compilation errors when depoyed using oc4j",
        "description": "An error in the Welcome.jsp was produced as follows:\n\ncannot find symbol symbol : method log(java.lang.String,java.lang.Throwable)\n\nIn a response from the user group it was determined that there should be no expectation in Jackrabbit that the JspPage implementation will inherit from the GeneralServlet base class.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1977",
        "summary": "authentication order has changed from 1.4.x to 1.5.x",
        "description": "In 1.4.x inside RepositoryImpl.login(...) at first the local configuration is checked for configured LoginModules and after it was unsuccessful, the JAAS component is asked:\n\n          AuthContext authCtx;\n            LoginModuleConfig lmc = repConfig.getLoginModuleConfig();\n            if (lmc == null) {\n                        authCtx = new AuthContext.JAAS(repConfig.getAppName(), credentials);\n            } else {\n...\n\nWith 1.5.x this behaviour has moved to SimpleSecurityManager.init(..) and is changed:\n        LoginModuleConfig loginModConf = config.getLoginModuleConfig();\n        authCtxProvider = new AuthContextProvider(config.getAppName(), loginModConf);\n        if (authCtxProvider.isJAAS()) {\n            log.info(\"init: using JAAS LoginModule configuration for \" + config.getAppName());\n        } else if (authCtxProvider.isLocal()) {\n...\n\nThe problem is with JBoss JAAS implemantation, that authCtxProvider.isJAAS()  is always true.\nBecause for any reason, the result of Configuration.getAppConfigurationEntry(appName) is never empty,\nwhen a jaas.config is specified for Liferay. Using different appName takes no effect, always the configuration inside the jaas.config is used.\n\nI think still first the local configuration should be concerned, before using JAAS.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-408",
        "summary": "RowIterator view of result for query '//*' only returns jcr:path column",
        "description": "The RowIterator view of a query result for '//*' only returns the jcr:path column. The spec states that this query is equivalent to:\nselect * from nt:base. Furthermore a query that selects * properties must return all non-residual properties that are declared for this node type and are not multi-valued. The pseudo properties jcr:path and jcr:score must always be available.\n\nFor nt:base this is:\n- jcr:primaryType\n- jcr:path\n- jcr:score",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1074",
        "summary": "PredefinedNodeTypeTest..getNodeTypeSpec handling unknown super types",
        "description": "This method tries to filter out custom super types, but produces a broken spec when *all* super types are custom (in which case it should emit \"[]\", but doesn't).\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2536",
        "summary": "spi2davex: InvalidItemStateException not properly extracted from ambiguous response error",
        "description": "NodeTest#testSaveInvalidStateException\nSessionTest#testSaveInvalidStateException\n\nfail with PathNotFoundException instead of InvalidItemStateException.\n\ni remember that i already addressed that issue in spi2dav a long time ago. with the batched writing in\nspi2davex it is back: the server isn't aware of the distinction and just isn't able to retrieve that removed\nitem... either the client side finds a way to distinguish between path-not-found and externally modified\nor we have to leave this as known issue...\n\nin spi2dav i added add quick hack: if the operation was some write operation the path-not-found is\nsimply converted into invaliditemstateexception.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1550",
        "summary": "Remove ItemInfo.getName() since it is redundant",
        "description": "I propose to remove the method getName() from org.apache.jackrabbit.spi.ItemInfo since it is redundant. The name is always the last element of the path which is available via the getPath() method.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-954",
        "summary": "Allow to disable referential integrity checking for workspace",
        "description": "Some operations like clone, remove operating on huge subtree of nodes requires a lot of memory. To copy, clone, remove subtree all nodes are loaded into transient spaces. It allows such operations to be transactional, from other side it requires a lot of heap size and this memory size is directly dependent on the size of subtree (number of nodes). In result of this in some cases it is impossible to make such operations in one step. In our environment sometimes 1 GB of java heap is not enough to succesfully clone subtree  from one workspace to another.\n\nYou can always clone (copy, remove) tree in chunks, but if you have references between subtrees such approach fails. Possibilty of temporary disabling referential integrity checking for experienced JCR user could be very usefull then.\n\nAnother use case is to allow to clone selected subtrees of the whole structure between worskpaces. In our application we need to clone only some selected subtrees from one workspace to another. But we can not do that because of existing references. We need to clone the whol estructure first, then remove all unwanted nodes, which is really time expensive and memory consuming.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1221",
        "summary": "IndexMerger blocks client threads when obsolete index segments are deleted",
        "description": "When index segments have been merged, the obsolete indexes are replaced with the new one an deleted afterwards. Currently deleting the obsolete segments is inside a MultiIndex synchronized block, which may block other threads from updating the index concurrently.",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2208",
        "summary": "update tests so that both Query.XPATH and Query:SQL are treated as optional features",
        "description": "In JCR 2.0, both Query.XPATH and Query.SQL are optional (or, actually, deprecated).\n\nWe either need to modify the tests so that they pass on a repository that doesn't support them (-> NotExecutableException), or remove them altogether.",
        "label": "NUG",
        "classified": "TEST",
        "type": ""
    },
    {
        "key": "JCR-3075",
        "summary": "incorrect HTML excerpt generation for queries on japanese text content ",
        "description": "The generated excerpt highlights single characters instead of full words. Test case (to be added to FullTextQueryTest):\n\n     public void testJapaneseAndHighlight() throws RepositoryException {\n        // http://translate.google.com/#auto|en|%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%88\n        String jContent = \"\\u30b3\\u30fe\\u30c6\\u30f3\\u30c8\";\n        // http://translate.google.com/#auto|en|%E3%83%86%E3%82%B9%E3%83%88\n        String jTest = \"\\u30c6\\u30b9\\u30c8\";\n        \n        String content = \"some text with japanese: \" + jContent\n                + \" ('content')\" + \" and \" + jTest + \" ('test').\";\n\n        // expected excerpt; note this may change if excerpt providers change\n        String expectedExcerpt = \"<div><span>some text with japanese: \" + jContent\n                + \" ('content') and <strong>\" + jTest\n                + \"</strong> ('test').</span></div>\";\n        \n        Node n = testRootNode.addNode(\"node1\");\n        n.setProperty(\"title\", content);\n        testRootNode.getSession().save();\n        \n        String xpath = \"/jcr:root\" + testRoot + \"/element(*, nt:unstructured)\"\n                + \"[jcr:contains(., '\" + jTest + \"')]/rep:excerpt(.)\";\n        Query q = superuser.getWorkspace().getQueryManager()\n                .createQuery(xpath, Query.XPATH);\n        \n        QueryResult qr = q.execute();\n        RowIterator it = qr.getRows();\n        int cnt = 0;\n        while (it.hasNext()) {\n            cnt++;\n            Row found = it.nextRow();\n            assertEquals(n.getPath(), found.getPath());\n            String excerpt = found.getValue(\"rep:excerpt(.)\").getString();\n            assertEquals(expectedExcerpt, excerpt);\n        }\n        \n        assertEquals(1, cnt);\n    }\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1605",
        "summary": "RepositoryLock does not work on NFS sometimes",
        "description": "The RepositoryLock mechanism currently used in Jackrabbit uses FileLock. This doesn't work on some NFS file system. It looks like only NFS version 4 and newer supports locking. Older implementations may throw a IOException \"No locks available\", which means the NFS does not support byte-range locking.\n\nI propose to add a second locking mechanism, and add a configuration option to use it. For example: <FileLocking class=\"acme\" />. This second locking mechanism is a cooperative locking protocol that uses a background (watchdog) thread and only uses regular file operations.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2169",
        "summary": "BundleDbPersistenceManager consistencyFix doesn't fix missing non system childnode  entries of the root node",
        "description": "The bundle check/fix mechanism completely skips the checks on the root node, but the root node can also have non system child node entries which can be broken/missing. The attached patch makes the check only check the non system child node entries of the root node. It would be nice if this patch (if/when accepted) could also be backported to the 1.5 and 1.6 branches.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2569",
        "summary": "Implement jcr-jackrabbit://... repository URIs",
        "description": "The current file://... URIs used by the Jackrabbit RepositoryFactoryImpl class make it hard to support extra ?parameters and prevent other JCR implementations from using similar repository URI patterns.\n\nThus I propose that we start supporting a jcr-jackrabbit://... URI pattern in addition to the current file://... pattern.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2133",
        "summary": "Remove deprecated classes in jackrabbit-webdav and the corresponding impls in jcr-server",
        "description": "",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1704",
        "summary": "Indexing rules inheritance doesn't work",
        "description": "Indexing rules are supposed to be inherited by children node types.\nIn org.apache.jackrabbit.core.query.lucene.IndexingConfigurationImpl.init, rules are registered for the declared node type and all its children. However, as the rule's node type is still the original one, the rule gets rejected in org.apache.jackrabbit.core.query.lucene.IndexingConfigurationImpl$IndexingRule.appliesTo.\n\nOne simple solution would be to register not the original rule, but a copy where the original node type has been replaced by the child one.\n\nPlease find corrected class attached.\n\nSincerely,\n\nSt\u00e9phane",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1479",
        "summary": "[PATCH] don't use the reflective form of {Collection}.toArray",
        "description": "Passing a prototype array into {Collection}.toArray that is too small makes the toArray call expend alot of effort using reflection to do it's job. It is more performant to just pass in a correctly sized prototype. This patch does this.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-988",
        "summary": "Configure the maven build for IDE project generation for IDEA and Eclipse",
        "description": "Can we add a plugin configuration for the maven-idea-plugin and maven-eclipse-plugin, with JDK version set for IDEA and configured source download of dependencies?\n\nSimplifies project regeneration and working with IDEA or Eclipse.\n\nI'll add a patch.\n\nThanks!\n\n\n ",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1295",
        "summary": "Tablespace (Filegroup) support for MS SQL Server",
        "description": "Tablespace support was added for Oracle database servers in this issue\n\nhttps://issues.apache.org/jira/browse/JCR-968\n\nWe would like tablespace (or filegroup) support for MS SQL Server as well. To address this, we have created a patch using the trunk of JackRabbit that closely follows the patch in the above named issue.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-831",
        "summary": "NPE Exception Thrown By AbstractJournal During Commit Operation",
        "description": "This seems related to JCR-712 (which was apparently fixed in 1.2.2), but I see the following error now-and-then on JR 1.2.2 (I'm using the DB based journal implementation with Oracle 10g):\n\njava.lang.NullPointerException\n        at org.apache.jackrabbit.core.cluster.AbstractJournal.commit(AbstractJournal.java:525)\n        at org.apache.jackrabbit.core.cluster.ClusterNode.updateCommitted(ClusterNode.java:424)\n        at org.apache.jackrabbit.core.cluster.ClusterNode$WorkspaceUpdateChannel.updateCommitted(ClusterNode.java:565)\n        at org.apache.jackrabbit.core.state.SharedItemStateManager$Update.end(SharedItemStateManager.java:712)\n        at org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:808)\n        at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:326)\n        at org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:313)\n        at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:302)\n        at org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:308)\n        at org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1204)\n        at org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:823)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-94",
        "summary": "Patch to JCR-RMI contribution adding Version/VersionHistory support",
        "description": "Hi Jukka,\n\nYou contributed the famous RMI extension to Jackrabbit. Many thanks. On my way to implement an Eclipse plugin to access repositories this provides great help. Unfortunately your contribution does not include support for versioning yet.\n\nI took the freedom to add this missing piece and provide it to you to add it to your contribution. Thanks.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-550",
        "summary": "OutOfMemoryError when re-indexing the repository",
        "description": "[ERROR] 20060825 17:06:40\n(org.apache.jackrabbit.core.observation.ObservationManagerFactory) -\nSynchronous EventConsumer threw exception. java.lang.OutOfMemoryError\n\nwhen we try to re-index a repository, the repository is quite big (more then 4 Gb of disk usage) and sometimes it stores 40Mb size documents.\n\nAs attach I put all the last logs we registered, with the full stack traces.\n\nRelated to this whe have also errors with Lucene:\n\n[DEBUG] 20060803 08:24:01 (org.apache.jackrabbit.core.query.LazyReader)\n- Dump: \njava.io.IOException: Invalid header signature; read 8656037701166316554,\nexpected -2226271756974174256\n        at org.apache.jackrabbit.core.query.MsWordTextFilter\n\nand then this ones:\n\n[DEBUG] 20060803 08:37:17 (org.apache.jackrabbit.core.ItemManager) -\nremoving item 8637bf5f-4689-4e75-888f-b7b89bef40c8 from cache\n[ WARN] 20060803 08:40:13 (org.apache.jackrabbit.core.RepositoryImpl) -\nExisting lock file at C:\\Wave\\Repository\\.lock deteteced. Repository was\nnot shut down properly.\n[ERROR] 20060803 09:33:14\n(org.apache.jackrabbit.core.observation.ObservationManagerFactory) -\nSynchronous EventConsumer threw exception.\njava.lang.NullPointerException: null values not allowed\n\nthis is our repository.xml configuration for indexing\n\n<SearchIndex\nclass=\"org.apache.jackrabbit.core.query.lucene.SearchIndex\">\n        <param name=\"path\" value=\"${wsp.home}/index\"/>\n        <param name=\"textFilterClasses\"\nvalue=\"org.apache.jackrabbit.core.query.lucene.TextPlainTextFilter,\norg.apache.jackrabbit.core.query.MsExcelTextFilter,\norg.apache.jackrabbit.core.query.MsPowerPointTextFilter, \norg.apache.jackrabbit.core.query.MsWordTextFilter,\norg.apache.jackrabbit.core.query.PdfTextFilter,\norg.apache.jackrabbit.core.query.HTMLTextFilter,\norg.apache.jackrabbit.core.query.XMLTextFilter,\norg.apache.jackrabbit.core.query.RTFTextFilter,\n                        org.apache.jackrabbit.core.query.OpenOfficeTextFilter\"/>\n        <param name=\"useCompoundFile\" value=\"true\"/>\n        <param name=\"minMergeDocs\" value=\"100\"/>\n        <param name=\"volatileIdleTime\" value=\"3\"/>\n        <param name=\"maxMergeDocs\" value=\"100000\"/>\n        <param name=\"mergeFactor\" value=\"10\"/>\n        <param name=\"bufferSize\" value=\"10\"/>\n        <param name=\"cacheSize\" value=\"1000\"/>\n        <param name=\"forceConsistencyCheck\" value=\"false\"/>\n        <param name=\"autoRepair\" value=\"true\"/>\n                <param name=\"respectDocumentOrder\" value=\"false\"/>\n        <param name=\"analyzer\"\nvalue=\"org.apache.lucene.analysis.standard.StandardAnalyzer\"/>\n</SearchIndex>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-36",
        "summary": "NodeTypeRegistry.reregister unregisters dependent types",
        "description": "NodeTypeRegistry.reregister allows modifying a registered node type if the difference to the currently registered node type with the same name is TRIVIAL according to NodeTypeDefDiff.\n\nBefore registering the new node type definition the old node type is unregistered. The side effect of that first step is that also all NodeTypes, which depend (extend ?) the node type to be re-registered, are removed from the registry.\n\nAfter the modified node type is then registered, the previously registered dependent node types will not be registered anymore and will not be known any more.\n\nWhile it makes sense to me, to temporarily unregister dependent node types, those must be registered again after the re-registered node type has been registered. Otherwise the system may become pretty useless.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3122",
        "summary": "QueryObjectModelImpl should execute queries as SessionOperation(s)",
        "description": "QueryObjectModelImpl doesn't leverage the SessionOperation closure approach (like the QueryImpl does). \n\nSwitching to this style of running a query yields some gains in speed (I ran 50 queries per test):\n - #1. old style   (no code change)       avg was 14.26 ms\n - #2. new style (as session operation) avg was 12.14 ms\n - #3. new style (as session operation) avg was   6.44 ms\n - #4. new style (as session operation) avg was   6.68 ms\n - #5. old style  (no code change)        avg was 11.62 ms\n - #6. old style  (no code change)        avg was 11.66 ms",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-62",
        "summary": "import must not ignore xml prefixed attributes",
        "description": "XML import currently ignores attributes that are in the xml namespace.\ne.g., DocViewImportHandler's startElement():\n\n                if (atts.getQName(i).startsWith(\"xml:\")) {\n                    // skipping xml:space, xml:lang, etc.\n                    log.debug(\"skipping reserved/system attribute \" + atts.getQName(i));\n                    continue;\n                }\n\nThat is a significant loss of information, since xml:base, xml:lang, and xml:id attributes are critical to the content.  We should register the xml prefix as a reserved namespace (not needing an xmlns declaration) and then treat it like any other attribute.\n\nHere are some useful XML examples:\n\nhttp://xformsinstitute.com/essentials/browse/ch03s02.php\nhttp://www.zvon.org/HowTo/Output/\nhttp://www.w3.org/Math/testsuite/testsuite/TortureTests/Complexity/complex1.xml\nhttp://intertwingly.net/wiki/pie/EchoExample\nhttp://support.sas.com/onlinedoc/913/getDoc/en/engxml.hlp/a002973381.htm\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1878",
        "summary": "Use Apache Tika for text extraction",
        "description": "Once Apache Tika is released with a resolution to TIKA-175 (making Tika available to Java 1.4 projects), we should replace our direct parser library dependencies with Tika parsers. Ideally we'd just use the Tika AutoDetectParser that'll automatically detect the type of a binary and parse it accordingly, solving JCR-728.\n\nI guess we should keep some level of backwards compatibility with existing textFilterClasses=\"...\" configurations, perhaps by keeping the existing TextExtractor classes as wrappers around respective Tika parsers.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2063",
        "summary": "FileDataStore: garbage collection can delete files that are still needed",
        "description": "It looks like the FileDataStore garbage collection (both regular scan and persistence manager scan) can delete files that are still needed.\n\nCurrently it looks like the reason is the last access time resolution of the operating system. This is 2 seconds for FAT and Mac OS X, NTFS 100 ns, and 1 second for other file systems. That means file that are scanned at the very beginning are sometimes deleted, because they have a later last modified time then when the scan was started.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1617",
        "summary": "Remove commons-collections and slf4j-api dependencies from jcr-commons",
        "description": "As noted in JCR-1615 and discussed on the mailing list [1] it would be good if jackrabbit-jcr-commons didn't come with extra dependencies beyond the standard Java class libraries and the JCR API.\n\nCurrently jackrabbit-jcr-commons depends on both commons-collections and slf4j-api, but both dependencies are relatively isolated and could be dropped with relatively little effort. Both dependency changes may be backwards incompatible with existing clients, but since the impact is reasonably small and easy to resolve I'd be OK doing this in 1.5.\n\n[1] http://markmail.org/message/724ruk4l7b5rjtan",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-79",
        "summary": "EventFilter misses Events for same Nodetype",
        "description": "If an ObservationListener registers with a NodeType-filter, \nit only gets informed about events on Sub-NodeTypes of the ones specified in the filter but not on the NodeType itself.\n\nExample:\n========\nObservationManager om = wsp.getObservationManager();\nom.addEventListener(listener, Event.PROPERTY_ADDED, \"/\", true, null, new String[]{\"nt:unstructured\"}, true);\n\nwould receive notifications on nodes of type \"rep:root\", which is based on \"nt:unstructured\" but not of \"nt:unstructured\"\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2044",
        "summary": "Pass resultFetchSize/limit hint to SortedLuceneQueryHits",
        "description": "The SortedLuceneQueryHits currently uses a default value of 100 (taken from lucene) for initially retrieved and sorted results. For larger result sets this is not optimal because it will cause re-execution of the underlying query with values 200, 400, 800, 1600, 3200, 6400, etc. Instead the query hits should get the limit that is set on the query or the resultFetchSize configured for the SearchIndex.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1840",
        "summary": "OCM test are too verbose",
        "description": "The OCM test cases print quite a bit of stuff on standard output which makes the standard build output harder to read. It would be better if the tests either used explicit assertions to verify correct behaviour or at least redirected free-form output to a log file in the target directory.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2463",
        "summary": "Minor spi2dav ExceptionConverter improvements",
        "description": "It would be nice if the ExceptionConverter class in spi2dav returned UnsupportedRepositoryOperationExceptions instead of the undeclared UnsupportedOperationExceptions for HTTP 501 responses.\n\nBesides that, the ExceptionConverter.generate() methods should be cleaned to always return the generated exception instead of in some cases returning and in others throwing it.\n\nFinally, there's some unused code and chances for Java 5 cleanups.\n\nI'll attach a patch, and commit it unless anyone objects.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-172",
        "summary": "Improved READMEs for building sequence of trunk and jcr-server",
        "description": "",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1926",
        "summary": "Text.unescape(\"%\") throws a StringIndexOutOfBoundsException",
        "description": "You get the following exception:\n\njava.lang.StringIndexOutOfBoundsException: String index out of range: 3\n\tat java.lang.String.substring(String.java:1935)\n\tat org.apache.jackrabbit.util.Text.unescape(Text.java:407)\n\tat org.apache.jackrabbit.util.Text.unescape(Text.java:438)\n\nIt would be better if it failed with IllegalArgumentException.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-827",
        "summary": "SetValueFormatExceptiontest.testNode() relies on addMixin(), does not allow specification of node type",
        "description": "SetValueFormatExceptiontest.testNode() has two flaws:\n\n- it doesn't cope with cases where the created node already is mix:referenceable.\n\n- it doesn't allow specification of the node typer to be created.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1526",
        "summary": "Various improvment to Path and PathImpl",
        "description": "There are various issues with Path and PathImpl which the following patch addresses:\n- Fixed problem with normalization of some paths in PathImpl. \n- Fixed handling of relative paths in PathImpl. \n- Fixed wrong return value for depth and ancestor count in PathImpl. \n- Added method for determining equivalence of paths in PathImpl.\n- Fixed subPath method in PathImpl. \n- Clarified blurry contract for Path.\n- Added many new test cases\n\nFor many of the fixes credits are due to Angela.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2659",
        "summary": "Fails to remove a previously assigned mixin",
        "description": "Jackrabbit fails to remove a previously assigned mixin. Works fine on version 1.6.1",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1018",
        "summary": "introduce QValue.getCalendar()",
        "description": "Introduce QValue.getCalendar() in order to avoid unnecessary conversions from/to string format.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1305",
        "summary": "JNDI data sources with BundleDbPersistenceManager: UnsupportedOperationException",
        "description": "When using the org.apache.tomcat.dbcp.dbcp.BasicDataSourceFactory, the BundleDbPersistenceManager can not open a database connection via JNDI because the method DataSource.getConnection(user, password) is not supported. Instead, DataSource.getConnection() must be used for this to work.\n\nConnectionFactory.getConnection should be changed to call this method if user name and password are empty.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1982",
        "summary": "Exception root cause is swallowed in various places",
        "description": "When re-throwing an exception, the root cause is swallowed in some places in Jackrabbit, mainly when converting to an IOException.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-235",
        "summary": "Cache jcr name to QName mappings",
        "description": "Currently jcr names are always parsed and resolved into QName instances. Introducing a cache would increase performance and also save memory because well known and often used jcr names would always return the same QName instance from cache.\n\nTesting with common read operations shows a performance improvement of about 25%.\nThe test involved the following methods on Node interface:\n\n- getProperty()\n- getProperties()\n- getName()\n- getPath()\n- isLocked()\n- isNodeType()\n- getPrimaryNodeType()\n- hasNodes()\n- getNodes()\n\nAttached proposed implementation of a QNameResolver.\n\nPlease comment.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-684",
        "summary": "The servlet-api dependency scope should be \"provided\" in jackrabbit-jcr-server",
        "description": "Using the default \"compile\" scope for servlet-api in jackrabbit-jcr-server causes warnings about the scope not being \"provided\" when building jackrabbit-webapp.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2864",
        "summary": "Use out-of-process text extraction",
        "description": "The upcoming Tika 0.9 release will contain a highly useful out-of-process text extraction feature (TIKA-416) that we should use also in Jackrabbit.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2577",
        "summary": "SISM.checkAddedChildNodes() prevents merging of concurrent changes",
        "description": "This is a regression caused by JCR-2456. The check method reports false positives and prevents merges of concurrently removed child nodes.\n\nThe check is done before the local item states are connected to their shared states, which means getAddedChildNodes() will always return the complete list of local child nodes. In addition the merge attempt is also done after the check, which means it is impossible to handle concurrently removed child nodes.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-487",
        "summary": "the jcr:frozenUuid property is of type REFERENCE instead of STRING",
        "description": "The spec says that jcr:frozenUuid is a STRING but jackrabbit 1.0.1 uses a REFERENCE for it.\n",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "JCR-2860",
        "summary": "Make version recovery extensible",
        "description": "Currently JCR-2551 (Recovery from a lost version history) is implemented within the protected method RepositoryImpl$WorkspaceInfo.doInitialize(). However, it is implemented in a way that can't be re-used in a subclass (RepositoryChecker is not a public class).\n\nI will create a new method doVersionRecovery() that contains the code for JCR-2551.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-276",
        "summary": "SimpleWebdavServlet: avoid 404 for the root collection",
        "description": "in order to avoid strange 404 error when accessing the root collection in simple webdav servlet (thus missing workspace name), that request should either be redirected or handled by a create fake root that has no correspondance in the jsr170 repository.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1839",
        "summary": "JSR 283: Introduce Event.getDate()",
        "description": "JSR 283 adds a method to an Event that returns the date when the change happened that caused the event.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-1944",
        "summary": "Privilege content representation should be of property type NAME",
        "description": "the content representation of jcr privileges should reflect that fact that privilege names changed from simple string to JCR name.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1377",
        "summary": "Reduce memory usage of DocNumberCache",
        "description": "Instead of using the uuid String the a UUID instance should be used as the key in the cache.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2189",
        "summary": "Move MemoryJournal from test to main",
        "description": "Running our tests with the FileJournal implementation on a windows box can be quite slow because of the many FileDescriptor.sync() calls.\n\nI'd like to move the MemoryJournal in jackrabbit-core test to the main sources. That way we can use it in other test setups.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1935",
        "summary": "Incomplete JCR-1664 fix in BindableRepository",
        "description": "The changes in JCR-1664 were not fully merged from trunk to the 1.4 branch due to a typo in the commit message of revision 683268. As a result a BindableRepository subclass becomes a bit cumbersome to implement. I hope to fix this in 1.4.7 so that subclasses written for both the partial and fully merged JCR-1664 fix should work.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3111",
        "summary": "InternalVersionManagerBase; missing null check after getNode()",
        "description": "There are at least two instances where we check for a node with hasNode(), and then call getNode() without checking for null.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3148",
        "summary": "Using transactions still leads to memory leak",
        "description": "This is a result of the way that JCR-395 was fixed. If you look at the code, you'll see that txGlobal.remove(xid) is called as the last statement in both XASessionImpl.commit() and XASessionImpl.rollback(). However, in both methods an exception could be thrown either as a result of calling tx.commit() (or tx.prepare()) and tx.rollback(). \n\nAs a result, the transaction will not be removed from txGlobals whenever the commit or the rollback has failed for any reason. My suggestion would be to move the txGlobal.remove(xid) into a finally block.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-119",
        "summary": "workspace.copy does not copy binary properties properly",
        "description": "Workspace copy works fine for everything else but if you copy a hierarchy which contains binary properties\nand remove the source after copying it removes the binary from \"copied\" newly created hierarchy as well.\n\nHow to reproduce:\n\n1. create hierarchy with any type of nodes  - /site / en / image [Type Binary]\n2. create another hierarchy at different level - /site2\n3. copy /site/en under /site2\n-- till now everything is fine, its a proper copy and if you export xml out of these 2 hierarchies you will see that \"image\" is actually copied\n4. now delete /site/en\n5. you will see all other properties as copied before /site2/en... except binary.\n\nare binary types are always referenced? even if you copy via workspace copy\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2823",
        "summary": "Replace TrackingInpuStream with Commons IO",
        "description": "The TrackingInputStream class in jackrabbit-core implements essentially the same functionality as the Commons IO class CountingInputStream.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2421",
        "summary": "Unable to create repository using jackrabbit-webapp because a directory called \"jackrabbit\" already exists",
        "description": "I mount the jackrabbit-webapp.war in a Jetty installation\n* at startup i have the following exception:\nERROR RepositoryStartupServlet: Either create thejackrabbit/bootstrap.properties file or\nERROR RepositoryStartupServlet: use the '/config/index.jsp' for easy configuration.\nERROR RepositoryStartupServlet: RepositoryStartupServlet initializing failed: javax.servlet.ServletException: Repository startup configuration is not valid.\n* then when i access http://localhost:8080/ i am forwarded to the page:\n http://localhost:8080/bootstrap/missing.jsp\n* creating the repository by clicking on \"Create Content Repository\" button fails complaining that the jackrabbit directory already exists\n\nIndeed, i find a jackrabbit directory in my JETTY_HOME (from where is started Jetty).\n\nA workaround is to delete this \"jackrabbit\" directory and then i can create the repository by clicking on the previous button and therefore access the newly created repository.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-411",
        "summary": "Binding repository to a nameserver with RegistryHelper causes failure on lookup.",
        "description": "Binding a repository to a nameserver using RegistryHelper causes the next subsequent lookup to fail.  This is what I observerd:\n\n1. RegistryHelper.registerRepository creates a new BindableRepository and initializes it.  This, in turn, initializes the \"real\" repository (i.e. delagtee).  It then binds this reference with the nameserver.\n\n2. On the next lookup, BindableRepositoryFactory.getObjectInstance is invoked.  Thie method checks it's cache for a repository.  Since one does not exist yet, it creates a new BindableRepository and tries to initialize it.  This fails since the call to RegistryHelper.registerRepository already initialized the repository.\n\nThe error message basically says the repository is already in use by another process because the .lock file is present.  To fix this, I modified RegistryHelper.registerRepository to NOT initialize the repository and simply bind the \"Reference\".",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-400",
        "summary": "PROPPATCH error marshalling when the resource can't be modified in general",
        "description": "Litmus test case \"notowner_modify\" (see <http://mail-archives.apache.org/mod_mbox/jackrabbit-dev/200604.mbox/%3c4432A7CF.30008@gmx.de%3e>) complains about a 423 (Locked) status code being sent back inside a 207 Multistatus:\n\n  9. notowner_modify....... WARNING: PROPPATCH failed with 0 not 423\n     ...................... pass (with 1 warning)\n\nI think that warning is correct, as this is an error condition that doesn't need to be marshalled inside multistatus (1: it affects the resource at the Request URI and only that, 2: the operation failed completely). Let me also note that none of the other servers I tested with do return a 207 here (MS IIS, Apache/moddav, Xythos, SAP Netweaver KM),\n\nRFC2518bis will hopefully clarify error marshalling for PROPPATCH. \n\nFrom the source code, the current server behaviour is fully intentional (by specifically catching the DavException and using it in MultiStatus). Removing that code seems to fix the issue.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1021",
        "summary": "Move repository home directory into target directory",
        "description": "Currently the spi test client uses the repository home directory from the jackrabbit-core module. Instead it should use its own repository home, preferably in the target directory which can be reset using the maven clean goal.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1683",
        "summary": "JCR2SPI: Move test execution to SPI2JCR",
        "description": "proposed patches see  issue JCR-1629\n\nthis allows to\n- remove dependency to jackrabbit-spi2jcr and jackrabbit-core from jcr2spi\n- remove duplicated tests from sandbox/spi",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-422",
        "summary": "charset in Content-Type header shouldn't be in quotes",
        "description": "The charset value in the Content-Type header returned from IOUtil.buildContentType is enclosed in quotes. This value should be a token which does not include double quotes.\n\nIndex: C:/jprojects/eclipse/jackrabbit/jcr-server/server/src/java/org/apache/jackrabbit/server/io/IOUtil.java\n===================================================================\n--- C:/jprojects/eclipse/jackrabbit/jcr-server/server/src/java/org/apache/jackrabbit/server/io/IOUtil.java\t(revision 397215)\n+++ C:/jprojects/eclipse/jackrabbit/jcr-server/server/src/java/org/apache/jackrabbit/server/io/IOUtil.java\t(working copy)\n@@ -112,7 +112,7 @@\n     public static String buildContentType(String mimeType, String encoding) {\n         String contentType = mimeType;\n         if (contentType != null && encoding != null) {\n-            contentType += \"; charset=\\\"\" + encoding + \"\\\"\";\n+            contentType += \"; charset=\" + encoding;\n         }\n         return contentType;\n     }\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-396",
        "summary": "RMI published Repository using the jcr-rmi library gets lost over time",
        "description": "The jcr-server/webapp project contains a servlet - RepositoryStartupServlet - which may be used in a web app to start a repository and optionally register the repository with JNDI and RMI. To register the repository with JNDI, the jcr-rmi library is used to create a Remote repository instance, which is registered with the RMI registry. Inside the RMI implementation mechanisms based on stub classes created by the RMI compiler are created to make the remote repository available remotely. This includes creating a object table to map remote references to local objects. This table stores references to the local object as weak references to support distributed garbage collection.\n\nOver time, it may now be that this remote repository instance is actually collected and the object table cannot access it anymore thus preventing the repository from being accessed remotely. To prevent this from happening, the RepositoryStartupServlet must keep a strong reference to the remote repository and drop this reference when the servlet is destroyed and the repository unregistered.\n\n*NOTE:* This is an issue to all long running applications which publish repository instances over RMI using the jcr-rmi library.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1972",
        "summary": "Preserving UUID and document version history on repository migration",
        "description": "I have been working I an migration utility for OpenKM and I performed some changes in jackrabit-core to enable version import, preserving\nthe modification date. Also modified org.apache.jackrabbit.core.NodeImpl to preserve UUID in the migration process.\n\nThis migration process is needed because there are changes in repository node definition, and Jackrabbit can't deal with this actually.\n\nI've attache a PDF with the changes needed in Jackrabbit-core. It works and there was no problems with the migrated repository.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-2923",
        "summary": "SQL2 parser: improved error message for ambiguous properties in joins",
        "description": "For queries of the form:\n\nselect id from parent inner join child on parent.id=child.parentid\n\nthe SQL2 parser currently only returns a generic error message \"This query result contains more than one selector\". \n\nThe error message should point to the problematic token: \n\nQuery: select id(*)from parent inner join child on parent.id=child.parentid; expected: Need to specify the selector name for \"id\" because the query contains more than one selector.\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-691",
        "summary": "Let NameException extend RepositoryException",
        "description": "Since the NameExceptions (IllegalNameException, UnknownPrefixException, etc.) are typically thrown when parsing or formatting JCR names at the JCR API level, it would make sense for the NameException class to extend RepositoryException instead of the internal BaseException. This idea is supported by the fact that the majority of cases where NameExceptions are encountered simply rethrow the exceptions wrapped inside RepositoryException instances. Making NameException extend RepositoryException would reduce the amount of try-catch blocks and wrapped exceptions.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-87",
        "summary": "Move to a newer vesion of Commons Collections",
        "description": "It would be useful if the developer wants to use jackrabbit in an application that uses a newer version of this library.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": ""
    },
    {
        "key": "JCR-129",
        "summary": "ORM PersistenceManagers don't compile",
        "description": "ORM PMs are out of synch with the latest changes of the api. ",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "JCR-844",
        "summary": "ArrayStoreException while reregistering existing node types",
        "description": "\nclass: NodeTypeManagerImpl\nmethod: public NodeType[] registerNodeTypes(InputStream in, String contentType, boolean reregisterExisting)\n\n                ...\n                return (NodeType[]) nodeTypes.toArray(new NodeTypeDef[nodeTypes.size()]);\n                ...\n\n=> should be (I suppose !)\n\n                return (NodeType[]) nodeTypes.toArray(new NodeType[nodeTypes.size()]);\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1456",
        "summary": "Database connection pooling",
        "description": "Jackrabbit should use database connection pools instead of a single connection per persistence manager, cluster journal, or database data store.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-60",
        "summary": "primaryItemName is not inherited",
        "description": "if no primaryItemName is defined for a nodetype definition, it should be inherited from one of the supertypes. the spec is unclear about this, though it seems to be the natural behaviour.\n\nfor example when extending nt:resource, the subtype should not be force to redefine the jcr:data as primaryItemName.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-992",
        "summary": "Improve Performance of DescendantSelfAxisQuery",
        "description": "In DescendantSelfAxisQuery.DescendantSelfAxisScorer.isValid(int) contextHits is populated with docs that are found on the way down the axis. The current algorithm unfortunately doesn't add any new docs at all because it only adds docs already present in contextHits. This leads to more calls to HierarchyResolver.getParent(int) than necessary.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-999",
        "summary": "SPI: provide batch read functionality",
        "description": "extend RepositoryService interface to allow for BatchRead and modify jcr2spi accordingly.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1780",
        "summary": "Wiki reference a missing CND resource",
        "description": "Wiki page \"http://wiki.apache.org/jackrabbit/nt%3aexample\" references a missing resource:  \"http://jackrabbit.apache.org/doc/nodetype/cnd.html\"",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-656",
        "summary": "JCR-Server: Allow header misses colong (RootCollection, WorkspaceResourceImpl)",
        "description": "List of supported dav methods misses some colons.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2925",
        "summary": "Various inner classes maintain references to owning class for no reason",
        "description": "Various inner classes maintain references to their owning classes for no reason, as they are independent classes. This issue will change these classes to be static inner classes, so that their footprint decreases, they ease gc work, and potentially reduce the lifetime of the owning classes if they outlive their owner.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-737",
        "summary": "unexpected session is used  in XATest.testAddNodeCommit()",
        "description": "In org.apache.jackrabbit.core.XATest.java:137\n\n        // assertion: node exists in this session\n        try {\n            otherSuperuser.getNodeByUUID(n.getUUID());\n        } catch (ItemNotFoundException e) {\n            fail(\"Committed node not visible in this session\");\n        }\n\n        // assertion: node also exists in other session\n        try {\n            otherSuperuser.getNodeByUUID(n.getUUID());\n        } catch (ItemNotFoundException e) {\n            fail(\"Committed node not visible in other session\");\n        }\n\nThe session instance of 'otherSuperuser' is used two times. In the first case, I think that it is not 'otherSuperuser' but 'superuser'. \n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-212",
        "summary": "decorator enhancements",
        "description": "added some decorating enhancements as we discussed on the mailing list (apparently there is nothing yet in the gmane /marc archives).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3056",
        "summary": "jcr-commons: Add utility to translate a string to a AuthorizableQuery and execute it on the user manager ",
        "description": "it would be convenient if jackrabbit-jcr-commons would provide a utility to generate authorizable\nqueries from a string.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1756",
        "summary": "Include OCM in the main Jackrabbit build when using Java 5",
        "description": "Currently the OCM component are separate from the rest of Jackrabbit build due to the fact that they need Java 5 to compile. I'd like to add a java5 profile to the main Jackrabbit build that contains the OCM components and is automatically activated when building with Java 5 or higher.\n\nThis would simplify build instructions and allow us to remove the extra Jackrabbit-ocm Hudson build that we currently use to build the OCM component.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-776",
        "summary": "More verbose message on reference constraint violation",
        "description": "",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3132",
        "summary": "Test tooling updates",
        "description": "To leverage advances in test tooling I'd like to upgrade our JUnit dependency to 4.x and switch to using the Maven Failsafe plugin  [1] instead of our current custom POM settings for integration tests. I'll also upgrade the Easymock dependency to 3.0.\n\n[1] http://maven.apache.org/plugins/maven-failsafe-plugin/",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2890",
        "summary": "Deadlock in acl.EntryCollector / ItemManager",
        "description": "Here's another three-way deadlock that we've encountered:\n\n* Thread A holds a downgraded SISM write lock and is about to start delivering observation events to synchronous listeners\n* Thread B wants to write something and blocks waiting for the SISM write lock (since A holds the lock)\n* Thread C wants to read something and blocks waiting for the SISM read lock (since B waits for the lock)\n\nNormally such a scenario is handled without any problems, but there's a problem if the session used by thread C has a synchronous observation listener that attempts to read something from the repository during event delivery. In this case the following can happen:\n\n* Thread C holds the ItemManager synchronization lock higher up in the call chain\n* Observation listener code called by thread A attempts to read something from the repository, and blocks trying to acquire the ItemManager synchronization lock (since C holds it)\n\nIn principle such a scenario should never happen as an observation listener (much less a synchronous one) should never try to use the session that might already be in use by another thread.\n\nUnfortunately the EntryCollector class in o.a.j.core.security.authorization.acl does not follow this guideline, which leads to the deadlock as shown below:\n\nThread A:\n\"127.0.0.1 [1297191119365] POST /bin/wcmcommand HTTP/1.0\" nid=1179 state=BLOCKED\n    - waiting on <0x11c329fd> (a org.apache.jackrabbit.core.ItemManager)\n    - locked <0x11c329fd> (a org.apache.jackrabbit.core.ItemManager)\n     owned by 127.0.0.1 [1297191138443] POST /bin/wcmcommand HTTP/1.0 id=67\n    at org.apache.jackrabbit.core.ItemManager.getNode(ItemManager.java:653)\n    at org.apache.jackrabbit.core.ItemManager.getNode(ItemManager.java:605)\n    at org.apache.jackrabbit.core.SessionImpl.getNode(SessionImpl.java:1406)\n    at org.apache.jackrabbit.core.security.authorization.acl.EntryCollector.onEvent(EntryCollector.java:253)\n    at org.apache.jackrabbit.core.observation.EventConsumer.consumeEvents(EventConsumer.java:246)\n    at org.apache.jackrabbit.core.observation.ObservationDispatcher.dispatchEvents(ObservationDispatcher.java:214)\n    at org.apache.jackrabbit.core.observation.EventStateCollection.dispatch(EventStateCollection.java:475)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager$Update.end(SharedItemStateManager.java:786)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:1488)\n    at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:349)\n    at org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:354)\n    at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:324)\n    at org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:328)\n    at org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1141)\n    at org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:920)\n\nThread B:\n\"Thread-2438\" nid=2582 state=WAITING\n    - waiting on <0x166e790e> (a EDU.oswego.cs.dl.util.concurrent.WriterPreferenceReadWriteLock$WriterLock)\n    - locked <0x166e790e> (a EDU.oswego.cs.dl.util.concurrent.WriterPreferenceReadWriteLock$WriterLock)\n    at java.lang.Object.wait(Native Method)\n    at java.lang.Object.wait(Object.java:485)\n    at EDU.oswego.cs.dl.util.concurrent.WriterPreferenceReadWriteLock$WriterLock.acquire(Unknown Source)\n    at org.apache.jackrabbit.core.state.DefaultISMLocking$WriteLockImpl.<init>(DefaultISMLocking.java:76)\n    at org.apache.jackrabbit.core.state.DefaultISMLocking$WriteLockImpl.<init>(DefaultISMLocking.java:70)\n    at org.apache.jackrabbit.core.state.DefaultISMLocking.acquireWriteLock(DefaultISMLocking.java:64)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager.acquireWriteLock(SharedItemStateManager.java:1808)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager.access$200(SharedItemStateManager.java:112)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager$Update.begin(SharedItemStateManager.java:565)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager.beginUpdate(SharedItemStateManager.java:1458)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:1488)\n    at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:349)\n    at org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:354)\n    at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:324)\n    at org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:328)\n    at org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1141)\n    at org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:920)\n\nThread C:\n\"127.0.0.1 [1297191138443] POST /bin/wcmcommand HTTP/1.0\" nid=67 state=WAITING\n    - waiting on <0xf820edb> (a EDU.oswego.cs.dl.util.concurrent.WriterPreferenceReadWriteLock$ReaderLock)\n    - locked <0xf820edb> (a EDU.oswego.cs.dl.util.concurrent.WriterPreferenceReadWriteLock$ReaderLock)\n    at java.lang.Object.wait(Native Method)\n    at java.lang.Object.wait(Object.java:485)\n    at EDU.oswego.cs.dl.util.concurrent.WriterPreferenceReadWriteLock$ReaderLock.acquire(Unknown Source)\n    at org.apache.jackrabbit.core.state.DefaultISMLocking$ReadLockImpl.<init>(DefaultISMLocking.java:102)\n    at org.apache.jackrabbit.core.state.DefaultISMLocking$ReadLockImpl.<init>(DefaultISMLocking.java:96)\n    at org.apache.jackrabbit.core.state.DefaultISMLocking.acquireReadLock(DefaultISMLocking.java:53)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager.acquireReadLock(SharedItemStateManager.java:1794)\n    at org.apache.jackrabbit.core.state.SharedItemStateManager.getItemState(SharedItemStateManager.java:257)\n    at org.apache.jackrabbit.core.state.LocalItemStateManager.getNodeState(LocalItemStateManager.java:107)\n    at org.apache.jackrabbit.core.state.LocalItemStateManager.getItemState(LocalItemStateManager.java:171)\n    at org.apache.jackrabbit.core.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:200)\n    at org.apache.jackrabbit.core.ItemManager.getItemData(ItemManager.java:391)\n    at org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:337)\n    at org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:638)\n    at org.apache.jackrabbit.core.security.authorization.acl.ACLProvider$AclPermissions.canRead(ACLProvider.java:507)\n      - locked java.lang.Object@6ad9b475\n    at org.apache.jackrabbit.core.security.DefaultAccessManager.canRead(DefaultAccessManager.java:251)\n    at org.apache.jackrabbit.core.query.lucene.QueryResultImpl.isAccessGranted(QueryResultImpl.java:374)\n    at org.apache.jackrabbit.core.query.lucene.QueryResultImpl.collectScoreNodes(QueryResultImpl.java:353)\n    at org.apache.jackrabbit.core.query.lucene.QueryResultImpl.getResults(QueryResultImpl.java:310)\n    at org.apache.jackrabbit.core.query.lucene.SingleColumnQueryResult.<init>(SingleColumnQueryResult.java:70)\n    at org.apache.jackrabbit.core.query.lucene.QueryImpl.execute(QueryImpl.java:133)\n    at org.apache.jackrabbit.core.query.QueryImpl.execute(QueryImpl.java:127)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-720",
        "summary": "TCK: NodeReadMethodsTest#testGetPrimaryItemItemNotFoundException selects wrong test data",
        "description": "Method locateNodeWithoutPrimaryItem is used to locate recursively node which does not define a primary item, but this method calls internally locateNodeWithPrimaryItem instead of locateNodeWithoutPrimaryItem.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-403",
        "summary": "add shutdown() or logoutAll() method to TransientRepository",
        "description": "It would be usefull to be able to explicitly ask a TransientRepository to shut down, instead of relying on all sessions to be closed by session.logout().",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2206",
        "summary": "Replace NodeReferencesId with NodeId",
        "description": "The NodeReferencesId class simply wraps a NodeId and forwards all essential method calls to it.\n\nThe main (only?) benefit of having NodeReferencesId as a separate class is the ability to distinguish between the overloaded exists() and load() method signatures on PersistenceManager. The downside is the need to instantiate all the NodeReferencesId wrapper objects whenever accessing the references to a node.\n\nI propose to rename the overloaded methods to hasReferencesTo(NodeId) and getReferencesTo(NodeId) and to replace the NodeReferencesId with just the target NodeId wherever used.\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1655",
        "summary": "Upgrade nekohtml dependency",
        "description": "The latest CyberNeko HTML parser versions are ALv2-licensed and have better Maven dependency metadata.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1343",
        "summary": "Replace xerces for serialization by JAXP",
        "description": "The org.apache.jackrabbit.rmi.xml.ImportContentHandler class currently uses Xerces to implement the SAX DocumentHandler and serialize XML into a byte[]. This dependency should be dropped and JAXP be used instead for this functionality.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2564",
        "summary": "SQL2 query: QOMFormatter create incorrect NOT conditions",
        "description": "Then the following query is parsed:\nSELECT test.* FROM test WHERE (NOT test.name = 'Hello') AND test.id = 3\nthen the SQL statement generated, it becomes:\nSELECT test.* FROM test WHERE NOT test.name = 'Hello' AND test.id = 3\nwhich is parsed differently and becomes:\nSELECT test.* FROM test WHERE NOT (test.name = 'Hello' AND test.id = 3)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1115",
        "summary": "Remove dependency on Jackrabbit-core",
        "description": "We should remove the dependency on Jackrabit core in the OCM subprojects \"jcr-mapping\" and \"annotation\". We can use Jackrabbit core only for the unit tests. \n\nWe can also split the jcr-nodemanagement into several subprojects (one per JCR repo impl).  We will have only one subproject for Jackrabbit but contributions for other JCR repo impl are welcome.  A specific jcr-nodemanagement jar can be produce for each JCR repo impl. When the JCR will support the node creation, we can refactor the jcr-nodemanagement. \n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-961",
        "summary": "Add workspace population tool",
        "description": "Add a simple tool to jackrabbit-webapp to populate the workspace with content.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2170",
        "summary": "Remove PropDefId and NodeDefId",
        "description": "the PropDefIds and NodeDefIds are used to quickly lookup a childnode- or property definition in the nodetype registry (or effective nodetype).\nthis is heavily used during reading, when calling Property.getDefinition() usually when checking the isMultiple() flag. and of course while writing when getting the definition for the property or childnode. \n\nhowever, this poses problems when a nodetype is changed that is still used in the content. if a property definition is changed due to an altered nodetype, subsequent accesses to that property result in a \"invalid propdefid\" warning in the log - but the id is recomputed. this is especially a problem when upgrade jackrabbit from 1.x to 2.0, where some of the builtin nodetypes are defined differently.\n\ni think that it should be feasible to remove the propdefids and nodedefids and compute the definition on demand. i think this can be implemented without performance loss, when some sort of 'signatures' of the items are computed to quickly find the definitions in the effective node type. furthermore, the most common usecase for using the property definition is probably the isMultiple() check - which is now on the Property interface itself - which does not need a definition lookup at all.\n\nand last but not least, it saves 8 bytes per item in the persistence layer.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-889",
        "summary": "Add bundle support for PostgreSQL",
        "description": "The class DbNameIndex does not work with this RDBMS since the RETURN_GENERATED_KEYS JDBC feature is not implemented in current PostgreSQL drivers.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-118",
        "summary": "Session.importXML and Workspace.importXML throw wrong exception",
        "description": "According to the JCR specification (section 7.3.6 and 7.3.7), if uuidBehaviour is set to IMPORT_UUID_COLLISION_REMOVE_EXISTING, a ConstraintViolationException should be thrown, when an incoming node has the same UUID as the node at parentAbsPath or one of its ancestors.\n\nCurrently, a RepositoryException is thrown instead.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-856",
        "summary": "NodeAddMixinTest assumptions on addMixin behaviour",
        "description": "NodeAddMixinTest.testAddMixinReferencable() assumes that mix:referenceable can be added to the test node type. In practice, the node type may already inherit mix:referenceable, but it may not be active until the node is saved. Thus, a ConstraintViolationException upon addMixin should be catched, and the mixin should be checked after save() again.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-2153",
        "summary": "Introduce QValueConstraint and change return type of QPropertyDefinition.getValueConstraints()",
        "description": "public interface QValueConstraint {\n+\n+    /**\n+     * Empty array of <code>QValueConstraint</code>.\n+     */\n+    public static final QValueConstraint[] EMPTY_ARRAY = new QValueConstraint[0];\n+\n+    /**\n+     * Check if the specified value matches this constraint.\n+     *\n+     * @param value The value to be tested.\n+     * @throws ConstraintViolationException If the specified value is\n+     * <code>null</code> or does not matches the constraint.\n+     * @throws RepositoryException If another error occurs.\n+     */\n+    void check(QValue value) throws ConstraintViolationException, RepositoryException;\n+\n+    /**\n+     * For constraints that are not namespace prefix mapping sensitive this\n+     * method returns the same defined in\n+     * <code>{@link PropertyDefinition#getValueConstraints()}</code>.\n+     * <p/>\n+     * Those that are namespace prefix mapping sensitive (e.g.\n+     * <code>NameConstraint</code>, <code>PathConstraint</code> and\n+     * <code>ReferenceConstraint</code>) return an expanded string.\n+     *\n+     * @return the expanded definition String\n+     */\n+    String getExpandedDefinition();\n+\n+}\n\n\n+++ jackrabbit-spi/src/main/java/org/apache/jackrabbit/spi/QPropertyDefinition.java\t(working copy)\n@@ -45,7 +45,7 @@\n      *\n      * @return the array of value constraints.\n      */\n-    public String[] getValueConstraints();\n+    public QValueConstraint[] getValueConstraints();\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-109",
        "summary": "Contrib RMI: NotSerializableException",
        "description": "org.apache.jackrabbit.rmi.client.RemoteRepositoryException:\n\nerror unmarshalling return; nested exception is:.java.io.WriteAbortedException: writing aborted; java.io.NotSerializableException: javax.jcr.NameValue\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-753",
        "summary": "Creation of JavaDoc fails on jackrabbit-jcr-server",
        "description": "The creation of JavaDoc fails on project jackrabbit-jcr-server if the command \"mvn javadoc:javadoc\" is called on the latest checkout of jackrabbit. See attached log...",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-1476",
        "summary": "Restore to base version throws NullPointerException",
        "description": "This only happens when the operations are enclosed in an XA transaction.\nSee test: org.apache.jackrabbit.core.version.RestoreTest",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1651",
        "summary": "Node.addNode(String, String) doesn't prevent use of mixin types as primary type",
        "description": "",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-10",
        "summary": "save() might create new transient properties",
        "description": "It seems that when a new node is saved through the parent node, new properties might get created, which are not saved. To persist those properties the new node must be saved again.\n\nExample:\n\n(Consider a mixin type \"extVer\" extending the standard type mix:versionable.)\n\n      Node node = parent.addNode(\"newNode\", \"nt:base\");\n      node.addMixin(\"extVer\");\n      // \"mix:versionable\" properties do not exist here\n      \n      // save the new node\n      parent.save();\n\n      // now \"mix:versionable\" properties like \"jcr:isCheckedOut\"\n      // exist in the \"node\" but:\n      //    node.getProperty(\"jcr:isCheckedOut\").isNew() == true\n      // fix:\n      node.save();\n\nIf the last node.save() opertation would not be done, a RepositoryException would result if a node.checkIn() would be done immediately after parent.save().\n\nThis seems counterintuitive and seems like an error. I wonder whether the properties should not be added upon \"node.addMixin\" ? At least \"parent.save()\" should (or might I say must ?) not only add the properties but also save them.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1747",
        "summary": "org.apache.jackrabbit.core.query.lucene.SearchIndex with in-memory lucene index",
        "description": "If I'm not wrong, there is actually no way to configure SearchIndex in order to use a memory only lucene index.\n\nSince you can configure a repository using a org.apache.jackrabbit.core.state.mem.InMemPersistenceManager, it makes sense that also search index offers a similar configuration.\nMultiIndex and PersistentIndex now always use a org.apache.lucene.store.FSDirectory, they should be refactored in order to allow a switching to a org.apache.lucene.store.RAMDirectory for this.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1053",
        "summary": "Calling size method of a ManageableArrayList causes NullPointerException",
        "description": "When using the NTCollectionConverterImpl with proxy=\"true\" a call on the size () method of a ManageableArrayList causes a NullPointerException if there is no underlying List. LazyCollectionLoader doLoad returns null because there is are no children.\n\nThe ManageableArrayList is created because the isNull method of the NTCollectionConverterImpl class always returns false. \nAccording to the comment line this is done because the getCollectionNodes always returns a list. \nBut after the fix for JCR-882 this is not correct anymore.\n\nThe attached fix corrects this. \n\nThe only question remaining is how to differ between an empty list and a null-value for the field containing the list.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1922",
        "summary": "Validate the SearchIndex configuration",
        "description": "The validation of the configuration (repository.xml / workspace.xml) was enabled in JCR-1462, unfortunately a problem with the LoginModule and SearchIndex was found (see JCR-1920), so it was later disabled for those two modules.\n\nValidation for SearchIndex is possible but needs some more changes. To avoid problems, those changes should be done in a major version and not in a minor version.",
        "label": "NUG",
        "classified": "SPEC",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2710",
        "summary": "Add support for large number of users in a group",
        "description": "In the current implementation there are several factors which limit the number of users in a group:\n\n- group membership is recorded in a multi valued property which does not scale well\n- members of groups are collected eagerly which does not scale well\n\nI propose to add complementary support for recording group membership in a node structure to the current solution. That node structure would - similar to users and groups - add intermediate nodes when a group reaches a certain threshold on the number of its users.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3151",
        "summary": "SharedFieldCache can cause a memory leak",
        "description": "The SharedFieldCache has some problems with the way it builds the cache:\n - as key is has the IndexReader\n - as value it has a inner cache (another map) that has as a key a static inner class called 'Key'.\n\nThis 'Key' holds a reference to the comparator used for in the queries ran.\nAssuming this comparator is of any type that extends from AbstractFieldComparator (I think all of the custom JR comparators), then it keeps a reference to all the InderReader instances in order to be able to load the values as Comparable(s).\n\nSo the circle is complete and the SharedFieldCache entries never get GC'ed.\n\nOne option would have been to implement a 'purge' method on the cache, similar to the lucene mechanism, and when an InderReader gets closed is could call 'purge'. But that is both ugly AND is doesn't seem to work that well :)\n\nA more radical option is to remove the cache completely. Each instance of SimpleFieldComparator (the only client of this cache) already builds an array of the available values, so the cache would only help other instances of the same type. We'll not analyze this further.\n\nThe proposed solution (patch will follow shortly) is to remove the Comparator reference from the Key class. \nIt looks like it has no real purpose there, just to impact the 'equals' of the key, which makes no sense in the first place as the lucene query does not use the Comparator info at all.\nIf anything, using the same field and 2 different Comparators we'll get 2 different cache entries based on the same values from the lucene index.\n\nFeedback is appreciated!\n\n\n\n\n\n\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2082",
        "summary": "Query does not work after logging into workspace with no indexes",
        "description": "When I login to workspace that does not have indexes, they are created but my queries do not return results unless I relog. Output from running attached code sample is:\n\nNode [node1240842434531] created in workspace [test1240842434312]\nProperty [name] set to [someValueOfMyProperty]\nAsking query: select * from nt:unstructured where nt:name like 'someValueOfMyProperty'\nFound: 1 nodes before deleting index.\nAsking query: select * from nt:unstructured where nt:name like 'someValueOfMyProperty'\nFound: 0 nodes after deleting index.\ndone",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-418",
        "summary": ".NET build scripts for Jackrabbit",
        "description": "Hugo Burm has created build scripts that make it possible to run Jackrabbit under .NET. We should add the scripts and excample client code as a contrib project or integrate them with the Maven build system.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "RFE"
    },
    {
        "key": "JCR-3014",
        "summary": "Identifier paths for inexistent items throw exception",
        "description": "The following fails with a RepositoryException but it should rather return false:\n\nsession.itemExists(\"[\" + UUID.randomUUID() + \"]\")",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-41",
        "summary": "ItemManager issues WARN message on Node.checkIn and Node.checkOut",
        "description": "Wenn checking in or checking out a node, the ItemManager.cacheItem method issues a WARN message because a cache entry is being replaced.\n\nWhile this message might be valuable in certain contexts, in the contetx of checking in or out a node, this is not valuable and harms confidence :-)",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1512",
        "summary": "Incorrect check for replace when importing item with colliding id",
        "description": "When fixing JCR-1128 bug was introduced due to incorrect check for UUID behavior. Current code is:\n201 : \t if (!(existing.getId().equals(id)\n202 : \t&& (uuidBehavior == ImportUUIDBehavior.IMPORT_UUID_COLLISION_REMOVE_EXISTING\n203 :\t|| uuidBehavior == ImportUUIDBehavior.IMPORT_UUID_COLLISION_REMOVE_EXISTING))) {\n204 :\tthrow new ItemExistsException(existing.safeGetJCRPath());\n205 :\t}\n\nWhile it should check for ImportUUIDBehavior.IMPORT_UUID_COLLISION_REPLACE_EXISTING in one of the cases (line 202 or 203).\nAlso it is possible that id of imported item is not known and therefore value of \"id\" variable is null and check will always fail. Would be nice if this case can be handled as well.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2363",
        "summary": "Node.orderBefore does not check permissions",
        "description": "It seems that Node.orderBefore(String, String) does not check if the editing session is allowed to modify the parent, neither immediately nor upon saving the transient changes.\n\nThis issue was found by Alexandre Capt. Thanks!",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1427",
        "summary": "XPath query with child axis predicates",
        "description": "Executing a query using a long child path in a child axis predicate (like //*[a/b/c/d/e/@prop='something']) may return too many or not enough nodes.\n\nI'll attach a zip file containing 2 tests cases showing this issue (I apologize but the test data are in French).\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2054",
        "summary": "Provide base classes to simplify read only RepositoryService implementations",
        "description": "There should be base classes that simplify the implementation of a RepositoryService for read only access.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1082",
        "summary": "cache getting out of sync with transientstore causes pathnotfoundexception",
        "description": "Done some further debugging and think the problem is in the synchronization between cache and transientstore. When I retrieve a childnode when I just made its parent node transient (by removing a prop or something), it will not be added to the cache. When I then remove this node, its nodeid is not removed from cache since its stateId wasn't saved in the cache.  After that I add the same node node again with the same name. When I now try to retrieve this node, I get a path not found exception. I see that by retrieving it, its nodeit is resolved from the cache using its path. Only since the removed node was not removed from cache it returns the nodeid of the already removed node. There is no node present with this id in the transientstore and therefor it throws a pathnotfoundexception.\n\nprovided a failing junit test and repository.xml",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2340",
        "summary": "CacheBehaviour Observation broken",
        "description": "While trying to fix JCR-2293 I discovered that CacheBehaviour Observation is broken:\n\n- HierarchyEventListener.onEvent ignores local event (despite the comment saying otherwise). Not sure which way it should be. However with local events being ignored, JCR-2293 will most probably also occur with CacheBehaviour Observation. \n\n- NodeEntryImpl.refresh(Event) does not set its child node entries to incomplete when a node/property was added.\n\n- After tentatively fixing above issues, I discovered that NodeEntryImpl.refresh(Event) and my own event listener operate on different NodeEntryImpl and ChildNodeEntryImpl instances. That is, even though I set childNodeEntries.complete to false in NodeEntryImpl.refresh(Event), when my own event listener retrieves that node (entry), it gets a different instance which has childNodeEntries.complete still set to true.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2885",
        "summary": "Move tika-parsers dependency to deployment packages",
        "description": "As discussed on the mailing list, it would be better if the tika-parsers dependency (and all the parser libraries it pulls in transitively) was included in our deployment packages but not directly in jackrabbit-core. This would make it easier for people to set up custom lightweight deployments with no or only partial full text extraction functionality.\n\nTo do this we'll first need to wait for Tika 0.9, as we currently have a custom PDFParser class in jackrabbit-core as a workaround to a problem in Tika 0.8.\n\nAt the same time we should do a more thorough review of the transitive parser dependencies we include. At least the rome and bouncycastle libraries were flagged as potentially unnecessary.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-441",
        "summary": "Session logout doesn't release locks acquired using addLockToken",
        "description": "Session.addLockToken doesn't register locks with the session so when logout is called they are not released. Locks acquired this way maintain a reference to the Session after logout and new sessions attempting to acquire the locks will fail.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-287",
        "summary": "session.setNamespacePrefix() creates ambiguous mappings",
        "description": "1.) assume the following initial global mappings in the NamespaceRegistry \n(prefixes in lowercase, URIs in uppercase):\n\na  <-> A\nb  <-> B\nc  <-> C\n\n2.) locally remap  the namespaces in a session using the following code:\n\n            session.setNamespacePrefix(\"x\", \"B\");\n            session.setNamespacePrefix(\"b\", \"C\");\n            session.setNamespacePrefix(\"c\", \"B\");\n\nthis results in the following session-local mappings:\n\na  <-> A\nc  <-> B\nb  <-> C\n\n3.) now the following stmt:\n\n            session.setNamespacePrefix(\"b\", \"A\");\n\nproduces this ambiguous mapping:\n\nb  <-> A\nc  <?> B\nc  <?> C\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1700",
        "summary": "Deprecate NamespaceListener and AbstractNamespaceResolver",
        "description": "The NamespaceListener interface is no longer used with the JSR 283 style namespace handling that avoids lots of the synchronization that was previously to keep the local namespace mappings up to date.\n\nAlso, the only (remaining) purpose of the AbstractNamespaceResolver class is to add support for managing NamespaceListeners. Since that functionality is nowhere used anymore, we can make all subclasses use the NamespaceResolver interface directly.\n\nSince NamespaceListener and AbstractNamespaceResolver are public in jackrabbit-spi-commons, I will for now only mark them as deprecated. We can get rid of them in Jackrabbit 2.0.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1005",
        "summary": "More Fine grained Permission Flags",
        "description": "It would be fine to have one more Permission Flag on node add.\nAt the moment there are 3 flags. We need to know if a node will be updated or created.\nThis is not possible with the current implementation because on node add the permission flag \nAccessManager.WRITE will be used. This is a Problem in a  WebDav Scenario with Microsoft-Word because if i open a Node and \ntry to save it i need write permissions on the parent node. this is ok. If a user trys to save the file with a other name\nhe can because the same PermissionFlag will be used.\nMaybe there is a other solution for this problem ?\nBR,\nclaus",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-158",
        "summary": "TextFilterService uses Sun specific classes",
        "description": "The TextFilterService uses the Sun specific and actually undocumented class sun.misc.Service class to lookup TextFilter implementations. This approach will not work on all JVM implementations.\n\nThe Service should rather use javax.imageio.spi.ServiceRegistry, which is part of the standard J2SE API.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3218",
        "summary": "UserImporter should trigger execution AuthorizableActions in case of user/group creation",
        "description": "in accordance to the new implementation specific extensions made to user mangement in JCR-3118 the user-importer\nshould be adjusted as well.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "BUG"
    },
    {
        "key": "JCR-1540",
        "summary": "BundleDbPersistenceManager.checkConsistency() only fixes inconsistency if consistencyFix is enabled in configuration",
        "description": "The method has a parameter that explicitly tells whether an inconsistency should be fixed, thus the configuration parameter should be ignored.\n\nSuggested patch:\n\nIndex: BundleDbPersistenceManager.java\n===================================================================\n--- BundleDbPersistenceManager.java\t(revision 648657)\n+++ BundleDbPersistenceManager.java\t(working copy)\n@@ -864,7 +864,7 @@\n         }\n \n         // repair collected broken bundles\n-        if (consistencyFix && !modifications.isEmpty()) {\n+        if (fix && !modifications.isEmpty()) {\n             log.info(name + \": Fixing \" + modifications.size() + \" inconsistent bundle(s)...\");\n             Iterator iterator = modifications.iterator();\n             while (iterator.hasNext()) {\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-687",
        "summary": "UUID compareTo and hashCode",
        "description": "The current UUID.compareTo implementation is not correct. Usually, 'equals' is used so this is not a big problem, but I need to create an ordered list of UUIDs and for this I need compareTo. The current implementation is based on subtraction, but this doesn't always work. Example:\n\n//long a = 10, b = 20, c = 0;\nlong a = Long.MAX_VALUE, b = Long.MIN_VALUE, c = 0;\nSystem.out.println((a - b) < 0 ? \"a < b\" : \"a >= b\");\nSystem.out.println((c - a) < 0 ? \"c < a\" : \"c >= a\");\nSystem.out.println((b - c) < 0 ? \"b < c\" : \"b >= c\");\n\nThe hashCode implementation is OK, but the multiplication is not required.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3162",
        "summary": "Index update overhead on cluster slave due to JCR-905",
        "description": "JCR-905 is a quick and dirty fix and causes overhead on a cluster slave node when it processes revisions.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-910",
        "summary": "jcr mapping layer does not expose node move and node copy via PersistenceManager.java",
        "description": "The PersistenceManagerImpl.java  in jcr-apping layer does not implement move and copy methods for a node.  ",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-1485",
        "summary": "Introduce daily integration test suite",
        "description": "Some time ago we discussed integration tests that would be run on a daily basis. See also comments in issue JCR-1452. It seems we reached consensus that running a daily integration test suite is desirable.\n\nHere's my proposal:\n\n- Introduce a test suite org.apache.jackrabbit.core.integration.daily.DailyIntegrationTest which includes all tests that should be run on a daily basis.\n- Configure our continuous integration system to run the test suite on a daily basis. e.g. mvn -Dtest=DailyIntegrationTest package\n\nWith this approach we don't need to introduce maven profiles or any other pom magic, yet it's easy for a developer to run the daily tests when needed.",
        "label": "NUG",
        "classified": "TEST",
        "type": "TEST"
    },
    {
        "key": "JCR-1644",
        "summary": "make NamespaceContext#getPrefix(java.lang.String) iterative instead of recursive",
        "description": "Currently the method org.apache.jackrabbit.core.xml.NamespaceContext#getPrefix(java.lang.String) uses recursion. For very large XML files (50 MB Magnolia website exports) this causes a stack overflow. The method can easily be rewritten using iteration.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-928",
        "summary": "NodeTypeManagerImpl.hasNodeType should allow unknown prefixes",
        "description": "The current implementation of NodeTypeImpl.hasNodeType(String) throws an exception if the given name uses an unknown prefix. A better alternative would be to just return false, as by definition a node type in an unknown namespace can not exist.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1841",
        "summary": "Workspace.xml can't be loaded if it has a BOM",
        "description": "I wondered if there was a specific reason why workspace.xml files are loaded using a FileReader instead of an InputStream in RepositoryConfig?\n\nIf the workspace.xml file has a BOM (which could happen if someone edited the file manually with some misbehaving editor), then it can't be loaded (\"Content not allowed in prolog\") - here's a little patch that fixes this.\n\nI left the output part untouched (i.e still using a Writer) - which makes it a little inconsistent - maybe someone with a better knowledge of the JR FileSystem api could fix this.\n\n",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "JCR-2541",
        "summary": "spi2dav : EventJournal not  implemented",
        "description": "i didn't look at the details just realized that all EventJournalTest of the TCK fail in the setup\njcr2spi - spi2dav(ex) - jcr-server.\ni assume that this is due to missing implementation (the corresponding SPI method throws UnsupportedRepositoryOperationException).",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-234",
        "summary": "VersionTest.testGetUUID() fails",
        "description": "VersionTest.testGetUUID() fails due to inproper invlaidation of the successor properties after checkin.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-453",
        "summary": "add/remove dispatchers from DelegatingObservationDispatcher is not synchronized",
        "description": "the 'dispatchers' hashset in DelegatingObservationDispatcher is not synchronized and can lead to errors, when a workspace goes offline or is creating during event dispatching.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-412",
        "summary": "JCA Concurrent Modification Exception when JCAManagedConnection.cleanup() called",
        "description": "The JCAManagedConnection.closeHandles() method causes a ConcurrentModificationException if the handles list is not empty.\nThis is caused by modification of the handles list by removeHandle(), while closeHandles() is iterating over the list.\n\nUnder SunOne AppServer 7 this can be caused simply by not closing the Session handle before the transaction commits.\n\nIt is probably not even necessary to send connectionClosed events during cleanup().  According to the API for connectionClosed, the event indicates that an application component has closed  the connection handle.  cleanup() is a container initiated action, and so the connectionClosed event is not applicable.\n\n\njava.util.ConcurrentModificationException\n    at java.util.LinkedList$ListItr.checkForComodification(LinkedList.java:552)\n    at java.util.LinkedList$ListItr.next(LinkedList.java:488)\n    at org.apache.jackrabbit.jca.JCAManagedConnection.closeHandles(JCAManagedConnection.java:382)\n    at org.apache.jackrabbit.jca.JCAManagedConnection.cleanup(JCAManagedConnection.java:145)\n    at com.sun.enterprise.resource.IASPoolObjectImp.cleanup(IASPoolObjectImp.java:243)\n    at com.sun.enterprise.resource.IASGenericPoolObjects.transactionCompleted(IASGenericPoolObjects.java:794)\n    at com.sun.enterprise.resource.ResourcePoolManagerImpl.transactionCompleted(ResourcePoolManagerImpl.java:347)\n    at com.sun.enterprise.resource.ResourcePoolManagerImpl$SynchronizationListener.afterCompletion(ResourcePoolManagerImpl.java:644)\n    at com.sun.jts.jta.SynchronizationImpl.after_completion(SynchronizationImpl.java:70)\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2785",
        "summary": "EffectiveNodeType#getNamedNodeDefs returns array QItemDefinition instead of QNodeDefinition",
        "description": "... thus requires unnecessary casting...",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-812",
        "summary": "TCK: RestoreTest.testRestoreLabel",
        "description": "According to tobi the jackrabbit implementation of 'Node.restoreByLabel' is an interpretation of the\nspecification regarding the restore behaviour of versionable child nodes. while that interpetration might\nbe legal unless the specification is violated, i would argue that the TCK should not test the interpretation.\n\ntherefore i suggest to modify\n\norg.apache.jackrabbit.test.api.version.RestoreTest.testRestoreLabel\n\nby skipping line 334 - 345 in order to limit the test case to the behaviour that is defined by the specification.\n\nregards\nangela\n\nps: the mentioned test is also executed within the scope of WorkspaceRestoreTest because the latter  extends RestoreTest.... that's misleading.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-765",
        "summary": "DatabasePersistenceManager: don't log exceptions for each statement when a connection needs to be reestablished",
        "description": "This is just a \"cosmetic\" fix: when reestablishConnection() is called in DatabasePersistenceManager all the statements are closed but if an error occurs two exceptions are logged for each statement.\nSince reestablishConnection() is already called when an exception has been caught and its only purpose is to cleanup an existing connection and to reopen a new one is pretty common that the connection is already not valid and that each statement close will throw an exception.\n\nFor example if the connection has been broken due to a network problem DatabasePersistenceManager  will log *40* exceptions (2 for each statement) before trying to establish a connection, and that's pretty annoying (expecially if you use a mail appender for log4j....)\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2975",
        "summary": "Make ItemInfoBuilder name space aware",
        "description": "Currently there is no way to to have NodeInfoBuilder/PropertyInfoBuilder build NodeInfos/ItemInfos on a name space other than the default one. I suggest to add appropriate methods to NodeInfoBuilder/PropertyInfoBuilder to set the name space.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2031",
        "summary": "Improved log message: include path",
        "description": "The cluster logs a message for each appended operation. The log message is currently the revision number. A more interesting log message would be the user name, and the path of the change (the most specific path if the change contains multiple nodes).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-615",
        "summary": "JCR2SPI: NPE when parentId returned by NodeInfo.getParentId does not show up in parent's child node list",
        "description": "In this custom SPI implementation, version history nodes appear as children of jcr:versionStorage, but jcr:versionStorage does not return them as children (which would be impractical for performance reasons - I expect similar approaches used by others...).\n\ngetParentId of a NodeInfo of a VersionHistory return the NodeId for jcr:versionStorage. In this case, I get the NPE below:\n\njava.lang.NullPointerException\n\tat org.apache.jackrabbit.jcr2spi.state.WorkspaceItemStateFactory.createNodeState(WorkspaceItemStateFactory.java:99)\n\tat org.apache.jackrabbit.jcr2spi.state.CachingItemStateManager.resolve(CachingItemStateManager.java:168)\n\tat org.apache.jackrabbit.jcr2spi.state.CachingItemStateManager.getItemState(CachingItemStateManager.java:94)\n\tat org.apache.jackrabbit.jcr2spi.WorkspaceManager.getItemState(WorkspaceManager.java:328)\n\tat org.apache.jackrabbit.jcr2spi.state.TransientISFactory.createNodeState(TransientISFactory.java:120)\n\tat org.apache.jackrabbit.jcr2spi.state.CachingItemStateManager.resolve(CachingItemStateManager.java:168)\n\tat org.apache.jackrabbit.jcr2spi.state.CachingItemStateManager.getItemState(CachingItemStateManager.java:94)\n\tat org.apache.jackrabbit.jcr2spi.state.TransientItemStateManager.getItemState(TransientItemStateManager.java:209)\n\tat org.apache.jackrabbit.jcr2spi.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:155)\n\tat org.apache.jackrabbit.jcr2spi.SessionImpl.getNodeById(SessionImpl.java:271)\n\tat org.apache.jackrabbit.jcr2spi.SessionImpl.getNodeByUUID(SessionImpl.java:239)\n\nReturning null in this special case fixes the problem over here, but seems to create new problems elsewhere.\n\nNeed to clarify the SPI itself, and potentially fix JCR2CPI.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2841",
        "summary": "Avoid path resolution in case of non-wildcard ACEs (follow-up to JCR-2573)",
        "description": "adding the ability to specify wildcard-ac-entries in the default resource based access control management lead to\nalways resolving the id passed to AccessControlProvider#canRead in order to be able to properly evaluate\nany wildcard-aces present.\n\nthis could be improved with minor refactoring that postpones the path resolution and omitting it if there are no\nwildcard-aces to compare with.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2451",
        "summary": "Implement RepositoryFactory in jcr2dav",
        "description": "It's currently a bit cumbersome to set up a spi2dav instance because of the two levels of factories (RepositoryFactory & RepositoryServiceFactory) involved in the process. It would be easier if spi2dav implemented RepositoryFactory directly, so downstream users would only need to provide the server URI parameter instead of specifying also the RepositoryServiceFactory classname.\n\nTo do this, spi2dav would need to depend also on jcr2spi. This change would actually simplify downstream projects, that then wouldn't need to depend also to jcr2spi to get JCR -> DAV connectivity.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1553",
        "summary": "ClusterNode not properly shutdown when repository has shutdown",
        "description": "Sometimes when the repository is shutdown the ClusterNode is not shutdown and it therefore tries to update records or access a closed Journal file.  The setup that generated the exception is I have 3 VMs each with a Repository that are all connected to the same database.  In the below stack trace one of the repositories is being shutdown however the ClusterNode thread is also trying to update the repository journal at the same time.  Below is a copy of the stack trace.\n\n[4/23/08 9:58:52:496 CDT] 00000061 SystemOut     O 89811653 [WebContainer : 2] INFO  org.apache.jackrabbit.core.RepositoryImpl  - Shutting down repository...\n[4/23/08 9:58:52:511 CDT] 0000054c SystemOut     O 89811621 [ClusterNode-b06e4fe7-a602-4a93-b106-e0834046ae0f] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7174\n[4/23/08 9:58:52:527 CDT] 00000061 SystemOut     O 89811684 [WebContainer : 2] INFO  org.apache.jackrabbit.core.RepositoryImpl  - shutting down workspace 'default'...\n[4/23/08 9:58:52:574 CDT] 00000061 SystemOut     O 89811715 [WebContainer : 2] INFO  org.apache.jackrabbit.core.observation.ObservationDispatcher  - Notification of EventListeners stopped.\n[4/23/08 9:58:53:058 CDT] 00000061 SystemOut     O 89812215 [WebContainer : 2] INFO  org.apache.jackrabbit.core.RepositoryImpl  - workspace 'default' has been shutdown\n[4/23/08 9:58:53:308 CDT] 00000308 SystemOut     O 91641048 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7165\n[4/23/08 9:58:53:324 CDT] 00000308 SystemOut     O 91641064 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7166\n[4/23/08 9:58:53:324 CDT] 00000308 SystemOut     O 91641064 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7167\n[4/23/08 9:58:53:339 CDT] 00000308 SystemOut     O 91641079 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7168\n[4/23/08 9:58:53:339 CDT] 00000308 SystemOut     O 91641079 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7169\n[4/23/08 9:58:53:355 CDT] 00000308 SystemOut     O 91641095 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7170\n[4/23/08 9:58:53:371 CDT] 00000308 SystemOut     O 91641111 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7171\n[4/23/08 9:58:53:386 CDT] 00000308 SystemOut     O 91641126 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7172\n[4/23/08 9:58:53:417 CDT] 00000308 SystemOut     O 91641157 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7173\n[4/23/08 9:58:53:433 CDT] 00000308 SystemOut     O 91641173 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7174\n[4/23/08 9:58:53:433 CDT] 00000308 SystemOut     O 91641173 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7175\n[4/23/08 9:58:53:496 CDT] 00000308 SystemOut     O 91641236 [ClusterNode-e609e8a6-320e-44ea-be0f-ab8c5cb89662] INFO  org.apache.jackrabbit.core.journal.AbstractJournal  - Synchronized to revision: 7175\n[4/23/08 9:58:54:292 CDT] 00000131 SystemOut     O 89171473 [ClusterNode-4930503b-ab33-4444-999e-c87fb3681bf7] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7173\n[4/23/08 9:58:54:308 CDT] 00000131 SystemOut     O 89171504 [ClusterNode-4930503b-ab33-4444-999e-c87fb3681bf7] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7174\n[4/23/08 9:58:54:308 CDT] 00000131 SystemOut     O 89171504 [ClusterNode-4930503b-ab33-4444-999e-c87fb3681bf7] INFO  org.apache.jackrabbit.core.cluster.ClusterNode  - Processing revision: 7175\n[4/23/08 9:58:54:386 CDT] 00000131 SystemOut     O 89171582 [ClusterNode-4930503b-ab33-4444-999e-c87fb3681bf7] INFO  org.apache.jackrabbit.core.journal.AbstractJournal  - Synchronized to revision: 7175\n[4/23/08 9:58:55:417 CDT] 00000061 SystemOut     O 89814574 [WebContainer : 2] INFO  org.apache.jackrabbit.core.RepositoryImpl  - Repository has been shutdown\n[4/23/08 9:58:56:089 CDT] 0000054c SystemOut     O 89815199 [ClusterNode-b06e4fe7-a602-4a93-b106-e0834046ae0f] ERROR org.apache.jackrabbit.core.cluster.ClusterNode  - Unable to read revision '7174'.\norg.apache.jackrabbit.core.journal.JournalException: I/O error while reading string.\n\tat org.apache.jackrabbit.core.journal.ReadRecord.readString(ReadRecord.java:169)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.consume(ClusterNode.java:979)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.doSync(AbstractJournal.java:198)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.sync(AbstractJournal.java:173)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.sync(ClusterNode.java:303)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.run(ClusterNode.java:274)\n\tat java.lang.Thread.run(Thread.java:797)\nCaused by: \njava.io.IOException: Closed Connection\n\tat oracle.jdbc.driver.DatabaseError.SQLToIOException(DatabaseError.java:517)\n\tat oracle.jdbc.driver.OracleBlobInputStream.needBytes(OracleBlobInputStream.java:187)\n\tat oracle.jdbc.driver.OracleBufferedStream.readInternal(OracleBufferedStream.java:130)\n\tat oracle.jdbc.driver.OracleBufferedStream.read(OracleBufferedStream.java:108)\n\tat java.io.DataInputStream.readBoolean(DataInputStream.java:246)\n\tat org.apache.jackrabbit.core.journal.ReadRecord.readString(ReadRecord.java:161)\n\t... 6 more\n[4/23/08 9:58:56:261 CDT] 0000054c SystemOut     O 89815355 [ClusterNode-b06e4fe7-a602-4a93-b106-e0834046ae0f] ERROR org.apache.jackrabbit.core.journal.DatabaseJournal  - Error while moving to next record.\njava.sql.SQLException: Closed Connection: next\n\tat oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112)\n\tat oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:146)\n\tat oracle.jdbc.driver.OracleResultSetImpl.next(OracleResultSetImpl.java:181)\n\tat org.apache.jackrabbit.core.journal.DatabaseRecordIterator.fetchRecord(DatabaseRecordIterator.java:136)\n\tat org.apache.jackrabbit.core.journal.DatabaseRecordIterator.hasNext(DatabaseRecordIterator.java:85)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.doSync(AbstractJournal.java:190)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.sync(AbstractJournal.java:173)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.sync(ClusterNode.java:303)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.run(ClusterNode.java:274)\n\tat java.lang.Thread.run(Thread.java:797)\n[4/23/08 9:58:56:402 CDT] 0000054c SystemOut     O 89815418 [ClusterNode-b06e4fe7-a602-4a93-b106-e0834046ae0f] WARN  org.apache.jackrabbit.core.cluster.ClusterNode  - Unable to set current revision to 7174.\norg.apache.jackrabbit.core.journal.JournalException: Revision file closed.\n\tat org.apache.jackrabbit.core.journal.FileRevision.set(FileRevision.java:100)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.setRevision(ClusterNode.java:1073)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.doSync(AbstractJournal.java:211)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.sync(AbstractJournal.java:173)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.sync(ClusterNode.java:303)\n\tat org.apache.jackrabbit.core.cluster.ClusterNode.run(ClusterNode.java:274)\n\tat java.lang.Thread.run(Thread.java:797)\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1484",
        "summary": "Node.getReferences() does not properly reflect saved but not yet committed changes",
        "description": "Node.getReferences() currently only returns committed references. The specification however says:\n\n<quote>\nSome level 2 implementations may only return properties that have been\nsaved (in a transactional setting this includes both those properties\nthat have been saved but not yet committed, as well as properties that\nhave been committed). Other level 2 implementations may additionally\nreturn properties that have been added within the current Session but are\nnot yet saved.\n</quote>\n\nJackrabbit does not support the latter, but at least has to support the first.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-499",
        "summary": "TCK: NamespaceRegistryTest#testRegisterNamespace doesn't remove node in new namespace",
        "description": "The test creates a node in the new namespace, but doesn't remove it.  This prevents tearDown from unregistering the namespace.\n\nProposal: the test should remove the new node before returning.\n\n--- NamespaceRegistryTest.java  (revision 422074)\n+++ NamespaceRegistryTest.java  (working copy)\n@@ -138,6 +138,10 @@\n  \n         testRootNode.addNode(namespacePrefix + \":root\");\n         testRootNode.save();\n+\n+        // Need to remove it here, otherwise teardown can't unregister the NS.\n+        testRootNode.getNode(namespacePrefix + \":root\").remove();\n+        testRootNode.save();\n     }\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1010",
        "summary": "Test failures with spi2jcr in AddEventListenerTest",
        "description": "Two tests fail:\n\n- AddEventListenerTest.testUUID\n- AddEventListenerTest.testNodeType",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3181",
        "summary": "add test case for recovering from broken version history hierarchy",
        "description": "The test should exercise recovery from a missing parent node of a VHR.",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2076",
        "summary": "JSR 283: QOM and SQL2",
        "description": "Adjusted title. This issue now covers all query changes and enhancements in JSR 283.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-2035",
        "summary": "IndexingQueue not checked on initial index creation",
        "description": "With a default value of 100 for extractorBackLogSize and lots of text extractions that time out, the temp folder gets filled with extractor*.tmp files. This is because the IndexingQueue.getFinishedDocuments() is not called during the initial index creation. This is not an issue during regular operation because the method is called periodically from a timer thread.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-549",
        "summary": "TransientFileFactory may throw ConcurrentModificationException on shutdown",
        "description": "When Jackrabbit is stopped the shutdown hook of the TransientFileFactory iterates over all tracked temp files and deletes them. At the same time the reaper thread may still remove file references from the list of tracked temp files. This may lead to a ConcurrentModificationException in the shutdown hook:\n\njava.util.ConcurrentModificationException\n\tat java.util.AbstractList$Itr.checkForComodification(Unknown Source)\n\tat java.util.AbstractList$Itr.next(Unknown Source)\n\tat org.apache.jackrabbit.util.TransientFileFactory$1.run(TransientFileFactory.java:86)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1653",
        "summary": "NodeIdImpl is not really serializable ",
        "description": "I've been trying to get jcr2spi - rmi - spi2jcr to work. \n\nThe error I'm seeing is reported as:\njava.io.NotSerializableException: org.apache.jackrabbit.spi.commons.identifier.IdFactoryImpl\n\nI believe I tracked this down.  It is because NodeIdImpl is implicitly referencing its containing instance IdFactoryImpl which is not serializable.\n\nNodeIdImpl is attempted to be serialized, in my case, with the following stack:\n\nat org.apache.jackrabbit.spi.rmi.client.ClientRepositoryService.getItemInfos(ClientRepositoryService.java:258)\nat org.apache.jackrabbit.jcr2spi.state.WorkspaceItemStateFactory.createNodeState(WorkspaceItemStateFactory.java:94)\nat org.apache.jackrabbit.jcr2spi.state.TransientISFactory.createNodeState(TransientISFactory.java:99)\nat org.apache.jackrabbit.jcr2spi.hierarchy.NodeEntryImpl.doResolve(NodeEntryImpl.java:972)\nat org.apache.jackrabbit.jcr2spi.hierarchy.HierarchyEntryImpl.resolve(HierarchyEntryImpl.java:95)\nat org.apache.jackrabbit.jcr2spi.hierarchy.HierarchyEntryImpl.getItemState(HierarchyEntryImpl.java:212)\nat org.apache.jackrabbit.jcr2spi.ItemManagerImpl.getItem(ItemManagerImpl.java:170)\nat org.apache.jackrabbit.jcr2spi.SessionImpl.getRootNode(SessionImpl.java:216)\n\nI think I must be doing something wrong, because it seems like this is a fundamental problem with doing jcr2spi - rmi - spi2jcr, and looking at the SVN history I don't see how this ever could have worked.  \nSo either session.getRootNode() has never been tested using jcr2spi - rmi - spi2jcr, or I've got something setup wrong.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-252",
        "summary": "new CachingNamespaceResolver introduces dependency from commons-jackrabbit to commons-collections",
        "description": "new CachingNamespaceResolver introduces dependency from commons-jackrabbit to commons-collections which is undesried",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2920",
        "summary": "Workspace.copy(src, dest) throws unexpected RepositoryException (\"Invalid path\")",
        "description": "when using the davex remoting layer (jcr2spi->spi2davex), \nthe following code fragment causes an unexpected RepositoryException:\n\n<snip>\n    Node testNode1 = session.getRootNode().addNode(\"test\", \"nt:folder\");\n\n    Node copyDestination = testNode1.addNode(\"CopyDestination\", \"nt:folder\");\n    testNode1.addNode(\"CopySource\", \"nt:folder\").addNode(\"testCopyCommand\", \"nt:folder\").addNode(\"abc\", \"nt:folder\");\n    session.save();\n    copyDestination.addMixin(\"mix:referenceable\");\n    session.save();\n\n    session.getWorkspace().copy(\"/test/CopySource/testCopyCommand\", \"/test/CopyDestination/testCopyCommand\");\n</snip>\n\n==> Caused by: javax.jcr.RepositoryException: Invalid path:/test/CopyDestination//testCopyCommand\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n\tat org.apache.jackrabbit.spi2dav.ExceptionConverter.generate(ExceptionConverter.java:69)\n\tat org.apache.jackrabbit.spi2dav.ExceptionConverter.generate(ExceptionConverter.java:51)\n\tat org.apache.jackrabbit.spi2dav.RepositoryServiceImpl.execute(RepositoryServiceImpl.java:482)\n\tat org.apache.jackrabbit.spi2dav.RepositoryServiceImpl.copy(RepositoryServiceImpl.java:1307)\n\tat org.apache.jackrabbit.spi2davex.RepositoryServiceImpl.copy(RepositoryServiceImpl.java:326)\n\tat org.apache.jackrabbit.jcr2spi.WorkspaceManager$OperationVisitorImpl.visit(WorkspaceManager.java:889)\n\tat org.apache.jackrabbit.jcr2spi.operation.Copy.accept(Copy.java:48)\n\tat org.apache.jackrabbit.jcr2spi.WorkspaceManager$OperationVisitorImpl.execute(WorkspaceManager.java:848)\n\tat org.apache.jackrabbit.jcr2spi.WorkspaceManager$OperationVisitorImpl.access$400(WorkspaceManager.java:793)\n\tat org.apache.jackrabbit.jcr2spi.WorkspaceManager.execute(WorkspaceManager.java:581)\n\tat org.apache.jackrabbit.jcr2spi.WorkspaceImpl.copy(WorkspaceImpl.java:149)\n\t[...]  \n\n\nhowever, the following slightly altered code fragment works as expected:\n\n\n<snip>\n    Node testNode1 = session.getRootNode().addNode(\"test\", \"nt:folder\");\n/*\n    Node copyDestination = testNode1.addNode(\"CopyDestination\", \"nt:folder\");\n    testNode1.addNode(\"CopySource\", \"nt:folder\").addNode(\"testCopyCommand\", \"nt:folder\").addNode(\"abc\", \"nt:folder\");\n    session.save();\n    copyDestination.addMixin(\"mix:referenceable\");\n    session.save();\n*/\n    testNode1.addNode(\"CopyDestination\", \"nt:folder\").addMixin(NodeType.MIX_REFERENCEABLE);\n    Node n = testNode1.addNode(\"CopySource\", \"nt:folder\").addNode(\"testCopyCommand\", \"nt:folder\").addNode(\"abc\", \"nt:folder\");\n    session.save();\n\n    session.getWorkspace().copy(\"/test/CopySource/testCopyCommand\", \"/test/CopyDestination/testCopyCommand\");\n</snip>\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1042",
        "summary": "Disable norms for untokenized fields to reduce memory consumption",
        "description": "For repositories with many indexed fields, the norms cause memory problems both during indexing and querying (see LUCENE-448). Since the fields in question were never boosted they could as well be indexed without norms.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-415",
        "summary": "Enhance indexing of binary content",
        "description": "Indexing of binary content should be enhanced in order to allow either configuration what fields are indexed or provide better support for custom NodeIndexer implementations.\n\nThe current design has a couple of flaws that should be addressed at the same time:\n- Reader instances are requested from the text filters even though the reader might never be used\n- only jcr:data properties of nt:resource nodes are fulltext indexed\n- It is up to the text filter implementation to decide the lucene field name for the text representation, responsibility should be moved to the NodeIndexer. A text filter should only provide a Reader instance.\n\nWith those changes a custom NodeIndexer can then decide if a binary property has one or more representations in the index.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1103",
        "summary": "JCR2SPI: VersionManagerImpl.getVersionableNodeEntry uses toString() rather than getString() to obtain property value",
        "description": "VersionManagerImpl.getVersionableNodeEntry uses toString() rather than getString() to obtain property value.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3024",
        "summary": "[SPI] Node.setProperty with null value throws ItemNotFoundException",
        "description": "Node.setProperty with a null value should not throw a ItemNotFoundException in the case a property with the given name does not exist. Rather should it return a stale property which throws an InvalidItemStateException when its methods are accessed. \n\nThis behavior is also consistent with jackrabbit-core.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2353",
        "summary": "Poor performance in range queries using dates",
        "description": "I am evaluating migrating from 1.5 to 1.6. I created several test cases that prove the query performance of 1.6 is the same or better than 1.5. That is until I add a date property into my query. The repository has 400,000 nodes. Each node as several string based properties (@property, @property2, ...) and a date based property (@datestart). Every node has a relatively unique datestart and the total date range spans 6 years.\n\nIn my tests, my base query is:\n//element(*,my:namespace)[@property='value'] order by @datestart descending\n\nThe time to run this query in 1.5 and 1.6 is:\n1.5 = 1.5 seconds\n1.6 = 1.5 seconds\n\nIf I add a date property:\n//element(*,my:namespace)[@property='value' and @datestart<=xs:dateTime('2009-09-24T11:53:23.293-05:00')] order by @datestart descending\n\nthe results are:\n1.5 = 1.5 seconds\n1.6 = 3.5 seconds \n\nI have isolated the slow down to the implementation of SortedLuceneQueryHits. SortedLuceneQueryHits is not present in 1.5. I have run versions of the test where the query is run 20 times simultaneously and a different time where the query is run 20 times sequentially. In both tests I do see evidence that caching is taking place, but it provides only very minor performance gains. Also, running the 1.6 query multiple times does not decrease the query time dramatically.\n\nhttp://www.nabble.com/Date-Property-Performance-in-1.6-td25704607.html",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-721",
        "summary": "Duplicate key in DatabasePersistenceManager",
        "description": "Hi,\n\nI ran into the exception pasted below. We had 2 threads that both were saving. Maybe it is a race condition?  \n\nRegards,\n\nMartijn Hendriks\n<GX> creative online development B.V.\n \nt: 024 - 3888 261\nf: 024 - 3888 621\ne: martijnh@gx.nl\n \nWijchenseweg 111\n6538 SW Nijmegen\nhttp://www.gx.nl/ \n\n\nJan 26, 2007 2:23:36 PM org.apache.jackrabbit.core.persistence.db.DatabasePersistenceManager store\nSEVERE: failed to write property state: e3847bad-f1ee-4adb-a109-e134900935b7/{http://gx.nl}edit_language\nERROR 23505: The statement was aborted because it would have caused a duplicate key value in a unique or primary key constraint or unique in dex identified by 'DEFAULT_PROP_IDX' defined on 'DEFAULT_PROP'.\n        at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n        at org.apache.derby.impl.sql.execute.IndexChanger.insertAndCheckDups(Unknown Source)\n        at org.apache.derby.impl.sql.execute.IndexChanger.doInsert(Unknown Source)\n        at org.apache.derby.impl.sql.execute.IndexChanger.insert(Unknown Source)\n        at org.apache.derby.impl.sql.execute.IndexSetChanger.insert(Unknown Source)\n        at org.apache.derby.impl.sql.execute.RowChangerImpl.insertRow(Unknown Source)\n        at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(Unknown Source)\n        at org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)\n        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)\n        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)\n        at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)\n        at org.apache.derby.impl.jdbc.EmbedPreparedStatement.execute(Unknown Source)\n        at org.apache.jackrabbit.core.persistence.db.DatabasePersistenceManager.executeStmt(DatabasePersistenceManager.java:835)\n        at org.apache.jackrabbit.core.persistence.db.DatabasePersistenceManager.store(DatabasePersistenceManager.java:466)\n        at org.apache.jackrabbit.core.persistence.AbstractPersistenceManager.store(AbstractPersistenceManager.java:75)\n        at org.apache.jackrabbit.core.persistence.db.DatabasePersistenceManager.store(DatabasePersistenceManager.java:274)\n        at org.apache.jackrabbit.core.state.SharedItemStateManager$Update.end(SharedItemStateManager.java:675)\n        at org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:808)\n        at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:326)\n        at org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:313)\n        at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:302)\n        at org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:295)\n        at org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1210)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2744",
        "summary": "Avoid element arrays in PathImpl",
        "description": "The path handling code in spi-commons shows quite often in thread dumps and profiling results, as the current implementation does quite a bit of repetitive allocating and copying of path element arrays. We should be able to streamline and simplify the path handling code by only tracking the latest path element and a reference to the parent path. To do this efficiently we may need to adjust some of the Path and PathFactory method declarations (that currently assume element array -based paths) also in the SPI.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1689",
        "summary": "Multiple tests test for locking instead of versioning",
        "description": "Multiple tests claim to check whether versioning is supported, but in reality check for locking.  Patch included.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-391",
        "summary": "WebDAV method invocation trying to create a new resource should fail with 409 (Conflict) if parent resource does not exist",
        "description": "This is Litmus test case copy_nodestcoll. An attempt is made to COPY an existing resource to a new location, where the parent collection of the resource-to-be-created does not exist. RFC2518 asks for status code 409 (Conflict) instead of 403 (Forbidden) in this case.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-650",
        "summary": "SimpleJbossAccessManager",
        "description": "http://wiki.apache.org/jackrabbit/SimpleJbossAccessManager\n\nCode contribution\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2655",
        "summary": "initVersions crashes with NPE",
        "description": "After delete some old versions. I get serious problems accessing the version history.\nThis is the stacktrace:\njava.lang.NullPointerException\n\tat org.apache.jackrabbit.core.version.VersionIteratorImpl.initVersions(VersionIteratorImpl.java:169)\n\tat org.apache.jackrabbit.core.version.VersionIteratorImpl.<init>(VersionIteratorImpl.java:87)\n\tat org.apache.jackrabbit.core.version.VersionIteratorImpl.<init>(VersionIteratorImpl.java:72)\n\tat org.apache.jackrabbit.core.version.VersionHistoryImpl.getAllVersions(VersionHistoryImpl.java:92)\n\nI stepped threw the code and see that the Method \n    currentVersion.getSuccessors() \nreturns an empty Array.\n\nAfter all the VersionHistory seems to be corrupt!!",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-166",
        "summary": "Versioned node importXML fails",
        "description": "When importing system-view XML previously exported for a repository, any nodes with a version history cannot be reimported. This appears to be due to the version manager attempting to create a new version history for the node, which fails due to a previous history existing for the same UUID. The behavior occurs with ImportUUIDBehavior.IMPORT_UUID_COLLISION_REPLACE_EXISTING and  ImportUUIDBehavior.IMPORT_UUID_COLLISION_REMOVE_EXISTING, with the following stack trace:\n\njavax.jcr.version.VersionException: History already exists for node a892651d-1688-46cd-bb12-14f2f0b3d886\n\tat org.apache.jackrabbit.core.version.VersionManagerImpl.createVersionHistory(VersionManagerImpl.java:194)\n\tat org.apache.jackrabbit.core.ItemImpl.initVersionHistories(ItemImpl.java:900)\n\tat org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1313)\n\tat org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:766)\n\nI am using the 1.0-dev version, revision 209290 obtained on 05 Jul, 2005 at 9:18:02 EST. Attached please find my repository configuration and the test code. Thanks!\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1838",
        "summary": "Garbage collection deletes temporary files in FileDataStore",
        "description": "In FileDataStore.addRecord(InputStream), a temporary file is created. The data is written to the file and then it is moved to its final location (based on the contents hash).\n\nIf the garbage collector runs whilst this temp file is present, it deletes it (on Solaris 10 at least), and the addRecord fails at the attempt to rename the now non-existent temp file.\n\nI am attaching a minimal patch that prevents these temp files being deleted by deleteOlderRecursive(..), regardless of their lastModified() value.\n\nI have made this a Minor priority, since there is the obvious workaround of disabling the GC.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2720",
        "summary": "Changes from Session.move() to a top-level node aren't seen in a second session",
        "description": "I'll attach a test case, but basically...\n\n* Create two sessions\n* Create a top-level node in the first session and save it.\n* Move the top-level node using the first session\n* In the second session, try itemExists() for the path of the node. It returns true when it should be false.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1330",
        "summary": "repository.xml DTD doesn't allow <DataStore> element",
        "description": "The repository.xml DTD at http://jackrabbit.apache.org/dtd/repository-1.4.dtd conflicts with the instructions in the wiki page at http://wiki.apache.org/jackrabbit/DataStore\n\nAdding the <DataStore> element as specified in the wiki page violates the DTD.\n\n",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "JCR-2607",
        "summary": "AbstractWebdavServlet: add protected method sendUnauthorized",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1562",
        "summary": "JNDI data sources with various PersistenceManager: wrong default values",
        "description": "With JCR-1305 Jackrabbit supports creating a connection throug a JNDI Datasource and without configuring user and password. This works for some but not all provided PersistenceManagers. Some of them - like the Oracle-specific BundleDBPersistenceManager - sets default values for user and password if none are provided in the jackrabbit config. This way its impossible to use such PersistenceManagers with the plain JNDI DS.\n\nThis concerns the following BundleDbPersistenceManagers: OraclePersistenceManager, DerbyPersistenceManager, H2PersistenceManager.\n\nThere also might be other PMs (perhaps some special SimpleDbPersistenceManagers) with similar behaviour.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-750",
        "summary": "[Patch] Adding history, tab completion, status info command and masked password input for jcr-commands",
        "description": "I have created this patch which improves the usability of the interactive jcr command line client. It uses jline (http://jline.sourceforge.net) for the input, which gives history, tab completion and masked password input. Tab completion completes on available commands and on the jcr children of the current node for command arguments.\n\nThe login command now asks for the password if none is given, this uses the advanced password masking feature of jline to avoid the echoing of the password while typing (which is not possible using standard java System.in).\n\nI also changed the Maven 2 pom to version 1.3-SNAPSHOT to compile with the current jackrabbit trunk and to include a manifest file with the correct starter class.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2081",
        "summary": "NameSet does not implement equals(Object) and hashCode() methods",
        "description": "The merge context uses the NameSet.equals(NameSet) method to compare two sets; however, the NameSet class does not override the default Object.equals(Object) method, and does not inherit from AbstractSet<E>.  Therefore, the merge check fails, even though the mixin sets are the same.  Object instance equivalence is being performed as opposed to set equivalence.  Behavior is observed when more than one thread is checking the ISM at a given time.  Demonstration code available upon request.\n\nFrom NodeStateMerger, line 83:\n                // mixin types\n                if (!state.getMixinTypeNames().equals(overlayedState.getMixinTypeNames())) {\n                    // the mixins have been modified but by just looking at the diff we\n                    // can't determine where the change happened since the diffs of either\n                    // removing a mixin from the overlayed or adding a mixin to the\n                    // transient state would look identical...\n                    return false;\n                }\n\nProposed solution:\n- Implement NameSet.equals(...) method:\n\tpublic boolean equals(Object obj) {\n\t\tif (obj != null && obj instanceof NameSet) {\n\t\t\tNameSet oo = (NameSet) obj;\n\t\t\treturn oo.names.equals(this.names);\n\t\t}\n\t\treturn false;\n\t}",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2870",
        "summary": "Transient Repository cannot be used more than once when configured with DataSources",
        "description": "The TransientRepository cannot be used more than once when the repository is configured with the DataSources construct. This has been verified with both Oracle and Derby configurations. Once the TransientRepository closes for the first time, the ConnectionFactory class sets a boolean value named closed to 'true'.  Thereafter, any use of the ConnectionFactory throws a runtime exception.\n\nThe following stacktrace is thrown on the second attempt to utilize the repository:\n\n2011-01-25 08:12:14 DatabaseFileSystem [ERROR] failed to initialize file system\njava.lang.IllegalStateException: this factory has already been closed\n\tat org.apache.jackrabbit.core.util.db.ConnectionFactory.sanityCheck(ConnectionFactory.java:213)\n\tat org.apache.jackrabbit.core.util.db.ConnectionFactory.getDataBaseType(ConnectionFactory.java:134)\n\tat org.apache.jackrabbit.core.fs.db.DbFileSystem.getDataSource(DbFileSystem.java:228)\n\tat org.apache.jackrabbit.core.fs.db.DatabaseFileSystem.init(DatabaseFileSystem.java:190)\n\tat org.apache.jackrabbit.core.config.RepositoryConfigurationParser$6.getFileSystem(RepositoryConfigurationParser.java:1057)\n\tat org.apache.jackrabbit.core.config.RepositoryConfig.getFileSystem(RepositoryConfig.java:892)\n\tat org.apache.jackrabbit.core.RepositoryImpl.<init>(RepositoryImpl.java:284)\n\tat org.apache.jackrabbit.core.RepositoryImpl.create(RepositoryImpl.java:602)\n\tat org.apache.jackrabbit.core.TransientRepository$1.getRepository(TransientRepository.java:179)\n\tat org.apache.jackrabbit.core.TransientRepository.startRepository(TransientRepository.java:279)\n\tat org.apache.jackrabbit.core.TransientRepository.login(TransientRepository.java:375)\n\tat org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:123)\n\t...\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:115)\n2011-01-25 08:12:14 RepositoryImpl [ERROR] failed to start Repository: File system initialization failure.\njavax.jcr.RepositoryException: File system initialization failure.\n\tat org.apache.jackrabbit.core.config.RepositoryConfigurationParser$6.getFileSystem(RepositoryConfigurationParser.java:1060)\n\tat org.apache.jackrabbit.core.config.RepositoryConfig.getFileSystem(RepositoryConfig.java:892)\n\tat org.apache.jackrabbit.core.RepositoryImpl.<init>(RepositoryImpl.java:284)\n\tat org.apache.jackrabbit.core.RepositoryImpl.create(RepositoryImpl.java:602)\n\tat org.apache.jackrabbit.core.TransientRepository$1.getRepository(TransientRepository.java:179)\n\tat org.apache.jackrabbit.core.TransientRepository.startRepository(TransientRepository.java:279)\n\tat org.apache.jackrabbit.core.TransientRepository.login(TransientRepository.java:375)\n\tat org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:123)\n\tat TransientRepositoryTest.addNodeToRepository(TransientRepositoryTest.java:32)\n\tat TransientRepositoryTest.shouldNotFailWhenUsingTransientRepositoryTwice(TransientRepositoryTest.java:26)\n\t...\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:115)\nCaused by: org.apache.jackrabbit.core.fs.FileSystemException: failed to initialize file system\n\tat org.apache.jackrabbit.core.fs.db.DatabaseFileSystem.init(DatabaseFileSystem.java:210)\n\tat org.apache.jackrabbit.core.config.RepositoryConfigurationParser$6.getFileSystem(RepositoryConfigurationParser.java:1057)\n\t... 42 more\nCaused by: java.lang.IllegalStateException: this factory has already been closed\n\tat org.apache.jackrabbit.core.util.db.ConnectionFactory.sanityCheck(ConnectionFactory.java:213)\n\tat org.apache.jackrabbit.core.util.db.ConnectionFactory.getDataBaseType(ConnectionFactory.java:134)\n\tat org.apache.jackrabbit.core.fs.db.DbFileSystem.getDataSource(DbFileSystem.java:228)\n\tat org.apache.jackrabbit.core.fs.db.DatabaseFileSystem.init(DatabaseFileSystem.java:190)\n\t... 43 more\n2011-01-25 08:12:14 RepositoryImpl [ERROR] Error while closing Version Manager.\njava.lang.NullPointerException\n\tat org.apache.jackrabbit.core.RepositoryImpl.doShutdown(RepositoryImpl.java:1117)\n\tat org.apache.jackrabbit.core.RepositoryImpl.shutdown(RepositoryImpl.java:1063)\n\tat org.apache.jackrabbit.core.RepositoryImpl.<init>(RepositoryImpl.java:388)\n\tat org.apache.jackrabbit.core.RepositoryImpl.create(RepositoryImpl.java:602)\n\tat org.apache.jackrabbit.core.TransientRepository$1.getRepository(TransientRepository.java:179)\n\tat org.apache.jackrabbit.core.TransientRepository.startRepository(TransientRepository.java:279)\n\tat org.apache.jackrabbit.core.TransientRepository.login(TransientRepository.java:375)\n\tat org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:123)\n\tat TransientRepositoryTest.addNodeToRepository(TransientRepositoryTest.java:32)\n\tat TransientRepositoryTest.shouldNotFailWhenUsingTransientRepositoryTwice(TransientRepositoryTest.java:26)\n\t...\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:115)\n2011-01-25 08:12:14 RepositoryImpl [ERROR] In addition to startup fail, another unexpected problem occurred while shutting down the repository again.\njava.lang.NullPointerException\n\tat org.apache.jackrabbit.core.RepositoryImpl.doShutdown(RepositoryImpl.java:1136)\n\tat org.apache.jackrabbit.core.RepositoryImpl.shutdown(RepositoryImpl.java:1063)\n\tat org.apache.jackrabbit.core.RepositoryImpl.<init>(RepositoryImpl.java:388)\n\tat org.apache.jackrabbit.core.RepositoryImpl.create(RepositoryImpl.java:602)\n\tat org.apache.jackrabbit.core.TransientRepository$1.getRepository(TransientRepository.java:179)\n\tat org.apache.jackrabbit.core.TransientRepository.startRepository(TransientRepository.java:279)\n\tat org.apache.jackrabbit.core.TransientRepository.login(TransientRepository.java:375)\n\tat org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:123)\n\tat TransientRepositoryTest.addNodeToRepository(TransientRepositoryTest.java:32)\n\tat TransientRepositoryTest.shouldNotFailWhenUsingTransientRepositoryTwice(TransientRepositoryTest.java:26)\n\t...\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:115)\n\njavax.jcr.RepositoryException: File system initialization failure.\n\tat org.apache.jackrabbit.core.config.RepositoryConfigurationParser$6.getFileSystem(RepositoryConfigurationParser.java:1060)\n\tat org.apache.jackrabbit.core.config.RepositoryConfig.getFileSystem(RepositoryConfig.java:892)\n\tat org.apache.jackrabbit.core.RepositoryImpl.<init>(RepositoryImpl.java:284)\n\tat org.apache.jackrabbit.core.RepositoryImpl.create(RepositoryImpl.java:602)\n\tat org.apache.jackrabbit.core.TransientRepository$1.getRepository(TransientRepository.java:179)\n\tat org.apache.jackrabbit.core.TransientRepository.startRepository(TransientRepository.java:279)\n\tat org.apache.jackrabbit.core.TransientRepository.login(TransientRepository.java:375)\n\tat org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:123)\n\tat TransientRepositoryTest.addNodeToRepository(TransientRepositoryTest.java:32)\n\tat TransientRepositoryTest.shouldNotFailWhenUsingTransientRepositoryTwice(TransientRepositoryTest.java:26)\n\t...\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:115)\nCaused by: org.apache.jackrabbit.core.fs.FileSystemException: failed to initialize file system\n\tat org.apache.jackrabbit.core.fs.db.DatabaseFileSystem.init(DatabaseFileSystem.java:210)\n\tat org.apache.jackrabbit.core.config.RepositoryConfigurationParser$6.getFileSystem(RepositoryConfigurationParser.java:1057)\n\t... 42 more\nCaused by: java.lang.IllegalStateException: this factory has already been closed\n\tat org.apache.jackrabbit.core.util.db.ConnectionFactory.sanityCheck(ConnectionFactory.java:213)\n\tat org.apache.jackrabbit.core.util.db.ConnectionFactory.getDataBaseType(ConnectionFactory.java:134)\n\tat org.apache.jackrabbit.core.fs.db.DbFileSystem.getDataSource(DbFileSystem.java:228)\n\tat org.apache.jackrabbit.core.fs.db.DatabaseFileSystem.init(DatabaseFileSystem.java:190)\n\t... 43 more",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-645",
        "summary": "DatabasePersistenceManager & DatabaseFileSystem: try to gracefully recover from connection loss",
        "description": "",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-927",
        "summary": "DatabaseJournal needs connection reestablishment logic",
        "description": "The DB based file system and persistence manager implementations have logic for connection reestablishment in case the DB server bounces while the repository is running, but the DB based journal implementation doesn't.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-564",
        "summary": "Remove geronimo JTA as a runtime dependency",
        "description": "Geronimo JTA is marked as a dependency for runtime when it should be (at most) a compile time dependency. \nIs it possible to remedy this so when using the war or building your own, you don't get the geronimo jar stowing away?",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1149",
        "summary": "JCR2SPI: several broken equals() comparisons",
        "description": "Detected by FindBugs:\n\nH C EC: Call to equals() comparing unrelated class and interface in org.apache.jackrabbit.jcr2spi.nodetype.NodeTypeManagerImpl.nodeTypeReRegistered(QName)\txythos-jcr/src/main/java/org/apache/jackrabbit/jcr2spi/nodetype\tNodeTypeManagerImpl.java\tline 218\t1190978573312\t1664752\nH C EC: Call to equals() comparing unrelated class and interface in org.apache.jackrabbit.jcr2spi.nodetype.NodeTypeManagerImpl.nodeTypeReRegistered(QName)\txythos-jcr/src/main/java/org/apache/jackrabbit/jcr2spi/nodetype\tNodeTypeManagerImpl.java\tline 227\t1190978573312\t1664753\nH C EC: Call to equals() comparing unrelated class and interface in org.apache.jackrabbit.jcr2spi.nodetype.NodeTypeManagerImpl.nodeTypeUnregistered(QName)\txythos-jcr/src/main/java/org/apache/jackrabbit/jcr2spi/nodetype\tNodeTypeManagerImpl.java\tline 255\t1190978573312\t1664754\nH C EC: Call to equals() comparing unrelated class and interface in org.apache.jackrabbit.jcr2spi.nodetype.NodeTypeManagerImpl.nodeTypeUnregistered(QName)\txythos-jcr/src/main/java/org/apache/jackrabbit/jcr2spi/nodetype\tNodeTypeManagerImpl.java\tline 264\t1190978573312\t1664755\nH C EC: org.apache.jackrabbit.jcr2spi.WorkspaceManager.canAccess(String) uses equals to compare an array and nonarray\t\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1755",
        "summary": "ClassCastException when registering custom node by XML file",
        "description": "When trying to register node type from XML file using following code:\n\n\t\tJackrabbitNodeTypeManager nodeTypeManager = (JackrabbitNodeTypeManager)workspace.getNodeTypeManager();\n\t\tfor(Resource resource : nodeDefinitions){\n\t\t\tSystem.out.println(\"** registering node:\"+resource);\n\t\t\tnodeTypeManager.registerNodeTypes(resource.getInputStream(), JackrabbitNodeTypeManager.TEXT_XML);\n\t\t}\n\nwe receive such surprise:\n\nCaused by: java.lang.ClassCastException: com.sun.org.apache.xerces.internal.dom.DeferredDocumentImpl\n\tat org.apache.jackrabbit.core.util.DOMWalker.iterateElements(DOMWalker.java:215)\n\tat org.apache.jackrabbit.core.nodetype.xml.NodeTypeReader.getNodeTypeDefs(NodeTypeReader.java:121)\n\tat org.apache.jackrabbit.core.nodetype.NodeTypeManagerImpl.registerNodeTypes(NodeTypeManagerImpl.java:257)\n\tat org.apache.jackrabbit.core.nodetype.NodeTypeManagerImpl.registerNodeTypes(NodeTypeManagerImpl.java:499)\n\tat pl.codeservice.jcr.JcrCustomNodeRegister.registerNodes(JcrCustomNodeRegister.java:41)\n\tat pl.codeservice.jcr.JcrCustomNodeRegister.init(JcrCustomNodeRegister.java:27)\n\t...\n\n\nRegistering nodes by .cnd files works fine.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2865",
        "summary": "a dead lock in DefaultISMLocking",
        "description": "The jackrabbit 2.2 's org.apache.jackrabbit.core.state.DefaultISMLocking has a defect which will cause a dead lock in concurrent use cases.\nThe use case is as follows:\n1.\tThread A apply a read lock, now there is an active reader hold the read lock.\n\n2.\tThread B apply a write lock, and then thread B will wait for thread A's reading end. You could see below code snippet from the Jackrabbit source. readerCount is the current active reader.\nwritersWaiting++;\nwhile (writerId != null? !isSameThreadId(writerId, currentId) : readerCount > 0) {\n                                wait();\n}\n\n3.\tThread A apply another read lock, then it will wait too, since there is a writer is waiting.  Then a dead lock happens.\nwhile (writerId != null? (writerCount > 0 && !isSameThreadId(writerId, currentId)): writersWaiting > 0) {\n                                wait();\n}\n\nSince the lock in DefaultISMLocking is global lock, so I think if a thread has already hold a reader lock, it could get the reader lock again. I create a fix with this idea.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-446",
        "summary": "Prevent logins during repository shutdown",
        "description": "Related to the last comment in JCR-445, should we prevent new sessions from being created during repository shutdown? It is an odd chance to run into a problem like that, but it seems like the issue could be easily solved by making getWorkspaceInfo() synchronized and adding sanityCheck() calls to the createSession() methods.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2630",
        "summary": "UserAccessControlProvider handles users who dont have Jackrabbit managed Principals or User node inconsistently.",
        "description": "JR core 2.0.0\nIn UserAccessControlProvider.compilePermissions(...), if no principal relating to a user node can be found, then a set or read only compiled permissions is provided. That set gives the session read only access to the entire security workspace regardless of path.\n\nIf the user node is found, then an instance of UserAccessControlProvider.CompilePermissions is used and in UserAccessControlProvider.CompilePermissions.buildResult(...) there is a check for no user node. If there is no user node, all permissions are denied regardless of path.\n\nAlthough the first case will never happen for an installation of Jackrabbit where there are no custom PrincipalManagers, I suspect, based on the impl of UserAccessControlProvider.CompilePermissions.buildResult(...) was to deny all access to the security workspace where there was no corresponding user node in a set of principals.\n\nSince this does not effect JR unless there is an external Principal Manager its a bit hard to produce a compact unit test, the issue was found by looking at the code.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2148",
        "summary": "Move extensions to the JSR 283 security API  from jackrabbit-core to jackrabbit-api",
        "description": "For the 2.0.0 release i'd like to have the jackrabbit-specific extensions to the JSR 283 security API being part of jackrabbit-api.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1525",
        "summary": "Jackrabbit depends on Oracle driver for BLOB support in Oracle versions previous than 10.2",
        "description": "In Oracle versions previous to 10.2, Jackrabbit explicitly uses a class from the Oracle driver to provide BLOB support (see OracleFileSystem.init()). This special handling is no longer necesary for Oracle 10.2+, so we should provide a new implementation. As discussed on the list, we can create a new class for Oracle 10.2+, make it inherit from DbFileSystem, and override the createSchema(), and table space related methods, which are the ones that need special handling. Furthermore, we could refactor the current OracleFileSystem and break it into two clases, one of them to keep the current behavior and a new one to keep the common code (which we could rename to OracleBaseFileSystem or similar, to maintain compatiblity with code that uses OracleFileSystem for versions previous to 10.2). Then we make the Oracle10FileSystem inherit from the latter.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3143",
        "summary": "SessionImpl#isSupportedOption: Skip descriptor evaluation if descriptor has not been loaded",
        "description": "followup issue for JCR-3076.\n\nas jukka stated changing the jcr-server to serve the repository-descriptor without mandating a successful login would\nrequire quite some changes on the server side as the current flow demands a successful repository login in order\nto be access any resource including the root resource that acts as parent for all (available) workspaces. since the\nrepository-descriptor report has be requested one of the resources it also mandates a successful login although\nretrieving descriptors on the jcr-level is possible when just having the repository at hand.\n\non the other hand i would assume that the descriptor functionality present on the Repository is rarely used.\ntherefore i would suggest to just relax the check for supported options in the jcr2spi session implementation\nand skip the evaluation if the descriptor isn't available at all. consequently the failure of a non-supported\nfeature would be postponed to the point it reaches the SPI (instead of informing the API consumer upfront). \non the other hand supported operations would not fail just because the descriptors have not been loaded.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-799",
        "summary": "AbstractJournal doesn't create deep paths for revision files",
        "description": "AbstractJournal throws when trying to create the revision file if the directory the revision file is in doesn't already exist. When initializing a repository during its startup, the create fails is you use a revision param like <param name=\"revision\" value=\"${rep.home}/repository/revision\" /> because the repository directory hasn't been created yet. Attached is a repository.xml that demonstrates. It uses Oracle for FS and PMs.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-890",
        "summary": "concurrent read-only access to a session",
        "description": "Even though the JCR specification does not make a statement about Sessions shared across a number of threads I think it would be great for many applications if we could state that sharing a read-only session is supported by Jackrabbit.\nOn many occasions in the mailing lists we stated that there should not be an issue with sharing a read-only session, however I think it has never been thoroughly tested or even specified as a \"design goal\".\n\nIf we can come to an agreement that this is desirable I think it would be great to start including testcases to validate that behaviour and update the documentation respectively.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2619",
        "summary": "improved internal representation of DATE values",
        "description": "DATE values are currently internally represented as java.util.Calendar objects.\n\nCalendar objects have a huge memory footprint (approx 200bytes per instance) \nand are mutable.\n\ni suggest to replace the internal DATE representation with a ISO8601 format string\n(immutable and approx. 85-90% smaller footprint).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1952",
        "summary": "DOMException: NAMESPACE_ERR thrown when exporting document view",
        "description": "When I try to export some nodes with ExportDocumentView I get a DOMException with Jackrabbit 1.5.2. Version 1.4.6 works fine. Xerces version was 2.8.1.\n\nCode:\n\nDocument document = documentBuilder.newDocument();\nElement exportElement = (Element) document.appendChild(document.createElement(\"Export\"));\nResult result = new DOMResult(exportElement);\nTransformerHandler transformerHandler = saxTransformerFactory.newTransformerHandler();\ntransformerHandler.setResult(result);\nsession.exportDocumentView(workflowNode.getPath(), transformerHandler, true, false);\n\nException:\n\norg.w3c.dom.DOMException: NAMESPACE_ERR: An attempt is made to create or change an object in a way which is incorrect with regard to namespaces.\n\tat org.apache.xerces.dom.CoreDocumentImpl.checkDOMNSErr(Unknown Source)\n\tat org.apache.xerces.dom.AttrNSImpl.setName(Unknown Source)\n\tat org.apache.xerces.dom.AttrNSImpl.<init>(Unknown Source)\n\tat org.apache.xerces.dom.CoreDocumentImpl.createAttributeNS(Unknown Source)\n\tat org.apache.xerces.dom.ElementImpl.setAttributeNS(Unknown Source)\n\tat com.sun.org.apache.xalan.internal.xsltc.trax.SAX2DOM.startElement(SAX2DOM.java:194)\n\tat com.sun.org.apache.xml.internal.serializer.ToXMLSAXHandler.closeStartTag(ToXMLSAXHandler.java:204)\n\tat com.sun.org.apache.xml.internal.serializer.ToSAXHandler.flushPending(ToSAXHandler.java:277)\n\tat com.sun.org.apache.xml.internal.serializer.ToXMLSAXHandler.startElement(ToXMLSAXHandler.java:646)\n\tat com.sun.org.apache.xalan.internal.xsltc.trax.TransformerHandlerImpl.startElement(TransformerHandlerImpl.java:263)\n\tat org.apache.jackrabbit.commons.xml.Exporter.startElement(Exporter.java:438)\n\tat org.apache.jackrabbit.commons.xml.DocumentViewExporter.exportNode(DocumentViewExporter.java:76)\n\tat org.apache.jackrabbit.commons.xml.Exporter.exportNode(Exporter.java:298)\n\tat org.apache.jackrabbit.commons.xml.Exporter.exportNodes(Exporter.java:214)\n\tat org.apache.jackrabbit.commons.xml.DocumentViewExporter.exportNode(DocumentViewExporter.java:77)\n\tat org.apache.jackrabbit.commons.xml.Exporter.exportNode(Exporter.java:295)\n\tat org.apache.jackrabbit.commons.xml.Exporter.export(Exporter.java:144)\n\tat org.apache.jackrabbit.commons.AbstractSession.export(AbstractSession.java:461)\n\tat org.apache.jackrabbit.commons.AbstractSession.exportDocumentView(AbstractSession.java:241)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1771",
        "summary": "jcr2spi: avoid unnecessary roundtrips with NodeEntry.getPropertyEntry",
        "description": "Since NodeInfo.getPropertyIds always returns the complete set of property names, there is no need for an extra round trip to the SPI upon NodeEntry.getPropertyEntry. The corresponding code could be simplified.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2964",
        "summary": "ItemSaveOperation should not swallow stacktrace",
        "description": "When a StaleItemStateException is thrown the stacktrace is swallowed. This makes it much harder to figure out what went wrong from the logs.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-347",
        "summary": "Jcr-server: Parsing NodeTypeProperty not compliant with definition",
        "description": "Creating a new NodeTypeProperty from an existing DavProperty fails, since assumptions made are not compliant with definition:\n\na) nodetype name is always enclosed in a 'nodetypename' element\nb) nodetype property may be empty, thus contain no 'nodetype' element.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-500",
        "summary": "TCK: NamespaceRegistryTest#testUnregisterNamespaceExceptions doesn't fail if expected exception isn't thrown",
        "description": "In two places, the test doesn't fail if an expected exception isn't thrown.\n\nProposal: test should fail if expected exception isn't thrown.\n\n--- NamespaceRegistryTest.java  (revision 422074)\n+++ NamespaceRegistryTest.java  (working copy)\n@@ -150,6 +154,7 @@\n         for (int t = 0; t < SYSTEM_PREFIXES.length; t++) {\n             try {\n                 nsp.unregisterNamespace(SYSTEM_PREFIXES[t]);\n+                fail(\"Trying to unregister \" + SYSTEM_PREFIXES[t] + \" must fail\");\n             } catch (NamespaceException e) {\n                 // expected behaviour\n             }\n@@ -159,6 +164,7 @@\n         // must throw a NamespaceException.\n         try {\n             nsp.unregisterNamespace(\"ThisNamespaceIsNotCurrentlyRegistered\");\n+            fail(\"Trying to unregister an unused prefix must fail\");\n         } catch (NamespaceException e) {\n             // expected behaviour\n         }\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1416",
        "summary": "[PATCH] No need to call toString on a String",
        "description": "code calls toString on a String",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1720",
        "summary": "Jcr2Spi: configuration entry for size of ItemCache",
        "description": "in order to make the size of the ItemCache configurable (see TODO in jcr2spi SessionImpl) i'd like to extend the jcr2spi RepositoryConfig and have a default value being provided with AbstractRepositoryConfig in the tests section.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-444",
        "summary": "Error while restoring OPV=Version childnodes (Restore of root version not allowed)",
        "description": "when restoring a version of a node (by name) that has opv=version childnodes, the following error is thrown, if such a version does not exist in the child nodes versionhistory:\n\nError while restoring nodes: javax.jcr.version.VersionException: Restore of root version not allowed.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-527",
        "summary": "TCK: DerefQueryLevel1Test requires support for optional jcr:deref function",
        "description": "Test fails if jcr:deref is not supported.  Per JSR-170, jcr:deref is optional.\n\nProposal: introduce new configuration property which indicates whether jcr:deref is supported; if not throw NotExecutableException\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-817",
        "summary": "TCK vs available property types",
        "description": "The TCK tests allow configuration of node type / property names to tests specific property types, but they do not take into account that a given repository may not support a specific property type (this is similar to issue JCR-801 about multiple workspace support).\n\nJSR-170 is a bit fuzzy here: it requires all types, but does not require that every type actually exists on a settable node type. In practice, a repository may support reference properties on the builtin nodetypes for version storage, but nowhere else.\n\nThus, there should be a way to configure the tests so that specific property type tests are left out. Again, there are a few possibilities to do that:\n\n1) reserve a special property name for the case where the test should be skipped (\"PROPERTY_TYPE_NOT_SUPPORT\"), or\n\n2) add new config flags.\n\nThe latter arguably is the cleaner approach, the former avoids introducing new configuration parameters. Thus, I'm leaning to 2). Feedback appreciated.\n\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1240",
        "summary": "Index segments are only committed on close",
        "description": "There is a check in AbstractIndex.commit(), which prevents that deleted documents are committed to the index. Up to lucene version 2.0 the index was locked when there were pending changes. Beginning with lucene 2.1 this is not true anymore. See LUCENE-701.\n\nThis is a regression of JCR-788, hence it does not occur in a release but only in trunk.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3133",
        "summary": "Query Stats should use the TimeSeries mechanism",
        "description": "Refactor the Query Stats to use TimeSeries for the average query duration.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-1159",
        "summary": "SPI: improve description of locking methods on RepositoryService",
        "description": "in detail:\n\n1) getLockInfo\n\n- intended behavior if no lock is present?\n- intended behavior if locking is not supported?\n\n2) lock\n\n- currently InvalidItemStateException is listed. i don't think this make too much sense.\n\n3) refreshLock\n\n- intended behavior if locking is not supported?\n\n4) unlock\n\n- currently InvalidItemStateException is listed. i don't think this make too much sense.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1535",
        "summary": "Some tests assume that an implementation of javax.jcr.Item overrides equals()",
        "description": "The following 3 tests (followed by the line number containing the bad assertion):\n\norg.apache.jackrabbit.test.api.ReferencesTest.testReferenceTarget:135\norg.apache.jackrabbit.test.api.ReferencesTest.testAlterReference:169\norg.apache.jackrabbit.test.api.version.VersionHistoryTest:152\n\nassume that an implementation of javax.jcr.Item overrides equals(), such that \n\nAssert.assertEquals(n1, n2) or \njava.util.Set.contains(n1) \n\nworks for two \"equal\" nodes n1,n2 or for some node n1 that has been previously put into a set. However, there is no section in the specification that would mandate this. The tests above should therefore replace assertEquals() with one of the other mechanism that officially supported, such as javax.jcr.Node.isSame().\n\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-1244",
        "summary": "No need for NodeReferences in jcr2spi",
        "description": "I happened to come across the org.apache.jackrabbit.jcr2spi.state.NodeReferences interface, and realized that with the current SPI definitions there's really no need for that abstraction. The PropertyId array returned by NodeInfo.getReferences() is quite good enough for jcr2spi without any NodeReferences wrapping around it.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2575",
        "summary": "Incorrect excerpt for index aggregates",
        "description": "Incorrect excerpts may be created when the relevant node has an index aggregate configured and the nodes have properties configured for the node scope index with some of them excluded for use in excerpts.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2506",
        "summary": "Stop text extraction when the maxFieldLength limit is reached",
        "description": "When indexing large documents the text extraction often takes quite a while and uses lots of memory even if only the first maxFieldLength (by default 10000) tokens are used. I'd like to add a maxExtractLength parameter that can be used to set the maximum number of characters to extract from a binary. The default value of this parameter could be something like ten times the maxFieldLength setting.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1711",
        "summary": "Download: improve user experience",
        "description": "The download section at http://jackrabbit.apache.org/downloads.html\ncontains many files. The number of files should be reduced.\n\nSome of them contain other files, for example the .rar files, and the .war files. \nThe file jackrabbit-jca-1.4.rar  contains an old version of jackrabbit-core:\njackrabbit-core-1.4.jar - however the newest version of jackrabbit-core is \njackrabbit-core-1.4.5.jar\n\nThis often leads to problems.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1826",
        "summary": "Change default value of SearchIndex extractorPoolSize",
        "description": "The current default value for the extractorPoolSize is 0, which means it is disabled by default. I think we should change that default because it is a useful feature and people should not have to dig through documentation to make use of it.\n\nThe new default should be computed based on the available processors. I suggest we use: 2 * Runtime.availableProcessors()",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2457",
        "summary": "Command line access to remote repositories",
        "description": "A few years ago Edgar Poce implemented a nice command line JCR access tool called jcr-commands. We haven't really been using it much and the code is currently parked in sandbox/inactive.\n\nI'd like to resurrect this codebase and integrate it to jackrabbit-standalone to implement command line access to remote repositories. The idea would be to have an easy-to-use tool for simple testing and administration tasks.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1064",
        "summary": "Optimize queries that check for the existence of a property",
        "description": "//*[@mytext] is transformed into the org.apache.jackrabbit.core.query.lucene.MatchAllQuery, that through the MatchAllWeight uses the MatchAllScorer.  The calculateDocFilter() in MatchAllScorer  does not scale and becomes slow for growing number of nodes. \n\nSolution: lucene documents will get a new Field:\n\npublic static final String PROPERTIES_SET = \"_:PROPERTIES_SET\".intern();\n\nthat holds the available properties of this document. \n\nNOTE: Lucene indices build without this performance improvement should still work and fall back to the original implementation",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3058",
        "summary": "BundleDumper to analyze broken bundles",
        "description": "The BundleReader fails if it can't read a bundle. We should have a tool to analyze broken bundles.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2065",
        "summary": "use the internal CND file for builtin nodetypes",
        "description": "the jackrabbit node type registry is reading the built in node types from a XML file.\nsince the CND (compact node type definition notation) is now specified by jsr283,\ni would like to drop the builtin .xml file and read the builtin node typesonly from the .cnd file.\nthis certainly helps the developers. furthermore, all the node types in jsr283 are now speced\nin CND, and converting them to XML is a pain and error prone.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3013",
        "summary": "ArrayIndexOutOfBoundsException: ConcurrentCache",
        "description": "ArrayIndexOutOfBoundsException after several days of uptime.\n\nI'm experiencing some strange ArrayIndexOutOfBoundsExceptions on\n accessing the jackrabbit ConcurrentCache in 2.2.5. in Line 241 during\n shrinkIfNeeded check.\n\n Caused by: java.lang.ArrayIndexOutOfBoundsException: -14\n        at\n org.apache.jackrabbit.core.cache.ConcurrentCache.shrinkIfNeeded(ConcurrentCache.java:241)\n\n\nI reviewed jackrabbit-code and I'm sure it's caused by that\n AtomicInteger for realizing accessCounter in AbstractCache, which will\n have become negative during increasing over the Integer.MAX_VALUE constant.\n\n         // Semi-random start index to prevent bias against the first\n segments\n         int start = (int) getAccessCount() % segments.length;\n         for (int i = start; isTooBig(); i = (i + 1) % segments.length) {\n             synchronized (segments[i]) {\n\n ___________________________\n\n Uncaught Throwable java.lang.ArrayIndexOutOfBoundsException: -7\n         at\n org.apache.jackrabbit.core.cache.ConcurrentCache.shrinkIfNeeded(ConcurrentCache.java:241)\n         at\n org.apache.jackrabbit.core.cache.ConcurrentCache.put(ConcurrentCache.java:176)\n         at\n org.apache.jackrabbit.core.persistence.bundle.AbstractBundlePersistenceManager.getBundle(AbstractBundlePersistenceManager.java:657)\n         at\n org.apache.jackrabbit.core.persistence.bundle.AbstractBundlePersistenceManager.load(AbstractBundlePersistenceManager.java:400)\n         at\n org.apache.jackrabbit.core.state.SharedItemStateManager.loadItemState(SharedItemStateManager.java:1819)\n         at\n org.apache.jackrabbit.core.state.SharedItemStateManager.getNonVirtualItemState(SharedItemStateManager.java:1739)\n         at\n org.apache.jackrabbit.core.state.SharedItemStateManager.getItemState(SharedItemStateManager.java:261)\n         at\n org.apache.jackrabbit.core.state.LocalItemStateManager.getNodeState(LocalItemStateManager.java:107)\n         at\n org.apache.jackrabbit.core.state.LocalItemStateManager.getItemState(LocalItemStateManager.java:172)\n         at\n org.apache.jackrabbit.core.state.XAItemStateManager.getItemState(XAItemStateManager.java:260)\n         at\n org.apache.jackrabbit.core.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:161)\n         at\n org.apache.jackrabbit.core.ItemManager.getItemData(ItemManager.java:370)\n         at\n org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:316)\n         at\n org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:610)\n         at\n org.apache.jackrabbit.core.SessionImpl.getNodeById(SessionImpl.java:493)\n         at\n org.apache.jackrabbit.core.SessionImpl.getNodeByIdentifier(SessionImpl.java:1045)\n         at sun.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)\n         at\n sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n         at java.lang.reflect.Method.invoke(Method.java:597)\n         at\n org.apache.sling.jcr.base.SessionProxyHandler$SessionProxyInvocationHandler.invoke(SessionProxyHandler.java:109)\n         at $Proxy2.getNodeByIdentifier(Unknown Source)\n         at\n de.dig.cms.frontend.servlet.helper.ResourceUtil.findResourceById(ResourceUtil.java:44)\n         at\n de.dig.cms.frontend.servlet.CMSContentEnrichServletFilter.doFilter(CMSContentEnrichServletFilter.java:194)\n         at\n org.apache.sling.engine.impl.filter.AbstractSlingFilterChain.doFilter(AbstractSlingFilterChain.java:60)\n         at\n de.dig.cms.frontend.servlet.CacheControlFilter.doFilter(CacheControlFilter.java:120)\n         at\n org.apache.sling.engine.impl.filter.AbstractSlingFilterChain.doFilter(AbstractSlingFilterChain.java:60)\n         at\n de.dig.cms.cache.impl.WallCacheServletFilter.processCacheableRequest(WallCacheServletFilter.java:244)\n         at\n de.dig.cms.cache.impl.WallCacheServletFilter.processCacheableRequestWithLatch(WallCacheServletFilter.java:185)\n         at\n de.dig.cms.cache.impl.WallCacheServletFilter.doFilter(WallCacheServletFilter.java:154)\n         at\n org.apache.sling.engine.impl.filter.AbstractSlingFilterChain.doFilter(AbstractSlingFilterChain.java:60)\n         at\n de.dig.cms.frontend.servletapi.CMSSlingHttpServletRequestFilter.doFilter(CMSSlingHttpServletRequestFilter.java:52)\n         at\n org.apache.sling.engine.impl.filter.AbstractSlingFilterChain.doFilter(AbstractSlingFilterChain.java:60)\n         at\n org.apache.sling.engine.impl.SlingMainServlet.service(SlingMainServlet.java:313)\n         at\n org.apache.sling.engine.impl.SlingMainServlet.service(SlingMainServlet.java:207)\n         at\n org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)\n         at\n org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:389)\n         at\n org.ops4j.pax.web.service.internal.HttpServiceServletHandler.handle(HttpServiceServletHandler.java:64)\n         at\n org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)\n         at\n org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)\n         at\n org.ops4j.pax.web.service.internal.HttpServiceContext.handle(HttpServiceContext.java:111)\n         at\n org.ops4j.pax.web.service.internal.JettyServerHandlerCollection.handle(JettyServerHandlerCollection.java:64)\n         at\n org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n         at org.mortbay.jetty.Server.handle(Server.java:324)\n         at\n org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:535)\n         at\n org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:865)\n         at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:539)\n         at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n         at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n         at\n org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)\n         at\n org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:520)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-734",
        "summary": "Update namespace uri for prefix fn",
        "description": "The SearchManager class still uses an outdated namespace uri for the 'fn' prefix: http://www.w3.org/2004/10/xpath-functions\n\nThe prefix should be re-mapped to the now offical namespace: http://www.w3.org/2005/xpath-functions\n\nSee: http://www.w3.org/TR/xquery-operators/#namespace-prefixes\n\nTo keep a minimum of backward compatibility, the existing namespace uri should still exist in the namespace registry, but refer to another prefix. E.g. fn_old.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2485",
        "summary": "Add method getID to interface ItemInfo",
        "description": "ItemInfo is the base for NodeInfo and PropertyInfo both of which declare a method getId with return type NodeId and PropertyId, respectively. With Java 1.5. it is now possible to override a method with a covariant return type. I thus propose to introduce a method getId on ItemInfo with return type ItemId which is the common base type of NodeId and PropertyId.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-540",
        "summary": "AbstractJCRTest fails on level 1 repositories",
        "description": "If a test case indicates that it's not read-only, org.apache.jackrabbit.test.AbstractJCRTest tries to cleanup the test root in the setUp method. This will cause the test case to fail, because a Level 1 repository will throw an UnsupportedOperationException here.\n\nProposal: before trying the cleanup, check for L2 functionality and throw a NotExecutableException otherwise:\n\n            if (! isSupported(Repository.LEVEL_2_SUPPORTED)) {\n              cleanUp();\n              String msg = \"Test case requires level 2 functionality\";\n              throw new NotExecutableException(msg);\n            }\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-2984",
        "summary": "JCR2SPI NamespaceRegistryImpl.unregisterNamespace passes prefix to storage when uri is expected",
        "description": "When trying to unregister a namespace through SPI, Jackrabbit throws a NamespaceException : <prefix>: is not a registered namespace uri.\n\njavax.jcr.NamespaceRegistry.unregisterNamespace(String prefix) expects the namespace prefix. Though, org.apache.jackrabbit.jcr2spi.NamespaceRegistryImpl.unregisterNamespace(String prefix) calls directly org.apache.jackrabbit.jcr2spi.NamespaceStorage.unregisterNamespace(String uri), which expects the namespace uri.\n\nThe namespace registry should first retrieve the uri for the provided prefix.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-309",
        "summary": "Extract the public API interfaces from o.a.j.core to o.a.j.api",
        "description": "To better document and track the public JCR extensions and component API provided by Jackrabbit and to allow more room for refactoring within the Jackrabbit core, we shoud move (or create) the supported API interfaces to a new org.apache.jackrabbit.api package.\n\nAt least the following interfaces should be moved along with any supporting implementation-independent classes:\n\n    * PersistenceManager\n    * FileSystem\n    * AccessManager\n    * QueryHandler\n    * TextFilter\n\nPossible dependencies to implementation-specific classes should preferably be abstracted using extra interfaces.\n\nAlso the workspace and node type administration methods should be published as Jackrabbit-specific extensions to the JCR API interfaces.\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "TASK"
    },
    {
        "key": "JCR-2646",
        "summary": "AccessControlManager#getEffectivePolicies(String) may expose AC content without proper permissions",
        "description": "The implementation of AccessControlManager#getEffectivePolicies(String) in the DefaultAccessManager only checks if the session is allowed\nto read AC content at the specified path. However the result may also include policies effective at absPath that should not be visible to the editing\nsession (read_AC permissions denied e.g. at an ancestor node) and could not be read by the editing session be means of #getPolicies().\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3057",
        "summary": "ItemInfoBuilder fails to set correct path on properties",
        "description": "This only happens if the parent node's nodeId is id based (in contrast to path based). The build() method should not rely on the nodeId providing the full path. Instead it should us the parent node's getPath() method to construct the full path. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-773",
        "summary": "Under heavy load, database journal may contain empty update records.",
        "description": "In a clustering scenario with a database journal, empty records may be produced. A passive node will then throw the following exception during its synchronization: \n\n28.02.2007 08:34:11 *ERROR* ClusterNode: Unexpected error while syncing of journal: null (ClusterNode.java, line 260)\njava.lang.NullPointerException\n\tat java.io.FilterInputStream.close(Unknown Source)\n\tat org.apache.jackrabbit.core.journal.ReadRecord.close(ReadRecord.java:197)\n\tat org.apache.jackrabbit.core.journal.DatabaseRecordIterator.close(DatabaseRecordIterator.java:148)\n\tat org.apache.jackrabbit.core.journal.DatabaseRecordIterator.close(DatabaseRecordIterator.java:114)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.doSync(AbstractJournal.java:196)\n\tat org.apache.jackrabbit.core.journal.AbstractJournal.sync(AbstractJournal.java:165)\n\tat org.apache.jackrabbit.core.journal.ClusterNode.sync(ClusterNode.java:283)\n\tat org.apache.jackrabbit.core.journal.ClusterNode.run(ClusterNode.java:254)\n\tat java.lang.Thread.run(Unknown Source)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1029",
        "summary": "CLONE -Handling of multiple residual prop defs in EffectiveNodeTypeImpl",
        "description": "org.apache.jackrabbit.jcr2spi.nodetype.EffectiveNodeTypeImpl currently rejects multiple residual property definitions, if they do not differ in getMultiple(). In fact, it should accept all combinations, so differing values for getOnParentVersionAction and other aspects should be accepted as well.\n\nSee JSR 170, 6.7.8:\n\n\"For purposes of the above, the notion of two definitions having the same name does not apply to two residual definitions. Two (or more) residual property or child node definitions with differing subattributes must be permitted to co-exist in the same effective node type. They are interpreted as disjunctive (ORed) options.\"",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-552",
        "summary": "Move listeners from item state to item state managers",
        "description": "Clients interested in item state modifications directly subscribe to the item states, which is a very flexible approach. On the other side, it increases the memory consumption of an item state, because every item state holds a collection of its listeners. It further increases complexity, because item state listeners can potentially have a shorter life and might be garbage collected.\n\nListeners should therefore be moved to their associated item state manager. At the same time, this enables an item state manager to completely remove an item state from its cache and resurrect it at a later time without losing the listeners interested in notifications.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2056",
        "summary": "JSR 283: Binary interfaces ",
        "description": "The Binary interface replaces the deprecated methods for getting/setting the InputStream of a given JCR value and the method to create binary value (ValueFactory).",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-2351",
        "summary": "Make Authorizable.setProperty more noisy in case of failures",
        "description": "setProperty fails with an unspecific warning, when there's an exception, but it doesn' print any useful information from this exception.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2930",
        "summary": "same named child nodes disappear on restore",
        "description": "When restoring a versionable node which has several (non-versionable) child nodes with the same name, some child nodes disappear. \n\n            Node node = session.getRootNode().addNode(\"myNode\");\n            node.addMixin(\"mix:versionable\");\n            for (int i = 1; i < 6; i++) {\n                Node child = node.addNode(\"child\");\n                child.setProperty(\"name\", \"child_\"+i);\n            }\n            session.save();\n            VersionManager versionManager = session.getWorkspace().getVersionManager();\n            versionManager.checkin(node.getPath());\n            System.out.println(\"number of child nodes: \" + node.getNodes().getSize());\n\n            versionManager.checkout(node.getPath());\n            node.getNode(\"child\").setProperty(\"name\", \"modified\");\n            session.save();\n            Version baseVersion = versionManager.getBaseVersion(node.getPath());\n            versionManager.restore(baseVersion, true);\n            System.out.println(\"number of child nodes in restored node: \"+node.getNodes().getSize());\n\n\nproduces the following output:\n\nnumber of child nodes: 5\nnumber of child nodes in restored node: 3\n\nGiving unique names or adding the mixin versionable to the child nodes solves the problem.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-146",
        "summary": "importXML prepending line feeds to tag values",
        "description": "Importing using Session.importXML(...) results in new line characters being inserted at the beginning of tag\nvalues:\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Policy xmlns=\"urn:oasis:names:tc:xacml:1.0:policy\"  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" PolicyId=\"test:policy-one\" RuleCombiningAlgId=\"urn:oasis:names:tc:xacml:1.0:rule-combining-algorithm:ordered-permit-overrides\">\n  <Description>policy-description</Description>\n  <Target>\n...\n\nBecomes\n\n/test/policies/Policy/jcr:primaryType=nt:unstructured\n/test/policies/Policy/PolicyId=test:policy-one\n/test/policies/Policy/RuleCombiningAlgId=urn:oasis:names:tc:xacml:1.0:rule-combining-algorithm:ordered-permit-overrides\n/test/policies/Policy/Description/jcr:primaryType=nt:unstructured\n/test/policies/Policy/Description/jcr:xmltext/jcr:primaryType=nt:unstructured\n/test/policies/Policy/Description/jcr:xmltext/jcr:xmlcharacters=\npolicy-description\n/test/policies/Policy/Target/jcr:primaryType=nt:unstructured\n\n(in other cases, many LFs are inserted)\n\nFULL EXAMPLE XML FILE:\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Policy xmlns=\"urn:oasis:names:tc:xacml:1.0:policy\" \n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n  PolicyId=\"test:policy-one\" \n  RuleCombiningAlgId=\"urn:oasis:names:tc:xacml:1.0:rule-combining-algorithm:ordered-permit-overrides\">\n  <Description>policy-description</Description>\n  <Target>\n    <Resources>\n      <Resource>\n        <ResourceMatch \n          MatchId=\"urn:oasis:names:tc:xacml:1.0:function:string-equal\">\n          <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">test/12345-resource-67890</AttributeValue>\n          <ResourceAttributeDesignator \n            DataType=\"http://www.w3.org/2001/XMLSchema#string\" \n            AttributeId=\"urn:oasis:names:tc:xacml:1.0:resource:resource-id\"/>\n        </ResourceMatch>\n      </Resource>\n    </Resources>\n    <Actions>\n      <AnyAction/>\n    </Actions>\n  </Target>\n  <Rule RuleId=\"PermitRule\" Effect=\"Permit\">\n    <Target>\n      <Subjects>\n        <Subject>\n          <SubjectMatch \n            MatchId=\"urn:oasis:names:tc:xacml:1.0:function:string-equal\">\n            <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">alice</AttributeValue>\n            <SubjectAttributeDesignator \n              DataType=\"http://www.w3.org/2001/XMLSchema#string\" \n              AttributeId=\"urn:oasis:names:tc:xacml:1.0:subject:subject-id\"/>\n          </SubjectMatch>\n        </Subject>\n      </Subjects>\n      <Actions>\n        <Action>\n          <ActionMatch \n            MatchId=\"urn:oasis:names:tc:xacml:1.0:function:string-equal\">\n            <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">read</AttributeValue>\n            <ActionAttributeDesignator \n              DataType=\"http://www.w3.org/2001/XMLSchema#string\" \n              AttributeId=\"urn:oasis:names:tc:xacml:1.0:action:action-id\"/>\n          </ActionMatch>\n        </Action>\n        <Action>\n          <ActionMatch \n            MatchId=\"urn:oasis:names:tc:xacml:1.0:function:string-equal\">\n            <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">write</AttributeValue>\n            <ActionAttributeDesignator \n              DataType=\"http://www.w3.org/2001/XMLSchema#string\" \n              AttributeId=\"urn:oasis:names:tc:xacml:1.0:action:action-id\"/>\n          </ActionMatch>\n        </Action>\n        <Action>\n          <ActionMatch \n            MatchId=\"urn:oasis:names:tc:xacml:1.0:function:string-equal\">\n            <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">delete</AttributeValue>\n            <ActionAttributeDesignator \n              DataType=\"http://www.w3.org/2001/XMLSchema#string\" AttributeId=\"urn:oasis:names:tc:xacml:1.0:action:action-id\"/>\n          </ActionMatch>\n        </Action>\n      </Actions>\n    </Target>\n  </Rule>\n</Policy>",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-897",
        "summary": "ItemState constructor throws IllegalArgumentException",
        "description": "When running ConcurrentReadWriteTest it may happen that a reading session gets an IllegalArgumentException:\n\nException in thread \"Thread-7\" java.lang.IllegalArgumentException: illegal status: 0\n\tat org.apache.jackrabbit.core.state.ItemState.<init>(ItemState.java:138)\n\tat org.apache.jackrabbit.core.state.PropertyState.<init>(PropertyState.java:79)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.getPropertyState(LocalItemStateManager.java:121)\n\tat org.apache.jackrabbit.core.state.LocalItemStateManager.getItemState(LocalItemStateManager.java:152)\n\tat org.apache.jackrabbit.core.state.XAItemStateManager.getItemState(XAItemStateManager.java:226)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:175)\n\tat org.apache.jackrabbit.core.ItemManager.createItemInstance(ItemManager.java:495)\n\tat org.apache.jackrabbit.core.ItemManager.getItem(ItemManager.java:326)\n\tat org.apache.jackrabbit.core.LazyItemIterator.prefetchNext(LazyItemIterator.java:90)\n\tat org.apache.jackrabbit.core.LazyItemIterator.<init>(LazyItemIterator.java:75)\n\tat org.apache.jackrabbit.core.ItemManager.getChildProperties(ItemManager.java:485)\n\tat org.apache.jackrabbit.core.NodeImpl.getProperties(NodeImpl.java:2481)\n\tat org.apache.jackrabbit.core.ConcurrentReadWriteTest$1$1.execute(ConcurrentReadWriteTest.java:61)\n\tat org.apache.jackrabbit.core.AbstractConcurrencyTest$Executor.run(AbstractConcurrencyTest.java:107)\n\tat java.lang.Thread.run(Thread.java:595)\n\nStatus 0 is STATUS_UNDEFINED. I think the following happens: when the reading session retrieves the ItemState from the SharedItemStateManager it is still valid but a short time later the writing session removes the item and changes the status to STATUS_UNDEFINED. Then the reading session tries to create an overlayed ItemState for the LocalItemStateManager using the changed status.\n\nAdding the STATUS_UNDEFINED to the list of 'valid' status in the ItemState constructor seems to solve the issue, but I'm not sure if that's the right way to do it.\n\nOpinions?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-278",
        "summary": "DBFileSystem MySQL DDL not compatible with pre-5.0 versions",
        "description": "The packaged ddl for mysql index sizes is too large for 4.x versions of MySQL. As the sum-total of the index sizes may only reach 500.\n\nSo, \n\ncreate unique index ${schemaObjectPrefix}FSENTRY_IDX on ${schemaObjectPrefix}FSENTRY (FSENTRY_PATH(745), FSENTRY_NAME)\n\nwill not work. I would suggest shortening the FSENTRY_PATH index value to 245, as FSENTRY_NAME is already set to 255.\n\ncreate unique index ${schemaObjectPrefix}FSENTRY_IDX on ${schemaObjectPrefix}FSENTRY (FSENTRY_PATH(245), FSENTRY_NAME)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2504",
        "summary": "Allow indexingConfiguration to be loaded from the classpath",
        "description": "The \"indexingConfiguration\" attribute in the SearchIndex configuration (http://wiki.apache.org/jackrabbit/IndexingConfiguration) actually requires an absolute filesystem path.\n\nIt would be nice if SearchIndex would also accept a file available in the classpath... although you can use variables like ${wsp.home} or similar there are many scenarios where a classpath resource would help (for example when creating a new workspace the directory structure is automatically created by jackrabbit and doesn't need to be already available but the indexing configuration file does).\n\nI am attaching a simple patch to SearchIndex that tries to load the file from the classpath if it has not been found. Since priority is given to the old behavior (file before classpath) so it's fully backward compatible.\n\nDiff has been generated against trunk, it would be nice to have this patch also on the 2.0 branch.\n \n ",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2008",
        "summary": "System search manager uses a SessionItemStateManager",
        "description": "As noted in JCR-2000, the system search manager (responsible for indexing the /jcr:system subtree) uses the SessionItemStateManager instance of the system session instead of the SharedItemStateManager of the underlying default workspace.\n\nThis can cause a deadlock (see the thread dumps in JCR-2000) when one thread is accessing the LockManager (that also uses the system session) while another thread is persisting versioning changes.\n\nSee the search-on-sism.patch attachment in JCR-2000 for a fix to this issue.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1537",
        "summary": "ClassDescriptor.hasIdField() fails if id is declared in upper class",
        "description": "org.apache.jackrabbit.ocm.mapper.model.ClassDescriptor.hasIdField() looks up only current class and not the whole hierarchy, so it fails when the id field is declared in a upper class.\n\nhasIdField should use getIdFieldDescriptor and not access idFieldDescriptor field directly, as follows :\n\n    public boolean hasIdField() {\n   \t\treturn (this.getIdFieldDescriptor() != null && this\n    \t\t\t\t.getIdFieldDescriptor().isId());\n    }\n\nPlease find patch enclosed.\n\nSincerely yours,\n\nSt\u00e9phane Landelle",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-189",
        "summary": "QueryHandler should use lucene Input-/OutputStream implementations",
        "description": "Currently the QueryHandler uses a jackrabbit specific implementation of the lucene Directory interface to make use of the jackrabbit FileSystem abstraction. Lucene operations on the file system however requires quite often random access on the index files. With the current FileSystem interface / abstraction random access is not possible on a FileSystemResource, therefore it is simulated by re-aquiring the InputStream and then seeking to the desired position. This it not efficient at all.\n\nWith respect to performance any other use than file based index storage does not make sense with lucene. Hence, the current abstraction using FileSystem should be dropped in favour of direct file access.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1884",
        "summary": "CachingIndexReader.initializeParents() does not scale well with large indexes",
        "description": "On a 40+ GB index that I'm testing with, the time to initialize the parents cache is 40 minutes.\n\nThis is way to much, needs optimization and should be done in a background thread.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2565",
        "summary": "spi2dav: Overwrite header T specified for MOVE and COPY causes failure if some API tests",
        "description": "failing tests are:\n\norg.apache.jackrabbit.test.api.WorkspaceCopySameNameSibsTest#testCopyNodesNodeExistsAtDestPath\norg.apache.jackrabbit.test.api.WorkspaceMoveSameNameSibsTest#testMoveNodesNodeExistsAtDestPath\n\nthose would be fixed by setting the overwrite header to F(alse)... however, this doesn't fit those cases where same-same\nsiblings would be allowed and the copy/move to a destination with existing item would succeed in JCR.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1372",
        "summary": "[PATCH] Fix possible Null Ptr exception in ConnectionFactory",
        "description": "code will throw npe if driver string is null - patch fixes this.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-714",
        "summary": "TCK: Test root path not escaped when used in XPath queries",
        "description": "A repository implementation might use a test root path that contains names that need _xXXXX_ escaping when used in XPath queries. Currently the TCK just uses the test path as-is when constructing queries. Even though this only affects few repositories (I've heard of one legacy connector to run into this problem), it would be good to add the proper escaping.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2709",
        "summary": "Missing XPath escape in query.jsp",
        "description": "As reported by Canberk Bolat of ADEO Security in a private communication, there search.jsp script in jackrabbit-webapp is missing an escape when it injects the path of a \"related:\" query into the constructed XPath statement. Further analysis showed that this issue has no security implications, so we can treat this as a normal bug report.\n\nsearch.jsp\n...\nString q = request.getParameter(\"q\");\n...\n      if (q != null && q.length() > 0) {\n           String stmt;\n           if (q.startsWith(\"related:\")) {\n               String path = q.substring(\"related:\".length());\n               stmt = \"//element(*, nt:file)[rep:similar(jcr:content,\n'\" + path + \"/jcr:content')]/rep:excerpt(.) order by @jcr:score\ndescending\";\n               queryTerms = \"similar to <b>\" +\nText.encodeIllegalXMLCharacters(path) + \"</b>\";\n           }\n...\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2845",
        "summary": "NodeBasedGroup#isMember(Principal) should have shortcut for the everyone group.",
        "description": "",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-386",
        "summary": "Query dump failed with deep query tree",
        "description": "With a big query (more than 400 OR operands) the query dump failed.\nThe query dump is made at QueryImpl.execute (line 136)\n\nIt failed because of the constant PADDING at QueryTreeDump.visit(line 85).\nThe constant PADDING is a 255 character array, but in my program it would need it to be bigger.\nI think putting it to 65535 would not be a problem : it would only take a little bit more memory.\n\nThis is the top of the stacktract for info:\njava.lang.ArrayIndexOutOfBoundsException\n\tat java.lang.System.arraycopy(Native Method)\n\tat java.lang.StringBuffer.append(StringBuffer.java:499)\n\tat org.apache.jackrabbit.core.query.QueryTreeDump.visit(QueryTreeDump.java:85)\n\tat org.apache.jackrabbit.core.query.OrQueryNode.accept(OrQueryNode.java:50)\n\tat org.apache.jackrabbit.core.query.QueryTreeDump.traverse(QueryTreeDump.java:263)\n                     ...\n\nThis is not critical because I can avoid the dump by unactivating debug logs.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-93",
        "summary": "Webdav: creating resource in case of RepositoryException",
        "description": "if accessing item fails for any other reason than PathNotFoundException, creating\nthe resource should rather fail (throwing 403).\n\n(reported by brian)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2621",
        "summary": "principalbased ACL editing fails if principalName differs from the authorizableID",
        "description": "this issue has been reported by alexK:\n\nediting the permissions for a principal whose name differs from the id of the corresponding user/group fails with AccessControlException.\n\ni quickly had a look at it and the main problem is caused by the ACEditor that assumes that the last segment of the \npath corresponds to the principal name. this isn't true if the principalName differs from the id.\n\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-562",
        "summary": "'OR' in XPath query badly interpreted",
        "description": "executing query: //*[@a=1 and @b=2 or @c=3] leads to creating wrong query tree. The builded tree looks like for query: //*[@a=1 and @b=2 and @c=3](see attachement). using brackets resolves the problem, but without brackets output query is different from input query. When AND and OR are switched(so the OR is in first palce - //*[@a=1 or @b=2 and @c=3]) everything is ok.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-826",
        "summary": "NodeTest.testAddNodeConstraintViolationExceptionUndefinedNodeType relies on addNode(name, \"nt:base\")",
        "description": "NodeTest.testAddNodeConstraintViolationExceptionUndefinedNodeType() relies on the ability to create a new node of type \"nt:base\", which isn't something repositories are required to support.\n\nProposal: make the node type name for this test case configurable.\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-203",
        "summary": "set jcr:encoding when importing files into simple webdav server",
        "description": "attached is a patch that sets the jcr:encoding property when importing files into the simple webdav server. it also strips parameters from the content type before setting the jcr:mimetype property.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-768",
        "summary": "Node.getPath() will corrupt the session",
        "description": "When calling Node.getPath() anytime, no mather if its before or after save, and when deleting nodes, the internal reference points to the wrong nodes. \nThe attached test will always fail with a javax.jcr.RepositoryException: /: cannot remove root node. \nWe have seen other configurations where a node suddenly behaves as the another node that has references and throw a reference exception, and yet other configurations where the node we though we deleted still exists, and another node has now disappeared.\n\nI do not know what causes the bug,a good bet is perhaps the CachingHierarchyManager?. It was not present in Jackrabbit 1.0.1, but was introduced in 1.1.\n\nHave also tested the latest release: 1.2.2, and the bug is still present there.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-749",
        "summary": "Add myqsql ddl for clustering (DatabaseJournal)",
        "description": "the default ddl for clustering does't work with mysql, so it would be nice to include a mysql specific ddl also for clustering.",
        "label": "NUG",
        "classified": "TASK",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2795",
        "summary": "Initializing SeededSecureRandom may be slow",
        "description": "For systems where reading from /dev/random is very slow (so that the alternative seed algorithm is used), initializing the org.apache.jackrabbit.core.id.SeededSecureRandom singleton may be very slow, because it is not synchronized. Each thread that calls SeededSecureRandom.getInstance() will wait up to 1 second until the singleton is initialized.\n\nAt the same time, I would like to add more entropy to the alternative seed algorithm.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1308",
        "summary": "Unnecessary null check in EffectiveNodeType.getApplicableChildNodeDef()",
        "description": "This is just a trivial thing I noticed this while inspecting the code. getApplicableChildNodeDef() says:\n\n        // try named node definitions first\n        ItemDef[] defs = getNamedItemDefs(name);\n        if (defs != null) {\n\nbut getNamedItemDefs() is currently defined to not return null:\n\n    public ItemDef[] getNamedItemDefs(Name name) {\n        List defs = (List) namedItemDefs.get(name);\n        if (defs == null || defs.size() == 0) {\n            return ItemDef.EMPTY_ARRAY;\n        }\n        return (ItemDef[]) defs.toArray(new ItemDef[defs.size()]);\n    }\n\nI didn't check to see if there were any other unnecessary null checks.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-154",
        "summary": "Documentation - jackrabbit features beyond the spec",
        "description": "",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "RFE"
    },
    {
        "key": "JCR-2338",
        "summary": "Tests not executable for already present mixins",
        "description": "org.apache.jackrabbit.test.api.NodeRemoveMixinTest.testCheckedIn() and \norg.apache.jackrabbit.test.api.NodeAddMixinTest.testCheckedIn() \n\nfail when the mixin being added is already present on the node. The tests should check for this and trow a NotExecutableException.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-871",
        "summary": "Provide Readme's for subprojects jcr-mapping and jcr-nodemanagement",
        "description": "There need to be Readme files in each of the subprojects \"jcr-mapping\" and \"jcr-nodemanagement\" to provide some information about the scope of the subproject, building and hints on how to get started.",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "JCR-850",
        "summary": "Promote the classloader component from contrib",
        "description": "This is a dummy issue for a change I already made (revisions 529068 and 529137) to promote the classloader component from contrib. I'm including this here in the issue tracker to complete the release notes for Jackrabbit 1.3.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-795",
        "summary": "Sessions are not logged out in case of exceptions",
        "description": "Some test cases do not logout sessions if an exception occurs.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-2175",
        "summary": "Return bind variable names on RepositoryService.checkQueryStatement()",
        "description": "To properly support JSR 283 bind variables the SPI layer needs to return the names of the bind variables. Otherwise the jcr2spi implementation cannot check for unknown names.",
        "label": "NUG",
        "classified": "SPEC",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1662",
        "summary": "Add pattern matching for paths",
        "description": "I suggest to add utility classes to spi-commons which can be used to do pattern matching on paths similar to regular expressions. ",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-380",
        "summary": "Run TCK on Jackrabbit 1.0-rc3",
        "description": "Run TCK on Jackrabbit 1.0-rc3",
        "label": "NUG",
        "classified": "TASK",
        "type": "TASK"
    },
    {
        "key": "JCR-1450",
        "summary": "move method of the MemoryFileSystem may accept invalid destination path resulting in invalid entries in FS",
        "description": "It seems there can be a problem with the move method of the MemoryFileSystem class: when looking at its code it looks that it can accept destinations, specifying folders that do not exist in the file system.\nFor example, if there is a \"somefolder/somefile\" file and I call the method passing, say \"somefolder/someotherfolder/somefile\" as the destination. The destination will be accepted by the code even if \"somefolder/someotherfolder\" is not an existing folder and the function execution will result in a file having the \"somefolder/someotherfolder/somefile\" path within a file system having no \"somefolder/someotherfolder\" folder - the code should probably check whether the destination path is really a valid one. Such  validation could be performed , for example, in the following way: take all path elements from the destination path except the last one and insure that the resulting path points to an existing folder, throw an exception otherwise.\nCurrently I have no JackRabbit build/test environment set up and could not verify practically whether the issue described can really take place, the supposition is made after looking at the move method implementation.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1795",
        "summary": "advertise support for RFC4918 (WebDAV) compliance class 3",
        "description": "With the recent changes for PROPFIND/allprop/include (JCR-1769) and the parsing of Destination/If headers (JCR-1770), we can advertise RFC 4918 L3 support (http://greenbytes.de/tech/webdav/rfc4918.html#rfc.section.18.3).\n\nNote we still have test failures for tagged If headers, but this has nothing to do with compliance class 3.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-706",
        "summary": "RTFTextExtractor should also support mime type text/rtf",
        "description": "There exist two mime types for RTF documents: application/rtf and text/rtf. The current RTFTextExtractor currently only recognizes the first.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1947",
        "summary": "JSR 283: Node Type Attribute Subtyping Rules ",
        "description": "JCR 2.0 clarifies node type attribute subtyping rules whereas JCR 1.0 didn't mandate any specific behavior.\n\n\"3.7.6.7 Node Type Attribute Subtyping Rules\" states  (assume T' being a subtype of T):\n\n- if T has orderable child nodes then T' must have orderable child nodes\n- if T specifies a primary item then T' inherits that setting and must not override it\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-273",
        "summary": "Registering cyclic dependent nodetypes does not work",
        "description": "when registering the followin 2 nodetypes:\n\n[foo] \n+ mybar (bar)\n\n[bar]\n+ myfoo (foo)\n\nNodeTypeRegistry.registerNodeTypes(Collection) throws:\n\n org.apache.jackrabbit.core.nodetype.InvalidNodeTypeDefException: the following node types could not be registered because of unresolvable dependencies: {}foo {}bar \n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2540",
        "summary": "spi2dav : move/reorder not properly handled by observation",
        "description": "all TCK tests including move or reorder fail in the setup jcr2spi - spi2dav(ex) - jcr-server.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1652",
        "summary": "Better 'invalid format' exception messages for value classes",
        "description": "The valueOf() methods of the Value classes throw an exception without information on the desired type and without the String value that gave the error.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1358",
        "summary": "Cluster revision file not closed on repository shutdown.",
        "description": "After having shut down a repository that has configured clustering, the cluster revision file is still open.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-274",
        "summary": "NodeTypeRegistry.registerNodetypes(Collection) should not register a partial set",
        "description": "the javadoc says:\n\n     * Note that in the case an exception is thrown, some node types might have\n     * been nevertheless successfully registered.\n\nthe problem hereby is, that it cannot be determined easily, what nodetypes could be registered, and which couldnt. i would rather prefer a all-or-nothing behaviour.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2217",
        "summary": "Enable DataStore in default configuration",
        "description": "Currently the default configuration causes binary properties to be stored in the derby database. This is very inefficient. The standalone server (and the web application it contains) should run with a reasonable default configuration. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-377",
        "summary": "Change project names to start with jackrabbit",
        "description": "All the released projects should have artifactId's starting with \"jackrabbit\".",
        "label": "NUG",
        "classified": "TASK",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1299",
        "summary": "Default configuration not suitable for demo web application",
        "description": "The default configuration is not suitable for the demo application. There are no text extractors configured, which makes the populate and search demos useless.\n\nProposed solution: create a new repository.xml in jackrabbit-webapp with text extractors configured.\n\nI know we should actually try to reduce the number of repository.xml files, but having one dedicated to jackrabbit-webapp seems reasonable, while we should try to achieve the same for the jackrabbit-core module.",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2939",
        "summary": "QueryObjectModel does not generate the corresponding SQL2 Query when dealing with spaces in the path",
        "description": "This is the original issue:\n----------\nI tried to get the childnodes of a node names \"/a b\" using the following code\n  QueryManager queryManager=session.getWorkspace().getQueryManager();\n  QueryObjectModelFactory qomf=queryManager.getQOMFactory();\n  Source source1=qomf.selector(NodeType.NT_BASE, \"selector_0\");\n  Column[] columns = new Column[]{qomf.column(\"selector_0\", null, null)};\n  Constraint constraint2 = qomf.childNode(\"selector_0\", \"/a b\");\n  QueryObjectModel qom = qomf.createQuery(source1, constraint2 , null, columns);\n\nThis is not giving any result when the session is acquired through webdav. But when connected using JNDI it is giving the child nodes. \n\nThe sql statement getting created is \nSELECT selector_0.* FROM [nt:base] AS selector_0 WHERE ISCHILDNODE(selector_0, \n[/a b]).\n\nWhen using webdav If i give this SQL2 query directly along with quotes around \nthe path i.e. ['/a b'] then it is working as expected.\n----------\n\nthis doesn't have anything to do with webdav. the problem is the QueryObjectModel generates an SQL2 query that is not 100% equivalent, it fails to escape paths that have spaces in them.\nthis way, in the case of davex remoting, the jr client will use the statement generated instead, which is not escaped, and will fail to return the expected nodes. \n\nThis can be seen easily if we do a System.out.println(qom.getStatement())\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1649",
        "summary": "Separate NOTICEs and LICENSEs for binary and source packages",
        "description": "Based on recent discussions on sling-dev@ (see [1]) and on legal-discuss@  (see [2]), I'd like to rearrange our NOTICE and LICENSE files so that the root level files refer only to bits included in source releases and that the (in some cases different) files to be included in the binary artifacts would be placed in src/main/resources/META-INF.\n\nSee also JCR-1630 for related work.\n\n[1] http://markmail.org/message/2enw6ktxhc4ixmrk\n[2] http://markmail.org/message/bttmkavpicxxg7gl\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1706",
        "summary": "Fix unexpected behavior of Text.getName()",
        "description": "Text.getName() and variants does return an empty string, if the given path is already a name. eg:\n\nText.getName(\"foo\") returns \"\" and not \"foo\" as one would expect for relative paths.\nsuggest to change this.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1984",
        "summary": "UserManagement: Limit set of properties exposed by AuthorizableImpl",
        "description": "AuthorizableImpl currently exposes all properties present on the Node representing the user/group. This should be limited to the properties set through the API (i.e. the non-protected props defined by the rep:Authorizable node type)",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1109",
        "summary": "Resource association not compliant to JTA spec",
        "description": "According to JTA specifcation, section 3.4.4 (Transaction Association), a resource's association may be ended (state T0 in the spec's table) in the suspended state (T2), i.e. without having been resumed (T1) again. The code in XASessionImpl.end(), however, assumes that the resource must be associated in order to end its association. This causes an exception in JBoss 4.0.5.GA:\n\n09:37:15,525 WARN  [TransactionImpl] XAException: tx=TransactionImpl:XidImpl[FormatId=257, GlobalId=kneipix.dev.day.com/14, BranchQual=, localId=14] errorCode=XAER_PROTO\njavax.transaction.xa.XAException\n        at org.apache.jackrabbit.core.XASessionImpl.end(XASessionImpl.java:279)\n        at org.apache.jackrabbit.jca.TransactionBoundXAResource.end(TransactionBoundXAResource.java:46)\n        at org.jboss.tm.TransactionImpl$Resource.endResource(TransactionImpl.java:2143)\n        at org.jboss.tm.TransactionImpl$Resource.endResource(TransactionImpl.java:2118)\n        at org.jboss.tm.TransactionImpl.endResources(TransactionImpl.java:1462)\n        at org.jboss.tm.TransactionImpl.beforePrepare(TransactionImpl.java:1116)\n        at org.jboss.tm.TransactionImpl.commit(TransactionImpl.java:324)\n        at org.jboss.tm.TxManager.commit(TxManager.java:240)\n        at org.jboss.aspects.tx.TxPolicy.endTransaction(TxPolicy.java:175)\n",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "JCR-2490",
        "summary": "jackrabbit wrongly think nodetype is changed on nodetype re-registration",
        "description": "When trying node type re-registration with jackrabbit 2.0, it wrongly detects a nodetype as having changed, with non-trivial changes. Example nodetype definition;\n\n[nen:profile] > mix:referenceable mixin orderable\n- nen:dn (string)\n- nen:cn (string)\n- * (string)\n+ * multiple\n\nException on nodetype re-registration;\n\njavax.jcr.RepositoryException: The following nodetype change contains\nnon-trivial changes.Up until now only trivial changes are supported.\n(see javadoc for org.apache.jackrabbit.core.nodetype.NodeTypeDefDiff):\norg.apache.jackrabbit.core.nodetype.NodeTypeDefDiff[\n       nodeTypeName={http://netenviron.com/nen/1.0}profile,\n       mixinFlagDiff=NONE,\n       supertypesDiff=NONE,\n       propertyDifferences=[\n               org.apache.jackrabbit.core.nodetype.NodeTypeDefDiff$PropDefDiff[itemName={http://netenviron.com/nen/1.0}dn,\ntype=TRIVIAL, operation=MODIFIED],\n               org.apache.jackrabbit.core.nodetype.NodeTypeDefDiff$PropDefDiff[itemName={http://netenviron.com/nen/1.0}cn,\ntype=TRIVIAL, operation=MODIFIED],\n               org.apache.jackrabbit.core.nodetype.NodeTypeDefDiff$PropDefDiff[itemName={}*,\ntype=TRIVIAL, operation=MODIFIED]\n       ],\n       childNodeDifferences=[\n               org.apache.jackrabbit.core.nodetype.NodeTypeDefDiff$ChildNodeDefDiff[itemName={}*,\ntype=MAJOR, operation=REMOVED],\n               org.apache.jackrabbit.core.nodetype.NodeTypeDefDiff$ChildNodeDefDiff[itemName={}*,\ntype=TRIVIAL, operation=ADDED]\n       ]\n]\n\n       at org.apache.jackrabbit.core.nodetype.NodeTypeRegistry.reregisterNodeType(NodeTypeRegistry.java:442)\n       at org.apache.jackrabbit.core.nodetype.NodeTypeRegistry.reregisterNodeType(NodeTypeRegistry.java:363)\n       at org.apache.jackrabbit.core.nodetype.NodeTypeManagerImpl.registerNodeTypes(NodeTypeManagerImpl.java:589)\n       at org.apache.jackrabbit.commons.cnd.CndImporter.registerNodeTypes(CndImporter.java:118)\n       at com.netenviron.content.manager.SessionManager.checkRepositorySchema(SessionManager.java:355)\n       at com.netenviron.content.manager.SessionManager.afterPropertiesSet(SessionManager.java:199)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1288)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1257)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:438)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:383)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:353)\n       at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:245)\n       at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:242)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:164)\n       at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:269)\n       at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:104)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1172)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:940)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:437)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:383)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:353)\n       at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:245)\n       at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:242)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:164)\n       at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:269)\n       at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:104)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1172)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:940)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:437)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:383)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:353)\n       at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:245)\n       at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:242)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:164)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getTypeForFactoryBean(AbstractBeanFactory.java:1223)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:582)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:438)\n       at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:214)\n       at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:189)\n       at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:143)\n       at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:614)\n       at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:572)\n       at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:496)\n       at org.springframework.beans.factory.annotation.InjectionMetadata.injectMethods(InjectionMetadata.java:87)\n       at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:250)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:928)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:437)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:383)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:353)\n       at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:245)\n       at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:242)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:164)\n       at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:269)\n       at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:104)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1172)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:940)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:437)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:383)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:353)\n       at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:245)\n       at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:242)\n       at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:164)\n       at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:299)\n       at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:955)\n       at org.springframework.context.support.AbstractApplicationContext.registerListeners(AbstractApplicationContext.java:712)\n       at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:366)\n       at org.springframework.web.context.ContextLoader.createWebApplicationContext(ContextLoader.java:261)\n       at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:199)\n       at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:45)\n       at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:3972)\n       at org.apache.catalina.core.StandardContext.start(StandardContext.java:4467)\n       at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:791)\n       at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:771)\n       at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:526)\n       at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:905)\n       at org.apache.catalina.startup.HostConfig.deployWARs(HostConfig.java:740)\n       at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:500)\n       at org.apache.catalina.startup.HostConfig.check(HostConfig.java:1345)\n       at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:303)\n       at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119)\n       at org.apache.catalina.core.ContainerBase.backgroundProcess(ContainerBase.java:1337)\n       at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1601)\n       at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1610)\n       at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1590)\n       at java.lang.Thread.run(Thread.java:637)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-909",
        "summary": "checkIfNodeLocked()  in jcr mapping layer  does not behave properly when open scoped locks are used",
        "description": "I am planning to use open-scoped lock.  For which , I need to persist the locktoken along with the node  so that it can be used by another session for unlocking.Tested with Jackrabbit RMI client and it works fine.\n\nBut I am using jcr-mapping layer to achieve the above in my project.Here I want that  as soon as a node is checked out, it gets locked by the session and the lock is stored in \"lockToken\" property of node \"Document\". For that I need to update the Document node after locking .\n\n*public void checkout(String path)throws CMSException {\n       pm = getPersistenceManager();\n        try{\n           pm.checkout(path);*\n*            String lockToken = pm.lock(path,true,false);   **        \n    Document doc = this.getDocument(path);**           \n  doc.setLockToken(lockToken);     //for persisting lockToken\n           doc.update();\n        }catch(LockedException le){\n          System.out.println(le.getLockedNodePath() + \"is locked by\" + le.getLockOwner());         }catch(Exception e){\n            throw new CMSException(e.getMessage(),e.getCause());\n        }\n   }*\n\n\nHere doc.update() fails with Locked Exception.  The problem here is PersistenceManagerImpl has a method checkIfNodeLocked(path)  which returns LockException if node is locked. This method is checked before every update/insert. So, I am not able to update a locked node. I need to persist the locktoken in the node . What is the reason of checking  for a lock before saving ? Ideally , it should throw error only if node is locked and session does not hold the lockToken .\n\nIf the session who has locked the node tries to save the node without unlocking, it should be allowed .\n\np.s.\nI am able to achieve the above by simple Jackrabbit RMI client.\n<code>\n               ClientRepositoryFactory factory = new ClientRepositoryFactory();\n               Repository repository = factory.getRepository(\"rmi://localhost:1101/jackrabbit\");\n               Session session = repository.login(new SimpleCredentials(\"superuser\", \"superuser\".toCharArray()),\"Portal\");                        String user = session.getUserID();\n               String name = repository.getDescriptor(Repository.REP_NAME_DESC);\n               System.out.println(\n                       \"Logged in as \" + user + \" to a \" + name + \" repository.\");\n\n               /* Testing the locks functionality */\n               Node n = session.getRootNode().getNode(\"cms/childfolder1/check.txt\");\n\n              * Lock lck = n.lock(true, false); // deeplock,open-scoped\n               n.setProperty(\"ps:locktoken\",lck.getLockToken());\n               n.setProperty(\"ps:language\", \"sanskrit\");\n*\n               System.out.println(\"Lock#isLive=\" + lck.isLive());\n               System.out.println(\"Node#isLocked=\" +  session.getRootNode().getNode(\"cms/childfolder1/check.txt\").isLocked());\n               session.save();\n               session.logout();\n     <code> ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1277",
        "summary": "ConnectionRecoveryManager is created twice in DBDataStore init method",
        "description": "It seems that after introducing pool, old initizialization of ConnectionRecoveryManager has not been removed.\n\nIndex: DbDataStore.java\n===================================================================\n--- DbDataStore.java\t(revision 605626)\n+++ DbDataStore.java\t(working copy)\n@@ -479,8 +479,6 @@\n             initDatabaseType();\n             connectionPool = new Pool(this, maxConnections);\n             ConnectionRecoveryManager conn = getConnection();\n-            conn = new ConnectionRecoveryManager(false, driver, url, user, password);\n-            conn.setAutoReconnect(true);\n             DatabaseMetaData meta = conn.getConnection().getMetaData();\n             log.info(\"Using JDBC driver \" + meta.getDriverName() + \" \" + meta.getDriverVersion());\n             meta.getDriverVersion();\n\nDuplicated initialization should be removed , but i've never run this code yet.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-953",
        "summary": "Support for transactions when using JCR over RMI.",
        "description": "At this time, the sessions obtained from o.a.j.rmi.client.LocalAdapterFactory do not implement the methods for the XASession.  Therefor the RMI access layer does not support a transactional session.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1948",
        "summary": "Let the AbstractISMLockingTest tests fail properly",
        "description": "The tests in the AbstractISMLockingTest class call junit.framework.Assert.fail() on threads that are not managed by the JUnit framework. Therefore, such calls to fail are not interpreted as test failures, but are merely logged to the console and the build succeeds. This is easy to see with a stub implementation of the ISMLocking type which returns non-null references from the two acquire methods and the downgrade method: many of the following stacktraces appear, but the build succeeds.\n\nException in thread \"Thread-1\" junit.framework.AssertionFailedError: acquireWriteLock must block\n\tat junit.framework.Assert.fail(Assert.java:47)\n\tat org.apache.jackrabbit.core.state.AbstractISMLockingTest.checkBlocking(AbstractISMLockingTest.java:214)\n\tat org.apache.jackrabbit.core.state.AbstractISMLockingTest$1.run(AbstractISMLockingTest.java:88)\n\tat java.lang.Thread.run(Thread.java:613)\n\n\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1842",
        "summary": "SPI: RepositoryService.obtain should allow to pass null workspaceName indicating the default workspace",
        "description": "improvement suggested by tobi\n\nthe contract of\n\npublic SessionInfo obtain(Credentials credentials, String workspaceName)\npublic SessionInfo obtain(Credentials credentials, String workspaceName)\n\nshould be changed to allow for null workspaceName.\n\n* @param workspaceName the name of the workspace the <code>SessionInfo</code>\n* should be built for. <code>null</code> indicates that the info should be created for the\n* default workspace.\n\nconsequently we could either deprecate \n\nRepositoryConfig.getDefaultWorkspaceName()\n\nor allow it to return null as well or remove it altogether.\n\n\n\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-326",
        "summary": "Initialize the cause of a login exception in the repository",
        "description": "===================================================================\n--- RepositoryImpl.java8(revision 379871)\n+++ RepositoryImpl.java (working copy)\n@@ -1056,7 +1056,9 @@\n             }\n             authCtx.login();\n         } catch (javax.security.auth.login.LoginException le) {\n-            throw new LoginException(le.getMessage());\n+           LoginException nle = new LoginException(le.getMessage());\n+           nle.initCause(le);\n+           throw nle;\n         }\n\n         // create session",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-820",
        "summary": "Add support for query result highlighting",
        "description": "Highlighting matches in a query result list is regularly needed for an application. The query languages should support a pseudo property or function that allows one to retrieve text fragments with highlighted matches from the content of the matching node.\n\nTo support this feature the following enhancements are required:\n- define a pseudo property or function that returns the text excerpt and can be used in the select clause\n- the index needs to *store* the original text it used when the node was indexed. this also includes extracted text from binary properties.\n- text fragments must be created based on the original text, the query and index information",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-331",
        "summary": "RepositoryConfig instance can not be reused once it has been passed to RepositoryImpl constructor",
        "description": "RepositoryConfig and other *Config classes maintain state apart from parsed configuration information;\nspecifically they instantiate FileSystem implementations based on their configurations. this makes it\nfor the config consumers very hard to control the lifecycle of such FileSystem instances as they need\nto close the file systems on repository shutdown.\n\nthe following code illustrates the issue:\n\nRepositoryConfig repConf = RepositoryConfig.create(configFile, repHomeDir);\nRepositoryImpl rep = RepositoryImpl.create(repConf);\n// ...\nrep.shutdown();\n\nrep = RepositoryImpl.create(repConf);   \n// ==> repConfig (et al) contains references to FileSystem objects \n// that have been closed by previous rep.shutdown() call\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1225",
        "summary": "ReadOnlyIndexReaders are re-created on every access",
        "description": "AbstractIndex.getReadOnlyIndexReader() creates a new instance on every call. The returned index reader should instead be cached and kept open as long as there are no changes on the underlying index.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2116",
        "summary": "JSR 283: Built-In Node Types",
        "description": "sync definitions of built-in node types with spec",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-837",
        "summary": "MatchAllQuery does not implement extractTerms()",
        "description": "This is required for rep:excerpt() functionality.",
        "label": "BUG",
        "classified": "BUG",
        "type": "RFE"
    },
    {
        "key": "JCR-2376",
        "summary": "Add basic I/O counters to query handler",
        "description": "There should be a couple of simple counters that track the number of I/O operations that are performed during a query execution. This will help debug query performance issues.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2484",
        "summary": "NPE if RepositoryService#getItemInfos throws ItemNotFoundException",
        "description": "When RepositoryService#getItemInfos throws an ItemNotFoundException, HierarchyEntryImpl#internalRemove in some cases throws an NPE. This is caused by a missing null check of the parent node.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-264",
        "summary": "TextFilters get called three times within checkin() method",
        "description": "If you want to add a PDF document to a repository using a PdfTextFilter, and you do the following steps:\n\nsession.save()\nnode.checkin();\n\nThe method PdfTextFilter.doFilter() gets called 4 times!!!\n\nsession's save method calls doFilter one time. This is normal\n\nBut checkin method calls doFilter three times. Is this normal? I do not see the sense.\n\n------------------\n\n\t\t\nMarcel Reutegger \t\n<marcel.reutegger@gmx.net> to jackrabbit-dev\n\t More options\t  11:43 am (13 minutes ago)\nHi Martin,\n\nthis is unfortunate and should be improved. the reason why this happens\nis the following:\nthe search index implementation always indexes a node as a whole to\nimprove query performance. that means even if a single property changes\nthe parent node with all its properties is re-indexed.\n\nunfortunately the checkin method sets properties in three separate\n'transactions', causing the search to re-index the according node three\ntimes.\n\nusually this is not an issue, because the index implementation keeps a\nbuffer for pending index work. that is, if you change the same property\nseveral times and save after each setProperty() call, it won't actually\nget re-indexed several times. but text filters behave differently here,\nbecause they extract the text even though the text will never be used.\n\neventually this will improve without any change to the search index\nimplementation, because as soon as versioning participates properly in\ntransactions there will only be one call to index a node on checkin().\n\nas a quick fix we could improve the text filter classes to only parse\nthe binary when the returned reader is acutally used.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2000",
        "summary": "Deadlock on concurrent commits",
        "description": "As reported in the followup to JCR-1979, there's a case where two transactions may be concurrently inside a commit. This is bad as it breaks the main assumption in http://jackrabbit.apache.org/concurrency-control.html about all transactions first acquiring the versioning write lock.\n\nLooking deeper into this I find that the versioning write lock is only acquired if the transaction being committed contains versioning operations. This is incorrect as all transactions in any case need to access the version store when checking for references.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2527",
        "summary": "Fix and simplify CryptedSimpleCredentials",
        "description": "the credentials retrieved from UserImpl and used to validate the simplecredentials passed to the repository login is overly complex\nand buggy as it tries to match all kind credentials variants with and without hashed password.\nin particular it contains the following problems:\n- simplecredentials containing the hashed pw are considered valid\n- passwords startign with {something} cause inconsistencies and may even prevent the user from login\n\nit should be improved as follows:\n- simplecredentials are always expected to contain the plain text password both for creation and\n  comparison with the cryptedsimplecredentials.\n- creating cryptedsimplecredentials from uid/pw however is left unchanged: the specified pw is\n  hashed with the default algorithm if it turns out not to be in the hashed format.\n- in addition the pw should also be hashed if it has the form {something}whatever but something\n  is an invalid algorithm.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2294",
        "summary": "Group.addMemeber() might add a REFERENCE instead of a WEAKREFERENCE",
        "description": "...and this causes that the member can't be removed afterwards.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-916",
        "summary": "Review pck names in the others ocm subprojects",
        "description": "Review package structure and graffito references in the other OCM subprojects : jcr-nodemanagement & spring. \n",
        "label": "NUG",
        "classified": "UNKNOWN",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2588",
        "summary": "UserManager.getAuthorizable() may fail with InvalidQueryException",
        "description": "Happens when the principal name contains an apostrophe.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-352",
        "summary": "Upgrade to Lucene 2.0",
        "description": "We would like to upgrade to Lucene 1.9.1. There are jar conflicts when integrating with other projects such as Liferay Portal --  which uses v 1.9.1.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1028",
        "summary": "Remove WARN logs for missing text extractors",
        "description": "In jackrabbit-core/src/main/java/org/apache/jackrabbit/core/query/lucene/JackrabbitTextExtractor.java, the method extractText logs at WARN level when no indexer is available.\n\nCan we move this to DEBUG, as not all applications need full text indexing of the text nodes and this message fills the logs?\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2945",
        "summary": "Token authentication parameters are not loaded from JAAS configuration.",
        "description": "token based authentication can be disabled and expiration time set in the login module config.\nhowever, this only works with local auth context but  not when using a jaas configuration.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2092",
        "summary": "make spi query code compatible with JCR 2.0",
        "description": "SPI-Commons currently has it's own outdated copy of the new JCR 2.0 query interfaces.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-1402",
        "summary": "Path.getAncestor and Path.isAncestor are not symmetric",
        "description": "Although the method names refer to ancestors they operate on sub-paths. Consider:\n\nPathFactory pf = PathFactoryImpl.getInstance();\nPath.Element p = pf.getParentElement();\n\nPath path = pf.create(new Path.Element[]{p, p});\nPath ancestor = path.getAncestor(1);\n\nassertFalse(ancestor.isAncestorOf(path) )  \n\nThis is not what one would expect from looking an the method signatures. \nI suggest to rename getAncestor to getSubPath, clarify the javadoc, and deprecate getAncestorCount. \n\nA patch follows.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-543",
        "summary": "DocViewSAXEventGenerator produces invalid SAX stream",
        "description": "ISO9075.encode() is called twice in DocViewSAXEventGenerator.leaving(), which produces invalid endElement events.\n\nFaulty block of code (note the encode method called twice):\n\n        // encode node name to make sure it's a valid xml name\n        name = ISO9075.encode(name);\n        // element name\n        String elemName;\n        if (node.getDepth() == 0) {\n            // root node needs a name\n            elemName = jcrRoot;\n        } else {\n            // encode node name to make sure it's a valid xml name\n            elemName = ISO9075.encode(name);\n        }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3213",
        "summary": "Speed up NodeIndexer.isIndexed() check",
        "description": "The isIndexed() method is called for every value in a multi-valued property. This may be quite expensive when there are a lot of values.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-388",
        "summary": "add support for RFC 3253 to the simple server",
        "description": "http://www.ietf.org/rfc/rfc3253.txt",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-956",
        "summary": "Reusable Repository access and bind servlets",
        "description": "As discussed in http://mail-archives.apache.org/mod_mbox/jackrabbit-dev/200705.mbox/%3C510143ac0705151453t7a0eb4cam859a40fb106e81f5@mail.gmail.com%3E and JCR-955, it would be useful to have a reusable set of servlet components for accessing and exposing repositories in various configurable ways.\n\nMy plan is to refactor the current RepositoryAccessServlet from jackrabbit-webapp and place the resulting servlet components in jackrabbit-jcr-commons, with servlet-api as a new optional (or provided) dependency.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-530",
        "summary": "Add files generated by eclipse or maven to svn:ignore",
        "description": "To make life easier for eclipse and maven users please add the following files to svn:ingore:\n\njackrabbit-jcr-rmi:\n-------------------\n.settings\n.classpath\n.project\njackrabbit-jcr-rmi-pom-snapshot-version\nproject.xml.md5\n\njackrabbit-core:\n----------------\n.settings\n.classpath\n.project\njackrabbit-core-pom-snapshot-version\nproject.xml.md5\n\nMaybe there some files missing in this list that could help developers using IDEA?",
        "label": "NUG",
        "classified": "OTHER",
        "type": "TASK"
    },
    {
        "key": "JCR-2723",
        "summary": "Exception when missing namespace in CND file should have clearer message",
        "description": "Using the attached CND file, when calling CndImporter.registerNodeTypes(..) the following message is in the returned exception:\n\n\"Unable to parse CND Input: Error setting name of sling:resourceType to sling:resourceType (bundle://23.0:0/SLING-INF/nodetypes/types.cnd, line 24)\"\n\nThe issue with line 24 is that the \"sling\" namespace has not been included.  The message should state that a namespace is missing and what prefix is not understood.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1465",
        "summary": "Configurable Similarity",
        "description": "The similarity implementation for indexing and searching should be configurable.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-948",
        "summary": "Support for JNDI configuration of BundleDbPersistenceManager",
        "description": "It would be nice to have the option to configure BundleDbPersistenceManager database specifying a JNDI name of a DataSource.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2760",
        "summary": "Use hash codes instead of sequence numbers for string indexes",
        "description": "We use index numbers instead of namespace URIs or other strings in many places. The two-way mapping between namespace URIs and index numbers is by default stored in the repository-global ns_idx.properties file, and the index numbers are allocated using a linear sequence. The problem with this approach is that two repositories will easily end up with different string index mappings, which makes it practically impossible to make low-level copies of workspace content across repositories.\n\nThe ultimate solution for this problem would be to store the namespace URIs closer to the stored content, ideally as an implementation detail of a persistence manager.\n\nAn easier short-term solution would be to decrease the chances of two repositories having different string index mappings. A simple (and backwards-compatible) way to do this is to use the hash code of a namespace URI as the basis of allocating a new index number. Hash collisions are fairly unlikely, and can be handled by incrementing the intial hash code until the collision is avoided. In the common case of no collisions (with a uniform hash function the chance of a collision is less than 1% even with tousands of registered namespaces) this solution allows workspaces to be copied between repositories without worrying about the namespace index mappings.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1864",
        "summary": "Database Data Store: clean up the code",
        "description": "There is some unnecessary code in the DbDataStore that should be removed.\nAlso, some more tests should be added.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-896",
        "summary": "Unnecessary parsing of Name value",
        "description": "When a Name value is created for a call like Property.getValue() the internal QName if formatted, parsed and formatted again.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2059",
        "summary": "JSR 283: Access Property/Node from Session",
        "description": "New methods to access properties and nodes from the Session:\n\n- getNode(String absPath) Node\n- getNodeByIdentifier(String id) Node\n- getProperty(String absPath) Property\n\n... test for their existence:\n\n- nodeExists(String absPath) boolean\n- propertyExists(String absPath) boolean\n\n... and remove them:\n\n- removeItem(String absPath) void\n\nThe functionality has been added at rev. 571494 and rev. 712984 but apart from Session.removeItem no\ntest cases are present so far.",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-1481",
        "summary": "VersionHistory.removeVersion() does not throw ReferentialIntegrityException",
        "description": "Inside an XATransaction immediately removing a version that was created by a checkin succeeds, even though it should fail because referential integrity is violated. The reason seems to be that the created version does not return any references.\n\nIn the end the transaction fails because referential integrity is checked again in the SharedItemStateManager, which is correct. But IMO removeVersion() should fail first.\n\nAdded test case: org.apache.jackrabbit.core.version.CheckinRemoveVersionTest",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1182",
        "summary": "Put everything in jackrabbit-spi-commons under org.apache.jackrabbit.spi.commons",
        "description": "To avoid confusion and naming conflicts, we should put all classes and packages in jackrabbit-spi-commons under org.apache.jackrabbit.spi.commons.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2918",
        "summary": "Avoid unnecessary index reader calls when using aggregate definitions",
        "description": "SearchIndex.retrieveAggregateRoot(Set<NodeId> removedIds, Map<NodeId, NodeState> map) identifies aggregate root nodes based on removed nodes and aggregate rules defined in the indexing configuration. This process requires index lookups. The method can be optimized for the case when no nodes are removed and an unnecessary call to the index reader can be avoided.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-741",
        "summary": "Handling of multiple residual prop defs in EffectiveNodeTypeImpl",
        "description": "org.apache.jackrabbit.jcr2spi.nodetype.EffectiveNodeTypeImpl currently rejects multiple residual property definitions, if they do not differ in getMultiple(). In fact, it should accept all combinations, so differing values for getOnParentVersionAction and other aspects should be accepted as well.\n\nSee JSR 170, 6.7.8:\n\n\"For purposes of the above, the notion of two definitions having the same name does not apply to two residual definitions. Two (or more) residual property or child node definitions with differing subattributes must be permitted to co-exist in the same effective node type. They are interpreted as disjunctive (ORed) options.\"",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1396",
        "summary": "DateValue.getDate not a copy",
        "description": "I noticed that getDate() in org.apache.jackrabbit.value.DateValue is returned \nby reference. According to the specification it should be a copy. (see.  JSR 170 section 6.2.7)\n\n \n private Calendar date;\n \n public Calendar getDate()\n             throws ValueFormatException, IllegalStateException,\n             RepositoryException {\n         setValueConsumed();\n \n         if (date != null) {\n             return date; // <-- HERE\n         } else {\n             throw new ValueFormatException(\"empty value\");\n         }\n     }\n\nshort test:\n\nValueFactory factory = session.getValueFactory();\n Value v = factory.createValue(GregorianCalendar.getInstance());\n Calendar c0 = v.getDate();   \n Calendar c1 = v.getDate();\n               \n if(c0 == c1){\n                   out.println(\"error - references are equal\");\n                    out.println(c0);\n }",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-296",
        "summary": "More details for beginners",
        "description": "Hi everyone,\n\nI'm one of these beginners trying to make their way in Jackrabbit and content repositories universe.\n\nBesides the fact that there exist but very few examples on Jackrabbit use, all of them, including the official web site of Jackrabbit miss few details, simple though essential, for beginners.\n\nMy first point is the following: once Jackrabbit source is checked out and built, time to test it using simple examples. But, where to put the example directory from the beginning. How to run it (maven java:compile....) ?\n\nA second point is the fact that there is no help forum on the Jackrabbit web site.\n\n A third point, taking my case as an example, the example would just not create a new workspace configuration.\nAnd many other troubleshoots - I repeat - basic but essential, that could avoid dozens of wasted hours and discouragment, if just mentioned on the website.\n\nHere it is my wish :-) for the best of Jackrabbit ;-) I hope!\nRegards,\nCelina",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": ""
    },
    {
        "key": "JCR-14",
        "summary": "{XML|Object}PersistenceManager.destroy(*) may fail",
        "description": "The destroy methods of the ObjectPersistenceManager class try to delete their files without checking for their existence. This may result in a FileSystemException being thrown because according to the specification of FileSystem.deleteFile() a FileSystemException is thrown \"if this path does not denote a file or if another error occurs.\"\n\nWhile the Jackrabbit LocalFileSystem implementation silently ignores a request to delete a non-existing file, our internal implementation of the interface throws a FileSystemException in this case, which cause destroy to fail.\n\nI suggest all destroy methods should be extended to first check for the existence of the file to prevent from being thrown.\n\nNote: This not only applies to ObjectPersistenceManager but also to XMLPersistenceManager.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1487",
        "summary": "Transient states should be persisted in depth-first traversal order",
        "description": "Inside Node.save(), when filling the list of transient (modified) items, the node itself is added first (if transient) and all transient descendant nodes in depth-first order. This can lead to the following problem with shareable nodes and path-based access management: \n\n1) assume a node N has a shared child S, which is shared with at least one other node N'\n2) S.removeShare is invoked: this removes S from the list of child nodes in N\n3) N.save is invoked\n\nN is persisted first, then S. If a path-based access manager tries to build the path of S after N has been persisted, S will no longer be returned in the list of removed child node entries, and an exception will be thrown. This can be circumvented by adding N last.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2218",
        "summary": "NodeEntryImpl.getWorkspaceId() very inefficient ",
        "description": "NodeEntryImpl.getWorkspaceId() calculates its path on each call by calling itself recursively. Further each call to getWorkspaceId() results in various calls to the path and item factories which might be somewhat expensive by themselves. \n\nIn my test scenario I have a RepositoryService.getItemInfos() call returning ~1000 items. Processing these items results in about 2700000 (!) calls to getWorkspaceId(). Profiler data shows, that 98% of the time to process the 1000 items is spent in getWorkspaceId()  and related calls. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1950",
        "summary": "Testing for indexable properties should check the default indexable properties first",
        "description": "org.apache.jackrabbit.core.query.lucene.NodeIndexer#addValue, uses the following condition for a PropertyType.NAME type of property:\n\nif (isIndexed(name)\n                    || name.equals(NameConstants.JCR_PRIMARYTYPE)\n                    || name.equals(NameConstants.JCR_MIXINTYPES)) {\n                addNameValue(doc, fieldName, value.getQName());\n}\n\nIt'd be more efficient to test the default properties first (which are on every node anyway) than to query the custom indexing rules every time. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-429",
        "summary": "Session scoped lock not always removed on Session.logout()",
        "description": "Consider the following use case:\n\n      Session s = repo.login(...);\n      Node root = s.getRootNode();\n      root.lock(true, true); // session-scoped, deep lock\n      // modifiy items\n      // root.isModified() still is true\n      s.logout();\n\nTo my understanding, the session scoped locks should be removed (unlocked) and unsaved should be dropped on logout of a session. Unfortunately currently this is not the case, as the lock implementation gets notified by the SessionImpl on the logout situation and just calls Node.unlock() on the lock's node for session scoped locks. This method fails as there are unsaved changes. Hence after logout, the lock on the session is still there and will only be gone when the repository is stopped.\n      ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1083",
        "summary": "SQL parser chokes on prefixes containing a \"-\" character",
        "description": "SQL parser chokes on prefixes containing a \"-\" character, such as in\n\n  SELECT a-b:c FROM nt:resource\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-272",
        "summary": "Removal of versions throws javax.jcr.ReferentialIntegrityException",
        "description": "From the following thread : http://www.mail-archive.com/jackrabbit-dev%40incubator.apache.org/msg03483.html\n\nWhen trying to remove a version of a Node  the VersionHistory.removeVersion() method throws : \"javax.jcr.ReferentialIntegrityException: Unable to remove version. At least once referenced.\".\n\nSecton 8.2.2.10 (Removal of Versions) of the specification indicates that the version graph should be automatically repaired upon removal. Then, VersionHistory.removeVersion() should take care of references. (In fact, a user cannot alter the references (jcr:predecessors and jcr:successors), since they are protected properties.)\n\nHere's the example (*updated) :\n\nNode root1 = session.getRootNode() ;\nNode test1 = root1.addNode(\"test\") ;\ntest1.addMixin(\"mix:versionable\");\ntest1.setProperty(\"test\", \"1\");\nsession.save();\ntest1.checkin();\n\ntest1.checkout();\ntest1.setProperty(\"test\", \"2\");\nsession.save();\ntest1.checkin();\n\ntest1.checkout();\ntest1.setProperty(\"test\", \"3\");\nsession.save();\ntest1.checkin();\n\nString baseVersion = test1.getBaseVersion().getName();\nSystem.out.println(\"Base version name: \" + baseVersion);\n\nVersionHistory vh = test1.getVersionHistory();\nfor (VersionIterator vi = vh.getAllVersions(); vi.hasNext(); ) {\n    Version currenVersion = vi.nextVersion();\n    String versionName = currenVersion.getName();\n    if (!versionName.equals(\"jcr:rootVersion\") && !versionName.equals(baseVersion)) { \n        String propertyValue = currenVersion.getNode(\"jcr:frozenNode\").getProperty(\"test\").getString();\n        System.out.println(\"Removing version : \" + versionName + \" with value: \" + propertyValue);\n        vh.removeVersion(versionName);\n    }\n}\n\nRegards, \n\nNicolas",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-333",
        "summary": "NodeTypeDef depends on supertype ordering",
        "description": "Currently the NodeTypeDef.setSupertypes() method simply sets the given QName array as the supertype QName array of the defined node type, thus preserving whatever ordering a node type parser or ultimately a node type definition file uses. This causes problems for example in the equals() method that uses the order-sensitive Arrays.equals() method to check for equality of the supertype QName arrays. The current implementation does therefore not consider the node type definitions \"A > B, C\" and \"A > C, B\" as equal even though they really should be so considered.\n\nThe same problem affects also child node and property definitions. The proper fix for this issue would probably be to use Sets to store and handle this information.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1885",
        "summary": "Make termInfosIndexDivisor configurable",
        "description": "Workspaces with large indexes may consume considerable heap memory. Lucene implements multi level skip lists for terms in the index. The first level of the skip list is kept in memory. This is usually not an issue, but when terms consist of long Strings the memory consumption increases drastically. Jackrabbit not just tokenizes string properties, but it also creates a single term, based on the complete string property value (needed for jcr:like function). These long terms are the reason for the increased memory consumption.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1404",
        "summary": "javadoc writing and generation with mvn",
        "description": "\"mvn -source 1.5 javadoc:javadoc\" does not work because following lines must be added to pom.xml\n<plugin>\n      <artifactId>maven-javadoc-plugin</artifactId>\n      <configuration>\n        <source>1.5</source>\n      </configuration>\n    </plugin> \nPlease also write more comprehensive javadocs to allow better source understanding and developer co-operation",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-803",
        "summary": "Improve performance of DescendantSelfAxisQuery",
        "description": "Instead of calculating the full result of the sub query, the DescendantSelfAxisQuery should make use of the skipTo() method on the sub scorer.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-587",
        "summary": "XMLTextFilter does not extract text elements",
        "description": "XMLTextFilter only returns the text from attributes, not the content of text elements,",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-100",
        "summary": "contrib/orm-persistence Node ordering not supported",
        "description": "Due to a limitation in the implementation, node ordering isn't supported (it is optional in the specification but Jackrabbit provides support for it) in the ORM persistence manager. This is due to the fact that in the database, although same-name sibling ordering is supported, no guarantee is given for the ordering of nodes in the child list.\n\nJackrabbit has some tests that use node ordering, such as the DerefQueryLevel1Test, where we look for the first property of type reference by using the following code :\n\n        Property refProp = PropertyUtil.searchProp(session, testRootNode, PropertyType.REFERENCE);\n\nThe searchProp method traverses the tree and stops at the first property of the type specified. If node ordering is not correct, we return a property that is not the expected one (in the case of the DerefTest we were returning a multi-values reference property), which can could test failures.",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-900",
        "summary": "Lucene queries are not properly rewritten",
        "description": "Some of the jackrabbit internal lucene queries are not properly rewritten and may lead to UnsupportedOperationException when terms are extracted from the lucene query.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3042",
        "summary": "jcr-commons: add cnd writer functionality",
        "description": "currently jcr-commons only provides an cnd-reader while the writer functionality is only present in spi-commons.\nfor JCR-2948 a implementation independent cnd-writer would be useful and i would therefore suggest to\nadd this to jcr-commons based on the code present in spi-commons and let the implementation in spi-commons\nextend from the general functionality.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1694",
        "summary": "System properties does not get replaced in a Cluster configuration",
        "description": "Since JCR-1304 has been added to jackrabbit 1.4 I guess this should be reported as a bug...\n\nStill not debugged deeply, but if I try to configure a Cluster using:\n<Cluster id=\"${server}\" syncDelay=\"10\">\n\nafter setting a \"server\" system property I expect to have the cluster initialized properly using the value of such property... I just realized that my cluster node gets initialized with the final value of \"${server}\" instead :(\n\nCluster config is a very good place where to use system properties, since all the configuration is usually identical between cluster nodes while the \"id\" property must be different...\n\nIs there anything I missed/did wrong in my configuration?\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1007",
        "summary": "Move common implementations of SPI interfaces to spi-commons module",
        "description": "Some of the spi modules use nearly duplicate code, which should be moved to the spi-commons module.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-375",
        "summary": "jcr:encoding not respected in NodeIndexer",
        "description": "The value of the jcr:encoding property is not passed to the TextFilter instances.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-170",
        "summary": "VirtualItemStates of node types definitions not accessible with uuid",
        "description": "The VirtualNodeTypeStateProvider that maps node type definitions into the workspace under /jcr:system/jcr:nodeTypes does not implement the methods:\n\n- internalGetNodeState(NodeId id)\n- internalHasNodeState(NodeId id)\n\nThis has the effect that ItemStates that reflect node type definitions are not accessible directly with their uuid.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1158",
        "summary": "jcr2spi spi2dav getProperties returns only cached properties",
        "description": "I'm using JCR through webdav (contrib jcr2spi and spi2dav libraries).\nServer is default jcr server (jackrabbit-webapp-1.3.1 on tomcat),\nclient is 2007/09/28 svn snapshot\n\nI've noticed that Node.getProperty returns only cached properties. \n\nSample test case can be found at http://kplab.tuke.sk/svn/kplab/ctm/trunk/test/org/kplab/tsf/CTMTest.java\n\nNote that sometimes properties do get printed, so it may not be so straightforwarding to reproduce this bug.\n\n\nSimple Example:\n\n// I have nt:file node at kplab/jojo in my repository\n...\nSession session = repository.login();\nNode root  = session.getRootNode();\nNode node = root.getNode(\"kplab/jojo\");\n// node.getProperty(\"jcr:content/jcr:data\"); // force to load property\nfrom server\ndump(node); // simple dump method from (\nhttp://jackrabbit.apache.org/doc/firststeps.html )\n\n\ndump prints:\n/kplab/jojo\n/kplab/jojo/jcr:content\n\nBut when I uncomment the getProperty line above, it prints:\n/kplab/jojo\n/kplab/jojo/jcr:content\n/kplab/jojo/jcr:content/jcr:lastModified = 2007-09-27T15:52:27.312+02:00\n/kplab/jojo/jcr:content/jcr:uuid = 4421ed5a-6200-4918-864e-c58643bc8d4e\n/kplab/jojo/jcr:content/jcr:mimeType = text/plain\n/kplab/jojo/jcr:content/jcr:data = hura hura\n/kplab/jojo/jcr:content/jcr:primaryType = nt:resource\n\n--\nJozef Wagner",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1016",
        "summary": "[PATCH] Allow RepositoryAccessServlet to get the Repository from a ServletContext attribute",
        "description": "The attached patch adds a repository.context.attribute.name init parameter to the RepositoryAccessServlet:\n\n        <init-param>\n          <param-name>repository.context.attribute.name</param-name>\n          <param-value>javax.jcr.Repository</param-value>\n          <description>\n            If this is set, the RepositoryAccessServlet expects a Repository in the ServletContext \n            attribute having this name. This allows servlets of this module to be used with repositories\n            intialized by the jackrabbit-jcr-servlet module utilities.\n          </description>\n        </init-param>",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3210",
        "summary": "NPE in spi2dav when server does not send all headers",
        "description": "The ValueLoader may throw a NPE if the desired headers are not present in the response:\n\norg.apache.jackrabbit.spi2davex.ValueLoader:\n\n    public Map<String, String> loadHeaders(String uri, String[] headerNames) throws IOException, RepositoryException {\n    ....\n                for (String name : headerNames) {\n--->                headers.put(name, method.getResponseHeader(name).getValue());\n                }\n    .....\n    }\n\nIn my case, the server does not return the ETag response header, but the 'loadHeaders' is indirectly called by the QValueFactoryImpl:\n\n                        this.preInitialize(new String[] {HEADER_ETAG, HEADER_LAST_MODIFIED});\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2222",
        "summary": "Unclosed files when aggregated property states are indexed",
        "description": "This is a regression caused by JCR-1990.\n\nThe lucene document for the node that contains the aggregated property may contain an extractor job that has an open file handle to the jcr:data binary property. The document must be disposed after the properties are transferred.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-575",
        "summary": "unicode escapes in files generated by JJTree",
        "description": "Maven build fails on windows machines if sources are located in a directory starting with a 'u'. This is because files created by JJTree (javacc) put filename and path in a comment of the generated files, like this:\n\n/*@bgen(jjtree) Generated By:JJTree: Do not edit this line. D:\\usr\\projects\\workspace\\jackrabbit\\target\\generated-src\\main\\org\\apache\\jackrabbit\\core\\query\\sql\\JCRSQL.jj */\n\nThe \\u in interpreted as an escape characted and so you get a \n\"BUILD FAILED ... Invalid escape character\"\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-1391",
        "summary": "[PATCH] remove minor unneeded code stutter",
        "description": "Code has a repeated method call on isOrderable for no reason as such\n\n{code}\npublic String getSupportedMethods() {\n        String ms = super.getSupportedMethods();\n        if (isOrderable()) {\n            StringBuffer sb = new StringBuffer(ms);\n            // Ordering\n            if (isOrderable()) {\n                sb.append(\", \").append(OrderingResource.METHODS);\n            }\n            return sb.toString();\n        } else {\n            return ms;\n        }\n    }\n{code}\n\npatch cleans this up.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2297",
        "summary": "Registering multiple node types with the same name in a single file must fail",
        "description": "Registering node types from a file (XML or CND) containing multiple definitions with the same name will succeed and only the last definition will be used.\nThe right behavior is to throw an exception as this kind of file is well-formed but invalid.",
        "label": "NUG",
        "classified": "SPEC",
        "type": "BUG"
    },
    {
        "key": "JCR-2037",
        "summary": "SPI2DAV: setup automated test execution",
        "description": "task copied from JCR-1877",
        "label": "NUG",
        "classified": "TEST",
        "type": "TASK"
    },
    {
        "key": "JCR-2645",
        "summary": "XML text extraction in Jackrabbit 1.x accesses external resources",
        "description": "As discussed on users@, we should add the following code to the ExtractorHandler class:\n\n   public InputSource resolveEntity(String publicId, String systemId) {\n       return new InputSource(new ByteArrayInputStream(new byte[0]));\n   }\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-668",
        "summary": "Allow pseudo properties in query relation",
        "description": "The XPath query parser does not allow using a function name as part of a relation in a query.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-807",
        "summary": "UUIDDocId should check IndexReader using equals()",
        "description": "The method UUIDDocId.getDocumentNumber(IndexReader) tests the passed index reader using its object identity.\n\nThis is a left over when there was one index per workspace and no system index. When the system index was introduced each query execution will create a new CombinedIndexReader covering the workspace index and the system index. The method should now use the equals() method to test the passed IndexReader.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2739",
        "summary": "RFC4918IfHeaderTest.testPutIfLockToken could fail with 412 Precondition Failed",
        "description": "In org.apache.jackrabbit.webdav.server.RFC4918IfHeaderTest:110 (webdav-test), \nthe lock request is initialized with a timeout of 1800 milliseconds, which is rounded as Timeout: Second-1 (at org.apache.jackrabbit.webdav.header.TimeoutHeader:46).\n\nThe assertion in the finally block MUST fail (412, Precondition Failed) if the lock has expired (cf. RFC 4918, Section 10.4.10).\n\nThe lock request should be initialized with a higher timeout, at least several seconds.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2829",
        "summary": "Offset not working correctly in user/group query when restricting to group members",
        "description": "For user/group queries having a scope *and* a  limit clause offsetting does not work correctly.\n\n    builder.setScope(\"contributors\", false);\n    builder.setLimit(100, 50);\n\nIn the above case, the result is often not offset at 100 but instead at some place >100.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1960",
        "summary": "Add support for the Ingres RDBMS",
        "description": "Hi Folks,\n    I've put together all the stuff I can figure out that is required to add support for using the Ingres RBMS. I'll upload a svn diff for what I've done. It is against the 1.5.2 version from the tags repository.\n\n    I was looking around but couldn't see if there was a way of running a test suite using Ingres as the DBMS provider. Is that possible with the current environment?\n\nCheers",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-2787",
        "summary": "IndexMerger: Synchronization issue on repository shutdown",
        "description": "After inserting a large number of nodes (~200000) into a repository and then closing the session, I get the following exception:\n\n19:42:40.556 [jackrabbit-pool-5] DEBUG o.a.j.core.query.lucene.IndexMerger - # of busy merge workers: 2\n19:42:40.556 [jackrabbit-pool-3] DEBUG o.a.j.core.query.lucene.IndexMerger - accepted merge request\n19:42:40.556 [jackrabbit-pool-5] DEBUG o.a.j.core.query.lucene.IndexMerger - Worker finished\n19:42:40.556 [jackrabbit-pool-3] DEBUG o.a.j.core.query.lucene.IndexMerger - create new index\n19:42:40.557 [jackrabbit-pool-3] DEBUG o.a.j.core.query.lucene.IndexMerger - get index readers from MultiIndex\n19:42:40.640 [main] INFO  c.a.kmp.generator.JpaToJcrImporter - end JCR save\n19:42:40.849 [main] INFO  o.a.j.core.TransientRepository - Session closed\n19:42:40.849 [main] INFO  o.a.jackrabbit.core.RepositoryImpl - Shutting down repository...\n19:42:40.849 [main] DEBUG o.a.j.core.query.lucene.IndexMerger - dispose IndexMerger\n19:42:40.849 [main] DEBUG o.a.j.core.query.lucene.IndexMerger - quit flag set\n19:42:40.849 [main] INFO  o.a.j.core.query.lucene.SearchIndex - Index closed: repository/repository/index\n19:42:40.850 [main] INFO  o.a.jackrabbit.core.RepositoryImpl - shutting down workspace 'default'...\n19:42:40.850 [main] INFO  o.a.j.c.o.ObservationDispatcher - Notification of EventListeners stopped.\n19:42:40.850 [main] DEBUG o.a.j.core.query.lucene.IndexMerger - dispose IndexMerger\n19:42:40.850 [main] DEBUG o.a.j.core.query.lucene.IndexMerger - quit flag set\n19:42:40.850 [main] DEBUG o.a.j.core.query.lucene.IndexMerger - IndexMerger.Worker thread stopped\n19:42:40.855 [main] DEBUG o.a.j.core.query.lucene.IndexMerger - index added: name=_6h, numDocs=890\n19:42:41.367 [jackrabbit-pool-3] DEBUG o.a.j.core.query.lucene.IndexMerger - deleting index _6g\n19:42:41.393 [main] INFO  o.a.j.core.query.lucene.SearchIndex - Index closed: repository/workspaces/default/index\n19:42:41.410 [jackrabbit-pool-3] ERROR o.a.j.core.query.lucene.IndexMerger - Error while merging indexes: \norg.apache.lucene.store.AlreadyClosedException: this IndexWriter is closed\n\tat org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:412) ~[lucene-core-2.4.1.jar:2.4.1 750176 - 2009-03-04 21:56:52]\n\tat org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:417) ~[lucene-core-2.4.1.jar:2.4.1 750176 - 2009-03-04 21:56:52]\n\tat org.apache.lucene.index.IndexWriter.startTransaction(IndexWriter.java:2511) ~[lucene-core-2.4.1.jar:2.4.1 750176 - 2009-03-04 21:56:52]\n\tat org.apache.lucene.index.IndexWriter.addIndexes(IndexWriter.java:3273) ~[lucene-core-2.4.1.jar:2.4.1 750176 - 2009-03-04 21:56:52]\n\tat org.apache.jackrabbit.core.query.lucene.PersistentIndex.addIndexes(PersistentIndex.java:114) ~[jackrabbit-core-2.1.1.jar:2.1.1]\n\tat org.apache.jackrabbit.core.query.lucene.IndexMerger$Worker.run(IndexMerger.java:525) ~[jackrabbit-core-2.1.1.jar:2.1.1]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) [na:1.6.0_20]\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) [na:1.6.0_20]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138) [na:1.6.0_20]\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98) [na:1.6.0_20]\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:207) [na:1.6.0_20]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) [na:1.6.0_20]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) [na:1.6.0_20]\n\tat java.lang.Thread.run(Thread.java:619) [na:1.6.0_20]\n19:42:41.420 [jackrabbit-pool-3] DEBUG o.a.j.core.query.lucene.IndexMerger - Worker finished\n19:42:41.839 [main] INFO  o.a.j.c.p.b.DerbyPersistenceManager - Database 'repository/workspaces/default/db' shutdown.\n\n\nThe problem is reproducible. Apparently, the Lucene index is closed before all IndexMerger worker threads are terminated. The root cause seems to be the AtomicBoolean IndexMerger.Worker.terminated which is always true. The enclosed patch solves the problem in my use case.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-505",
        "summary": "TCK: AbstractJCRTest fails if setUp/tearDown cannot remove children of test node",
        "description": "If the test node exists, the setUp and tearDown methods remove all its child nodes.  In some repositories these child nodes may be mandatory or protected, causing test setup/teardown to fail.\n\nProposal: tolerate exceptions thrown in removing a child node in test setup/teardown.\n\n--- ../AbstractJCRTest.java     (revision 422074)\n+++ ../AbstractJCRTest.java     (working copy)\n@@ -344,7 +344,11 @@\n                 // clean test root\n                 testRootNode = root.getNode(testPath);\n                 for (NodeIterator children = testRootNode.getNodes(); children.hasNext();) {\n-                    children.nextNode().remove();\n+                    try {\n+                      children.nextNode().remove();\n+                    } catch (RepositoryException e) {\n+                      // consume\n+                    }\n                 }\n             } else {\n                 // create nodes to testPath\n@@ -375,7 +379,11 @@\n                         // clean test root\n                         testRootNode = root.getNode(testPath);\n                         for (NodeIterator children = testRootNode.getNodes(); children.hasNext();) {\n-                            children.nextNode().remove();\n+                            try {\n+                              children.nextNode().remove();\n+                            } catch (RepositoryException e) {\n+                              // consume\n+                            }\n                         }\n                         root.save();\n                     }\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-583",
        "summary": "TCK: NodeReadMethodsTest.testGetName fails with NPE if  'testroot' has no child node",
        "description": "The 'testGetName' does not assert, that  the childnode field has been populated during setup.\nif  for whatever reason  the test data don't provide a single childnode below the test root, this test will fail with nullpointer\nexception.\n\ni would like to suggest to use the same assertion as in testGetPath and throw a NotExecutableException in case of\nmissing child node.\n\npatch attached.\n\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-2643",
        "summary": "Avoid item state reads during Session.logout()",
        "description": "This is a follow up issue for JCR-2231. There's a second CachingHierarchyManager attached to the LocalItemStateManager, which it unregistered too late and causes reads on the SharedItemStateManager on Session logout. The hierarchy manager should be unregistered as listener before the state manager is disposed.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-887",
        "summary": "DateField class should be public",
        "description": "The class org.apache.jackrabbit.core.query.lucene.DateField should be made public.  It has several public methods which are useful but are currently not accessible because the class itself is not accessible outside of its package.  All of the other Field classes in that package are public and accessible (LongField, DoubleField, etc.)",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-865",
        "summary": "JCR mapping: Upgrade to Maven 2",
        "description": "Upgrade the JCR Mapping components to Maven 2 before a release.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "BUG"
    },
    {
        "key": "JCR-1813",
        "summary": "Invalid journal records during XATransactions",
        "description": "During the prepare phase of a XATransaction, XAItemStateManager.prepare calls ShareItemStageManager.beginUpdate that, in case of a ClusterNode, calls ClusterNode.updatePrepared that does a ChangeLogRecord.write().\n\nThis last method is located in ClusterRecord and systematically write the begin and the end of the journal record.\n\nAs a consequence, useless corrupted records are written in the journal everytime a transaction ends without jackrabbit update! This causes polution of the journal, as other cluster nodes try to sync with the corrupted updates and fail doing so as ClusterRecordDeserializer can't deserialize it (the record identifier is empty).\n\nChangeLogRecord (and even other ClusterRecord implementations too) should only write if there's effective updates.\n\nI propose the following solution:\n*) add the following method in Changelog so clients can know if there's effective updates:\n    public boolean hasUpdates() {\n    \treturn !(addedStates.isEmpty() && modifiedStates.isEmpty() && deletedStates.isEmpty() && modifiedRefs.isEmpty());\n    }\n\n*) change ClusterRecord with:\n    public final void write() throws JournalException {\n    \t\n    \tif (hasUpdates()) {\n\t        record.writeString(workspace);\n\t        doWrite();\n\t        record.writeChar(END_MARKER);\n    \t}\n    }\n    \n    protected abstract boolean hasUpdates();\n\n*) implement hasUpdates for every ClusterRecord implementation:\n ----> ChangeLogRecord:\n    protected boolean hasUpdates() {\n    \treturn changes.hasUpdates() || !events.isEmpty();\n    }\n ----> LockRecord and NamespaceRecord:\n    protected boolean hasUpdates() {\n    \treturn true;\n    }\n\n ----> NodeTypeRecord:\n    protected boolean hasUpdates() {\n    \treturn !collection.isEmpty();\n    }\n\nBest regards,\n\nStephane Landelle",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2209",
        "summary": "Versioning operations should be done on the workspace",
        "description": "currently all versioning operations modify the transient states of the items where the operation is executed although all operations are workspace operations.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1974",
        "summary": "JSR 283: Evaluate Capabilities ",
        "description": "Exposed by Session.hasCapability",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-2869",
        "summary": "AccessControlManager#setPolicy may fail for new applicable policy despite jcr:modifyAccessControl privilege being granted",
        "description": "the sequence AccessControlManager.getApplicablePolicies -> modify -> AccessControlManager#setPolicy fails\ndue to bug in AC evaluation if target is an AC-item but not yet existing. in this case the\nwrong parent node is used for AC-evaluation.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-718",
        "summary": "NoSuchItemStateException on removing node (no versioning)",
        "description": "I'm using jackrabbit 1.2.1\nwith no versioning\nwith a very simple SimpleAccessManager (this try to compute the path of the passed ItemId and verify permissions over that path)\n\nwhen I remove a node (nt:file or nt:folder),  calling session.save() I obtains the exception reported below.\n\nis it really a bug or am i wrong?\nthanks\n\nthe following is the code I'm using to build the path\n----------------------------------------- CODE START\npublic String getStringPath(ItemId id) throws ItemNotFoundException, RepositoryException, NoPrefixDeclaredException\n\t{\n\t\tString p = \"\";\n\t\tNamespaceResolver nsResolver = ((HierarchyManagerImpl) hierMgr).getNamespaceResolver();\n\t\tPath path = hierMgr.getPath(id);\n\t\tPathElement[] pe = path.getElements();\n\t\tfor (int i = 0; i < pe.length; i++)\n\t\t{\n\t\t\tif (pe[i].denotesName())\n\t\t\t\tp += \"/\" + pe[i].toJCRName(nsResolver);\n\t\t}\n\t\treturn p;\n\t}\n----------------------------------------- CODE END\n\n\n----------------------------------------- START\njavax.jcr.ItemNotFoundException: failed to build path of d688e92f-26ae-4f7c-aba7-aaff1df62c2c: d688e92f-26ae-4f7c-aba7-aaff1df62c2c: d688e92f-26ae-4f7c-aba7-aaff1df62c2c\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getPath(HierarchyManagerImpl.java:362)\n\tat org.apache.jackrabbit.core.CachingHierarchyManager.getPath(CachingHierarchyManager.java:224)\n\tat it.unict.faq.jackrabbit.SimpleAccessManager.getStringPath(SimpleAccessManager.java:238)\n\tat it.unict.faq.jackrabbit.SimpleAccessManager.controllo(SimpleAccessManager.java:215)\n\tat it.unict.faq.jackrabbit.SimpleAccessManager.isGranted(SimpleAccessManager.java:183)\n\tat org.apache.jackrabbit.core.ItemImpl.validateTransientItems(ItemImpl.java:645)\n\tat org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1162)\n\tat org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:821)\n\tat it.unict.faq.driver.manager.impl.DAO.JcrDAO.CancellaNodo(JcrDAO.java:638)\n\tat it.unict.faq.driver.manager.impl.DocumentServerManager.ds_del(DocumentServerManager.java:58)\n\tat elearn.portal.action.ds_del_portal.execute(ds_del_portal.java:28)\n\tat org.apache.struts.action.RequestProcessor.processActionPerform(RequestProcessor.java:421)\n\tat org.apache.struts.action.RequestProcessor.process(RequestProcessor.java:226)\n\tat org.apache.struts.action.ActionServlet.process(ActionServlet.java:1158)\n\tat org.apache.struts.action.ActionServlet.doPost(ActionServlet.java:415)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:709)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:252)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:264)\n\tat org.acegisecurity.intercept.web.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:107)\n\tat org.acegisecurity.intercept.web.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:72)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.ui.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:110)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.providers.anonymous.AnonymousProcessingFilter.doFilter(AnonymousProcessingFilter.java:125)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.ui.rememberme.RememberMeProcessingFilter.doFilter(RememberMeProcessingFilter.java:142)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.wrapper.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:81)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.ui.AbstractProcessingFilter.doFilter(AbstractProcessingFilter.java:217)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.ui.logout.LogoutFilter.doFilter(LogoutFilter.java:108)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.context.HttpSessionContextIntegrationFilter.doFilter(HttpSessionContextIntegrationFilter.java:193)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.util.FilterChainProxy.doFilter(FilterChainProxy.java:148)\n\tat org.acegisecurity.util.FilterToBeanProxy.doFilter(FilterToBeanProxy.java:98)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:213)\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:178)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:126)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:105)\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:107)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:148)\n\tat org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:869)\n\tat org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:664)\n\tat org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:527)\n\tat org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:80)\n\tat org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:684)\n\tat java.lang.Thread.run(Thread.java:595)\nCaused by: org.apache.jackrabbit.core.state.NoSuchItemStateException: d688e92f-26ae-4f7c-aba7-aaff1df62c2c\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.getTransientItemState(SessionItemStateManager.java:323)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:154)\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getItemState(HierarchyManagerImpl.java:120)\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getPath(HierarchyManagerImpl.java:357)\n\t... 52 more\norg.apache.jackrabbit.core.state.NoSuchItemStateException: d688e92f-26ae-4f7c-aba7-aaff1df62c2c\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.getTransientItemState(SessionItemStateManager.java:323)\n\tat org.apache.jackrabbit.core.state.SessionItemStateManager.getItemState(SessionItemStateManager.java:154)\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getItemState(HierarchyManagerImpl.java:120)\n\tat org.apache.jackrabbit.core.HierarchyManagerImpl.getPath(HierarchyManagerImpl.java:357)\n\tat org.apache.jackrabbit.core.CachingHierarchyManager.getPath(CachingHierarchyManager.java:224)\n\tat it.unict.faq.jackrabbit.SimpleAccessManager.getStringPath(SimpleAccessManager.java:238)\n\tat it.unict.faq.jackrabbit.SimpleAccessManager.controllo(SimpleAccessManager.java:215)\n\tat it.unict.faq.jackrabbit.SimpleAccessManager.isGranted(SimpleAccessManager.java:183)\n\tat org.apache.jackrabbit.core.ItemImpl.validateTransientItems(ItemImpl.java:645)\n\tat org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1162)\n\tat org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:821)\n\tat it.unict.faq.driver.manager.impl.DAO.JcrDAO.CancellaNodo(JcrDAO.java:638)\n\tat it.unict.faq.driver.manager.impl.DocumentServerManager.ds_del(DocumentServerManager.java:58)\n\tat elearn.portal.action.ds_del_portal.execute(ds_del_portal.java:28)\n\tat org.apache.struts.action.RequestProcessor.processActionPerform(RequestProcessor.java:421)\n\tat org.apache.struts.action.RequestProcessor.process(RequestProcessor.java:226)\n\tat org.apache.struts.action.ActionServlet.process(ActionServlet.java:1158)\n\tat org.apache.struts.action.ActionServlet.doPost(ActionServlet.java:415)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:709)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:252)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:264)\n\tat org.acegisecurity.intercept.web.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:107)\n\tat org.acegisecurity.intercept.web.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:72)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.ui.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:110)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.providers.anonymous.AnonymousProcessingFilter.doFilter(AnonymousProcessingFilter.java:125)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.ui.rememberme.RememberMeProcessingFilter.doFilter(RememberMeProcessingFilter.java:142)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.wrapper.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:81)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.ui.AbstractProcessingFilter.doFilter(AbstractProcessingFilter.java:217)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.ui.logout.LogoutFilter.doFilter(LogoutFilter.java:108)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.context.HttpSessionContextIntegrationFilter.doFilter(HttpSessionContextIntegrationFilter.java:193)\n\tat org.acegisecurity.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:274)\n\tat org.acegisecurity.util.FilterChainProxy.doFilter(FilterChainProxy.java:148)\n\tat org.acegisecurity.util.FilterToBeanProxy.doFilter(FilterToBeanProxy.java:98)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:213)\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:178)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:126)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:105)\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:107)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:148)\n\tat org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:869)\n\tat org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:664)\n\tat org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:527)\n\tat org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:80)\n\tat org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:684)\n\tat java.lang.Thread.run(Thread.java:595)\n----------------------------------------- END",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1282",
        "summary": "Publish the jackrabbit-ocm DTD",
        "description": "The jackrabbit-ocm DTD from jackrabbit-ocm/src/dtd should be made available for reference on the Jackrabbit web site.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2586",
        "summary": "Missing synchronization in InternalVersionHistoryImpl",
        "description": "The InternalVersionHistoryImpl objects can be accessed (and modified) concurrently by multiple sessions, which can in some rare cases result in corruption in the internal cache map data structures. Access to these cache maps should be properly synchronized.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1072",
        "summary": "SPI-commons:  QValueTest.testDateValueEquality2 fails due to changes made with JCR-1018",
        "description": "with the introduction of QValue.getCalendar() the internal value for DATE-properties is now a Calendar (was\nString). however, the equals() method has not been adjusted.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-723",
        "summary": "OpenDocument files missing in mimetypes.properties",
        "description": "The mime-types from Oasis OpenDocument are missing from mimetypes.properties file. ",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2667",
        "summary": "NodeReferences are lost when deleting and setting the same reference in the same save() cycle",
        "description": "I've written the following snippet to illustrate the issue :\n\n        Node root = session.getRootNode();\n        \n        Node a = root.addNode(\"a\");\n        Node b = root.addNode(\"b\");\n        b.addMixin(\"mix:referenceable\");\n        \n        a.setProperty(\"p\", b);\n        \n        root.save();\n        \n        System.out.println(b.getReferences().getSize());     // --> correctly returns 1\n        \n        a.setProperty(\"p\", (Node) null);\n        a.setProperty(\"p\", b);\n        \n        root.save();\n        \n        System.out.println(b.getReferences().getSize());    // --> returns 0 !\n\nWhen the ChangeLog is processed, added references are processed before deleted ones, so the persisted NodeReferences is finally wrong.\n\nI've set the priority of this issue to critical, because the persisted references count is corrupted.\n\nA simple workaround is to first remove the property, then save, then add the property again, but it not satisfying.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2593",
        "summary": "Upgrade to Tika 0.7",
        "description": "Apache Tika 0.7 is now available. It's probably too late for the 2.1 release, but I'll upgrade the dependency in the trunk for Jackrabbit 2.2.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-211",
        "summary": "jcr ext doesn't compile with jdk 1.4",
        "description": "IllegalStateException(String str, Exception e) isn't supported.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-1482",
        "summary": "Jackrabbit web page scroll is slow with Firefox",
        "description": "When I visit http://jackrabbit.apache.org/ from my Firefox in Ubuntu  the browser scroll is very slow and make CPU go to 100%. \n\nThe problem seems to be the \"fixed\" attribute in the css background definition, so it should be removed.\n\nbody {\n  background:white url(bg.png) repeat-x fixed center bottom;\n  font-family:Verdana,Helvetica,Arial,sans-serif;\n  font-size:small;\n  margin:0pt;\n  padding:0pt;\n}",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": ""
    },
    {
        "key": "JCR-345",
        "summary": "Jcr-Server: DavException doesn't allow to specify an exception cause",
        "description": "While DavException extends Exception it does not allow to specify a exception cause in the constructor.\nAdding a separate constructor taking status code plus a Throwable would provide the possibility to specify the original cause.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-102",
        "summary": "how-to deployment models",
        "description": "how-to with a detailed description of the steps required for each deployment model. ",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-463",
        "summary": "Uncommitted changes or connection leak with Container Managed Transactions",
        "description": "Apparently the connector doesn't support CMT (container managed transactions). if the jcr session is closed inside a CMT the AS (application server) throws an exception on commit. And if the jcr session is leaved open, the AS commits the TX successfully but it causes a connection leak by leaving the session open.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1589",
        "summary": "JSR 283: Retention & Hold Management",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-45",
        "summary": "Version.getReferences() does not work correctly",
        "description": "since the /jcr:system/jcr:versionStorage is shared among all workspaces, referes of versions and version histories need to be workspace sensitive. for example can a workspace W1 contain a versionable node N1. Its respective version history VH is visible in the jcr:versionStorage. calling VH.getReferences() should return the jcr:versionHistory property of that node N1. If accessing the repository using another workspace, W2, which does not have the node N2 (that corresponds to N1), calling VH.getReferences() should return an empty set. The same is true for version nodes referenced by jcr:baseVersion and jcr:predecessors properties.\n\n\nsee also spec chapter 8.2.2.1 (jcr:versionStorage):\nThe full set of version histories in the version storage, though stored in a single location in the repository, must be reflected in each workspace as a subtree below the node /jcr:system/jcr:versionStorage. \n[...]",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-200",
        "summary": "move log4j initialization out of RepositoryStartupServlet",
        "description": "the RepositoryStartupServlet initializes/configures the Log4J environment. this might not be desirable since other applications might already done so.\n\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1236",
        "summary": "New Jackrabbit site skin",
        "description": "Some time ago Michael Eppelheimer from Day created a new skin for the Jackrabbit web site, and I've now streamlined it a bit and integrated it with the Maven site build mechanism.\n\nThe templates should be easy to adapt also for Confluence when we get around to that migration.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-490",
        "summary": "TCK: ExportDocViewTest.exportValues fails on empty multivalued property",
        "description": "In ExportDocViewTest.exportValues, line 988 fails if the property being exported is empty (array of size 0, which is allowed by the spec) since there is no space to remove. This code should be skipped if the number of values is zero.",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-259",
        "summary": "XPath query with negative numbers incorrect",
        "description": "A XPath query that contains a negative number does not return correct results.\n\nE.g. the query:\n\n//*[@number = -10]\n\ndoes not return nodes with number properties containing a value of -10 but will return nodes with number values equal to 10. Similarly the query returns wrong results for double values.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1736",
        "summary": "Expose BootstrapConfig in Servlets",
        "description": "the RepostitoryStartup and RepositroyAccess servlets use a bootstrap config object for initialization. in order to generate diagnostics reports it would be very useful to be able to access them.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1376",
        "summary": "SearchIndex parameter cacheSize is ignored",
        "description": "The cacheSize is always set to 1024 no matter what is specified in the configuration.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2084",
        "summary": "DataStore: garbage collection fails if a workspace is not initialized",
        "description": "The test case GCEventListenerTest fails with the following exception:\n\ntestEventListener(org.apache.jackrabbit.core.data.GCEventListenerTest)  Time elapsed: 10.235 sec  <<< ERROR!\njava.lang.IllegalStateException: workspace 'test' not initialized\n\tat org.apache.jackrabbit.core.RepositoryImpl$WorkspaceInfo.getPersistenceManager(RepositoryImpl.java:1703)\n\tat org.apache.jackrabbit.core.SessionImpl.createDataStoreGarbageCollector(SessionImpl.java:694)\n\tat org.apache.jackrabbit.core.data.GCEventListenerTest.doTestEventListener(GCEventListenerTest.java:75)\n\tat org.apache.jackrabbit.core.data.GCEventListenerTest.testEventListener(GCEventListenerTest.java:49)\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3146",
        "summary": "Text extraction may congest thread pool in the repository",
        "description": "Text extraction congests the thread pool in the repository when e.g. many PDFs are loaded into the workspace. Tasks submitted by the index merger are delayed because of that and will result in many index segment folders.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1886",
        "summary": "jcr2spi: Unprocessed ItemInfos call to RepositoryService#getItemInfos",
        "description": "stefan reported the following problem:\n\n- batchread config reads with depths infinity\n- invalidate tree by calling Node.refresh(false)\n- force loading of the tree (e.g. Node.getPath())\n\nafterwards, there may still be invalidated item states indicating that not all ItemInfos were processed.\nconsequently, there are additional calls to getItemInfos that should have been covered by the loading of the tree.\nthe problem occuring is not related to limitation of the item-cache size.\n\nproblem analysis:\n\nthere is a bug in WorkspaceItemStateFactory#createItemStates.\nthere is a wrapper built around the ItemInfo-Iterator but later on the ItemInfo-Iterator is used instead of the wrapper, which pre-fetches items from the underlying iterator and process them upon hasNext()/next().",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2508",
        "summary": "JsonWriter: missing handling of new JCR 2.0 property types",
        "description": "the json writer sends extra type information in case it cannot be determined unambiguously from the json string.\nthis needs to be adjusted for the new property types added for JCR 2.0",
        "label": "NUG",
        "classified": "RFE",
        "type": "BUG"
    },
    {
        "key": "JCR-1593",
        "summary": "JSR 283: Simple versioning",
        "description": "",
        "label": "NUG",
        "classified": "RFE",
        "type": ""
    },
    {
        "key": "JCR-1415",
        "summary": "Clustering configuration documentation for syncDelay doesn't match",
        "description": "There is a bit of mismatch in the current documentation that is available on configuring a Cluster node for a repository.  If you look at the DTD for repository.xml[1] it states that the syncDelay attribute of the Cluster element is in seconds.  However if you read the Javadoc for the ClusterConfig[2] object it states the syncDelay is in milliseconds.  I'm guessing that the value is actually in milliseconds but at the very least the two documents should be telling the same story.\n\n\n[1] -http://jackrabbit.apache.org/dtd/repository-1.4.dtd\n[2] - http://jackrabbit.apache.org/api/1.4/org/apache/jackrabbit/core/config/ClusterConfig.html",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-845",
        "summary": "Links Pointing to Javadocs Are Incorrect and Return 404",
        "description": "There are various links on the \"Configuring Jackrabbit\"  page (http://jackrabbit.apache.org/doc/config.html) that are invalid.  For example, I wanted to read the \"PersistenceManager javadocs\" link, but it returns a 404.  This will decrease the confidence in the project and hinder its adoption.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "JCR-2656",
        "summary": "Embedded Derby fails under JBoss because of JMX-related conflicts",
        "description": "JBoss fails to start due to a bug in Derby-10.4.2.0. The dependency should be agains derby-10.4.2.1 which seems to has this bug fixed. More info at https://issues.apache.org/jira/browse/DERBY-3887\n\nPlease, include this fix in the upcoming 1.6.3",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-139",
        "summary": "Query for name literal without namespace fails",
        "description": "Query for a name literal without a namespace fails. \n\nExample:\n//*[@foo = 'bla']\n\nshould return nodes with foo property that contain the String value 'bla' or the Name value 'bla' (no namespace). Only nodes with String value 'bla' are returned.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-370",
        "summary": "SearchIndex class contains garbled String",
        "description": "Somehow during the switch to SL4J also a String literal in the SearchIndex class got garbled.\n\nSee:\nhttp://svn.apache.org/viewcvs.cgi/incubator/jackrabbit/trunk/jackrabbit/src/main/java/org/apache/jackrabbit/core/query/lucene/SearchIndex.java?rev=385280&r1=378221&r2=385280\n\nSince this is a low risk change I would like to get this included into the 1.0 branch.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-131",
        "summary": "Remove old hooks for the implementation of hard links",
        "description": "Early drafts of the JCR specification specified that repositories should support \"hard links\", which woud lead to the situation, that items might have multiple parent nodes. In the meantime hard links have been removed from the spec and are unlikely to be re-added in future revisions.\n\nNevertheless, Jackrabbit still contains some references to supporting this mechanism (e.g. the NodeState.parentUUIDs field), which should be removed.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1397",
        "summary": "Allow query results with unknown size",
        "description": "To further optimize certain queries the query implementation should be changed to allow for unknown result sizes. Currently there is only one query ( //* ) where the query result returns an unknown size and a special query result implementation is returned. At the same time, this should be fixed that only one implementation is used.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-602",
        "summary": "importXML still depends on Xerces",
        "description": "Przemo Pakulski commented on JCR-367:\n> Jackrabbit-core is still dependent on Xerces directly during runtime, SessionImpl.importWorkspace,\n> Workspacempl.importWorkspace methods contains folliwng lines :\n>\n>             XMLReader parser =\n>                     XMLReaderFactory.createXMLReader(\"org.apache.xerces.parsers.SAXParser\");\n>\n> It works in maven1 probably because maven1 itself needs xerces to run test goal.\n>\n> I suggest reopening the issue.\n\nCreating a new issue since JCR-367 is already closed after the 1.1 release.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "JCR-243",
        "summary": "expose shutdown method in o.a.j.jndi.BindableRepository",
        "description": "see http://thread.gmane.org/gmane.comp.apache.jackrabbit.devel/3680\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-221",
        "summary": "NoSuchItemStateException if Node.checkin() is invoked within a transaction",
        "description": "When you run a code that takes versionning outside transactions - everything goes ok. But when you run it inside transaction, it fails:\nHere's the stacktrace:\n\n15:41:14,434 ERROR (TransactionalItemStateManager.java:114) -\njava.lang.Exception: Cannot commit transaction.\n[...]\nCaused by: org.apache.jackrabbit.core.state.TransactionException: Unable\nto commit transaction.:\n31f78b39-6422-4ec8-b41e-2571b6807b05/{http://www.jcp.org/jcr/1.0}isCheckedOut\n[...]\nCaused by: org.apache.jackrabbit.core.state.NoSuchItemStateException:\n31f78b39-6422-4ec8-b41e-2571b6807b05/{http://www.jcp.org/jcr/1.0}isCheckedOut\n[...]\n\nWhen you dont checkin the node transaction commits well, but the node is left checked out...",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2432",
        "summary": "Escape colon in statement of jcr:contains",
        "description": "The colon is a special character in the lucene query parser and allows to prefix query terms with an optional field name. JCR does not specify such a feature, thus a colon in the fulltext statement should be treated as a regular character. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1716",
        "summary": "Prefer PathFactory.createElement() over createPath().getNameElement()",
        "description": "The latter creates an unnecessary Path instance.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-3051",
        "summary": "AbstractLockTest.testLockExpiration fails intermittently ",
        "description": "This seems to be a timing issue. I propose to wait a bit longer for the lock to expire. ",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1615",
        "summary": "WebDAV: drop dependency on commons-collections",
        "description": "the webdav library brings in a dependency on commons-collections solely for one reference to LinkedMap. Since none of the additional features of this class are used, and as I understand it Jackrabbit requires JDK 1.4+, this can be replaced with LinkedHashMap.\n\njcr-commons still brings in the commons-collections dependency, but I believe it can be safely excluded by users that don't need to use the predicates (Which is true of the webdav client)",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2943",
        "summary": "UserManagement: membership cache default size too small",
        "description": "The membership cache that has been introduced in JCR-2703 is making use of an LRUMap to cache group memberships (authorizable nodeId -> group nodeIds). In environments where users belong to more than 100 groups, the cache quickly becomes ineffective due to the default maximum size of the LRUMap.\n\nOnce the cache limit is hit, the rather expensive Node#getWeakReferences API calls resulting in search queries are executed again, leading to quite noticeable performance drops. Thus I'd suggest to either make the membership cache configurable or introduce some logic to let the cache grow dynamically as needed (still having some kind of hard limit to avoid memory issues).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-761",
        "summary": "JCA build failure with J2EE 1.3",
        "description": "The fix to JCR-736 introduced a similar problem as was previously reported in JCR-413. The fix in JCR-413 should apply also to this case.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-3029",
        "summary": "JcrRemotingServlet should interpolate system properties in the home init-param",
        "description": "For deployment scenarios where the same Jackrabbit WAR file is deployed multiple times on the same server with the same current working directory, it is useful to have the home init-param support system property interpolation.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1530",
        "summary": "MsPowerPointTextExtractor does not extract from PPTs with \u20ac sign",
        "description": "The MsPowerPointTextExtractor class has a problem when reading PPTs when an \u20ac sign is contained. All text following that sign is ignored. Perhaps the POI PowerPointExtractor should be used instead of parsing the data by hand. As a side effect, this would simply the code. Extracting could be done as follows:\n\n\tpublic Reader extractText(InputStream stream, String type, String encoding) throws IOException {\n\t\ttry {\n\t\t\tPowerPointExtractor extractor = new PowerPointExtractor(stream);\n\t\t\treturn new StringReader(extractor.getText(true,true));\n\t\t} catch (RuntimeException e) {\n\t\t\tlogger.warn(\"Failed to extract PowerPoint text content\", e);\n\t\t\treturn new StringReader(\"\");\n\t\t} finally {\n\t\t\ttry { stream.close(); } catch (IOException ignored) {}\n\t\t}\n\t}\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1036",
        "summary": "JCR2SPI; setProperty(name, date-string) fails when property is added and property type is PropertyType.DATE.",
        "description": "Example code:\n\n        Node l_parent = (Node)session.getItem(this.m_path);\n        \n        Node l_test = l_parent.addNode(\"createcontenttest\", \"nt:file\");\n        Node l_content = l_test.addNode(\"jcr:content\", \"nt:resource\");\n        \n        l_content.setProperty(\"jcr:encoding\", \"UTF-8\");\n        l_content.setProperty(\"jcr:mimeType\", \"text/plain\");\n        l_content.setProperty(\"jcr:data\", new ByteArrayInputStream(\"foobar\".getBytes()));\n        l_content.setProperty(\"jcr:lastModified\", \"2007-07-25T17:04:00.000Z\"); // TODO: this should work as well, bug in JCR2SPI?\n        session.save();\n\nThis will fail when the property is defined as DATE, what should happen is that a value comparison is attempted (note that it works when the property already exists and just is overwritten).\n\nThe exception is:\n\njavax.jcr.nodetype.ConstraintViolationException: no matching property definition found for {http://www.jcp.org/jcr/1.0}lastModified\n        at org.apache.jackrabbit.jcr2spi.nodetype.ItemDefinitionProviderImpl.getQPropertyDefinition(ItemDefinitionProviderImpl.java:269)\n        at org.apache.jackrabbit.jcr2spi.nodetype.ItemDefinitionProviderImpl.getQPropertyDefinition(ItemDefinitionProviderImpl.java:159)\n        at org.apache.jackrabbit.jcr2spi.NodeImpl.getApplicablePropertyDefinition(NodeImpl.java:1672)\n        at org.apache.jackrabbit.jcr2spi.NodeImpl.createProperty(NodeImpl.java:1369)\n        at org.apache.jackrabbit.jcr2spi.NodeImpl.setProperty(NodeImpl.java:264)\n        at org.apache.jackrabbit.jcr2spi.NodeImpl.setProperty(NodeImpl.java:345)\n        at org.apache.jackrabbit.jcr2spi.NodeImpl.setProperty(NodeImpl.java:336)\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2715",
        "summary": "Improved join query performance",
        "description": "Our current implementation of SQL2 join queries does not perform very well on pretty much any non-trivial data set.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-2953",
        "summary": "PathParser accepts illegal paths containing curly brackets",
        "description": "o.a.jackrabbit.spi.commons.conversion.PathParser accepts the following path:\n\n\"/public/.{.}/private\"\n\nthe normalized resulting Path object represents \"/private\" \n\nthat's a potential security risk.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1697",
        "summary": "Simple Google style query",
        "description": "In the Sling project there's a need for a simple query language. See SLING-573.\n\nI've created a parser that translates the simple query into an XPath query statement and executes it on a JCR workspace.\n\nI'll commit it to the jackrabbit-jcr-commons module.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1406",
        "summary": "Add the org.apache.jackrabbit.rmi.jackrabbit package to the rmic generation ",
        "description": "From the UnicastRemoteObject's (ServerJackrabbitNodeTypeManager, ServerJackrabbitWorkspace) should be stubs generated.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-617",
        "summary": "CachingHieraarchyManager may serve moved items",
        "description": "There is a problem with weak referenced item states and event notification in the\nLocalItemStateManager.\n\nconsider the following:\n- Session A traverses some nodes and fills-up the cache of the ChachingHierarchyManager\n- This also fills the weak-ref cache in Session A LocalItemStateManager.\n- Session B does some operations\n- At some point, GC decides to remove the weakly refferenced ItemStates in Session As\n  LocalItemStateManager\n- Session B moves a node and saves the changes.\n- The SharedItemStateManager notifies all listeners that a node was modified\n- The LocalItemStateManager of Session A receives the event, but does not bubble it,\n  because it does not have the item anymore in its cache\n- The CachingHierarchyManager of Session A never receives the modification event and still\n  servers the items at the old location.\n\nSolution A:\nreconnect missing states in the LocalItemStateManager when an event is received. this has\nthe drawback that a lot of state would be generated that are not needed.\n\nSolution B:\nadd a new event 'nodeModified' that is only sent by the LocalItemStateManager if a\n'stateModified' was received for which it does not have the item aymore. this has the\ndrawback that alot more events are generated.\n\nWill implement solution B\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-779",
        "summary": "Timeout for Session and/or Lock",
        "description": "I think there needs to be a mechanism where we can set the timeout for a particular jcr Session.  Or at the most, there should be a provision to set a timeout for a lock on a node.\n\nHope this is implemented soon.\n\nThanks.",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-874",
        "summary": "Move & copy objects",
        "description": "Add new methods in the persistence manager to move and copy objects",
        "label": "NUG",
        "classified": "OTHER",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1310",
        "summary": "Webdav: Drop xerces dependency",
        "description": "jukka is the final assignee :) thanks for taking over.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-713",
        "summary": "ConcurrentModificationException during registration of nodetypes",
        "description": "During the registration of a set of nodetypes this exception may be encountered:\n\njava.util.ConcurrentModificationException\n        at org.apache.commons.collections.map.AbstractReferenceMap$ReferenceEntrySetIterator.checkMod(AbstractReferenceMap.java:761)\n        at org.apache.commons.collections.map.AbstractReferenceMap$ReferenceEntrySetIterator.hasNext(AbstractReferenceMap.java:735)\n        at org.apache.jackrabbit.core.nodetype.NodeTypeRegistry.notifyRegistered(NodeTypeRegistry.java:1750)\n        at org.apache.jackrabbit.core.nodetype.NodeTypeRegistry.registerNodeTypes(NodeTypeRegistry.java:223)\n\nIt seems that the copying of the listeners triggered this exception:\n\n    private void notifyRegistered(QName ntName) {\n        // copy listeners to array to avoid ConcurrentModificationException\n        NodeTypeRegistryListener[] la =\n                new NodeTypeRegistryListener[listeners.size()];\n        Iterator iter = listeners.values().iterator();\n        int cnt = 0;\n1750:   while (iter.hasNext()) {\n            la[cnt++] = (NodeTypeRegistryListener) iter.next();\n        }\n        for (int i = 0; i < la.length; i++) {\n            if (la[i] != null) {\n                la[i].nodeTypeRegistered(ntName);\n            }\n        }\n    }\n\nThe methods \"notifyReRegistered\" and \"notifyUnregistered\" will probably suffer from the same problem.\n\nReproduction of this exception may be tricky; it only occurred once in our application. It is probably a race condition: another thread might access the listeners during the copy. It may be helpful to use a debugger and set a breakpoint in the middle of the copy giving other threads the opportunity to access the listeners...\n\nWe think that a possible solution is the following:\n\n    /**\n     * Notify the listeners that a node type <code>ntName</code> has been registered.\n     */\n    private void notifyRegistered(QName ntName) {\n        // copy listeners to array to avoid ConcurrentModificationException\n    \tNodeTypeRegistryListener[] la;\n    \tsynchronized (listeners) {\n            la = (NodeTypeRegistryListener[]) listeners.values().toArray(new NodeTypeRegistryListener[listeners.size()]);\n\t\t}\n\n        for (int i = 0; i < la.length; i++) {\n            if (la[i] != null) {\n                la[i].nodeTypeRegistered(ntName);\n            }\n        }\n    }\n\n\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1978",
        "summary": "Clean up spi-commons pom.xml",
        "description": "The pom.xml contains lines that were copied from the jackrabbit-core but are not actually needed. A log4j.properties is also missing in test resources.\n\nSee attached patch.",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-379",
        "summary": "Remove the unneeded cqfs dependencies",
        "description": "There's still unneeded dependencies to the cqfs libraries in jcr-server/webapp and jca.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "JCR-1022",
        "summary": "Reduce calls to RepositoryService.getRepositoryDescriptors()",
        "description": "Descriptors do not change and should not be requested for each session.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1119",
        "summary": "SimpleFieldsHelper emits a lot warnings",
        "description": "The SimpleFieldsHelper.retrieveSimpleField method is used to load JCR properties into simple Java object fields according to the mapping descriptor. If the node does not have the named property, a WARN message is emited.\n\nIf the missing property is defined as optional in the node type definition, it is quite normal, that it may be missing. Therefore emitting a WARN message does not seem appropriate. It would be better, to do the following (in order):\n\n   If the missing property is declared to be required in the descriptor, throw an exception\n   else if the descriptor has a default value for the missing property, use that value\n   else if the property is defined with a default value in the node type definition, use that value\n   else emit a DEBUG message and leave the field undefined\n\nNot sure, whether it makes absolute sense to define a property as mandatory in the descriptor but not in the node type definition. Are there any opinions on that ?",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1730",
        "summary": "Background text extraction not possible when supportHighlighting is set true",
        "description": "There is an IndexingQueue that holds nodes that are indexed with a background thread when text extraction takes more time than a configurable limit. When supportHighlighting is set to true the IndexingQueue is never used because the text extract is immediately requested in NodeIndexer. Instead the text extract should be retrieved only when the node is added to the index. ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1385",
        "summary": "UUID field not populated when saving a new node",
        "description": "In the following 'Article' class, there is are fields set to true for 'path' and 'uuid' jcr properties. \nThe mixins for referencing (hence, support for UUID) are declared at the @Node level of the class. \n\nAfter saving the node with the ObjectContentManager, the uuid field is not populated as it could be expected\n\n@Node(jcrMixinTypes=\"mix:referenceable,mix:lockable,mix:versionable\")\npublic class Article {\n\n        @Field(uuid=true)\n        private String id = null;\n       \n        @Field(path=true)\n        private String path = null;\n       \n        @Field\n        private String content = null;\n\n        ... constructor, getters and setters\n} \n\nThe full discussion is here : http://www.nabble.com/OCM-issues-with-path-and-id-fields-%28annotations%29-tt15460625.html#a15460625 ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2042",
        "summary": "RepositoryFactory implementation for jcr2spi",
        "description": "There should be a RepositoryFactory implementation in jcr2spi that also covers acquiring the underlying RepositoryService.\n\nFor this purpose I suggest to create:\n-  a RepositoryServiceFactory in jackrabbit-spi, which encapsulates the spi implementation specifc instantiation of the RepositoryService. the factory probably just needs a single method that takes a parameters map.\n- a RepositoryFactory implementation in jcr2spi, which works with a URI that contains all required information to connect/acquired the RepositoryService.\n\nTo use jcr2spi/spi2jcr/jackrabbit-core:\n- jcr+file://path/to/repository/home?config=repository.xml\n\nTo use jcr2spi/spi2dav:\n- jcr+dav://localhost:8080/server/repository/?br=4\n\nTo use jcr2spi/spi2davex:\n- jcr+davex://localhost:8080/server/repository/\n\nAn implementation of RepositoryServiceFactory must check the scheme and decide if it can handle it and create a RepositoryService instance with it, otherwise it must return null. This means there would be a single name for the connect URI for all RepositoryServiceFactory implementations.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-1674",
        "summary": "Provide means for exception handling for QueryNodeVisitor implementations",
        "description": "Currently the methods of QueryNodeVisitor do not declare any exceptions. Even though the query tree might be syntactically correct, an implementation might reach a point where it cannot continue (i.e. if it does not support one of the optional query features). For such cases there are currently two solution: 1. throw an unchecked exception or 2. communicate the error state through the visitor using the data object passed along. \nWhile I don't like 2. it is still an option. For 1. I'm not sure if this is the right way to go. It might be better to actually throw a checked exception. I therefore created a patch which declares RepositoryException on all visit methods of QueryNodeVisitor. Although the necessary changes in classes using QueryNodeVisitor are trivial, there are quite many of them. \n\nAny opinions on checked exception with probably breaking (trivially) existing code vs. using not checked exceptions?\n\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-998",
        "summary": "Annotation based implementation of jackrabbit ocm",
        "description": "we have created an annotation based implementation of jackrabbit-ocm that can be used instead of the digester one",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "JCR-3203",
        "summary": "GroupImp#getMembers and #getDeclaredMembers should return RangeIterator",
        "description": "for those cases where the total amount of members can easily be detected/calculated the\nimplementations of Group#getMembers() and #getDeclaredMembersOf() should return a RangeIterator.\n\nso far i found that Group#declaredMembers() can be easily adjusted for those cases where\nthe group members are stored in a multivalued property.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-124",
        "summary": "Session.import() failes to resolve propert property definition in some cases",
        "description": "Some Properties get assigned the wrong definiton when imported via SysView XML.\n\nThe selecteion of the definition failes under the following condition:\nThe nodetype contains a multi-valued property and a single-valued\nresidual property.\nIf the data to be imported than contains only one value for the multivalued property, it will be created with the residual definition.\nA later access to this propertie's values will fail with an ValueFormatException.\n\nExample:\nNode-Type\n - Property\n  - name: myapp:name\n  - mulitple: true\n - Property\n  - name: *\n  - multible: false\n\nSysview:\n<sv:node sv:name=\"somenode\">\n  <sv:property sv:name=\"jcr:primaryType\" sv:type=\"Name\">\n   <sv:value>myapp:sampleNt</sv:value> \n  </sv:property>\n \n  <sv:property sv:name=\"myapp:name\" sv:type=\"String\">\n   <sv:value>At least I could have multi values</sv:value> \n  </sv:property>\n</sv:node>\n\n=> The \"mayapp:name\" will be imported into the residule property.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-164",
        "summary": "SharedItemStateManager not properly synchronized",
        "description": "Some time ago we removed synchronized modifiers from the methods store() hasItemState() and getItemState(). While some care has been taken to ensure the cache integrity, I think the contract for the SharedItemStateManager (SISM) is now broken. The JavaDoc does not clearly document this, but I think all relevant methods of the SISM working on ItemStates should be atomic.\n\nE.g. a call to hasItemState() should not return true for an ItemState that another thread is currently adding in store(). Similarly a getItemState() should not return an ItemState that is currenly added or modified in a store() operation.\n\nCurrently I see two options:\n- Change the methods to synchronized again. This will actually serialize all calls to the SISM.\n- Implement a more sophisticated synchronisation. E.g. multiple store operations can still be allowed, as long as their ChangeLogs do not intersect. Retrieving ItemStates might still be allowed while a ChangeLog is stored, as long as the ItemState to retrieve is not part of the ChangeLog.\n\nComments and suggestions are very welcome.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2244",
        "summary": "NodeDefinitionTemplateImpl.setDefaultPrimaryTypeName(null) throws exception",
        "description": "expect to clear the name.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-1830",
        "summary": "XMLTextExtractor returns an empty reader when encoding is unsupported",
        "description": "XMLTextExtractor is failing to index xml files.  Searching for content in xml files is not coming back with results.\n\nOn the extractText(InputStream stream, String type, String encoding) method, the encoding is coming in as an empty string, and it throws an exception at line 62 (reader.parse(source)).\n\nmodifying the following statement fixes the problem:\nbefore:  if (encoding != null) {\nafter:  if (encoding != null && !encoding.equals(\"\")) {",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "JCR-2636",
        "summary": "Litmus prophighunicode test failure on JRE 1.5",
        "description": "The WebDAV Litmus test suite contains a test case for writing and reading the Unicode character &#x10000; which can't be represented as a single 16-bit char in Java. Instead the character is stored as a surrogate pair of two 16-bit chars. Unfortunately the Xalan XML serializer used by Sun JRE 1.5 incorrectly encodes these as two separate characters in UTF-8, which leads to the following Litmus test failure:\n\n-> running `props':\n[...]\n17. prophighunicode....... pass\n18. propget............... FAIL (PROPFIND on `/default/litmus/prop2': XML parse error at line 1: not well-formed (invalid token))\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "JCR-726",
        "summary": "Improve NodeTypeRegistry.effectiveNodeType()",
        "description": "The current getEffectiveNodeType() implementation has a minor bug that prevents from proper caching for certain nodetype combinations. further performance enhancements can be made to the effective node type cache.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "JCR-1934",
        "summary": "DbDataStore: delete temporary files using finalize()",
        "description": "Currently, reading from the DbDataStore creates a temporary file by default. If the application doesn't fully read or close the input stream, the file is not deleted. The best solution is to use finally { in.close() } in the application, but this is easily forgotten.\n\nI suggest to delete the temp file using finalize(). There is a small performance penalty when creating the temporary object, but compared to I/O it is very small. Note that FileInputStream and FileOutputStream also use finalize().",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-249",
        "summary": "Demo: DeleteFiles doesn't delete files by their path names",
        "description": "It appears that delete(term) fails to delete the last document containing term, which\nfor a unique match means that you can't remove an individual document.\n\nCode attempting to remove document with specific 'path' (slightly modified version of demo code):\n\nDirectory directory = FSDirectory.getDirectory(\"index\", false);\nIndexReader reader = IndexReader.open(directory);\nTerm term = new Term(\"path\", args[0]);  // path passed via command line arg\nint deleted = reader.delete(term);\nreader.close();\ndirectory.close();\n\nSystem.out.println(\"deleted \" + deleted + \" documents containing \" + term);\n\nExecuting this always returns \"deleted 0 documents containing <path entered>\"\n\nIn IndexReader.java, delete() has:\n\npublic final int delete(Term term) throws IOException {\n  TermDocs docs = termDocs(term);\n  if (docs == null) return 0;\n  int n = 0;\n  try {\n    while (docs.next()) {\n      delete(docs.doc());\n      n++;\n    }\n  } finally {\n    docs.close();\n  }\n  return n;\n}\n\nIt appears that docs.next() always returns false when there is only one doc, hence\ndelete() is never called and 0 is always returned.  I assume that this also means that\nif there are multiple matches, the last doc will not be deleted either, but I have not tested\nthat.\n\nI modified the code as follows:\n\n    boolean more = true;\n    try {\n      docs.next();\n      while (more) {\n        delete(docs.doc());\n        n++;\n        more = docs.next();\n      }\n    } finally {\n      docs.close();\n    }\n\nand then it worked as expected (at least attempts to delete a single document from the\nindex succeeded whereas previously they did not).",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "LUCENE-913",
        "summary": "Two consecutive score() calls return different scores for Boolean Queries.",
        "description": "Two consecutive calls to score() return different scores (no next() or skipTo() calls in between). \nBackground in LUCENE-912 .\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-245",
        "summary": "FieldCacheImpl cache gets rebuilt every time",
        "description": "FieldCacheImpl uses WeakHashMap to store the cached objects, but since \nthere is no other reference to this cache it is getting released every time.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "BUG"
    },
    {
        "key": "LUCENE-1375",
        "summary": "add IndexCommit.getTimestamp method",
        "description": "Convenience method for getDirectory().fileModified(getSegmentsFileName()).",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3408",
        "summary": "Remove unnecessary memory barriers in DWPT",
        "description": "Currently DWPT still uses AtomicLong to count the bytesUsed. Each write access issues an implicite memory barrier which is totally unnecessary since we doing everything single threaded on that level. This might be very minor but we shouldn't issue unnecessary memory barriers causing processors to lock their instruction pipeline for no reason.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-1529",
        "summary": "back-compat tests (\"ant test-tag\") should test JAR drop-in-ability",
        "description": "\nWe now test back-compat with \"ant test-tag\", which is very useful for\ncatching breaks in back compat before committing.\n\nHowever, that currently checks out \"src/test\" sources and then\ncompiles them against the trunk JAR, and runs the tests.  Whereas our\nback compat policy:\n\n  http://wiki.apache.org/lucene-java/BackwardsCompatibility\n\nstates that no recompilation is required on upgrading to a new JAR.\nIe you should be able to drop in the new JAR in place of your old one\nand things should work fine.\n\nSo... we should fix \"ant test-tag\" to:\n\n  * Do full checkout of core sources & tests from the back-compat-tag\n\n  * Compile the JAR from the back-compat sources\n\n  * Compile the tests against that back-compat JAR\n\n  * Swap in the trunk JAR\n\n  * Run the tests\n\n",
        "label": "NUG",
        "classified": "BUILD_SYSTEM",
        "type": "RFE"
    },
    {
        "key": "LUCENE-2858",
        "summary": "Separate SegmentReaders (and other atomic readers) from composite IndexReaders",
        "description": "With current trunk, whenever you open an IndexReader on a directory you get back a DirectoryReader which is a composite reader. The interface of IndexReader has now lots of methods that simply throw UOE (in fact more than 50% of all methods that are commonly used ones are unuseable now). This confuses users and makes the API hard to understand.\n\nThis issue should split \"atomic readers\" from \"reader collections\" with a separate API. After that, you are no longer able, to get TermsEnum without wrapping from those composite readers. We currently have helper classes for wrapping (SlowMultiReaderWrapper - please rename, the name is really ugly; or Multi*), those should be retrofitted to implement the correct classes (SlowMultiReaderWrapper would be an atomic reader but takes a composite reader as ctor param, maybe it could also simply take a List<AtomicReader>). In my opinion, maybe composite readers could implement some collection APIs and also have the ReaderUtil method directly built in (possibly as a \"view\" in the util.Collection sense). In general composite readers do not really need to look like the previous IndexReaders, they could simply be a \"collection\" of SegmentReaders with some functionality like reopen.\n\nOn the other side, atomic readers do not need reopen logic anymore? When a segment changes, you need a new atomic reader? - maybe because of deletions thats not the best idea, but we should investigate. Maybe make the whole reopen logic simplier to use (ast least on the collection reader level).\n\nWe should decide about good names, i have no preference at the moment.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "TASK"
    },
    {
        "key": "LUCENE-3588",
        "summary": "Try harder to prevent SIGSEGV on cloned MMapIndexInputs",
        "description": "We are unmapping mmapped byte buffers which is disallowed by the JDK, because it has the risk of SIGSEGV when you access the mapped byte buffer after unmapping.\n\nWe currently prevent this for the main IndexInput by setting its buffer to null, so we NPE if somebody tries to access the underlying buffer. I recently fixed also the stupid curBuf (LUCENE-3200) by setting to null.\n\nThe big problem are cloned IndexInputs which are generally not closed. Those still contain references to the unmapped ByteBuffer, which lead to SIGSEGV easily. The patch from Mike in LUCENE-3439 prevents most of this in Lucene 3.5, but its still not 100% safe (as it uses non-volatiles).\n\nThis patch will fix the remaining issues by also setting the buffers of clones to null when the original is closed. The trick is to record weak references of all clones created and close them together with the original. This uses a ConcurrentHashMap<WeakReference<MMapIndexInput>,?> as store with the logic borrowed from WeakHashMap to cleanup the GCed references (using ReferenceQueue).\n\nIf we respin 3.5, we should maybe also get this in.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-2321",
        "summary": "use packed ints for the terms dict index",
        "description": "Terms dict index needs to store large RAM resident arrays of ints, but, because their size is bound & variable (depending on the segment/docs), we should used packed ints for them.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3672",
        "summary": "IndexCommit.equals() bug",
        "description": "IndexCommit.equals() checks for equality of Directories and versions, but it doesn't check IMHO the more important generation numbers. It looks like commits are really identified by a combination of directory and segments_XXX, which means the generation number, because that's what the DirectoryReader.open() checks for.\n\nThis bug leads to an unexpected behavior when the only change to be committed is in userData - we get two commits then that are declared equal, they have the same version but they have different generation numbers. I have no idea how this situation is treated in a few dozen references to IndexCommit.equals() across Lucene...\n\nOn the surface the fix is trivial - either add the gen number to equals(), or use gen number instead of version. However, it's puzzling why these two would ever get out of sync??? and if they are always supposed to be in sync then maybe we don't need both of them at all, maybe just generation or version is sufficient?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-3255",
        "summary": "Corrupted segment file not detected and wipes index contents",
        "description": "Lucene will happily wipe an existing index if presented with a latest generation segments_n file of all zeros. File format documentation says segments_N files should start with a format of -9 but SegmentInfos.read accepts >=0 as valid for backward compatibility reasons.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-2213",
        "summary": "Small improvements to ArrayUtil.getNextSize",
        "description": "Spinoff from java-dev thread \"Dynamic array reallocation algorithms\" started on Jan 12, 2010.\n\nHere's what I did:\n\n  * Keep the +3 for small sizes\n\n  * Added 2nd arg = number of bytes per element.\n\n  * Round up to 4 or 8 byte boundary (if it's 32 or 64 bit JRE respectively)\n\n  * Still grow by 1/8th\n\n  * If 0 is passed in, return 0 back\n\nI also had to remove some asserts in tests that were checking the actual values returned by this method -- I don't think we should test that (it's an impl. detail).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-504",
        "summary": "FuzzyQuery produces a \"java.lang.NegativeArraySizeException\" in PriorityQueue.initialize if I use Integer.MAX_VALUE as BooleanQuery.MaxClauseCount",
        "description": "PriorityQueue creates an \"java.lang.NegativeArraySizeException\" when initialized with Integer.MAX_VALUE, because Integer overflows. I think this could be a general problem with PriorityQueue. The Error occured when I set BooleanQuery.MaxClauseCount to Integer.MAX_VALUE and user a FuzzyQuery for searching.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-2487",
        "summary": "IndexReader subclasses must implement flex APIs",
        "description": "To be fixed only on trunk...\n\nI made IndexReader's base flex APIs abstract, fixed all core/contrib/solr places that subclassed IR and didn't already implement flex (including contrib/memory, contrib/instantiated), and remove all the classes for the back-compat layer that emulated flex APIs on top of pre-flex APIs.",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-2945",
        "summary": "Surround Query doesn't properly handle equals/hashcode",
        "description": "In looking at using the surround queries with Solr, I am hitting issues caused by collisions due to equals/hashcode not being implemented on the anonymous inner classes that are created by things like DistanceQuery (branch 3.x, near line 76)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-977",
        "summary": "internal hashing improvements",
        "description": "Internal power-of-two closed hashtable traversal in DocumentsWriter and CharArraySet could be better.\n\nHere is the current method of resolving collisions:\n    if (text2 != null && !equals(text, len, text2)) {\n      final int inc = code*1347|1;\n      do {\n        code += inc;\n        pos = code & mask;\n        text2 = entries[pos];\n      } while (text2 != null && !equals(text, len, text2));\n\nThe problem is that two different hashCodes with the same lower bits will keep picking the same slots (the upper bits will be ignored).\nThis is because multiplication (*1347) only really shifts bits to the left... so given that the two codes already matched on the right, they will both pick the same increment, and this will keep them on the same path through the table (even though it's being added to numbers that differ on the left).  To resolve this, some bits need to be moved to the right when calculating the increment.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-2031",
        "summary": "Move PatternAnalyzer out of contrib/memory to contrib/analyzers",
        "description": "in the memory index contrib there is a PatternAnalyzer.\ni think this analyzer belongs in contrib/analyzers instead, it has no relation to memory index.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "TASK"
    },
    {
        "key": "LUCENE-1369",
        "summary": "Eliminate unnecessary uses of Hashtable and Vector",
        "description": "Lucene uses Vector, Hashtable and Enumeration when it doesn't need to. Changing to ArrayList and HashMap may provide better performance.\n\nThere are a few places Vector shows up in the API. IMHO, List should have been used for parameters and return values.\n\nThere are a few distinct usages of these classes:\n# internal but with ArrayList or HashMap would do as well. These can simply be replaced.\n# internal and synchronization is required. Either leave as is or use a collections synchronization wrapper.\n# As a parameter to a method where List or Map would do as well. For contrib, just replace. For core, deprecate current and add new method signature.\n# Generated by JavaCC. (All *.jj files.) Nothing to be done here.\n# As a base class. Not sure what to do here. (Only applies to SegmentInfos extends Vector, but it is not used in a safe manner in all places. Perhaps, implements List would be better.)\n# As a return value from a package protected method, but synchronization is not used. Change return type.\n# As a return value to a final method. Change to List or Map.\n\nIn using a Vector the following iteration pattern is frequently used.\nfor (int i = 0; i < v.size(); i++) {\n  Object o = v.elementAt(i);\n}\n\nThis is an indication that synchronization is unimportant. The list could change during iteration.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3142",
        "summary": "benchmark/stats package is obsolete and unused - remove it",
        "description": "This seems like a leftover from the original benchmark implementation and can thus be removed.\n",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "BUG"
    },
    {
        "key": "LUCENE-764",
        "summary": "Document the temporary free space requirements of IndexWriter methods",
        "description": "Just opening an issue to track fixes to javadocs around Directory\nspace usage of optimize(), addIndexes(*), addDocument.\n\nThis came out of a recent thread on the users list around unexpectedly\nhigh temporary disk usage during optimize():\n\n  http://www.gossamer-threads.com/lists/lucene/java-user/43475\n\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-1974",
        "summary": "BooleanQuery can not find all matches in special condition",
        "description": "query: (name:tang*)\ndoc=5137 score=1.0  doc:Document<stored,indexed<name:tangfulin>>\ndoc=11377 score=1.0  doc:Document<stored,indexed<name:tangfulin>>\nquery: name:tang* name:notexistnames\ndoc=5137 score=0.048133932  doc:Document<stored,indexed<name:tangfulin>>\n\nIt is two queries on the same index, one is just a prefix query in a\nboolean query, and the other is a prefix query plus a term query in a\nboolean query, all with Occur.SHOULD .\n\nwhat I wonder is why the later query can not find the doc=11377 doc ?\n\nthe problem can be repreduced by the code in the attachment .",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-1892",
        "summary": "Demo HTMLParser compares StringBuffer to an empty String with .equals",
        "description": "",
        "label": "NUG",
        "classified": "OTHER",
        "type": "BUG"
    },
    {
        "key": "LUCENE-2911",
        "summary": "synchronize grammar/token types across StandardTokenizer, UAX29EmailURLTokenizer, ICUTokenizer, add CJK types.",
        "description": "I'd like to do LUCENE-2906 (better cjk support for these tokenizers) for a future target such as 3.2\n\nBut, in 3.1 I would like to do a little cleanup first, and synchronize all these token types, etc.\n",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": ""
    },
    {
        "key": "LUCENE-627",
        "summary": "highlighter problems with overlapping tokens",
        "description": "The lucene highlighter has problems when tokens that overlap are generated.\n\nFor example, if analysis of iPod generates the tokens \"i\", \"pod\", \"ipod\" (with pod and ipod in the same position),\nthen the highlighter will output this as iipod, regardless of if any of those tokens are highlighted.\n\nDiscovered via http://issues.apache.org/jira/browse/SOLR-24\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-511",
        "summary": "New BufferedIndexOutput optimization fails to update bufferStart",
        "description": "New BufferIndexOutput optimization of writeBytes fails to update bufferStart under some conditions. Test case and fix attached.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-1509",
        "summary": "IndexCommit.getFileNames() should not return dups",
        "description": "If the index was created with autoCommit false, and more than 1\nsegment was flushed during the IndexWriter session, then the shared\ndoc-store files are incorrectly duplicated in\nIndexCommit.getFileNames().  This is because that method is walking\nthrough each SegmentInfo, appending its files to a list.  Since\nmultiple SegmentInfo's may share the doc store files, this causes dups.\n\nTo fix this, I've added a SegmentInfos.files(...) method, and\nrefactored all places that were computing their files one SegmentInfo\nat a time to use this new method instead.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-1378",
        "summary": "Remove remaining @author references",
        "description": "$ find . -name \\*.java | xargs grep '@author' | cut -d':' -f1 | xargs perl -pi -e 's/ \\@author.*//'\n",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "TASK"
    },
    {
        "key": "LUCENE-3217",
        "summary": "Improve DocValues merging",
        "description": "Some DocValues impl. still load all values from merged segments into memory during merge. For efficiency we should merge them on the fly without buffering in memory",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3203",
        "summary": "Rate-limit IO used by merging",
        "description": "Large merges can mess up searches and increase NRT reopen time (see\nhttp://blog.mikemccandless.com/2011/06/lucenes-near-real-time-search-is-fast.html).\n\nA simple rate limiter improves the spikey NRT reopen times during big\nmerges, so I think we should somehow make this possible.  Likely this\nwould reduce impact on searches as well.\n\nTypically apps that do indexing and searching on same box are in no\nrush to see the merges complete so this is a good tradeoff.\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-1280",
        "summary": "NPE in PhraseQuery.toString(String f)",
        "description": "the section\n\npublic String toString(String f) {\n    StringBuffer buffer = new StringBuffer();\n    if (!field.equals(f)) {\n      buffer.append(field);\n      buffer.append(\":\");\n    }\n    <snip>\n\n\nshould be\n\npublic String toString(String f) {\n    StringBuffer buffer = new StringBuffer();\n    if (field != null && !field.equals(f)) {\n      buffer.append(field);\n      buffer.append(\":\");\n    }\n    <snip>\n\n\nThe issue arises if a phrase query is created, no terms are added, then the phrase query is added to a boolean query. Calling toString on the boolean query will result in a NPE insdie of the PhraseQuery.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-220",
        "summary": "Inconsistent behaviour sorting against field with no related documents",
        "description": "In StringSortedHitQueue - generateSortIndex seems to mistake \nthe TermEnum having values as indicating that the sort field \nhas entries in the index.\n\nIn the case where the search has matching results an ArrayIndexOutOfBounds\nexception is thrown in sortValue (line 177 StringSortedHitQueue)\nas generateSortIndex creates a terms array of zero length and fieldOrder\ncontains 0 for all documents.\n\nIt would seem more helpful if:\na) generateSortIndex catches the lack of any documents with the sort field.\n\nor\n\nb) reserve terms[0] as a special value for documents that do not have\nmatching sort field values. ie Change the current implementation to add 1\nto the index and change terms[0] to ensure it sorts \"untagged\" documents to\nfirst or last.\n\nFor my application Id much prefer solution (b) as it allows much smaller \nindexes and make searching using sort values less brittle.\n\nThats the best my communication skills can muster just now. Could change\ncurrent code to something like:\n\nprivate final int[] generateSortIndex()\nthrows IOException {\n\n\tfinal int[] retArray = new int[reader.maxDoc()];\n\tfinal String[] mterms = new String[reader.maxDoc() + 1];  // guess length\n\tif (retArray.length > 0) {\n\t\tTermDocs termDocs = reader.termDocs();\n\t\t// change this value to control if documents without sort field come first or last\n\t\tmterms[0] = \"\";  // XXXXXXXXX change\n\t\tint t = 1;  // current term number  XXXXXXXXXXXXX change\n\t\ttry {\n\t\n\n\t\t\tdo {\n\t\t\t\tTerm term = enumerator.term();\n\t\t\t\tif (term.field() != field) break;\n\n\t\t\t\t// store term text\n\t\t\t\t// we expect that there is at most one term per document\n\t\t\t\tif (t >= mterms.length) throw new RuntimeException (\"there are more terms\nthan documents in field \\\"\"+field+\"\\\"\");\n\t\t\t\tmterms[t] = term.text();\n\n\t\t\t\t// store which documents use this term\n\t\t\t\ttermDocs.seek (enumerator);\n\t\t\t\twhile (termDocs.next()) {\n\t\t\t\t\tretArray[termDocs.doc()] = t;\n\t\t\t\t}\n\n\t\t\t\tt++;\n\t\t\t} while (enumerator.next());\n\t\t} finally {\n\t\t\ttermDocs.close();\n\t\t}\n\n\t\t// if there are less terms than documents,\n\t\t// trim off the dead array space\n\t\tif (t < mterms.length) {\n\t\t\tterms = new String[t];\n\t\t\tSystem.arraycopy (mterms, 0, terms, 0, t);\n\t\t} else {\n\t\t\tterms = mterms;\n\t\t}\n\t}\n\treturn retArray;\n}\n\nHaving very quick look at IntegerSortedHitQueue would seem possible\nto do same thing. Maybe creating Integer wrapper objects once.\n\nHope that made some sort of sense. Im not very familiar with the code\nor Lucene terminology.\nIf the above seems like a useful approach Id be glad to generate patches\nfor a cleaned up version.\n\nThanks\n\nSam",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-2864",
        "summary": "add maxtf to fieldinvertstate",
        "description": "the maximum within-document TF is a very useful scoring value, \nwe should expose it so that people can use it in scoring\n\nconsider the following sim:\n{code}\n@Override\npublic float idf(int docFreq, int numDocs) {\n  return 1.0F; /* not used */\n}\n\n@Override\npublic float computeNorm(String field, FieldInvertState state) {\n  return state.getBoost() / (float) Math.sqrt(state.getMaxTF());\n}\n{code}\n\nwhich is surprisingly effective, but more interesting for practical reasons.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "LUCENE-3695",
        "summary": "FST Builder methods need fixing,documentation,or improved type safety",
        "description": "Its confusing the way an FST Builder has 4 add() methods, and you get assertion errors (what happens if assertions are disabled?) if you use the wrong one:\n\nFor reference we have 3 FST input types:\n* BYTE1 (byte)\n* BYTE2 (char)\n* BYTE4 (int)\n\nFor the builder add() method signatures we have:\n* add(BytesRef)\n* add(char[], int offset, int len)\n* add(CharSequence)\n* add(IntsRef)\n\nBut certain methods only work with certain FST input types, and these mappings are not the ones you think. \n\nFor example, you would think that if you have a char-based FST you should use add(char[]) or add(CharSequence), but this is not the case: those add methods actually only work with int-based FST (they use codePointAt() to extract codepoints). Instead, you have to use add(IntsRef) for the char-based one.\n\nThe worst is if you use the wrong one, you get an assertion error, but i'm not sure what happens if assertions are disabled.\n\nMaybe the ultimate solution is to parameterize FST's generics on input too (FST<input,output>) and just require BytesRef/CharsRef/IntsRef as the parameter? Then you could just have add(), and this might clean up FSTEnum too (it would no longer need that InputOutput class but maybe could use Map.Entry<input,output> or something?\n \nI think the documentation is improving but i still notice add(BytesRef) has no javadoc at all, and it only works with BYTE1, so I think we still have some work to do even if we want to just pursue a documentation fix.\n",
        "label": "NUG",
        "classified": "DESIGN_DEFECT",
        "type": "BUG"
    },
    {
        "key": "LUCENE-1536",
        "summary": "if a filter can support random access API, we should use it",
        "description": "I ran some performance tests, comparing applying a filter via\nrandom-access API instead of current trunk's iterator API.\n\nThis was inspired by LUCENE-1476, where we realized deletions should\nreally be implemented just like a filter, but then in testing found\nthat switching deletions to iterator was a very sizable performance\nhit.\n\nSome notes on the test:\n\n  * Index is first 2M docs of Wikipedia.  Test machine is Mac OS X\n    10.5.6, quad core Intel CPU, 6 GB RAM, java 1.6.0_07-b06-153.\n\n  * I test across multiple queries.  1-X means an OR query, eg 1-4\n    means 1 OR 2 OR 3 OR 4, whereas +1-4 is an AND query, ie 1 AND 2\n    AND 3 AND 4.  \"u s\" means \"united states\" (phrase search).\n\n  * I test with multiple filter densities (0, 1, 2, 5, 10, 25, 75, 90,\n    95, 98, 99, 99.99999 (filter is non-null but all bits are set),\n    100 (filter=null, control)).\n\n  * Method high means I use random-access filter API in\n    IndexSearcher's main loop.  Method low means I use random-access\n    filter API down in SegmentTermDocs (just like deleted docs\n    today).\n\n  * Baseline (QPS) is current trunk, where filter is applied as iterator up\n    \"high\" (ie in IndexSearcher's search loop).",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-1398",
        "summary": "Add ReverseStringFilter",
        "description": "add ReverseStringFilter and ReverseStringAnalyzer that can be used for backword much. For Example, \"*ry\", \"*ing\", \"*ber\".",
        "label": "NUG",
        "classified": "RFE",
        "type": "RFE"
    },
    {
        "key": "LUCENE-2277",
        "summary": "QueryNodeImpl throws ConcurrentModificationException on add(List<QueryNode>)",
        "description": "on adding a List of children to a QueryNodeImplemention a ConcurrentModificationException is thrown.\nThis is due to the fact that QueryNodeImpl instead of iteration over the supplied list, iterates over its internal clauses List.\n\nPatch:\nIndex: QueryNodeImpl.java\n===================================================================\n--- QueryNodeImpl.java    (revision 911642)\n+++ QueryNodeImpl.java    (working copy)\n@@ -74,7 +74,7 @@\n           .getLocalizedMessage(QueryParserMessages.NODE_ACTION_NOT_SUPPORTED));\n     }\n \n-    for (QueryNode child : getChildren()) {\n+    for (QueryNode child : children) {\n       add(child);\n     }\n ",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-3077",
        "summary": "DWPT doesn't see changes to DW#infoStream",
        "description": "DW does not push infostream changes to DWPT since DWPT#infoStream is final and initialized on DWPTPool initialization (at least for initial DWPT) we should push changes to infostream to DWPT too",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-1642",
        "summary": "IndexWriter.addIndexesNoOptimize ignores the compound file setting of the destination index",
        "description": "IndexWriter.addIndexesNoOptimize(Directory[]) ignores the compound file setting of the destination index. It is using the compound file flags of segments in the source indexes.\nThis sometimes causes undesired increase of the number of files in the destination index when non-compound file indexes are added until merge kicks in.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-2468",
        "summary": "reopen on NRT reader should share readers w/ unchanged segments",
        "description": "A repoen on an NRT reader doesn't seem to share readers for those segments that are unchanged.\nhttp://search.lucidimagination.com/search/document/9f0335d480d2e637/nrt_and_caching_based_on_indexreader",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-3280",
        "summary": "Add new bit set impl for caching filters",
        "description": "I think OpenBitSet is trying to satisfy too many audiences, and it's\nconfusing/error-proned as a result.  It has int/long variants of many\nmethods.  Some methods require in-bound access, others don't; of those\nothers, some methods auto-grow the bits, some don't.  OpenBitSet\ndoesn't always know its numBits.\n\nI'd like to factor out a more \"focused\" bit set impl whose primary\ntarget usage is a cached Lucene Filter, ie a bit set indexed by docID\n(int, not long) whose size is known and fixed up front (backed by\nfinal long[]) and is always accessed in-bounds.\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3870",
        "summary": "VarDerefBytesImpl doc values prefix length may fall across two pages",
        "description": "The VarDerefBytesImpl doc values encodes the unique byte[] with prefix (1 or 2 bytes) first, followed by bytes, so that it can use PagedBytes.fillSliceWithPrefix.\n\nIt does this itself rather than using PagedBytes.copyUsingLengthPrefix...\n\nThe problem is, it can write an invalid 2 byte prefix spanning two blocks (ie, last byte of block N and first byte of block N+1), which fillSliceWithPrefix won't decode correctly.\n\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-1322",
        "summary": "Remove synchronization in CompoundFileReader",
        "description": "Currently there is what seems to be unnecessary synchronization in CompoundFileReader.  This is solved by cloning the base IndexInput.  Synchronization in low level IO classes creates lock contention on highly multi threaded Lucene installations, so much so that in many cases the CPU utilization never reaches the maximum without using something like ParallelMultiSearcher.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-1646",
        "summary": "QueryParser throws new exceptions even if custom parsing logic threw a better one",
        "description": "We have subclassed QueryParser and have various custom fields.  When these fields contain invalid values, we throw a subclass of ParseException which has a more useful message (and also a localised message.)\n\nProblem is, Lucene's QueryParser is doing this:\n\n{code}\n    catch (ParseException tme) {\n        // rethrow to include the original query:\n        throw new ParseException(\"Cannot parse '\" +query+ \"': \" + tme.getMessage());\n    }\n{code}\n\nThus, our nice and useful ParseException is thrown away, replaced by one with no information about what's actually wrong with the query (it does append getMessage() but that isn't localised.  And it also throws away the underlying cause for the exception.)\n\nI am about to patch our copy to simply remove these four lines; the caller knows what the query string was (they have to have a copy of it because they are passing it in!) so having it in the error message itself is not useful.  Furthermore, when the query string is very big, what the user wants to know is not that the whole query was bad, but which part of it was bad.\n\n",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-356",
        "summary": "ArrayIndexOutOfBoundsException when using MultiFieldQueryParser",
        "description": "We get the following exception:\n\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: -1\n        at java.util.Vector.elementAt(Vector.java:434)\n        at org.apache.lucene.queryParser.QueryParser.addClause(QueryParser.java:181)\n        at org.apache.lucene.queryParser.QueryParser.Query(QueryParser.java:529)\n        at org.apache.lucene.queryParser.QueryParser.parse(QueryParser.java:108)\n        at org.apache.lucene.queryParser.QueryParser.parse(QueryParser.java:87)\n        at\norg.apache.lucene.queryParser.MultiFieldQueryParser.parse(MultiFieldQueryParser.java:77)\n        at idx.Mquery.main(Mquery.java:64)\n\n\nWe are using a query with 'AND' like 'bla AND blo' on 5 fields.\nOne of the fields has a Tokenizer which returns no token\nat all on this query, and this together with the AND\ntriggers the exception.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-442",
        "summary": "TestIndexModifier.testIndexWithThreads is not valid?",
        "description": "I recently started playing with the trunk of SVN, and noticed that intermitently, TestIndexModifier.testIndexWithThreads (revision 292010) would fail.\n\nThe basic premise of the test seems to be that 3 pairs of IndexThread instances can be started in parallel, each pair using the same instance of IndexModifier to concurrently and randomly add/delete/optimize a single FSDirectory index.  \nThe test is considered a success if the sum of additions-deletions recorded by each pair of threads equals the final docCount() for the IndexModifier instance used by that pair of threads.\n\nNow I freely admit that I'm not 100% familiar with the code for IndexModifier, but at a glance, the basic premise seems to be: \n   a) If method for IndexWriter is called, open it if needed, close the IndexReader first if needed.\n   b) if method for IndexReader is called, open it if needed, close the IndexWriter first if needed.\n\nIf I'm understnading that correctly, I see no reason to assume this test will pass.  \nIt seems like there could be plenty of scenerios in which the number of additions-deletions != docCount(). The most trivial example I can think of is:\n   1) the first IndexThread instance which has a chance to run adds a document, and optimizes before any other IndexThreads ever open the Directory.\n   2) a subsequent pair of IndexThread instances open their IndexModifier instance before any documents are deleted.\n   3) the IndexThread instances from #2 do nothing but add documents\n...that pair of IndexThreads is now garunteed to have recorded a differnet number of additions then the docCount returned by their IndexModifier.\n\nAm I missing something, or should this test be removed?\n\n",
        "label": "NUG",
        "classified": "TEST",
        "type": "BUG"
    },
    {
        "key": "LUCENE-679",
        "summary": "CLONE -QueryParser is not applicable for the arguments (String, String, Analyzer) error in results.jsp when executing search in the browser (demo from Lucene 2.0)",
        "description": "When executing search in the browser (as described in demo3.html Lucene demo) I get error, because the demo uses the method (QueryParser with three arguments) which is deleted (it was deprecated).\nI checked the demo from Lucene 1.4-final it with Lucene 1.4-final - it works, because those time the method was there.\nBut demo from Lucene 2.0 does not work with Lucene 2.0\n\nThe error stack is here:\nTTP Status 500 -\n\ntype Exception report\n\nmessage\n\ndescription The server encountered an internal error () that prevented it from fulfilling this request.\n\nexception\n\norg.apache.jasper.JasperException: Unable to compile class for JSP\n\nAn error occurred at line: 60 in the jsp file: /results.jsp\nGenerated servlet error:\nThe method parse(String) in the type QueryParser is not applicable for the arguments (String, String, Analyzer)\n\n\norg.apache.jasper.servlet.JspServletWrapper.handleJspException(JspServletWrapper.java:510)\norg.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:375)\norg.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:314)\norg.apache.jasper.servlet.JspServlet.service(JspServlet.java:264)\njavax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n\nroot cause\n\norg.apache.jasper.JasperException: Unable to compile class for JSP\n\nAn error occurred at line: 60 in the jsp file: /results.jsp\nGenerated servlet error:\nThe method parse(String) in the type QueryParser is not applicable for the arguments (String, String, Analyzer)\n\n\norg.apache.jasper.compiler.DefaultErrorHandler.javacError(DefaultErrorHandler.java:84)\norg.apache.jasper.compiler.ErrorDispatcher.javacError(ErrorDispatcher.java:328)\norg.apache.jasper.compiler.JDTCompiler.generateClass(JDTCompiler.java:409)\norg.apache.jasper.compiler.Compiler.compile(Compiler.java:297)\norg.apache.jasper.compiler.Compiler.compile(Compiler.java:276)\norg.apache.jasper.compiler.Compiler.compile(Compiler.java:264)\norg.apache.jasper.JspCompilationContext.compile(JspCompilationContext.java:563)\norg.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:303)\norg.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:314)\norg.apache.jasper.servlet.JspServlet.service(JspServlet.java:264)\njavax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n\nnote The full stack trace of the root cause is available in the Apache Tomcat/5.5.15 logs.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "BUG"
    },
    {
        "key": "LUCENE-1497",
        "summary": "Minor changes to SimpleHTMLFormatter",
        "description": "I'd like to make few minor changes to SimpleHTMLFormatter.\n\n1. Define DEFAULT_PRE_TAG and DEFAULT_POST_TAG and use them in the default constructor. This will not trigger String lookups by the JVM whenever the highlighter is instantiated.\n\n2. Create the StringBuffer in highlightTerm with the right number of characters from the beginning. Even though StringBuffer's default constructor allocates 16 chars, which will probably be enough for most highlighted terms (pre + post tags are 7 chars, which leaves 9 chars for terms), I think it's better to allocate SB with the right # of chars in advance, to avoid char[] allocations in the middle.",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3376",
        "summary": "Move ReusableAnalyzerBase into core",
        "description": "In LUCENE-2309 it was suggested that we should make Analyzer reusability compulsory.  ReusableAnalyzerBase is a fantastic way to drive reusability so lets move it into core (so that we can then change all impls over to using it).",
        "label": "NUG",
        "classified": "REFACTORING",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-2178",
        "summary": "Benchmark contrib should allow multiple locations in ext.classpath",
        "description": "When {{ant run-task}} is invoked with the  {{-Dbenchmark.ext.classpath=...}} option, only a single location may be specified.  If a classpath with more than one location is specified, none of the locations is put on the classpath for the invoked JVM.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3037",
        "summary": "TestFSTs.testRealTerms produces a corrupt index",
        "description": "seems to be prox/skip related: the test passes, but the checkindex upon closing fails.\n\nant test-core -Dtestcase=TestFSTs -Dtests.seed=-4012305283315171209:0 -Dtests.multiplier=3 -Dtests.nightly=true -Dtests.linedocsfile=c:/data/enwiki.random.lines.txt.gz\n\nNote: to get the enwiki.random.lines.txt.gz you have to fetch it from hudson (warning 1 gigabyte file).\nyou also have to run the test a few times to trigger it.\n\nill upload the index this thing makes to this issue.\n",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-3200",
        "summary": "Cleanup MMapDirectory to use only one MMapIndexInput impl with mapping sized of powers of 2",
        "description": "Robert and me discussed a little bit after Mike's investigations, that using SingleMMapIndexinput together with MultiMMapIndexInput leads to hotspot slowdowns sometimes.\n\nWe had the following ideas:\n- MultiMMapIndexInput is almost as fast as SingleMMapIndexInput, as the switching between buffer boundaries is done in exception catch blocks. So normal code path is always the same like for Single*\n- Only the seek method uses strange calculations (the modulo is totally bogus, it could be simply: int bufOffset = (int) (pos % maxBufSize); - very strange way of calculating modulo in the original code)\n- Because of speed we suggest to no longer use arbitrary buffer sizes. We should pass only the power of 2 to the indexinput as size. All calculations in seek and anywhere else would be simple bit shifts and AND operations (the and masks for the modulo can be calculated in the ctor like NumericUtils does when calculating precisionSteps).\n- the maximum buffer size will now be 2^30, not 2^31-1. But thats not an issue at all. In my opinion, a buffer size of 2^31-1 is stupid in all cases, as it will no longer fit page boundaries and mmapping gets harder for the O/S.\n\nWe will provide a patch with those cleanups.",
        "label": "NUG",
        "classified": "CLEANUP",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-1704",
        "summary": "org.apache.lucene.ant.HtmlDocument added Tidy config file passthrough availability",
        "description": "Parsing HTML documents using the org.apache.lucene.ant.HtmlDocument.Document method resulted in many error messages such as this:\n\n    line 152 column 725 - Error: <as-html> is not recognized!\n    This document has errors that must be fixed before\n    using HTML Tidy to generate a tidied up version.\n\nThe solution is to configure Tidy to accept these abnormal tags by adding the tag name to the \"new-inline-tags\" option in the Tidy config file (or the command line which does not make sense in this context), like so:\n\n    new-inline-tags: as-html\n\nTidy needs to know where the configuration file is, so a new constructor and Document method can be added.  Here is the code:\n\n{code}\n    /**                                                                                                                                                                                            \n     *  Constructs an <code>HtmlDocument</code> from a {@link                                                                                                                                      \n     *  java.io.File}.                                                                                                                                                                             \n     *                                                                                                                                                                                             \n     *@param  file             the <code>File</code> containing the                                                                                                                                \n     *      HTML to parse                                                                                                                                                                          \n     *@param  tidyConfigFile   the <code>String</code> containing                                                                                                                                  \n     *      the full path to the Tidy config file                                                                                                                                                  \n     *@exception  IOException  if an I/O exception occurs                                                                                                                                          \n     */\n    public HtmlDocument(File file, String tidyConfigFile) throws IOException {\n        Tidy tidy = new Tidy();\n        tidy.setConfigurationFromFile(tidyConfigFile);\n        tidy.setQuiet(true);\n        tidy.setShowWarnings(false);\n        org.w3c.dom.Document root =\n                tidy.parseDOM(new FileInputStream(file), null);\n        rawDoc = root.getDocumentElement();\n    }\n\n    /**                                                                                                                                                                                            \n     *  Creates a Lucene <code>Document</code> from a {@link                                                                                                                                       \n     *  java.io.File}.                                                                                                                                                                             \n     *                                                                                                                                                                                             \n     *@param  file                                                                                                                                                                                 \n     *@param  tidyConfigFile the full path to the Tidy config file                                                                                                                                 \n     *@exception  IOException                                                                                                                                                                      \n     */\n    public static org.apache.lucene.document.Document\n        Document(File file, String tidyConfigFile) throws IOException {\n\n        HtmlDocument htmlDoc = new HtmlDocument(file, tidyConfigFile);\n\n        org.apache.lucene.document.Document luceneDoc = new org.apache.lucene.document.Document();\n\n        luceneDoc.add(new Field(\"title\", htmlDoc.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n        luceneDoc.add(new Field(\"contents\", htmlDoc.getBody(), Field.Store.YES, Field.Index.ANALYZED));\n\n        String contents = null;\n        BufferedReader br =\n            new BufferedReader(new FileReader(file));\n        StringWriter sw = new StringWriter();\n        String line = br.readLine();\n        while (line != null) {\n            sw.write(line);\n            line = br.readLine();\n        }\n        br.close();\n        contents = sw.toString();\n        sw.close();\n\n        luceneDoc.add(new Field(\"rawcontents\", contents, Field.Store.YES, Field.Index.NO));\n\n        return luceneDoc;\n    }\n{code}\n\nI am using this now and it is working fine.  The configuration file is being passed to Tidy and now I am able to index thousands of HTML pages with no more Tidy tag errors.\n\n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3794",
        "summary": "DirectoryTaxonomyWriter can lose the INDEX_CREATE_TIME property, causing DirTaxoReader.refresh() to falsely succeed (or fail)",
        "description": "DirTaxoWriter sets createTime to null after it put it in the commit data once. But that's wrong because if one calls commit(Map<>) twice, the second time doesn't record the creation time. Also, in the ctor, if an index exists and OpenMode is not CREATE, the creation time property is not read.\n\nI wrote a couple of unit tests that assert this, and modified DirTaxoWriter to always record the creation time (in every commit) -- that's the only safe way.\n\nWill upload a patch shortly.",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-389",
        "summary": "MatchAllDocsQuery to return all documents",
        "description": "It would be nice to have a type of query just return all documents from an index.",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-298",
        "summary": "NullPointerExc. when indexing empty field with term vectors",
        "description": "Mark Harwood mentioned this on the user's list. Running the attached code \nyou'll get this exception: \n \nException in thread \"main\" java.lang.NullPointerException \n\tat \norg.apache.lucene.index.TermVectorsReader.clone(TermVectorsReader.java:303) \n\tat \norg.apache.lucene.index.SegmentReader.getTermVectorsReader(SegmentReader.java:473) \n\tat \norg.apache.lucene.index.SegmentReader.getTermFreqVectors(SegmentReader.java:507) \n\tat \norg.apache.lucene.index.SegmentMerger.mergeVectors(SegmentMerger.java:204) \n\tat org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:94) \n\tat \norg.apache.lucene.index.IndexWriter.mergeSegments(IndexWriter.java:618) \n\tat \norg.apache.lucene.index.IndexWriter.flushRamSegments(IndexWriter.java:571) \n\tat org.apache.lucene.index.IndexWriter.close(IndexWriter.java:339) \n\tat TVBug.main(TVBug.java:16)",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    },
    {
        "key": "LUCENE-2573",
        "summary": "Tiered flushing of DWPTs by RAM with low/high water marks",
        "description": "Now that we have DocumentsWriterPerThreads we need to track total consumed RAM across all DWPTs.\n\nA flushing strategy idea that was discussed in LUCENE-2324 was to use a tiered approach:  \n- Flush the first DWPT at a low water mark (e.g. at 90% of allowed RAM)\n- Flush all DWPTs at a high water mark (e.g. at 110%)\n- Use linear steps in between high and low watermark:  E.g. when 5 DWPTs are used, flush at 90%, 95%, 100%, 105% and 110%.\n\nShould we allow the user to configure the low and high water mark values explicitly using total values (e.g. low water mark at 120MB, high water mark at 140MB)?  Or shall we keep for simplicity the single setRAMBufferSizeMB() config method and use something like 90% and 110% for the water marks?",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3289",
        "summary": "FST should allow controlling how hard builder tries to share suffixes",
        "description": "Today we have a boolean option to the FST builder telling it whether\nit should share suffixes.\n\nIf you turn this off, building is much faster, uses much less RAM, and\nthe resulting FST is a prefix trie.  But, the FST is larger than it\nneeds to be.  When it's on, the builder maintains a node hash holding\nevery node seen so far in the FST -- this uses up RAM and slows things\ndown.\n\nOn a dataset that Elmer (see java-user thread \"Autocompletion on large\nindex\" on Jul 6 2011) provided (thank you!), which is 1.32 M titles\navg 67.3 chars per title, building with suffix sharing on took 22.5\nseconds, required 1.25 GB heap, and produced 91.6 MB FST.  With suffix\nsharing off, it was 8.2 seconds, 450 MB heap and 129 MB FST.\n\nI think we should allow this boolean to be shade-of-gray instead:\nusually, how well suffixes can share is a function of how far they are\nfrom the end of the string, so, by adding a tunable N to only share\nwhen suffix length < N, we can let caller make reasonable tradeoffs. \n",
        "label": "NUG",
        "classified": "RFE",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-646",
        "summary": "[PATCH] fix various small issues with the \"getting started\" demo pages",
        "description": "\nThis patch contains numerous small fixes for the \"getting started\"\npages on the Lucene Java web site.  Here are the rough fixes:\n\n  * To results.jsp:\n\n    - changed StopAnalyzer -> StandardAnalyzer\n\n    - changed references of \"url\" to \"path\" (field \"url\" is never set\n      and was therefore always null)\n\n    - remove prefix of \"../webapps\" from path so clicking through works\n\n  * Fixed typos, grammar and other cosmetic things.\n\n  * Modernized some things that have changed with time (names of JAR\n    files, which languages have analyzers, etc.)\n\n  * Added outbound links to Javadocs, Wiki, Lucene static web site,\n    external sites, when appropriate.\n\n  * Removed exact version of Tomcat for the demo web app (I think all\n    recent versions of Tomcat will work as described)\n\n  * Other small changes...\n\nNet/net I think this is an improved version of what's available on the\nsite today.",
        "label": "NUG",
        "classified": "DOCUMENTATION",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-3639",
        "summary": "Add test case support for shard searching",
        "description": "New test case that helps stress test the APIs to support sharding....",
        "label": "NUG",
        "classified": "TEST",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-2354",
        "summary": "Convert NumericUtils and NumericTokenStream to use BytesRef instead of Strings/char[]",
        "description": "After LUCENE-2302, we should use TermToBytesRefAttribute to index using NumericTokenStream. This also should convert the whole NumericUtils to use BytesRef when converting numerics.",
        "label": "NUG",
        "classified": "IMPROVEMENT",
        "type": "IMPROVEMENT"
    },
    {
        "key": "LUCENE-1903",
        "summary": "Incorrect ShingleFilter behavior when outputUnigrams == false",
        "description": "ShingleFilter isn't working as expected when outputUnigrams == false. In particular, it is outputting unigrams at least some of the time when outputUnigrams==false.\n\nI'll attach a patch to ShingleFilterTest.java that adds some test cases that demonstrate the problem.\n\nI haven't checked this, but I hypothesize that the behavior for outputUnigrams == false got changed when the class was upgraded to the new TokenStream API?",
        "label": "BUG",
        "classified": "BUG",
        "type": "BUG"
    }
]